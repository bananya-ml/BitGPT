INTRODUCTION
Molecular spectral line column densities are fundamental
 to the study of the physical and chemical conditions
within dense molecular clouds. Chemical composition,
molecular isomer and isotopomer ratios, molecular hydrogen
 column densities, and molecular volume densities
 are all based on a measure of the molecular column
density. Past reviews and tutorials on this subject, including
 Genzel (1991), Evans et al. (1991), Evans (1999),
and Goldsmith & Langer (1999), along with spectroscopic
 textbooks such as Townes & Schawlow (1975),
Gordy & Cook (1984), and Draine (2011) have provided
an excellent basis upon which one can derive the molecular
 spectral line column density for a variety of dense
molecular cloud environments. The intent of this tutorial
is to provide students and scientists a general single reference
 point for the calculation of the molecular spectral
line column density.
We have organized the document such that some basic
background information is first provided to allow a contextural
 foundation to be lain for further calculations.
This foundation includes a basic understanding of radiative
 transfer and statistical equilibrium (Sections 2 and
jmangum@nrao.edu
yshirley@as.arizona.edu
3), molecular degeneracy (Sections 5 and 6), partition
functions (Section 7), line strength (Sections 8 and 9),
and hyperfine structure (Section 10). The derivation of
the most general form of the molecular spectral line column
 density is presented in Section 4. We also explore
a number of commonly-used practical approximations to
the calculation of the molecular spectral line column density
 in Section 11. As the calculation of the molecular
spectral line column density normally assumes constant
excitation temperature, we address the consequences of
this assumption when non-LTE conditions are present
in Section 12. We also summarize non-LTE approaches
to the calculation of molecular cloud volume density, kinetic
 temperature, and molecular column density in Section
 13.
Molecular cloud structure and its relationship to the
spatial resolution of a measurement system affects the
derivation of molecular spectral line column density. To
quantify these effects we address the distinction between
beam- and source-averaged column density in Section 14.
As worked examples are often illustrative for many astrophysical
 calculations, we provide step-by-step derivations
 of the molecular column density for several representative
 molecules; C18O, C17O, N2H+, NH3, and
H2CO in Section 15. Appendices provide ancillary in2

Mangum & Shirley
formation on some subtleties often encountered when
calculating molecular spectral line column density, including
 line profile functions (Appendix A), conversion
between integrated flux and brightness temperature (Appendix
 B), the calculation of the uncertainty associated
with an integrated intensity measurement (Appendix C),
the calculation of spectral line optical depth using hyperfine
 or isotopologue measurements (Appendix D), the
calculation of the kinetic temperature from a symmetric
 molecule excitation temperature measurement (Appendix
 E), and relative hyperfine intensity calculations
for NH3 (Appendix F).
2. RADIATIVE AND COLLISIONAL EXCITATION
OF MOLECULES
When the energy levels of a molecule are in statistical
equilibrium, the rate of transitions populating a given
energy level is balanced by the rate of transitions which
depopulate that energy level. For a molecule with multiple
 energy levels statistical equilibrium can be written
as:
ni
X
j
Rij =
X
j
njRji,
(1)
where ni and nj are the populations of the energy levels i
and j and Rij and Rji are transition rates between levels
i and j. The transition rates contain contributions from:
• Spontaneous radiative excitation (Aij)
• Stimulated radiative excitation and de-excitation
(Rij ≡niBij
R ∞
0
Jνφij(ν)dν)
• Collisional
excitation
and
de-excitation
(ncolliderCij)
where φν(ν) is the line profile function and Jν is defined
as the integral of the specific intensity Iν over the source
of emission:
Jν ≡1
4π
Z
IνdΩ.
(2)
Our statistical equilibrium equation then becomes:
ni
"X
j

ncolliderCij + Bij
Z ∞
0
Jνφij(ν)dν

+
X
j<i
Aij
#
=
X
j
nj

ncolliderCij + Bji
Z ∞
0
Jνφji(ν)dν

+
X
j>i
njAji.
(3)
For a two-level system with i defined as the lower energy
 level l and j defined as the upper energy level u,
P
j<i Aij = 0 and the statistical equilibrium equation
(Equation 3) becomes:
nl

ncolliderClu + Blu
Z ∞
0
Jνφlu(ν)dν

=
nu

ncolliderCul + Bul
Z ∞
0
Jνφul(ν)dν + Aul

.
(4)
As hydrogen (H) is the most abundant atom in the interstellar
 medium, and in dense molecular clouds most
of the H is in molecular form (H2), ncollider is usually
assumed to be n(H2).
At this point we can derive the Einstein relations Aul,
Bul, and Blu by considering only radiative excitation
(Clu = Cul = 0) and complete redistribution over the
line profile (φul(ν) = φlu(ν)).
Physically, this means
that emitted and absorbed photons are completely independent.
 Equation 4 then becomes:
nlBlu
Z ∞
0
Jνφlu(ν) = nuBul
Z ∞
0
Jνφul(ν) + nuAul
Z ∞
0
[nlBluJνφlu(ν)] dν =
Z ∞
0
[nuBulJνφlu(ν) + nuAul] dν
nlBluJνφlu = nuBulJνφlu + nuAul.
(5)
For a system in thermal equilibrium, the relative level
populations follow the Boltzmann distribution:
nu
nl
≡gu
gl
exp

−hν
kT

,
(6)
and the radiation field Jν is described by the Planck
Function Bν(T ):
Bν(T ) ≡2hν3
c2

exp
 hν
kT

−1
−1
.
(7)
Substituting Equations 6 and 7 into Equation 5 (which
eliminates the line profile function φlu) yields, after some
rearrangement:
 c2
2hν3 Aul −gl
gu
Blu
 
exp
 hν
kT

−1

= gl
gu
Blu + Bul,
(8)
which implies that:
glBlu = guBul
(9)
Aul = 2hν3
c2 Bul.
(10)
For dipole emission, the spontaneous emission coefficient
Aul can be written in terms of the dipole matrix element
|µlu|2 as:
Aul ≡64π4ν3
3hc3 |µlu|2.
(11)
3. RADIATIVE TRANSFER
The radiative transfer equation, ignoring scattering
processes (such as those involving electrons or dust) is
defined as follows (see Spitzer (1978) or Draine (2011)
for details):
dIν
ds = −κνIν + jν
(12)
How to Calculate Molecular Column Density
3
where
s ≡Path of propagation along the line of sight
Iν ≡Specific Intensity
κν ≡Absorption Coefficient
= hν
4π (nlBlu −nuBul) φν
(13)
=
c2
8πν2
gu
gl
nlAul

1 −glnu
gunl

φν
(14)
jν ≡Emission Coefficient
= hν
4π Aulnu,
(15)
Since we generally do not know what the propagation
path is for our measured radiation it is convenient to
change independent variables from pathlength s to “optical
 depth” τν, which is defined as:
dτν ≡κνds,
(16)
where we use the convention adopted by Draine (2011)1
that the radiation propagates in the direction of increasing
 optical depth. Switching variables from s to τν in
our radiative transfer equation (Equation 12) results in
the following radiative transfer equation:
dIν = Sνdτν −Iνdτν,
(17)
where we define the Source Function Sν:
Sν ≡jν
κν
.
(18)
By multiplying both sides of Equation 17 by the “integrating
 factor” eτν, we can integrate the radiative transfer
 equation from a starting point where τν = 0 and
Iν = Iν(0) to find that:
eτν (dIν + Iνdτν) = eτνSνdτν
eτνIν −Iν(0) =
Z τ ′
0
Sνdτ ′
Iν = Iν(0)e−τν +
Z τ ′
0
exp [−(τν −τ′)] Sνdτ ′. (19)
Equation 19 is a completely general solution to the
equation of radiative transfer (again, assuming that scattering
 is neglected).
It defines the intensity measured
by the observer (Iν) as the sum of the background intensity
 (Iν(0)) attenuated by the interstellar medium
(exp (−τν)) plus the integrated emission (Sνdτ ′) attenuated
 by the effective absorption due to the interstellar
medium between the point of emission and the observer
{exp [−(τν −τ ′)]}.
For an infinitely large medium the radiation field would
be defined as blackbody: Iν = Bν. We further assume
that the medium through which the radiation is traveling
is uniform at an excitation temperature Tex, defined as:
Tex =
hν/k
ln

nl gu
nu gl
,
(20)
1 Draine (2011) points out that Spitzer (1978) uses the opposite
convention, that radiation propagates in the direction of decreasing
optical depth.
where n is the density (cm−3) in the upper (u) or lower (l)
energy level for a transition with frequency ν. The source
function Sν is then equivalent to the Planck Function at
temperature Tex (Equation 7): Sν = Bν(Tex). This condition
 is sometimes referred to as “local thermodynamic
equilibrium” (LTE). Equation 19 becomes:
Iν = Iν(0)e−τν +
Z τ ′
0
exp [−(τν −τ ′)] Bν(Tex)dτ ′. (21)
If we further assume that Tex is a constant, Equation 21
becomes:
Iν = Iν(0) exp(−τν) + Bν(Tex) [1 −exp(−τν)] .
(22)
Molecular spectral line measurements involve differencing
 the measured intensity toward a reference position
which contains only background intensity from that measured
 towards a molecular line source position:
∆Iν ≡Iν −Iν(0)
= Iν(0) exp(−τν) + Bν(Tex) [1 −exp(−τν)] −Iν(0)
= [Bν(Tex) −Bν(Tbg)] [1 −exp(−τν)] .
(23)
In many cases the specific intensity Iν is replaced by
the Rayleigh-Jeans Equivalent Temperature, which is the
equivalent temperature of a black body at temperature
T:
Jν(T ) ≡
hν
k
exp
  hν
kT

−1.
(24)
If we further define the Radiation Temperature TR as
follows:
TR ≡
c2
2kν2 ∆Iν,
(25)
we can relate Bν(T ) and Jν(T ) as follows:
c2
2kν2 Bν(T ) = Jν(T ).
(26)
We can write our radiative transfer equation in a form
which involves the observable Source Radiation Temperature
 TR derived from a differencing measurement:
TR = f [Jν(Tex) −Jν(Tbg)] [1 −exp(−τν)] ,
(27)
where we have introduced an extra factor f which is
the fraction of the spatial resolution of the measurement
filled by the source (sometimes called the “filling factor”).
See Ulich & Haas (1976) for a complete derivation of the
source radiation temperature for the case of a single antenna
 position switched measurement.
4. COLUMN DENSITY
In order to derive physical conditions in the interstellar
 medium it is often useful to measure the number of
molecules per unit area along the line of sight.
This
quantity, called the “column density”, is basically a firststep
 to deriving basic physical quantities such as spatial
density, molecular abundance, and kinetic temperature.
Using the two-energy level system defined above, we can
express the column density as the number of molecules
in energy level u integrated over the pathlength ds:
Nu ≡
Z
nuds.
(28)
4
Mangum & Shirley
Since we want to use our molecular spectral line measurements
 to calculate the molecular column density,
which will ultimately involve the radiative transfer properties
 of the molecular spectral line measured, we can use
the definition of the optical depth (Equation 16), the definition
 of the absorption coefficient κ (Equation 14), the
Boltzmann equation for statistical equilibrium (Equation
 6), the definition of the spontaneous emission coefficient
 Aul (Equation 11), and our definition of the column
 density (Equation 28) to relate τν to the number of
molecules in the upper energy state Nu:
τν =
c2
8πν2
gu
gl
Aulφν
Z
ds′nl(s′)

1 −glnu(s′)
gunl(s′)

=
c2
8πν2
gu
gl
AulφνNl

1 −glNu
guNl

=
c2
8πν2

exp
 hν
kT

−1

AulφνNu
= 8π3ν|µlu|2
3hc

exp
 hν
kT

−1

φνNu
Z
τνdν = 8π3ν|µlu|2
3hc

exp
 hν
kT

−1

Nu,
(29)
where in the last step we have integrated over the line
profile such that
R
φν = 1. Rearranging and converting
our frequency axis to velocity ( dν
ν = dv
c ) in Equation 29,
we get an expression for the column density of molecules
in the upper transition state (Nu):
Nu =
3h
8π3|µlu|2

exp
 hν
kT

−1
−1 Z
τνdv.
(30)
At this point we have our basic equation for the number
of molecules in the upper energy state u of our two-level
system. In order to relate this to the total molecular column
 density as measured by the intensity of a transition
at frequency ν, we need to relate the number of molecules
in the upper energy level u (Nu) to the total population of
all energy levels in the molecule Ntot. Assuming detailed
balance at a constant temperature defined by the excitation
 temperature Tex, we can relate these two quantities
as follows:
Ntot
Nu
= Qrot
gu
exp
 Eu
kTex

,
(31)
where we have introduced the “rotational partition function”
 Qrot, a quantity that represents a statistical sum
over all rotational energy levels in the molecule (see Section
 7) and gu, the degeneracy of the energy level u.
Substituting for Nu in Equation 31, the total molecular
column density becomes:
Ntot =
3h
8π3|µlu|2
Qrot
gu
exp
 Eu
kTex

×

exp
 hν
kTex

−1
−1 Z
τνdv.
(32)
In the following we show how to calculate the level degeneracy
 gu (Section 5), the rotational partition function
Qrot ≡P
i gi exp
 −Ei
kT

(Section 7), the dipole matrix
element |µlu|2 and associated line strength S and dipole
moment µ (such that |µjk|2 ≡Sµ2; Section 8). For absorption
 lines where the integral of the optical depth over
velocity may be derived from a spectrum, Equation 32
may be used directly to determine the total column density.
 For emission lines, the integral over optical depth
is typically converted to an integrated intensity
R
TRdv
(see Section 11). We derive several commonly-used approximations
 to Equation 32, including optically thin,
optically thick, and the Rayleigh-Jeans approximation
in Section 11. We also evaluate the limitations of the
common assumption that the molecular excitation temperature
 is constant (Section 12), summarize non-LTE
models of the molecular column density (Section 13), and
the distinction between beam- and source-averaged column
 density (Section 14). We then close this discussion
of molecular column density by working through several
example calculations (Section 15). We also discuss some
minor issues related to the assumed line profile function
(Appendix A), the relationship between integrated fluxes
and brightness temperatures (Appendix B), and the uncertainty
 associated with an integrated intensity measurement
 (Appendix C) in the appendices. In a calculation
 which utilizes the column density calculation formalism
 presented below, Appendix E describes the standard
three-level model for low-temperature NH3 excitation often
 used to derive the kinetic temperature from measurements
 of the (1,1) and (2,2) inversion transitions of that
molecule.
5. DEGENERACIES
For rotational molecular transitions the total degeneracy
 for an an energy level of a transition is given by the
product of rotational (gJ and gK) and spin (gI) degeneracies:

gu ≡gJgKgI.
(33)
In the following we derive the expressions for these three
contributions to the degeneracy of a molecular energy
level.
5.1. Rotational Degeneracy (gJ)
The rotational degeneracy due to the projection of the
angular momentum on the spatial axis z, gJ, exists in all
molecules and is given by:
gJ = 2Ju + 1.
(34)
5.2. K Degeneracy (gK)
The K degeneracy (gK) describes the degeneracy associated
 with the internal quantum number K in symmetric
and asymmetric top molecules due to projections of the
total angular momentum onto a molecular axis. Because
of the opposite symmetry of the doubly-degenerate levels
for which K ̸= 0, gK is defined as follows:
gK = 1 for K=0 and all linear and asymmetric top
molecules,
(35)
= 2 for K̸= 0 in symmetric top molecules.
(36)
K-level doubling is due to the asymmetry in the molecule
about the molecular axes and removes the K degeneracy
in asymmetric top molecules.
How to Calculate Molecular Column Density
5
5.3. Nuclear Spin Degeneracy (gI)
The nuclear spin degeneracy gI takes account of the
statistical weights associated with identical nuclei in a
nonlinear molecule with symmetry (which most nonlinear
 molecules have). For a molecule with no symmetry
or hyperfine splitting, each rotational level will have a
nuclear spin degeneracy given by:
gn =
Y
i
(2Ii + 1) = (2I + 1)σ
(37)
gI ≡gnuclear
gn
,
(38)
where Ii represents the spin of the ith nucleus, σ is the
number of identical nuclei, and gnuclear is given in Table
 1 for two of the largest classes of molecules found in
the interstellar medium medium: those with two (C2v
symmetry2) and three (C3v symmetry) identical nuclei.
Symmetry and hyperfine splitting changes gn for all practical
 cases. Hyperfine splitting is covered elsewhere in
this document, while symmetry considerations are wellcovered
 by Gordy & Cook (1984) (Chapter III.4). See
also Turner (1991) for a general discussion applicable to
the high-temperature limit.
Keep in mind that if you
are only interested in studying one symmetry state (i.e.
the para species) of a molecule, gI = 1. In the following
we list some examples of gnuclear calculations for several
molecules.
5.3.1. H2CO and c-C3H2
Formaldehyde (H2CO) is a (slightly; κ = −0.96; see
Equation 45) prolate (see Section 6) asymmetric top
molecule, while Cyclopropenylidene (c-C3H2) is a cyclic
(slightly; κ = +0.69) oblate (see Section 6) asymmetric
 top molecule.
Both have two opposing identical
 H (spin= 1
2) nuclei. The coordinate wavefunction is
symmetric/asymmetric for K−1 even/odd, respectively.
Therefore, from the two identical spin 1
2 nuclei cases in
Table 1:
gnuclear = (2I + 1)I = 1 for K−1 even,
(39)
= (2I + 1)(I + 1) = 3 for K−1 odd.
(40)
5.3.2. NH3 and CH3CN
Ammonia (NH3) and Acetonitrile (CH3CN) are symmetric
 top molecules with three opposing identical H
(spin= 1
2) nuclei. Therefore, from the three identical spin
1
2 nuclei cases in Table 1:
gnuclear = 1
3(2I + 1)(4I2 + 4I + 3) = 4 for K=3n,
(41)
= 1
3(2I + 1)(4I2 + 4I) = 2 for K̸=3n.
(42)
5.3.3. c–C3H and SO2
2 The number of symmetry states for a molecule are determined
 by the number of configurations within which the wavefunction
 of the molecule is unchanged with a rotation of π
about a symmetry axis and a reflection of π through that
symmetry plane.
For a nice tutorial on molecular symmetry
see Stefan Immel’s extensive discussion at http://csi.chemie.tudarmstadt.de/ak/immel/tutorials/symmetry/index7.html

Cyclopropynylidyne (c–C3H) is an oblate (κ = +0.17)
asymmetric top molecule with two opposing identical
carbon (spin=0) nuclei, while SO2 is a prolate (κ =
−0.94) asymmetric top molecule with two opposing identical
 oxygen (spin=0) nuclei. For both molecules the coordinate
 wavefunction is symmetric/asymmetric for K−1
even/odd, respectively. Therefore, from the two identical
spin 0 nuclei cases in Table 1:
gnuclear = (2I + 1)I = 0 for K−1 even,
(43)
= (2I + 1)(I + 1) = 1 for K−1 odd.
(44)
This indicates that half of the levels are missing (those
for which K−1 is even).
6. SYMMETRY CONSIDERATIONS FOR
ASYMMETRIC ROTOR MOLECULES
The symmetry of the total wavefunction ψ for a given
rotational transition is determined by the product of the
coordinate wavefunction ψeψvψr and the nuclear spin
wavefunction ψn. It is common to refer to a symmetric
 nuclear spin state as “ortho” and an anti-symmetric
nuclear spin state as “para”. These wavefunctions are of
two types: Fermions and Bosons. Table 2 lists the symmetries
 for the various wavefunctions in both cases for
exchange of two identical nuclei.
Since an asymmetric
 top can be thought of as belonging to one of two
limiting cases, prolate or oblate symmetric, we need to
consider these two cases in the context of the coordinate
wavefunction ψeψvψr.
Limiting Prolate:: We consider the symmetry of the
coordinate wavefunctions with respect to rotation
of 180◦about the axis of least moment of inertia.
Since the coordinate wavefunction ψeψvψr depends
on this rotation angle ξ as exp (±iK−1ξ), it is symmetric
 when K−1 is even and antisymmetric when
K−1 is odd. H2CO is a limiting prolate asymmetric
top molecule (though it is only slightly asymmetric).

Limiting Oblate:: We consider the symmetry of the coordinate
 wavefunctions with respect to rotation of
180◦about the axis of greatest moment of inertia.
Since the coordinate wavefunction ψeψvψr depends
on this rotation angle ξ as exp (±iK+1ξ), it is symmetric
 when K+1 is even and antisymmetric when
K+1 is odd. NH2D is a limiting oblate asymmetric
top molecule.
The level of asymmetry in molecules is often described
in terms of Ray’s asymmetry parameter κ (Ray 1932):
κ ≡2B −A −C
A −C
,
(45)
where A, B, and C are constants which represent the
three principle moments of inertia for an asymmetric rotor
 molecule (see Gordy & Cook (1984) for more information),
 usually expressed in megahertz (MHz).
The
limits to κ are:
• B = A: κ = +1 and the molecule is an oblate symmetric
 rotor.
• B = C: κ = −1 and the molecule is a prolate symmetric
 rotor.
6
Mangum & Shirley
Table 1
Nuclear Statistical Weight Factors for C2v and C3v Moleculesa
Identical Nuclei (σ)b
Spin
J
Kc
gnuclear
2
1
2, 3
2 , . . .
Any
Even
(2I + 1)I
2
1
2, 3
2 , . . .
Any
Odd
(2I + 1)(I + 1)
2
0, 1, 2, . . .
Any
Odd
(2I + 1)(I + 1)
2
0, 1, 2, . . .
Any
Even
(2I + 1)I
3
Any
Even or Odd
3n, ̸= 0
1
3 (2I + 1)(4I2 + 4I + 3)
3
Any
Even or Odd
̸= 3n
1
3 (2I + 1)(4I2 + 4I)
a Derived from Gordy & Cook (1984), Table 3.2 and 3.3.
b gI ≡gnuclear
(2I+1)σ
c Where n is an integer.
Table 2
Eigenfunction Symmetries for Exchange of Two Identical Nucleia
Wavefunctionb
Statistics
Spin (I)
Total (ψ)
Coordinate (ψeψvψr)
Spin (ψn)
gnuclear
Fermi
1
2, 3
2 , . . .
A
S
A
(2I + 1)I
Fermi
1
2, 3
2 , . . .
A
A
S
(2I + 1)(I + 1)
Bose
0, 1, 2, . . .
S
S
S
(2I + 1)(I + 1)
Bose
0, 1, 2, . . .
S
A
A
(2I + 1)I
a From Gordy & Cook (1984), Table 3.2.
b Key: A = Asymmetric; S = Symmetric. For nuclear spin states asymmetric = “para”
while symmetric = “ortho”.
Taking a more general example, the rotational angular
momentum constants for H2CO are A = 281970.37MHz,
B = 38835.42558MHz, and C = 34005.73031MHz.
Equation 45 then yields κ ≃−0.961, which means that
H2CO is nearly a prolate symmetric rotor.
7. ROTATIONAL PARTITION FUNCTIONS (QROT )
For a parcel of gas that exchanges energy with the ambient
 medium, statistical mechanics states that the partition
 function Q which describes the relative population
of states in the gas is given by:
Q =
X
i
gi exp

−Ei
kT

.
(46)
Following Gordy & Cook (1984) (chapter 3, section 3),
the partition function for molecules in a gaseous state
is a function of the electronic, vibrational, rotational,
and nuclear spin states of the molecule. Assuming that
there are no interactions between these states, the total
partition function for the molecule can be expressed as
the product of the partition functions of these four types
of energy states:
Q = QeQvQrQn.
(47)
The ground electronic state of most molecules observed
in the interstellar medium are stable,
1Σ electronic
states, although there are a few notable exceptions (i.e.
OH 2Π, SO
3Σ, CN
2Σ, etc.).
For these molecules
Qe = 1.
For simplicity we will also assume that the
molecules are in their ground vibrational state (Qv = 1).
This leaves us with rotational and nuclear partition functions
 comprising the total molecular partition function,
which we can write as:
Qrot ≡QrQn
=
X
J,K,I
gJgKgI exp

−EJK
kT

,
(48)
where the degeneracies gJ, gK, and gI are described in
Section 5.1, Section 5.2, Section 5.3, respectively. See
Turner (1991) for a nice general discussion listing expressions
 for Qrot in the high-temperature limit for a variety
of molecules. In the following we derive the rotational
partition function Qrot for linear, symmetric, and asymmetric
 rotor molecules.
7.1. Linear Molecule Rotational Partition Function
For linear molecules:
• gJ = 2J + 1 (Section 5.1)
• gK = 1 (Section 5.2)
• gI = 1 (since linear molecules with allowed electric
dipole transitions are polar and have no center of
symmetry)
which implies that Equation 48 becomes:
Qrot =
∞
X
J=0
(2J + 1) exp

−EJ
kT

.
(49)
The energy levels for a linear molecule can be described
by a multi-term expansion as a function of J(J + 1)
(Jennings et al. 1987):
EJ = h(B0J(J + 1) −D0J2(J + 1)2 + H0J3(J + 1)3
−L0J4(J + 1)4 + M0J5(J + 1)5 + ...),
(50)
How to Calculate Molecular Column Density
7
10
20
30
40
TK (K)
0
5
10
15
20
Qrot (unitless)
12CO
Linear Molecule Rotational Partition Function
Qrot(exact)
0
2
4
6
8
10
Qfracdif
rot
(percent)
Qfracdif
rot
Gordy & Cook
Qfracdif
rot
McDowell
Figure 1. Rotational partition function calculations for CO using
the lowest 51 levels of the molecule. Shown are Qrot (Equation 49;
vertical scale on left) and the percentage differences between Qrot
and the expansions of Equation 49 provided by Equation 52 (using
terms to third-order in hB0
kT ) and Equation 53 (vertical scale on
right).
where B0 is the rigid rotor rotation constant and D0, H0,
L0, and M0 are the first- through fourth-order centrifugal
distortion constants for the molecule, respectively, all in
megahertz (MHz). Using the rigid rotor approximation
to the level energies, thus ignoring all terms other than
those linear in J(J+1), Equation 50 becomes:
EJ = hB0J(J + 1).
(51)
This allows us to approximate Qrot for diatomic linear
molecules as follows:
Qrot ≃
∞
X
J=0
(2J + 1) exp

−hB0J(J + 1)
kT

≃kT
hB0
+ 1
3 + 1
15
hB0
kT

+
4
315
hB0
kT
2
+
1
315
hB0
kT
3
+ . . .
(52)
(from Gordy & Cook (1984) Chapter 3, Equation 3.64
and McDowell (1988), where application of the EulerMacLaurin
 summation formula has been used). This approximate
 form is good to < 1% for T > 2 K (Figure 1).
This level of accuracy is maintained even if one includes
only the first two terms in Equation 52.
An alternate approximation for linear polyatomic
molecules is derived by McDowell (1988):
Qrot ≃kT
hB0
exp
hB0
3kT

,
(53)
which is reported to be good to 0.01% for
hB0
kT
≲0.2
(T > 13.7 K for CO) and is good to better than 1% for
T > 3.5 K (Figure 1). Note that Equation 53 reduces to
Equation 52 when expanded using a Taylor Series.
7.2. Symmetric and Slightly-Asymmetric Rotor
Molecule Rotational Partition Function
For symmetric and asymmetric rotor molecules:
• gJ = 2J + 1 (Section 5.1)
• gK = 1 for K = 0 and 2 for K ̸= 0 in symmetric
rotors (Section 5.2)
• gK = 1 for all K in asymmetric rotors
• gI = gnuclear
(2I+1)σ (See Table 1)
which implies that Equation 48 becomes:
Qrot =
∞
X
J=0
J
X
K=−J
gKgI(2J + 1) exp

−EJK
kT

.
(54)
Like the energy levels for a linear molecule, the energy
 levels for a symmetric or slightly-asymmetric3 rotor
molecule can be described by a multi-term expansion as
a function of J(J + 1):
EJK = h(B0J(J + 1) + s0K2 + DjJ2(J + 1)2
+ DjkJ(J + 1)K2 + DkK4 + HjkkJ(J + 1)K4
+ HjjkJ2(J + 1)2K2 + Hj6J3(J + 1)3
+ Hk6K6 + ...),
(55)
where s0 ≡A0 −B0 for a prolate symmetric
rotor
molecule and s0 ≡C0 −B0 for an oblate symmetric
rotor, and the other constants represent various terms
in the centrifugal distortion of the molecule.
All constants
 are in megahertz (MHz). For rigid symmetric or
slightly-asymmetric rotor molecules, using the rigid rotor
approximation to the level energies:
EJK = h
 B0J(J + 1) + s0K2
.
(56)
From McDowell (1990) we can then approximate Qrot
for a symmetric or slightly-asymmetric rotor molecule as
follows:
Qrot ≃
√mπ
σ
exp
hB0(4 −m)
12kT
  kT
hB0
3/2
×
"
1 + 1
90
hB0(1 −m)
kT
2
+ ...
#
,
(57)
where
m =B0
A0
for a prolate symmetric rotor molecule,
=B0
C0
for an oblate symmetric rotor molecule,
= B2
0
A0C0
for a slightly-asymmetric rotor molecule
(see Herzberg (1945)).
3 Slightly-asymmetric rotor molecules are defined such that B0 ≃
C0. In Equation 55 replace B with √B0C0.
8
Mangum & Shirley
10
20
30
40
TK (K)
0
1
2
3
4
5
6
Qrot (unitless)
14NH3
Symmetric Rotor Molecule Rotational Partition Function
Qrot(exact)
Qrot(approx) McDowell
Qrot(approx) Gordy & Cook
0
20
40
60
80
100
Qfracdif
rot
(percent)
Qfracdif
rot
McDowell
Qfracdif
rot
Gordy & Cook
Figure 2. Rotational partition function calculations for NH3 using
 the lowest 51 levels of the molecule. Shown are the exact summation
 for Qrot (Equation 54) and the approximate forms given
by Equations 57 and 58 (vertical scale on left). Shown also are the
fractional percentage differences (vertical scale on right), given by
100 ∗Qrot(exact)−Qrot(approx)
Qrot(exact)
, of these two approximations relative
 to Qrot (Equation 54).
If we expand the exponential and take only up to first
order terms in the expansion in Equation 57:
Qrot ≃
√mπ
σ

1 + hB0(4 −m)
12kT
+ ...
  kT
hB0
3/2
≃
√mπ
σ
 kT
hB0
3/2
≃1
σ
"
mπ
 kT
hB0
3#1/2
,
(58)
which is the equation for symmetric rotor partition functions
 quoted by Gordy & Cook (1984) (Chapter 3, Equations
 3.68 and 3.69). Figure 2 compares Qrot calculated
using Equation 54 and the approximate forms given by
Equation 57 and Equation 58 for NH3. In this example
 Equation 57 is good to ≲20% for TK > 10 K and
≲0.25% for TK > 50 K, while Equation 58 is much less
accurate, good to ≲40% for TK > 10 K and ≲6% for
TK > 50 K.
8. DIPOLE MOMENT MATRIX ELEMENTS
(|µJK|2) AND LINE STRENGTHS (S)
The following discussion is derived from the excellent
 discussion given in Gordy & Cook (1984), Chapter
II.6. A detailed discussion of line strengths for diatomic
molecules can be found in Tatum (1986). Spectral transitions
 are induced by interaction of the electric or magnetic
 components of the radiation field in space with the
electric or magnetic dipole components fixed in the rotating
 molecule. The strength of this interaction is called
the line strength S. The matrix elements of the dipole
moment with reference to the space-fixed axes (X,Y,Z)
for the rotational eigenfunctions ψr can be written as
follows:
Z
ψ∗
rµF ψ′
rdτ =
X
g
µg
Z
ψ∗
rΦF gψ′
rdτ,
(59)
where ΦF g is the direction cosine between the space-fixed
axes F=(X,Y,Z) and the molecule-fixed axes g=(x,y,z).
The matrix elements required to calculate line strengths
for linear and symmetric top molecules are known and
can be evaluated in a straightforward manner, but these
calculations are rather tedious because of the complex
form of the eigenfunction. Using commutation rules between
 the angular momentum operators and the direction
 cosines ΦF g, Cross et al. (1944) derive the nonvanishing
 direction cosine matrix elements in the symmetric
top representation (J,K,M):
⟨J, K, M|ΦF g|J′, K′, M ′⟩= ⟨J|ΦF g|J′⟩
× ⟨J, K|ΦF g|J′, K′⟩⟨J, M|ΦF g|J′, M ′⟩.
(60)
where M is the projection of the total angular momentum
 J on a fixed space axis. There are 2J+1 projections
of M allowed. The dipole moment matrix element |µlu|2
can then be written as:
|µlu|2 =
X
F =X,Y,Z
X
M′
|⟨J, K, M|µF |J′, K′, M ′⟩|2,
(61)
where the sum over g = x, y, z is contained in the expression
 for µF (Equation 59). Table 3 lists the direction cosine
 matrix element factors in Equation 60 for symmetric
rotor and linear molecules. In the following we give examples
 of the use of the matrix elements in line strength
calculations
9. LINEAR AND SYMMETRIC ROTOR LINE
STRENGTHS
For all linear and most symmetric top molecules, the
permanent dipole moment of the molecule lies completely
along the axis of symmetry of the molecule (µ = µz).
This general rule is only violated for the extremely-rare
“accidentally symmetric top” molecule (where Ix = Iy).
For all practical cases, then, Equation 61 becomes:
|µlu|2 = µ2
X
F =X,Y,Z
X
M′
|⟨J, K, M|ΦF g|J′, K′, M ′⟩|2
= µ2S,
(62)
where we have defined the line strength S as:
S ≡
X
F =X,Y,Z
X
M′
|⟨J, K, M|ΦF g|J′, K′, M ′⟩|2.
(63)
9.1. (J, K) →(J −1, K) Transitions
Using the matrix element terms listed in the fourth
column of Table 3 with the definition of the direction
cosine matrix elements (Equation 60), we can write the
terms which make-up Equation 62 for the case (J, K) →
How to Calculate Molecular Column Density
9
Table 3
Direction Cosine Matrix Element Factorsa for Linearb and Symmetric Top Molecules
J′ Value
Matrix Element Term
J + 1
J
J −1
⟨J|ΦF g|J′⟩
n
4(J + 1) [(2J + 1)(2J + 3)]
1
2
o−1
[4J(J + 1)]−1
h
4J(4J2 + 1)
1
2
i−1
⟨J, K|ΦF z|J′, K⟩
2 (J + 1)2 −K2 1
2
2K
−2(J2 −K2)
1
2
⟨J, K|ΦF y|J′, K ± 1⟩= ∓i⟨J, K|ΦF x|J′, K ± 1⟩
∓[(J ± K + 1)(J ± K + 2)]
1
2
[J(J + 1) −K(K + 1)]
1
2
∓[(J ∓K)(J ∓K −1)]
1
2
⟨J, M|ΦZg|J′, M⟩
2 (J + 1)2 −M2 1
2
2M
−2(J2 −M2)
1
2
⟨J, M|ΦY g|J′, M ± 1⟩= ±i⟨J, M|ΦXg|J′, M ± 1⟩
∓[(J ± M + 1)(J ± M + 2)]
1
2
[J(J + 1) −M(M + 1)]
1
2
∓[(J ∓M)(J ∓M −1)]
1
2
a Derived from Gordy & Cook (1984), Table 2.1, which is itself derived from Cross et al. (1944).
b For linear molecules, set K=0 in the terms listed.
(J −1, K)4 as follows:
|µlu|2 = µ2
 (J2 −K2)1/2
J(4J2 −1)1/2
 (
(J2 −M 2)1/2
+
i ± 1
2

[(J ∓M)(J ∓M −1)]1/2
)
.
(64)
Applying these terms to the dipole moment matrix element
 (Equation 61, which simply entails squaring each
of the three terms in Equation 64 and expanding the ±
terms) and using the definition of |µlu|2 (Equation 63):
S =
 (J2 −K2)
J2(4J2 −1)
 "
(J2 −M 2)
+ 1
2 [(J −M)(J −M −1) + (J + M)(J + M −1)]
#
.
(65)
Reducing Equation 65 results in the following for a symmetric
 top transition (J, K) →(J −1, K):
S = J2 −K2
J(2J + 1) for (J, K) →(J −1, K).
(66)
To derive the equation for a linear molecule transition
J →J −1, simply set K = 0 in Equation 66.
9.2. (J, K) →(J, K) Transitions
Using the matrix element terms listed in the fourth
column of Table 3 with the definition of the direction
cosine matrix elements (Equation 60), we can write the
terms which make-up Equation 62 for the case (J, K) →
(J, K)5 as follows:
|µlu|2 = µ2

2K
4J(J + 1)

×
n
2M ± 2 [J(J + 1) −M(M ± 1)]1/2o
.
(67)
Applying these terms to the dipole moment matrix element
 (Equation 61) and using the definition of |µlu|2
4 Also referred to as “P-branch transitions”.
5 Also referred to as “Q-branch transitions”.
(Section 8):
S =

K2
4J2(J + 1)2
 "
4M 2
+2 [J(J + 1) −M(M + 1) + J(J + 1) −M(M −1)]
#
.
(68)
Reducing Equation 68 results in the following for a symmetric
 top transition (J, K) →(J, K):
S =
K2
J(J + 1) for (J, K) →(J, K).
(69)
9.3. (J, K) →(J + 1, K) Transitions
Using the matrix element terms listed in the second
column of Table 3 with the definition of the direction
cosine matrix elements (Equation 60), we can write the
terms which make-up Equation 62 for the case (J, K) →
(J + 1, K)6 as follows:
|µlu|2 = µ2

(J + 1)2 −K21/2
(J + 1) [(2J + 1)(2J + 3)]1/2
×
(

(J + 1)2 −M 21/2
−
i ± 1
2

[(J ± M + 1)(J ± M + 2)]1/2
)
.
(70)
Applying these terms to the dipole moment matrix element
 (Equation 61, which simply entails squaring each
of the three terms in Equation 70 and expanding the ±
terms) and using the definition of |µlu|2 (Equation 63):
S =

(J + 1)2 −K21/2
(J + 1) [(2J + 1)(2J + 3)]1/2
(
(J + 1)2 −M 2
+ 1
2
"
(J + M + 1)(J + M + 2)
+ (J −M + 1)(J −M + 2)
#)
.
(71)
6 Also referred to as “R-branch transitions”.
10
Mangum & Shirley
Reducing Equation 71 results in the following for a symmetric
 top transition (J, K) →(J + 1, K):
S = (J + 1)2 −K2
(J + 1)(2J + 1) for (J, K) →(J + 1, K).
(72)
To derive the equation for a linear molecule transition
J →J + 1, simply set K = 0 in Equation 72.
10. HYPERFINE STRUCTURE AND RELATIVE
INTENSITIES
Hyperfine splitting in molecular spectra occurs when a
nucleus in the molecule has non-zero nuclear spin. Hyperfine
 splitting is commonly observed in molecules that
contain 1H (I = 1/2), 2D (I = 1), 13C (I = 1/2), 14N (I
= 1), 15N (I = 1/2), 17O (I = 5/2), and 33S (I = 3/2)
nuclei. For a molecule with a single coupling nucleus, the
vector addition of angular momenta is used to define a
new hyperfine quantum number, F, such that ⃗
F = ⃗
I + ⃗
J
is the total molecular angular momentum, where ⃗
I and
⃗
J are the nuclear spin and rotational angular momentum
of the molecule respectively (⃗
I and ⃗
J precess around ⃗
F).
The allowed scalar values of ⃗
F are given by
F = J + I, J + I −1, ..., |J −I| .
(73)
Selection rules stipulate that ∆F = 0, ±1 (but F = 0
cannot go to 0). For example, the 14N nucleus in HCN
is responsible for strong hyperfine coupling because the
spin of 14N is I = 1. Equation 73 shows that the J = 0
level remains unsplit (F = 1), the J = 1 level splits into a
triplet (F = 2, 1, 0), and the J = 2 level also splits into a
triplet (F = 3, 2, 1). The selection rule allows 3 hyperfine
transitions from J = 1 −0 and six hyperfine transitions
from J = 2 −1. Since I = 1 and the Clebsch-Gordon
series (Equation 73) terminates with F = |J −I|, all of
the levels with J > 2 will also be split into triplets.
The relative strengths can be calculated by using irreducible
 tensor methods (see Gordy & Cook (1984) Chapter
 15). We define the relative strength such that the
sum of the relative strength, Ri, of all transitions from
F ′ →F for a given J′ →J are equal to one:
X
F ′F
Ri(J′F ′ →JF) = 1.
(74)
The relative line strengths are calculated in terms of a
6 −j symbol,
Ri(J′F ′ →JF) = (2F + 1)(2F ′ + 1)
(2I + 1)

I F ′ J′
1
J
F
2
.
(75)
With the aid of 6 −j Tables (Edmonds 1960)7, and the
property that 6 −j symbols are invariant with permutation
 of the columns, we find the appropriate 6−j symbol
7 Many online calculation tools are available that will calculate
6j symbols. For example, see http://www.svengato.com/sixj.html.
for each transition:

a
b
c
1 c −1 b −1
2
=
s(s + 1)(s −2a −1)(s −2a)
(2b −1)2b(2b + 1)(2c −1)2c(2c + 1)

a
b
c
1 c −1 b
2
=
2(s + 1)(s −2a)(s −2b)(s −2c + 1)
2b(2b + 1)(2b + 2)(2c −1)2c(2c + 1)

a
b
c
1 c −1 b + 1
2
=
(s −2b −1)(s −2b)(s −2c + 1)(s −2c + 2)
(2b + 1)(2b + 2)(2b + 3)(2c −1)2c(2c + 1)

a b c
1 c b
2
=
[2b(b + 1) + 2c(c + 1) −2a(a + 1)]2
2b(2b + 1)(2b + 2)2c(2c + 1)(2c + 2) ,
(76)
where s = a + b + c. For example, in the case of the
J = 1 −0 F = 2 −1 transition of HC14N, the first 6 −j
symbol in Equation 76 should be used with a = I = 1,
b = F ′ = 2, and c = J′ = 1.
The formalism above may be generalized when multiple
 coupling nuclei are present. By extension, an arbitrary
 number, n, of coupling nuclei may be included
in the nested vector addition of angular momenta (i.e.
⃗
Fi = ⃗
J + ⃗
I1, ⃗
F2 = ⃗
F1 + ⃗
I2, · · ·
, ⃗
F = ⃗
Fn−1 + ⃗
In) and
the relative intensities can be calculated by multiplying
the relative strength equation n times with appropriate
quantum numbers for each step in the nested vector addition.
 For example, in the case of two coupling nuclei
with unequal strength, such as the outer (I1) and inner
(I2) 14N of N2H+, the nested coupling scheme ⃗
F1 = ⃗
J+⃗
I1
and ⃗
F = ⃗
F1 + ⃗
I2 is used. The relative strength of the
hyperfine transitions are then given by
Ri(J′F ′
1F ′ →JF1F) =
(2F ′
1 + 1)(2F1 + 1)(2F ′ + 1)(2F + 1)
(2I1 + 1)(2I2 + 1)
×

I1 F ′
1 J′
1
J
F1
2 
I2 F ′ F ′
1
1
F1
F
2
.
(77)
While we have specifically discussed hyperfine splitting
from nuclei with unequal coupling in this section, the addition
 of vector angular momenta in quantum mechanics
 is a general problem and the formalism above may
be extended to problems with equal coupling nuclei (i.e.
H2CO) or for fine structure splitting (i.e. in molecules
with electronic states with total electronic spin S > 0)
with an appropriate mapping of the quantum numbers.
We end this section by noting an important caveat
with regards the interpretation of the relative intensities
 of hyperfine transitions.
Anomalies between
observed
hyperfine
transition
intensities
and
those
predicted by the quantum mechanics described in
How to Calculate Molecular Column Density
11
this section have been observed (see Kwan & Scoville
(1974),
Guilloteau & Baudry (1981),
Walmsley et al.
(1982),
Stutzki et al.
(1984),
Stutzki & Winnewisser
(1985), Bachiller et al. (1997), Daniel et al. (2006), and
Hily-Blant et al. (2010) for examples). These anomalies
are likely due to spectral line overlap between hyperfine
transitions and can result in non-LTE hyperfine ratios.
11. APPROXIMATIONS TO THE COLUMN
DENSITY EQUATION
In the following we derive several commonly-used approximations
 to the column density Equation 32: Optically
 thin (τ ≪1), optically thin when in the RayleighJeans
 limit (hν ≪kTex), and optically thin when in the
Rayleigh-Jeans limit and negligible background emission
(Tbg ≪Tex).
11.1. Optically Thin Approximation
If we assume that τν ≪1, the radiative transfer equation
 (Equation 27) becomes:
TR = f [J(Tex) −J(Tbg)] τ,
(78)
and the column density equation (Equation 32) becomes:
N thin
tot
=

3h
8π3Sµ2Ri
  Qrot
gJgKgI

exp

Eu
kTex

exp

hν
kTex

−1
×
Z
TRdv
f (Jν(Tex) −Jν(Tbg)).
(79)
The Jν(Tex) −Jν(Tbg) term may be removed from the
integral because the Planck function does not vary substantially
 across the frequency extent of a typical spectral
line. For example, if we take the CO J = 1 −0 transition
 at 115 GHz, then for a spectral line with a full width
zero intensity of 200 MHz (corresponding to an extent of
520 km s−1), the fractional change in the Planck function
across the spectral line is less than 0.3% for all excitation
temperatures above the CMB. For most sources within
the Milky Way Galaxy, the extent of a spectral line is
an order of magnitude smaller and the corresponding
change in the Planck function across the transition is also
smaller. The fractional uncertainty in the Planck function
 increases as the frequency of the transition increases;
however, even at 1 THz, the fractional uncertainty is still
less than 3% for a 500 km/s wide transition. As a result,
the Jν(Tex) −Jν(Tbg) term is approximately constant in
all realistic cases and the integral term in Equation 79
reduces to just the integrated intensity of the spectral
line:
N thin
tot
=

3h
8π3Sµ2Ri
  Qrot
gJgKgI

exp

Eu
kTex

exp

hν
kTex

−1
×
1
(Jν(Tex) −Jν(Tbg))
Z TRdv
f
.
(80)
11.2. Optically Thin with Rayleigh-Jeans
Approximation
Assume that τ ≪1 and hν ≪kTex.
This reduces
the term in [ ] in Equation 32 to
hν
kTex , Jν(T ) to T , and
reduces the radiative transfer equation to that derived in
Equation 78. Equation 32 then reduces to
N thin+RJ
tot
=

3k
8π3νSµ2Ri
  Qrot
gJgKgI

exp
 Eu
kTex

×
Z
TRTexdv
f (Tex −Tbg).
(81)
We test the validity of these approximations by comparing

the ratio of Equation 80 (N thin
tot ) to Equation 81
(N thin+RJ
tot
) in Figure 3.
The column density calculated
 from Equation 80 is always less than the column
density calculated from Equation 81 in the RayleighJeans
 limit. Darker shading corresponds to worse agreement
 between the equations. For example, the RayleighJeans
 approximation is a good approximation (less than
5% disagreement between equations) for the low frequency
 (4.8 GHz) H2CO K-doublet transition for all excitation
 temperatures. The Rayleigh-Jeans approximation
is still a good approximation for the NH3 inversion transitions
 (e.g.˙
(1,1), (2,2), etc.) at 24 GHz with less than
10% disagreement between the equations for Tex > 5 K.
Rayleigh-Jeans failure is more apparent for transitions
at millimeter and shorter wavelengths. For instance, the
C18O J = 1 −0 line at 109.7 GHz has more than 15%
disagreement between the optically-thin and opticallythin
 plus Rayleigh-Jeans approximations for Tex < 9 K
that rapidly increases toward lower excitation temperatures.
 It is possible to use Equation 81 at submillimeter
wavelengths ν > 300 GHz if the excitation temperature
is large (i.e. less than 10% disagreement at 300 GHz if
Tex > 26 K); however, for most cases in dense regions
of molecular clouds where the tracer is sub-thermally
populated with low excitation temperatures, Equation 80
should be used.
11.3. Optically Thin with Rayleigh-Jeans
Approximation and Negligible Background
Assuming that the temperature of the background
source (i.e. the cosmic microwave background radiation)
is small in comparison to the molecular excitation temperature
 (Tbg ≪Tex), Equation 81 becomes:
N thin+RJ+noBG
tot
=

3k
8π3νSµ2Ri
  Qrot
gJgKgI

× exp
 Eu
kTex
 Z TRdv
f
.
(82)
We test when it is appropriate to use this approximation
 by comparing
the column density calculated
 with Equation 80 (N thin
tot ) versus Equation 82
(N thin+RJ+noBG
tot
). The ratio of these two equations is
given by N thin
tot /N thin+RJ+noBG
tot
= Jν(Tex)/[Jν(Tex) −
Jν(Tbg)]. Figure 3 shows contours of this ratio as a function
 of Tex and the transition frequency.
The general
trend is such that the thin+RJ+noBG approximation
is poor for low frequencies and for low Tex.
At first,
12
Mangum & Shirley
Figure 3.
In the top panel we compare the molecular column
 density calculated assuming optically-thin (Nthin
tot
; Equation
 80) and optically-thin within the Rayleigh-Jeans approximation
 (Nthin+RJ
tot
; Equation 81). In the bottom panel we show the
comparison between molecular column density calculated assuming
optically-thin and optically-thin within the Rayleigh-Jeans approximation
 and with the assumption of negligible background emission
(Nthin+RJ+noBG
tot
: Equation 82).
it seems counterintuitive that agreement between the
two approximations would be better at high frequencies
when failure of the Rayleigh-Jeans limit is more likely
to occur (see Section 11.2); however, ignoring the background
 term in Equation 82 compensates for RayleighJeans
 failure. For high frequency and for Tex >> Tbg, the
Jν(Tbg) term in the equation ratio becomes small such
that N thin
tot /N thin+RJ+noBG
tot
→1. The disagreement between
 the two equations is worse at smaller Tex.
As a first example, we consider the NH3 (1,1) lowest
inversion transition at 23.7 GHz. At Tex = 10 K, a common
 value found in NH3 studies (see Rosolowsky et al.
2008), the thin+RJ+noBG approximation results in a
systematic 30% underestimate of the column density. At
these frequencies, the CMB cannot be ignored.
This
result indicates that a column density expression with
background (Equation 80 or 81) should be used to calculate
 column densities from NH3 (1,1) observations. In
contrast, the thin+RJ+noBG approximation is more applicable
 at higher frequencies. For the HCO+ J = 3 −2
transition at 267.5 GHz, Equation 82 (thin+RJ+noBG
approximation) has better than 10% accuracy for Tex >
5.4 K. Equation 82 may be used for submillimeter transitions
 (ν > 300 GHz) unless the level populations for the
transition are severely sub-thermally populated (Tex <
5 K).
11.4. Not Optically Thin Approximation8
If we assume that τν ≳1, we use the radiative transfer
equation (Equation 27) to solve for τν:
τν = −ln

1 −
TR
f [J(Tex) −J(Tbg)]

,
(83)
and insert this expression for τν in the column density
equation (Equation 32):
N thick
tot
=

3h
8π3Sµ2Ri
  Qrot
gJgKgI

exp

Eu
kTex

exp

hν
kTex

−1
×
Z
−ln

1 −
TR
f [J(Tex) −J(Tbg)]

dv.
(84)
Note that Equation 84 is quite general, applicable to all
values of ν, τ, Tex, Tbg, and TR. Furthermore, one can
derive a simple relationship between the column density
derived assuming τ ≪1 and those derived assuming τ ≮
1 by noting that one can write N thin
tot
(Equation 80) using
the radiative transfer equation (Equation 27) as follows:
N thin
tot
=

3h
8π3Sµ2Ri
  Qrot
gJgKgI

exp

Eu
kTex

exp

hν
kTex

−1
×
Z
(1 −exp(−τ)) dv.
(85)
Therefore, a column density calculated assuming τ ≪1
is related to a column density calculated more generally
by the following:
Ntot = N thin
tot
τ
1 −exp(−τ).
(86)
The factor τ/(1 −exp(−τ)) is the “optical depth correction
 factor” derived by Goldsmith & Langer (1999).
Note that Equation 86 also applies to the approximation
cases hν ≪kTex (Section 11.2) and Tbg ≪Tex (11.3).
12. THE CONSEQUENCES OF ASSUMING A
CONSTANT EXCITATION TEMPERATURE
The calculation of column density requires a determination
 of the gas excitation temperature (Equation 20).
The excitation temperature is a very general concept that
describes an energy density (in units of temperature),
whether kinetic, radiative, rotational, vibrational, spin,
etc.
Since molecules are fundamentally multi-level systems,
an excitation temperature may be defined for each transition
 allowed via electric dipole (or magnetic dipole or
electric quadrupole) selection rules9. Most molecules (in
particular, dense gas tracers) in the ISM are in non-LTE
with different gas excitation temperatures for different
transitions. However, to simplify the problem of calculating
 the total molecular column density from a single
8 The condition τ ≳1 is often somewhat erroneously referred
to as “optically thick”, while in fact the analysis presented in this
section is appropriate for all conditions excluding τ ≪1.
9 You can also define an “excitation temperature” between levels
which are not radiatively coupled - e.g. the (1,1) and (2,2) inversion
states of NH3. This is usually called a rotation temperature Trot.
How to Calculate Molecular Column Density
13
Figure 4. The optically thin column density at 1 K km/s for transitions
 of HCO+. The J = 1 −0 (blue solid line), J = 3 −2 (red
dotted line), and J = 4 −3 (green dashed line) are plotted for different
 excitation temperatures in the CTEX approximation. The
inset shows the energy level diagram for the lowest 5 energy levels
of HCO+ and the three transitions easily observable from groundbased
 observatories.
transition, the constant excitation temperature approximation
 (CTEX) is usually assumed where all transitions
have the same excitation temperature
Tex
=
T CT EX
ex
∀u →l .
(87)
The optically thin column densities using Equation 80
are shown in Figure 4 for the three lowest energy transitions
 of the HCO+ molecule that are observable from the
ground in atmospheric windows. Note that the column
density equation diverges for T CT EX
ex
→2.735 K due to
the Jν(Tex) −Jν(Tbg) term in the denominator.
This
divergence has the consequence that as the level populations
 approach equilibrium with the CMB, it becomes
more difficult to accurately determine the column density.

The plotted curves show Nthin/I or the column
density in the optically thin limit for an integrated intensity
 of 1 K km/s. These curves should be multiplied
by the observed integrated intensity and corrected for
any optical depth effects by τ/(1 −exp(−τ)). The 1 −0
transition is the least sensitive transition to changes in
the excitation temperature above 3 K with a minimum at
T CT EX
ex
= 7.46 K. As a result, the difference between assuming
 an excitation temperature between 5 K and 10 K
results in a less than 10% uncertainty in the calculated
column density assuming CTEX. This statement is in
general true for the 3 mm transitions of several famous
dense gas tracers such as HCO+, HCN, N2H+, and CS. If
a lower limit to the column density is desirable, then the
column density can be calculated at the excitation temperature
 of the minimum excitation temperature curve
(e.g. Nthin/I > 1.03×1012 cm−2 / K km/s for the HCO+
J = 1 −0 transition at T CT EX
ex
= 7.46 K.)
Estimating the total column density from higher energy
 transitions is more uncertain for low excitation temperatures.

Unfortunately, this situation does occur in
observations of dense cores in the ISM where the dense
gas tracer is typically both optically thick and very subthermally
 populated (see Shirley et al. 2013).
For the
HCO+ J = 4 −3 transition, the uncertainty in the total
column density calculation between assuming an excitation
 temperature of 5 K versus 10 K is a factor of 40!
The J = 4 −3 curve does not reach its minimum until
T CT EX
ex
= 43.55 K, close to the energy of the J = 4 level
above ground (Eu/k = 42.80 K). It is therefore advisable
to observe transitions with Eu/k that are comparable to
the typical excitation temperature to minimize this uncertainty.

Proper estimation of the gas excitation temperature
usually requires observations of multiple transitions coupled
 with modeling of the statistical equilibrium and radiative
 transfer. In general, the excitation temperature
is a sigmoid function that varies between the background
radiation temperature at low density and the gas kinetic
temperature at high density. At low gas densities, collisions
 are not as important for setting the level populations
 as interaction with the background radiation field
and the excitation temperature equilibrates with the radiation
 temperature.
At high gas densities, collisions
dominate in setting the level populations and the excitation
 temperature equilibrates to the gas kinetic temperature
 of the dominant collisional partner. A transition
is said to be “thermalized” if Tex is equal to TK. Subthermal
 excitation indicates that Tex is less than TK.
In the general case of non-LTE in the ISM, it is possible
 that some transitions for a particular molecule may
be thermalized (i.e. CO J = 1 −0), while higher energy
levels are subthermally populated (i.e. CO J = 6 −5).
Strong non-LTE effects are also observed in some cases
(i.e. masers where naturally occurring population inversions
 can occur). Most molecular transitions of dense gas
tracers observed in the ISM are subthermally populated.
Multi-level effects can cause departures from the sigmoid
 shape.
For example, a bottleneck due to longer
rates of spontaneous decay, Aul ∼ν3, for low J transitions
 can cause super-thermal excitation in the J =
1 −0 transition where, over a narrow range of densities,
 Tex > TK. A full discussion of multi-level statistical
equilibrium with radiative transfer is beyond the scope of
this tutorial. There are situations where the excitation
temperature can be directly estimated from the observations.
 If it is known that the line is very optically thick,
then the (1−e−τ) term in the radiative transfer equation
(Equation 27) approaches 1 and the excitation temperature
 may be solved analytically with an assumption of
the gas filling factor:
T obs
ex =
hν/k
ln

1 +
hν/k
TR/f+Jν(Tcmb)

(if τ >> 1) .
(88)
Molecular line ratios of well resolved hyperfine transitions
 or ratios of isotopologues may be used to determine
the optical depth in a line by taking ratios of Equation 27
(see Appendix D), although these methods usually assume
 that the excitation temperature in each hyperfine
line or among different isotopologue transitions are the
same which may not always be true.
Figure 5 shows the dependence of Equation 27 on the
14
Mangum & Shirley
Figure 5. The ratio of the excitation temperature at a given gas
filling fraction compared to the excitation temperature calculated
assuming a gas filling fraction f = 1. The four curves correspond to
spectral lines with TR = 0.1, 1, 10, 100 K. The curves are calculated
for a transition at 3 mm. The curves are a weak function of the
transition frequency. The horizontal dashed line correspond to an
error in Tex of 10% compared to the f = 1 assumption.
filling fraction by plotting the ratio of the excitation temperature
 at a filling fraction, f, divided by the excitation
temperature with a filling fraction of f = 1 (the usual assumption
 when filling fraction is unknown). For intense
spectral lines TR > 1 K, calculation of Tex from Equation
 27 is very sensitive to the gas filing fraction. For a
line with TR = 1 K, Tex is 28% larger for f = 0.5. Tex(f)
quickly increases toward lower gas filling fractions. The
dependence on gas filling fraction is steeper for brighter
lines and flatter for weaker lines. The curves plotted in
Figure 5 are not a strong function of the wavelength for
transitions with λ > 1 cm.
If the line is optically thin, then it is not possible to
determine the excitation temperature from a single transition
 as the observed line temperature, TR, is degenerate
with excitation temperature, optical depth, and filling
fraction. However, in this case, the excitation temperature
 can still be estimated from multiple transitions using
a rotation diagram. A detailed discussion of the limits of
the CTEX approximation for HCO+ observations may
be found in Shirley et al. (2013).
13. NON-LTE APPROACHES TO THE
DERIVATION OF MOLECULAR COLUMN
DENSITY
Although beyond the scope of this tutorial, we should
mention that there are a number of non-LTE approaches
to the solution of the coupled multi-level statistical equilibrium
 and radiative transfer equations. These modelbased
 solutions normally rely on the measurements of a
number of molecular spectral lines from a given species
to constrain the physical conditions within the dense
gas environment under study.
If one is interested in
the global physical conditions within a molecular cloud,
the radiative transfer solution for these models is simplified
 greatly by the introduction of a geometricallyaveraged
 escape probability (usually denoted by β). A
number of escape probability expressions which depend
upon the assumed molecular cloud geometry and global
velocity field can be used in these global cloud models
 (see van der Tak et al. (2007) for an excellent discussion).

One of the most popular of these non-LTE
escape probability models incorporates the Large Velocity
 Gradient (LVG) approximation (Sobolev 1960) to the
solution of the radiative transfer and statistical equilibrium
 equations.
At the heart of the LVG approximation
 is the assumption that photons which are emitted
within the modelled molecular cloud escape quickly from
the cloud due to the large velocity gradient (often assumed
 to be a result of cloud collapse). As described
in Mangum & Wootten (1993) and van der Tak et al.
(2007), in the LVG approximation the escape probability
is given by β = 1−e−τ
τ
within a uniform collapsing spherical
 geometry. The molecular cloud is assumed to have
uniform volume density, kinetic temperature, and molecular
 column density. Inputs to an LVG model include a
specification of the molecular spectrum and collisional
excitation rates involving the primary collision partner
in the molecular cloud (usually assumed to be H2) and
the molecular species under study. Although the LVG
approximation entails the use of a rather simplified uniform
 physical model, it often produces plausible physical
conditions for environments where the transitions used
to constrain the model are not too optically thick.
Other non-LTE approaches include the generalized escape
 probability code RADEX (van der Tak et al. 2007),
microturbulent velocity models (Leung & Liszt 1976)
and Monte Carlo approaches (Brinch & Hogerheijde
2010). In the microturbulent model solution the molecular
 cloud is assumed to have a power-law distribution
in volume density and kinetic temperature with a line
profile that is produced due to a combination of thermal
 and turbulent motions. The radiative transfer equation
 is iteratively solved using a quasi-diffusion method.
Monte Carlo models are generalized solutions to the radiative
 transfer in molecular clouds which incorporate
up to three dimensions of arbitrarily complex structure.
This complex structure is organized into a grid of cells
with uniform volume density, kinetic temperature, and
molecular abundance.
By ray tracing along random
paths through this grid the radiative transfer equation
is iteratively solved.
Even though non-LTE approaches result is a more
accurate representation of the physical conditions in a
molecular cloud, they must be constrained by multiple
 molecular spectral line measurements from a given
molecular species. Non-LTE models also require knowledge
 of the collisional excitation rates for the molecular
 species under study. Collisional excitation rates for
a wide variety of molecules have been calculated (see,
for example, the Leiden Atomic and Molecular Database
(LAMDA); Sch¨
oier et al. (2005)).
In general, though,
limitations to their accuracy and kinetic temperature
range can result in added uncertainty in non-LTE modelling
 of radiative transfer. Due to these limitations, LTE
How to Calculate Molecular Column Density
15
calculations of the molecular column density are often
satisfactory with limited measurements.
14. BEAM-AVERAGED VERSUS
SOURCE-AVERAGED COLUMN DENSITY
An aspect of the calculation of molecular column density
 from a spectral line measurement that is often
overlooked is the difference between beam- and sourceaveraged
 measurements. Beam-averaged molecular column
 densities are derived from spectral line measurements
 with a defined spatial resolution element (a radio
telescope “beam” θbeam). Without an understanding of
the actual spatial extent of the measured emission (i.e.
θbeam > θsource), one normally assumes that it is simply
averaged over the beam of the measurement, or “beamaveraged”.
 For measurements which resolve the spatial
extent of emission (i.e. θbeam < θsource), spectral line
measurements measured over a source, usually considered
 “extended”, result in “source-averaged” molecular
column densities.
15. MOLECULAR COLUMN DENSITY
CALCULATION EXAMPLES
In the following we describe in detail some illustrative
 calculations of the molecular column density. These
example molecules were chosen for their commonality
(C18O is an abundant, though often optically-thin, isotopomer
 of CO), relatively simple hyperfine structure
(C17O), somewhat more complex hyperfine structure
(N2H+), or general usage as kinetic temperature (NH3)
or volume density (H2CO) probes.
In these examples
we adopt the more conventional notation for a generic
(emission or absorption) transition, i.e. “J = 1 −0”, instead
 of the more explicit (and somewhat less convenient)
“J = 1 →0” notation. We also address a common point
of confusion for students learning this material and its reliance
 on CGS (Centimeter-Gram-Second) units. For the
calculations presented below dipole moments are quoted
in the CGS unit “Debye”, which is equal to 10−18 esu cm
(electrostatic units times centimeter). A good source for
molecular dipole moments (µ) and rotational constants
(i.e. A0, B0, C0) is the Jet Propulsion Laboratory (JPL)
Molecular Spectroscopy database and spectral line catalog
 (Pickett et al. 1998)10.
15.1. C18O
To derive the column density for C18O from a measurement
 of its J = 1 −0 transition we use the general equation
 for molecular column density (Equation 32) with the
10 Available online at http://spec.jpl.nasa.gov (use the “catalog
 directory with links” to access dipole moment and molecular
constants information).
following properties of the C18O J = 1 −0 transition:
S =
Ju
2Ju + 1
µ = 0.11079 Debye = 1.1079 × 10−19 esu cm
B0 = 54891.420 MHz
gJ = 2Ju + 1
gK = 1 (for linear molecules)
gI = 1 (for linear molecules)
Qrot ≃kT
hB + 1
3 (Equation 52)
≃0.38 (T + 0.88)
Eu = 5.27 K
ν = 109.782182 GHz
which leads to:
Ntot(C18O) =
3h
8π3µ2JuRi
kTex
hB + 1
3

exp
 Eu
kTex

×

exp
 hν
kTex

−1
−1 Z
τνdv.
(89)
Assuming that the emission is optically thin (τν ≪1;
Equation 80), Equation 89 becomes:
Ntot(C18O) =
2.48 × 1014 (Tex + 0.88)exp

5.27
Tex

exp

5.27
Tex

−1
×

R
TRdv(km/s)
f (Jν(Tex) −Jν(Tbg))

cm−2.
(90)
If we are using integrated fluxes (Sν∆v) instead of integrated
 brightness temperatures, we use Equation B2
(see Appendix B), with the assumption that τ ≪1):
Ntot(C18O) =
3c2
16π3ΩsSµ2ν3
 Qrot
gJgKgI

× exp
Eu
kT
 Z
Sν∆v
=4.77 × 1015 (Tex + 0.88)
θmaj(asec)θmin(asec)
exp

5.27
Tex

exp

5.27
Tex

−1
×
 R
Sν(Jy)dv(km/s)
f (Jν(Tex) −Jν(Tbg))

cm−2.
(91)
where we have assumed a Gaussian source (Ωs
=
1.133θmajθmin) with θmaj and θmin the major and minor
 source diameters (in arcseconds).
15.2. C17O
C17O is a linear molecule with hyperfine structure due
to interaction with the electric quadrupole moment of
the 17O (I = 5
2) nucleus. Using the selection rule:
F = J + I, J + I −1, J + I −2, ..., |J −I|,
we find that each J-level is split into the hyperfine levels
indicated in Table 4 (for the first five J-levels). Since
16
Mangum & Shirley
Table 4
Allowed C17O Hyperfine Energy Levels
J
Number of Energy Levels
Allowed F
0
1
5
2
1
3
7
2, 5
2, 3
2
2
5
9
2, 7
2, 5
2 , 3
2 , 1
2
3
6
11
2 , 9
2 , 7
2, 5
2, 3
2 , 1
2
4
7
13
2 , 11
2 , 9
2 , 7
2, 5
2, 3
2 , 1
2
C
J
1
0
2
7/2
5/2
3/2
9/2
1/2
5/2
7/2
3/2
5/2
F
O
17
Figure 6. Electric quadrupole hyperfine energy level structure for
the J=0, 1, and 2 levels of C17O. Note that the 3 (J = 1 −0) and
9 (J = 2 −1) allowed transitions are marked with arrows ordered
by increasing frequency from left to right.
the selection rules for the single-spin coupling case is,
∆F = 0, ±1, and ∆J = ±1, there are 3, 9, and 14 allowed
hyperfine transitions for the J = 1 −0, J = 2 −1, and
J = 3 −2 transitions, respectively. Figure 6 shows the
energy level structure for the J = 1 −0 and J = 2 −1
transitions.
We can calculate the relative hyperfine intensities (Ri)
for the J = 1 −0 and J = 2 −1 transitions using
the formalism derived in Section 10. Using the formalism
 described in Section 10 we can derive the relevant
Ri for the electric quadrupole hyperfine coupling cases
(Ri(F, J), I = 5
2; Table 5). Figure 7 shows the synthetic
spectra for the C17O J = 1−0 and J = 2−1 transitions.
To derive the column density for C17O from a measurement
 of its J = 1 −0 transition we use the general equation
 for molecular column density (Equation 32) with
the following properties of the C17O J = 1 −0 F= 5
2 −5
2
Figure 7.
Synthetic spectra for the C17O J = 1 −0 (top) and
2−1 (bottom) transitions. Horizontal axes are offset velocity (top)
and frequency (bottom) relative to 112359285.0 and 224714386.0
kHz, respectively. Overlain as a dashed line is a synthetic 100 kHz
gaussian linewidth source spectrum.
transition:
S =
Ju
2Ju + 1
µ = 0.11032 Debye = 1.1032 × 10−19 esu cm
B0 = 56179.9911 MHz
gJ = 2Ju + 1
gK = 1 (for linear molecules)
gI = 1 (for linear molecules)
Qrot ≃kT
hB + 1
3 (Equation 52)
≃0.37 (T + 0.90)
Eu = 5.39 K
Ri = 3
9
How to Calculate Molecular Column Density
17
Table 5
Hyperfine Intensitiesa for C17O J = 1 −0 and J = 2 −1
F ′ →F
J′ →J
a
b
c
(2F ′+1)(2F +1)
(2I+1)
∆νb (kHz)
6j
Ri(F, J)
( 3
2 , 5
2 )
(1,0)
5
2
0
5
2
4
−501
−
1
3
√
2
2
9
( 7
2 , 5
2 )
(1,0)
5
2
1
7
2
8
−293
−
1
3
√
2
4
9
( 5
2 , 5
2 )
(1,0)
5
2
5
2
1
6
+724
1
3
√
2
3
9
( 3
2 , 5
2 )
(2,1)
5
2
1
5
2
4
−867
1
10
1
25
( 5
2 , 5
2 )
(2,1)
5
2
5
2
2
6
−323
−4
√
2
15
√
7
64
525
( 7
2 , 5
2 )
(2,1)
5
2
2
7
2
8
−213
√
3
2
√
35
6
35
( 9
2 , 7
2 )
(2,1)
5
2
2
9
2
40
3
−169
−
1
2
√
10
1
3
( 1
2 , 3
2 )
(2,1)
5
2
1
3
2
4
3
−154
−
1
2
√
5
1
15
( 3
2 , 3
2 )
(2,1)
5
2
3
2
2
8
3
+358
√
7
10
√
2
7
75
( 5
2 , 7
2 )
(2,1)
5
2
1
7
2
8
+694
−
1
6
√
14
1
63
( 7
2 , 7
2 )
(2,1)
5
2
7
2
2
32
3
+804
1
4
√
7
2
21
( 5
2 , 3
2 )
(2,1)
5
2
2
5
2
4
+902
−
√
7
15
√
2
14
225
a The sum of the relative intensities P
i Ri = 1.0 for each ∆J = 1 transition.
b Frequency offsets in kHz relative to 112359.285 and 224714.368 MHz for J = 1 −0
and J = 2−1, respectively (from the spectroscopic constants in Klapper et al. (2003)).
which leads to:
Ntot(C17O) =
3h
8π3µ2JuRi
kTex
hB + 1
3

exp
 Eu
kTex

×

exp
 hν
kTex

−1
−1 Z
τνdv.
(92)
Assuming that the emission is optically thin (τν ≪1;
Equation 80), Equation 92 becomes:
Ntot(C17O) = 2.44 × 1014 (Tex + 0.90)
Ri
exp

Eu
kTex

exp

hν
kTex

−1
×

R
TRdv(km/s)
f (Jν(Tex) −Jν(Tbg))

cm−2,
(93)
where ν is the frequency of the hyperfine transition
used. For example, if the F= 5
2 −5
2 hyperfine was chosen
 for this calculation, Ri =
3
9 (See Table 5) and
ν = 112359.285 + 0.724 MHz = 112.360009GHz. Equation
 93 then becomes:
Ntot(C17O) = 7.32 × 1014 (Tex + 0.90)
exp

5.39
Tex

exp

5.39
Tex

−1
×

R
TRdv(km/s)
f (Jν(Tex) −Jν(Tbg))

cm−2.
(94)
15.3. N2H+
N2H+ is a multiple spin coupling molecule due to the
interaction between its spin and the quadrupole moments
of the two nitrogen nuclei. For a nice detailed description
 of the hyperfine levels of the J = 1 −0 transition
see Shirley et al. (2005); Pagani et al. (2009). Since the
outer N nucleus has a much larger coupling strength than
Table 6
Outer Nitrogen (F1) Hyperfine Intensities for N2H+ J = 1 −0
F ′
1 →F1a
J′ →Ja
a
b
c
(2F ′
1+1)(2F1+1)
(2IN +1)
6j
Ri(F1, J)
(0,1)
(1,0)
1
0
1
1
1
3
1
9
(1,1)
(1,0)
1
1
1
3
−1
3
1
3
(2,1)
(1,0)
1
1
2
5
1
3
5
9
a IN = 1.
the inner N nucleus, the hyperfine structure can be determined
 by a sequential application of the spin coupling:
⃗
F1 = ⃗
J + ⃗
IN,
⃗
F = ⃗
F1 + ⃗
IN.
When the coupling from both N nuclei is considered:
• The J = 0 level is split into 3 energy levels,
• The J = 1 level is split into 7 energy levels,
• The J = 2 and higher levels are split into nine
energy levels.
Since the selection rules for the single-spin coupling case
apply, ∆F1 = 0, ±1, ∆F = 0, ±1, 0 ↛0, and ∆J = ±1,
there are 15, 34, and 38 hyperfine transitions for the J =
1 −0, J = 2 −1, and J = 3 −2 transitions, respectively.
Figure 8 shows the energy level structure for the J = 1−0
transition.
To illustrate the hyperfine intensity calculation for
N2H+, we derive the relative intensities for the J = 1−0
transition. Relative intensities, derived using the formalism
 presented in Section 10 and Equation 77, are listed
in Tables 6, 7, and 8. Figure 9 shows the synthetic spectrum
 for the N2H+ J = 1 −0 transition.
To derive the column density for N2H+ we start with
the general equation for the total molecular column den18

Mangum & Shirley
Table 7
Inner Nitrogen (F ) Hyperfine Intensities for N2H+ J = 1 −0
F ′ →F a
F ′
1 →F1a
a
b
c
(2F ′+1)(2F +1)
(2IN +1)
6j
Ri(F, F1)
(1,0)
(0,1)
1
0
1
1
1
3
1
9
(1,1)
(0,1)
1
1
1
3
−1
3
1
3
(1,2)
(0,1)
1
1
2
5
1
3
5
9
(0,1)
(1,1)
1
1
1
1
1
3
1
9
(1,0)
(1,1)
1
1
1
1
−1
3
1
9
(1,1)
(1,1)
1
1
1
3
1
6
1
12
(1,2)
(1,1)
1
1
2
5
1
6
5
36
(2,1)
(1,1)
1
1
2
5
1
6
5
36
(2,2)
(1,1)
1
2
1
25
3
−
1
2
√
5
5
12
(1,0)
(2,1)
1
2
1
1
1
3
1
9
(1,1)
(2,1)
1
1
2
3
1
6
1
12
(1,2)
(2,1)
1
1
2
5
1
30
1
180
(2,1)
(2,1)
1
2
2
5
−
1
2
√
5
1
4
(2,2)
(2,1)
1
2
2
25
3
−1
10
1
12
(3,2)
(2,1)
1
2
3
35
3
1
5
7
15
a IN = 1.
Table 8
Hyperfine Intensitiesa for N2H+ J=1 −0
F ′ →F b
F ′
1 →F1b
J′ →J
Ri(F1, J)Ri(F, F1)
∆νb (kHz)
Ri(obs)c
(0,1)
(1,1)
(1,0)
1
27
−2155.7
1
27
(2,2)
(1,1)
(1,0)
5
36
−1859.9
5
27
(2,1)
(1,1)
(1,0)
5
108
(1,2)
(1,1)
(1,0)
5
108
−1723.4
1
9
(1,1)
(1,1)
(1,0)
1
36
(1,0)
(1,1)
(1,0)
1
27
(2,1)
(2,1)
(1,0)
5
36
−297.1
5
27
(2,2)
(2,1)
(1,0)
5
108
(3,2)
(2,1)
(1,0)
7
27
+0.0
7
27
(1,1)
(2,1)
(1,0)
5
108
+189.9
1
9
(1,2)
(2,1)
(1,0)
1
324
(1,0)
(2,1)
(1,0)
5
81
(1,2)
(0,1)
(1,0)
5
81
+2488.3
1
9
(1,1)
(0,1)
(1,0)
1
27
(1,0)
(0,1)
(1,0)
1
81
a The sum of the relative intensities P
i Ri = 1.0.
b Frequency offset in kHz relative to 93173.7767 MHz (Caselli et al. 1995).
c Since the J=0 level has no hyperfine splitting, only the sum of all transitions
into the J=0 is observed.
sity (Equation 32) with:
S =
Ju
2Ju + 1 (see Section 9.1)
µ= 3.40 Debye = 3.40 × 10−18 esu cm
B0 = 46586.88 MHz
Ri = (see Section 10 or, for J=1-0, see Table 8)
gJ = 2Ju + 1
gK = 1 (for linear molecules)
gI = 1 (for linear molecules)
Qrot ≃kT
hB + 1
3 (Equation 52)
≃0.45 (T + 0.75)
Eu = 4.4716 K
which leads to:
Ntot(N2H+) =
3h
8π3µ2
Qrot
JuRi
exp
 Eu
kTex

×

exp
 hν
kTex

−1
−1 Z
τνdv.
(95)
Assuming optically thin emission (Equation 80), we find
How to Calculate Molecular Column Density
19
+
J
F1
0
1
1
2
0
1
Outer Nitrogen Coupling
3
2
1
2
1
0
2
1
0
F
Inner Nitrogen Coupling
1
N
2H
Figure 8.
Energy level structure for the J = 1 −0 transition
of N2H+.
Note that of the 15 hyperfine split levels only 7 are
observed due to the fact that there is no hyperfine splitting of the
J=0 level, but it is degenerate in energy. Grouping of the indicated
transitions show the 7 observed transitions. Transitions are ordered
by increasing frequency from left to right.
Figure 9.
Synthetic spectra for the N2H+ J = 1 −0 transition.
Horizontal axes are offset velocity (top) and frequency (bottom)
relative to 93173.7767 MHz. Overlain as a dashed line is a synthetic
100 kHz (∆v = 0.3218 km s−1) gaussian linewidth source spectrum.
that Equation 95 becomes11:
Ntot(N2H+) = 3.10 × 1011 (Tex + 0.75)
Ri
exp

Eu
kTex

exp

hν
kTex

−1
×

R
TRdv(km/s)
f (Jν(Tex) −Jν(Tbg))

cm−2,
(96)
where ν is the frequency of the hyperfine transition used.
11 Alternatively, one can derive τ using the ratio of two hyperfine
transition intensities as described in Appendix D.
For example, if the F=(2,1), J=(1,0) hyperfine was chosen
 for this calculation, Ri =
7
27 (See Table 8) and
ν = 93.1737767GHz. Equation 96 then becomes:
Ntot(N2H+(3, 2; 2, 1)) = 1.20 × 1012 (Tex + 0.75)
exp

4.47
Tex

exp

4.47
Tex

−1
×

R
TRdv(km/s)
f (Jν(Tex) −Jν(Tbg))

cm−2.
(97)
where the transition designation is in the (F′,F′
1:F,F1)
format.
Note that this transition is blended with the
nearby F′ = 1 and 2 (F′
1,F1) = (2,1) hyperfine transitions
under many molecular cloud physical conditions.
15.4. NH3
Ammonia (NH3) is a symmetric top molecule with
three opposing identical H (spin= 1
2) nuclei. Quantum
mechanical tunneling of the N nucleus through the potential
 energy plane formed by the H nuclei leads to inversion
 splitting of each NH3 energy level. On top of this
inversion splitting the energy levels are split due to two
hyperfine interactions:
J–IN:: Coupling between the quadrupole moment of the
N nucleus (IN = 1) and the electric field of the
H atoms, which splits each energy level into three
hyperfine states. For this interaction the angular
momentum vectors are defined as follows:
⃗
F1 =
⃗
J + ⃗
IN.
F1–IH:: Coupling between the magnetic dipole of the
three H nuclei (IH =
1
2 for K̸= 0 or 3n (para),
IH = 3
2 for K=3n (ortho)) with the weak current
generated by the rotation of the molecule. For this
interaction the angular momentum vectors are defined
 as follows: ⃗
F = ⃗
F1 + ⃗
IH.
Weaker N-H spin-spin and H-H spin-spin interactions
also exist, but only represent small perturbations of the
existing hyperfine energy levels.
Figure 10 shows all NH3 energy levels below 1600 K,
while Table 9 lists the level energies for J ≤6. Figure 11
shows the rotational energy level diagram for the first
four J-levels of NH3, while Figure 12 shows the inversion
 and hyperfine level structure for the (1,1) and (2,2)
transitions.
We can calculate the relative hyperfine intensities (Ri)
for the (1,1), (2,2), (3,3), and (4,4) transitions using the
formalism derived in Section 10.
Using the formalism
presented in Section 10 we can derive the relevant Ri for
the quadrupole hyperfine (Ri(F1, J), IN = 1; Tables 11,
12, 13, and 14) and magnetic hyperfine (Ri(F, F1), IH =
1
2 (para, K ̸= 0 or 3n) or 3
2 (ortho, K = 3n); Tables 15,
16, 17, and 18) coupling cases. The resultant total hyperfine
 intensities are derived by multiplying the magnetic
 hyperfine intensities (Ri(F, F1)) by the associated
quadrupole hyperfine intensities (Ri(F1, J)). Tables 19
and 20 show the results of this calculation for the NH3
(1,1) and (2,2) transitions, respectively. Figure 13 shows
the synthetic spectra for the NH3 (1,1) and (2,2) transitions.

For illustration we can derive the column density equation
 for a para-NH3 (K̸=0 or 3n) inversion (∆K = 0)
20
Mangum & Shirley
Figure 10. Rotational energy level diagram for NH3. All levels with energy < 1600 K are shown.
Table 9
NH3 Level Energiesa,b
Level
Energy (K)
Level
Energy (K)
(0,0,a)
1.14
. . .
. . .
(1,1,s)
23.21
(1,1,a)
24.35
(1,0,s)
28.64
. . .
. . .
(2,2,s)
64.20
(2,2,a)
65.34
(2,1,s)
80.47
(2,1,a)
81.58
(2,0,a)
86.99
. . .
. . .
(3,3,s)
122.97
(3,3,a)
124.11
(3,2,s)
150.06
(3,2,a)
151.16
(3,1,s)
166.29
(3,1,a)
167.36
(3,0,s)
171.70
. . .
. . .
(4,4,s)
199.51
(4,4,a)
200.66
(4,3,s)
237.40
(4,3,a)
238.48
(4,2,s)
264.41
(4,2,a)
265.45
(4,1,s)
280.58
(4,1,a)
281.60
(4,0,a)
286.98
. . .
. . .
(5,5,s)
293.82
(5,5,a)
295.00
(5,4,s)
342.49
(5,4,a)
343.58
(5,3,s)
380.23
(5,3,a)
381.25
(5,2,s)
407.12
(5,2,s)
408.10
(5,1,s)
423.23
(5,1,a)
424.18
(5,0,s)
428.60
. . .
. . .
(6,6,s)
405.91
(6,6,a)
407.12
(6,3,s)
551.30
(6,3,a)
552.25
(6,0,a)
600.30
. . .
. . .
a Listed in level energy order per J and
inversion-paired as appropriate.
b See Poynter & Kakar (1975) for lower-state
energy calculations.
4
12
20
6
6
10
10
10
10
Figure 11.
Ammonia energy levels below 100 K. The notation
J±
K is used where ± refers to the symmetry of the energy level.
Allowed electric dipole transitions are indicated with frequencies
of the transitions. The total statistical weight of each energy level
is indicated in red to the left of each energy level.
How to Calculate Molecular Column Density
21
(1,1)
N
1
F = F  + I
H
1
(1,1)
F1
1
2
0
1/2
3/2
3/2
5/2
1/2
+ Parity
F
1
2
0
1/2
3/2
3/2
5/2
1/2
− Parity
Electric Quadrupole
Magnetic Dipole
NH
3
F  = J + I
(2,2)
N
1
F = F  + I
H
1
(2,2)
F1
2
3
1
5/2
7/2
+ Parity
F
3/2
1/2
2
3
1
5/2
7/2
3/2
− Parity
Electric Quadrupole
Magnetic Dipole
1/2
5/2
3/2
5/2
3/2
NH
3
F  = J + I
Figure 12. Inversion and hyperfine energy level structure for the (1,1) (top) and (2,2) (bottom) transitions of NH3. Note that the 18 (1,1)
and 24 (2,2) allowed transitions are marked with arrows ordered by increasing frequency from left to right. Adapted from Ho & Townes
(1983).
22
Mangum & Shirley
Figure 13.
Synthetic spectra for the NH3 (1,1) (top) and
(2,2) (bottom) transitions.
Horizontal axes are offset velocity
 (top) and frequency (bottom) relative to 23694.495487 and
23722.633335 MHz, respectively. Overlain as a dashed line is a synthetic
 100 kHz (∆v = 1.265 and 1.264 km s−1, respectively) gaussian
 linewidth source spectrum.
transition. For para-NH3 inversion transitions:
S =
K2
Ju(Ju + 1)
µ = 1.468 Debye = 1.468 × 10−18 esu cm
Ri = (see Section 10 or, for (1,1) and (2,2), see
Tables 19 and 20)
gJ = 2Ju + 1
gK = 2 for K̸= 0
gI = 2
8 for K̸= 3n
Doing the calculation in two stages, we can first derive
the following equation for the molecular column density
 in NH3 as derived from a measurement of a (J,K)
inversion (∆J = 0,∆K = 0) transition assuming optically
 thin emission (see Rosolowsky et al. (2008) for the
methodology to fit hyperfine transitions in the optically
thick limit) using Equation 80:
Ntot(NH3) =
3h
8π3µ2Ri
Ju(Ju + 1)
K2
Qrot
gJgKgI
×
exp

Eu
kTex

exp

hν
kTex

−1

R
TRdv
f (Jν(Tex) −Jν(Tbg))

.
(98)
Further assuming that we are measuring para-NH3 (K̸=0
or 3n), Equation 98 becomes:
Ntot(NH3) ≃7.44 × 1012Ju(Ju + 1)Qrot
RiK2(2Ju + 1)
×
exp

Eu
kTex

exp

hν
kTex

−1

R
TRdv(km/s)
f (Jν(Tex) −Jν(Tbg))

cm−2.
(99)
15.5. H2CO
Formaldehyde (H2CO) is a slightly asymmetric rotor
 molecule with κ ≃−0.961 (Equation 45), which
means that H2CO is nearly a prolate symmetric rotor.
The slight asymmetry in H2CO results in limiting prolate
 (quantum number K−1) and oblate (quantum number
 K+1) symmetric rotor energy levels that are closely
spaced in energy, a feature commonly referred to as “Kdoublet
 splitting”. Figure 14 shows the energy level diagram
 for H2CO including all energy levels E ≤300 K. In
addition to the asymmetric rotor energy level structure
H2CO possesses spin-rotation and spin-spin hyperfine energy
 level structure. Magnetic dipole interaction between
the H nuclei (IH = 0/1 for para-/ortho-H2CO) and rotational
 motion of the molecule result in spin-rotation
hyperfine energy level splitting.
Since the two H nuclei
 have equal coupling, the two H nuclei spins couple
with each other first and the hyperfine coupling scheme
is ⃗
IH = ⃗
I1 + ⃗
I2 and ⃗
F = ⃗
J + ⃗
IH. Since the interchange
of the two 1H atoms (I1 = I2 = 1/2) obey Fermi-Dirac
statistics (total wave function is anti-symmetric to this
interchange) and alternating Ka ladders in H2CO have a
different rotational wavefunction symmetry, only orthoH2CO
 levels (IH = 1) with Ka = odd integers have hyperfine
 splitting. For the ortho-H2CO 110 −111 transition,
 the frequency offsets of these hyperfine transitions
are ∆ν ≤18.5 kHz. The weaker spin-spin interactions
between the nuclei are generally not considered.
Table 10 lists the frequencies and relative intensities
for the spin-rotation hyperfine transitions of the H2CO
110 −111, 211 −212, and 312 −313 transitions.
Figure
 15 shows the synthetic spectra for the H2CO 110−111,
211 −212, and 312 −313 transitions. Note that the hyperfine
 intensities are exactly equal to those calculated
for the spin-rotation hyperfine components of NH3 (see
Section F).
For illustration we can derive the column density equation
 for an ortho-H2CO (K−1 odd) K-doublet (∆K−1 =
How to Calculate Molecular Column Density
23
Figure 14. Rotational energy level diagram for H2CO including all energy levels with E ≤300 K.
Table 10
F1-IH Hyperfine Frequencies and Intensities for H2CO J=1, 2, and 3 K-Doublet
Transitions
F ′ →F a
J′ →Ja
∆HF b (kHz)
a
b
c
(2F ′
1+1)(2F1+1)
(2IH +1)
6j
Ri(F1, J)
(1,0)
(1,1)
−18.53
1
1
1
1
−1
3
1
9
(0,1)
(1,1)
−1.34
1
1
1
1
−1
3
1
9
(2,2)
(1,1)
−0.35
1
2
1
25
3
−
1
2
√
5
5
12
(2,1)
(1,1)
+4.05
1
1
2
5
1
6
5
36
(1,2)
(1,1)
+6.48
1
1
2
5
1
6
5
36
(1,1)
(1,1)
+11.08
1
1
1
3
1
6
1
12
(1,1)
(2,2)
−20.73
1
1
2
3
1
2
√
5
3
20
(1,2)
(2,2)
−8.5
1
2
2
5
−1
10
1
20
(2,1)
(2,2)
−0.71
1
2
2
5
−1
10
1
20
(3,3)
(2,2)
+0.71
1
3
2
49
3
−2
√
2
3
√
35
392
945
(3,2)
(2,2)
+1.42
1
2
3
35
3
1
15
7
135
(2,3)
(2,2)
+9.76
1
2
3
35
3
1
15
7
135
(2,2)
(2,2)
+10.12
1
2
2
25
3
1
6
25
108
(2,3)
(3,3)
. . .
1
3
3
35
3
−1
21
5
189
(4,3)
(3,3)
. . .
1
3
4
21
1
28
3
112
(4,4)
(3,3)
+0.00
1
4
3
27
−
√
5
4
√
21
45
112
(3,3)
(3,3)
−10.4
1
3
3
49
3
11
84
121
432
(2,2)
(3,3)
+23.0
1
2
3
25
3
−2
√
2
3
√
35
40
189
(3,4)
(3,3)
. . .
1
3
4
21
1
28
3
112
(3,2)
(3,3)
. . .
1
3
3
35
3
−1
21
5
189
a IH = 1 (ortho-H2CO).
b Frequency offset in kHz relative to 4829.6596 MHz for 110 −111, 14488.65 MHz for 211 −
212, and 28974.85 MHz for 312 −313.
24
Mangum & Shirley
Figure 15. Synthetic spectra for the H2CO 110 −111, 211 −212,
and 312 −313 transitions. Horizontal axes are offset velocity (top)
and frequency (bottom) relative to 4829.6596 MHz for 110 −111,
14488.650 MHz for 211 −212, and 28974.85 MHz for 312 −313, respectively.
 For the 312 −313 transition only the ∆F = 0 hyperfine
transitions are shown.
Overlain as a dashed line is a synthetic
10 kHz (∆v = 0.621, 0.207, and 0.103 km s−1, respectively) gaussian
 linewidth source spectrum.
0) transition. For ortho-H2CO transitions:
S =
K2
Ju(Ju + 1)
µ = 2.331 Debye = 2.331 × 10−18 esu cm
Ri = (see Section 10 or, for 110 −111, 211 −212,
or 312 −313 see Table 10)
gJ = 2Ju + 1
gK = 1 (for an asymmetric rotor)
gI = 3
4 for K−1 odd
We can derive the following equation for the molecular
column density in H2CO as derived from a measurement
of an ortho-H2CO (K−1 odd) K-doublet transition assuming
 optically thin emission using Equation 80:
Ntot(H2CO) =
3h
8π3µ2Ri
Ju(Ju + 1)
K2
Qrot
gJgKgI
×
exp

Eu
kTex

exp

hν
kTex

−1

R
TRdv
f (Jν(Tex) −Jν(Tbg))

≃1.97 × 1012Ju(Ju + 1)Qrot
RiK2(2Ju + 1)
×
exp

Eu
kTex

exp

hν
kTex

−1

R
TRdv(km/s)
f (Jν(Tex) −Jν(Tbg))

cm−2.
(100)
Note that the K-doublet transitions of H2CO are rather
unusual in that, due to an unusual collisional excitation
effect, these transitions are often measured in absorption
against the cosmic microwave background radiation. For
n(H2) ≲105.5 cm−3, a collisional selection effect overpopulates
 the lower energy states of the 110 −111 through
514 −515 transitions (Evans et al. 1975; Garrison et al.
1975).
This overpopulation of the lower energy states
results in a “cooling” of the J≤5 K-doublets to an excitation
 temperature that is lower than that of the cosmic
microwave background. This causes the J ≤5 K-doublet
transitions to appear in absorption. For volume densities
n(H2) ≳105.5 cm−3 and TK ≃40 K this collisional pump
is quenched. For these higher volume densities the J ≤
5 K-doublets are driven into emission over a wide range
of kinetic temperatures and abundances (see Figure 1 in
Mangum et al. 2008).
16. SUMMARY
The most general form of the molecular spectral line
column density is given by Equation 32:
Ntot =
3h
8π3|µlu|2
Qrot
gu
exp
 Eu
kTex

×

exp
 hν
kTex

−1
−1 Z
τνdv.
(101)
For absorption line measurements one should use the velocity

integrated opacity directly in Equation 32. For
emission lines, the velocity integrated opacity is usually
How to Calculate Molecular Column Density
25
converted to an integrated intensity. In the optically thin
limit, the column density becomes (Equation 80):
N thin
tot
=

3h
8π3Sµ2Ri
  Qrot
gJgKgI

exp

Eu
kTex

exp

hν
kTex

−1
×
1
(Jν(Tex) −Jν(Tbg))
Z TRdv
f
.
(102)
The optically thick column density is related to the optically
 thin column density by Equation 86:
Ntot = N thin
tot
τ
1 −exp(−τ).
(103)
In this tutorial, we have carefully derived the terms in
Equations 32, 80, and 86. Note, though, that these equations
 assume all energy levels are characterized by the
same excitation temperature (the “CTEX LTE approximation”;
 See Section 12)). We have also explored the
limits of the CTEX approximation (Section 12). NonLTE
 determinations of the column density require a coupled
 radiative transfer and statistical equilibrium calculation
 and can be performed with publically available
tools.
JGM thanks Remy Indebetouw for many extremely
fruitful discussions. We also thank the 2013 University
of Arizona AST515 graduate ISM class, Brian Svoboda,
and Scott Schnee for reviewing the manuscript.
The
referee, Malcolm Walmsley, provided a fantastic review
which resulted in many important improvements to this
manuscript.
The National Radio Astronomy Observatory
 is a facility of the National Science Foundation operated
 under cooperative agreement by Associated Universities,
 Inc.
Introduction
When analyzing complex physical systems, a common problem is that the system parameters
of interest cannot be measured directly. For many of these systems, scientists have developed
sophisticated theories on how measurable quantities y arise from the hidden parameters x.
We will call such mappings the forward process. However, the inverse process is required to
infer the hidden states of a system from measurements. Unfortunately, the inverse is often
both intractable and ill-posed, since crucial information is lost in the forward process.
To fully assess the diversity of possible inverse solutions for a given measurement, an inverse
solver should be able to estimate the complete posterior of the parameters, conditioned on an
observation. This makes it possible to quantify uncertainty, reveal multi-modal distributions,
and identify degenerate and unrecoverable parameters – all highly relevant for applications
in natural science. In this paper, we ask if invertible neural networks (INNs) are a suitable
model class for this task. INNs are characterized by three properties:
(i) The mapping from inputs to outputs is bijective, i.e. its inverse exists,
(ii) both forward and inverse mapping are efficiently computable, and
(iii) both mappings have a tractable Jacobian, which allows explicit computation of
posterior probabilities.
Networks that are invertible by construction offer a unique opportunity: We can train
them on the well-understood forward process x →y and get the inverse y →x for free by
1
arXiv:1808.04730v3  [cs.LG]  6 Feb 2019
Published as a conference paper at ICLR 2019
Invertible Neural Network
Standard (Bayesian) Neural Network
x
INN
y
z
forward (simulation): x →y
inverse (sampling): [y, z] →x
USL
SL
USL
x
(Bayesian) NN
y
forward (simulation): x →y
inverse (prediction): y →x
SL
Figure 1: Abstract comparison of standard approach (left) and ours (right). The
standard direct approach requires a discriminative, supervised loss (SL) term between
predicted and true x, causing problems when y →x is ambiguous. Our network uses a
supervised loss only for the well-defined forward process x →y. Generated x are required
to follow the prior p(x) by an unsupervised loss (USL), while the latent variables z are made
to follow a Gaussian distribution, also by an unsupervised loss. See details in Section 3.3.
running them backwards at prediction time. To counteract the inherent information loss
of the forward process, we introduce additional latent output variables z, which capture
the information about x that is not contained in y. Thus, our INN learns to associate
hidden parameter values x with unique pairs [y, z] of measurements and latent variables.
Forward training optimizes the mapping [y, z] = f(x) and implicitly determines its inverse
x = f −1(y, z) = g(y, z). Additionally, we make sure that the density p(z) of the latent
variables is shaped as a Gaussian distribution.
Thus, the INN represents the desired
posterior p(x | y) by a deterministic function x = g(y, z) that transforms (“pushes”) the
known distribution p(z) to x-space, conditional on y.
Compared to standard approaches (see Fig. 1, left), INNs circumvent a fundamental difficulty
of learning inverse problems: Defining a sensible supervised loss for direct posterior learning is
problematic since it requires prior knowledge about that posterior’s behavior, constituting a
kind of hen-end-egg problem. If the loss does not match the possibly complicated (e.g. multimodal)
 shape of the posterior, learning will converge to incorrect or misleading solutions.
Since the forward process is usually much simpler and better understood, forward training
diminishes this difficulty. Specifically, we make the following contributions:
• We show that the full posterior of an inverse problem can be estimated with invertible
networks, both theoretically in the asymptotic limit of zero loss, and practically on
synthetic and real-world data from astrophysics and medicine.
• The architectural restrictions imposed by invertibility do not seem to have detrimental
effects on our network’s representational power.
• While forward training is sufficient in the asymptotic limit, we find that a combination
with unsupervised backward training improves results on finite training sets.
• In our applications, our approach to learning the posterior compares favourably
to approximate Bayesian computation (ABC) and conditional VAEs. This enables
identifying unrecoverable parameters, parameter correlations and multimodalities.
2
Related work
Modeling the conditional posterior of an inverse process is a classical statistical task that
can in principle be solved by Bayesian methods. Unfortunately, exact Bayesian treatment
of real-world problems is usually intractable. The most common (but expensive) solution
is to resort to sampling, typically by a variant of Markov Chain Monte Carlo (Robert and
Casella, 2004; Gamerman and Lopes, 2006). If a model y = s(x) for the forward process is
available, approximate Bayesian computation (ABC) is often preferred, which embeds the
forward model in a rejection sampling scheme for the posterior p(x|y) (Sunnåker et al., 2013;
Lintusaari et al., 2017; Wilkinson, 2013).
Variational methods offer a more efficient alternative, approximating the posterior by an
optimally chosen member of a tractable distribution family (Blei et al., 2017). Neural
2
Published as a conference paper at ICLR 2019
networks can be trained to predict accurate sufficient statistics for parametric posteriors
(Papamakarios and Murray, 2016; Siddharth et al., 2017), or can be designed to learn a
mean-field distribution for the network’s weights via dropout variational inference (Gal and
Ghahramani, 2015; Kingma et al., 2015). Both ideas can be combined (Kendall and Gal, 2017)
to differentiate between data-related and model-related uncertainty. However, the restriction
to limited distribution families fails if the true distribution is too complex (e.g. when it
requires multiple modes to represent ambiguous or degenerate solutions) and essentially
counters the ability of neural networks to act as universal approximators. Conditional GANs
(cGANs; Mirza and Osindero, 2014; Isola et al., 2017) overcome this restriction in principle,
but often lack satisfactory diversity in practice (Zhu et al., 2017b). For our tasks, conditional
variational autoencoders (cVAEs; Sohn et al., 2015) perform better than cGANs, and are
also conceptually closer to our approach (see appendix Sec. 2), and hence serve as a baseline
in our experiments.
Generative modeling via learning of a non-linear transformation between the data distribution
and a simple prior distribution (Deco and Brauer, 1995; Hyvärinen and Pajunen, 1999)
has the potential to solve these problems. Today, this approach is often formulated as a
normalizing flow (Tabak et al., 2010; Tabak and Turner, 2013), which gradually transforms a
normal density into the desired data density and relies on bijectivity to ensure the mapping’s
validity. These ideas were applied to neural networks by Deco and Brauer (1995); Rippel and
Adams (2013); Rezende and Mohamed (2015) and refined by Tomczak and Welling (2016);
Berg et al. (2018); Trippe and Turner (2018). Today, the most common realizations use
auto-regressive flows, where the density is decomposed according to the Bayesian chain rule
(Kingma et al., 2016; Huang et al., 2018; Germain et al., 2015; Papamakarios et al., 2017;
Oord et al., 2016; Kolesnikov and Lampert, 2017; Salimans et al., 2017; Uria et al., 2016).
These networks successfully learned unconditional generative distributions for artificial data
and standard image sets (e.g. MNIST, CelebA, LSUN bedrooms), and some encouraging
results for conditional modeling exist as well (Oord et al., 2016; Salimans et al., 2017;
Papamakarios et al., 2017; Uria et al., 2016).
These normalizing flows possess property (i) of an INN, and are usually designed to fulfill
requirement (iii) as well. In other words, flow-based networks are invertible in principle,
but the actual computation of their inverse is too costly to be practical, i.e. INN property
(ii) is not fulfilled. This precludes the possibility of bi-directional or cyclic training, which
has been shown to be very beneficial in generative adversarial nets and auto-encoders (Zhu
et al., 2017a; Dumoulin et al., 2016; Donahue et al., 2017; Teng et al., 2018). In fact,
optimization for cycle consistency forces such models to converge to invertible architectures,
making fully invertible networks a natural choice. True INNs can be built using coupling
layers, as introduced in the NICE (Dinh et al., 2014) and RealNVP (Dinh et al., 2016)
architectures. Despite their simple design and training, these networks were rarely studied:
Gomez et al. (2017) used a NICE-like design as a memory-efficient alternative to residual
networks, Jacobsen et al. (2018) demonstrated that the lack of information reduction from
input to representation does not cause overfitting, and Schirrmeister et al. (2018) trained such
a network as an adverserial autoencoder. Danihelka et al. (2017) showed that minimization
of an adversarial loss is superior to maximum likelihood training in RealNVPs, whereas
the Flow-GAN of Grover et al. (2017) performs even better using bidirectional training, a
combination of maximum likelihood and adverserial loss. The Glow architecture by Kingma
and Dhariwal (2018) incorporates invertible 1x1 convolutions into RealNVPs to achieve
impressive image manipulations. This line of research inspired us to extend RealNVPs for the
task of computing posteriors in real-world inverse problems from natural and life sciences.
3
Methods
3.1
Problem specification
We consider a common scenario in natural and life sciences: Researchers are interested in a
set of variables x ∈RD describing some phenomenon of interest, but only variables y ∈RM
can actually be observed, for which the theory of the respective research field provides a
model y = s(x) for the forward process. Since the transformation from x to y incurs an
3
Published as a conference paper at ICLR 2019
information loss, the intrinsic dimension m of y is in general smaller than D, even if the
nominal dimensions satisfy M > D. Hence we want to express the inverse model as a
conditional probability p(x | y), but its mathematical derivation from the forward model is
intractable in the applications we are going to address.
We aim at approximating p(x | y) by a tractable model q(x | y), taking advantage of the
possibility to create an arbitrary amount of training data {(xi, yi)}N
i=1 from the known
forward model s(x) and a suitable prior p(x). While this would allow for training of a
standard regression model, we want to approximate the full posterior probability. To this
end, we introduce a latent random variable z ∈RK drawn from a multi-variate standard
normal distribution and reparametrize q(x | y) in terms of a deterministic function g of y
and z, represented by a neural network with parameters θ:
x = g(y, z; θ)
with
z ∼p(z) = N(z; 0, IK).
(1)
Note that we distinguish between hidden parameters x representing unobservable real-world
properties and latent variables z carrying information intrinsic to our model. Choosing a
Gaussian prior for z poses no additional limitation, as proven by the theory of non-linear
independent component analysis (Hyvärinen and Pajunen, 1999).
In contrast to standard methodology, we propose to learn the model g(y, z; θ) of the inverse
process jointly with a model f(x; θ) approximating the known forward process s(x):
[y, z] = f(x; θ) = [fy(x; θ), fz(x; θ)] = g−1(x; θ)
with
fy(x; θ) ≈s(x).
(2)
Functions f and g share the same parameters θ and are implemented by a single invertible
neural network. Our experiments show that joint bi-directional training of f and g avoids
many complications arising in e.g. cVAEs or Bayesian neural networks, which have to learn
the forward process implicitly.
The relation f = g−1 is enforced by the invertible network architecture, provided that the
nominal and intrinsic dimensions of both sides match. When m ≤M denotes the intrinsic
dimension of y, the latent variable z must have dimension K = D −m, assuming that the
intrinsic dimension of x equals its nominal dimension D. If the resulting nominal output
dimension M + K exceeds D, we augment the input with a vector x0 ∈RM+K−D of zeros
and replace x with the concatenation [x, x0] everywhere. Combining these definitions, our
network expresses q(x | y) as
q
 x = g(y, z; θ) | y

= p(z)

Jx

−1,
Jx = det

∂g(y, z; θ)
∂[y, z]




y,fz(x)
!
(3)
with Jacobian determinant Jx. When using coupling layers, according to Dinh et al. (2016),
computation of Jx is simple, as each transformation has a triangular Jacobian matrix.
3.2
Invertible architecture
To create a fully invertible neural network, we follow the architecture proposed by Dinh et al.
(2016): The basic unit of this network is a reversible block consisting of two complementary
affine coupling layers. Hereby, the block’s input vector u is split into two halves, u1 and
u2, which are transformed by an affine function with coefficients exp(si) and ti (i ∈{1, 2}),
using element-wise multiplication (⊙) and addition:
v1 = u1 ⊙exp(s2(u2)) + t2(u2),
v2 = u2 ⊙exp(s1(v1)) + t1(v1).
(4)
Given the output v = [v1, v2], these expressions are trivially invertible:
u2 = (v2 −t1(v1)) ⊙exp(−s1(v1)),
u1 = (v1 −t2(u2)) ⊙exp(−s2(u2)).
(5)
Importantly, the mappings si and ti can be arbitrarily complicated functions of v1 and
u2 and need not themselves be invertible. In our implementation, they are realized by a
succession of several fully connected layers with leaky ReLU activations.
A deep invertible network is composed of a sequence of these reversible blocks. To increase
model capacity, we apply a few simple extensions to this basic architecture. Firstly, if the
4
Published as a conference paper at ICLR 2019
dimension D is small, but a complex transformation has to be learned, we find it advantageous
to pad both the in- and output of the network with an equal number of zeros. This does not
change the intrinsic dimensions of in- and output, but enables the network’s interior layers
to embed the data into a larger representation space in a more flexible manner. Secondly,
we insert permutation layers between reversible blocks, which shuffle the elements of the
subsequent layer’s input in a randomized, but fixed, way. This causes the splits u = [u1, u2]
to vary between layers and enhances interaction among the individual variables. Kingma
and Dhariwal (2018) use a similar architecture with learned permutations.
3.3
Bi-directional training
Invertible networks offer the opportunity to simultaneously optimize for losses on both the inand
 output domains (Grover et al., 2017), which allows for more effective training. Hereby, we
perform forward and backward iterations in an alternating fashion, accumulating gradients
from both directions before performing a parameter update. For the forward iteration,
we penalize deviations between simulation outcomes yi = s(xi) and network predictions
fy(xi) with a loss Ly
 yi, fy(xi)

. Depending on the problem, Ly can be any supervised loss,
e.g. squared loss for regression or cross-entropy for classification.
The loss for latent variables penalizes the mismatch between the joint distribution of network
outputs q
 y = fy(x), z = fz(x)

= p(x)/|Jyz| and the product of marginal distributions of
simulation outcomes p
 y = s(x)

= p(x)/|Js| and latents p(z) as Lz
 q(y, z), p(y) p(z)

.
We block the gradients of Lz with respect to y to ensure the resulting updates only affect the
predictions of z and do not worsen the predictions of y. Thus, Lz enforces two things: firstly,
the generated z must follow the desired normal distribution p(z); secondly, y and z must be
independent upon convergence (i.e. p(z | y) = p(z)), and not encode the same information
twice. As Lz is implemented by Maximum Mean Discrepancy D (Sec. 3.4), which only
requires samples from the distributions to be compared, the Jacobian determinants Jyz and
Js do not have to be known explicitly. In appendix Sec. 1, we prove the following theorem:
Theorem:
If an INN f(x) = [y, z] is trained as proposed, and both the supervised loss
Ly =E[(y−fy(x))2] and the unsupervised loss Lz =D
 q(y, z), p(y) p(z)

reach zero, sampling
according to Eq. 1 with g=f −1 returns the true posterior p(x | y∗) for any measurement y∗.
Although Ly and Lz are sufficient asymptotically, a small amount of residual dependency
between y and z remains after a finite amount of training. This causes q(x | y) to deviate
from the true posterior p(x | y). To speed up convergence, we also define a loss Lx on the
input side, implemented again by MMD. It matches the distribution of backward predictions
q(x) = p
 y = fy(x)

p
 z = fz(x)

/|Jx| against the prior data distribution p(x) through
Lx
 p(x), q(x)

. In the appendix, Sec. 1, we prove that Lx is guaranteed to be zero when the
forward losses Ly and Lz have converged to zero. Thus, incorporating Lx does not alter the
optimum, but improves convergence in practice.
Finally, if we use padding on either network side, loss terms are needed to ensure no
information is encoded in the additional dimensions. We a) use a squared loss to keep those
values close to zero and b) in an additional inverse training pass, overwrite the padding
dimensions with noise of the same amplitude and minimize a reconstruction loss, which
forces these dimensions to be ignored.
3.4
Maximum mean discrepancy
Maximum Mean Discrepancy (MMD) is a kernel-based method for comparison of two
probability distributions that are only accessible through samples (Gretton et al., 2012).
While a trainable discriminator loss is often preferred for this task in high-dimensional
problems, especially in GAN-based image generation, MMD also works well, is easier to use
and much cheaper, and leads to more stable training (Tolstikhin et al., 2017). The method
requires a kernel function as a design parameter, and we found that kernels with heavier
tails than Gaussian are needed to get meaningful gradients for outliers. We achieved best
results with the Inverse Multiquadratic k(x, x′) = 1/(1 + ∥(x −x′)/h∥2
2), reconfirming the
5
Published as a conference paper at ICLR 2019
Ground truth
INN, all losses INN, only Ly + Lz INN, only Lx
Figure 2: Viability of INN for a basic inverse problem. The task is to produce the
correct (multi-modal) distribution of 2D points x, given only the color label y∗. When
trained with all loss terms from Sec. 3.3, the INN output matches ground truth almost
exactly (2nd image). The ablations (3rd and 4th image) show that we need Ly and Lz to
learn the conditioning correctly, whereas Lx helps us remain faithful to the prior.
suggestion from Tolstikhin et al. (2017). Since the magnitude of the MMD depends on the
kernel choice, the relative weights of the losses Lx, Ly, Lz are adjusted as hyperparameters,
such that their effect is about equal.
4
Experiments
We first demonstrate the capabilities of INNs on two well-behaved synthetic problems and
then show results for two real-world applications from the fields of medicine and astrophysics.
Additional details on the datasets and network architectures are provided in the appendix.
4.1
Artificial data
Gaussian mixture model:
To test basic viability of INNs for inverse problems, we train
them on a standard 8-component Gaussian mixture model p(x). The forward process is very
simple: The first four mixture components (clockwise) are assigned label y = red, the next
two get label y = blue, and the final two are labeled y = green and y = purple (Fig. 2).
The true inverse posteriors p(x | y∗) consist of the mixture components corresponding to
the given one-hot-encoded label y∗. We train the INN to directly regress one-hot vectors
y using a squared loss Ly, so that we can provide plain one-hot vectors y∗to the inverse
network when sampling p(x | y∗).
We observe the following: (i) The INN learns very
accurate approximations of the posteriors and does not suffer from mode collapse. (ii) The
coupling block architecture does not reduce the network’s representational power – results
are similar to standard networks of comparable size (see appendix Sec. 2). (iii) Bidirectional
training works best, whereas forward training alone (using only Ly and Lz) captures the
conditional relationships properly, but places too much mass in unpopulated regions of
x-space. Conversely, pure inverse training (just Lx) learns the correct x-distribution, but
loses all conditioning information.
Inverse kinematics: For a task with a more complex and continuous forward process,
we simulate a simple inverse kinematics problem in 2D space: An articulated arm moves
vertically along a rail and rotates at three joints. These four degrees of freedom constitute
the parameters x. Their priors are given by a normal distribution, which favors a pose with
180◦angles and centered origin. The forward process is to calculate the coordinates of the
end point y, given a configuration x. The inverse problem asks for the posterior distribution
over all possible inputs x that place the arm’s end point at a given y position. An example
for a fixed y∗is shown in Fig. 3, where we compare our INN to a conditional VAE (see
appendix Fig. 7 for conceptual comparison of architectures). Adding Inverse Autoregressive
Flow (IAF, Kingma et al., 2016) does not improve cVAE performance in this case (see
appendix, Table 2). The y∗chosen in Fig. 3 is a hard example, as it is unlikely under the
prior p(x) (Fig. 3, right) and has a strongly bi-modal posterior p(x | y∗).
In this case, due to the computationally cheap forward process, we can use approximate
Bayesian computation (ABC, see appendix Sec. 7) to sample from the ground truth posterior.
Compared to ground truth, we find that both INN and cVAE recover the two symmetric
6
Published as a conference paper at ICLR 2019
Figure 3: Distribution over articulated poses x, conditioned on the end point y∗.
The desired end point y∗is marked by a gray cross. A dotted line on the left represents the
rail the arm is based on, and the faint colored lines indicate sampled arm configurations x
taken from the true (ABC) or learned (INN, cVAE) posterior p(x | y∗). The prior (right) is
shown for reference. The actual end point of each sample may deviate slightly from the target
y∗; contour lines enclose the regions containing 97% of these end points. We emphasize the
articulated arm with the highest estimated likelihood for illustrative purposes.
modes well. However, the true end points of x-samples produced by the cVAE tend to miss
the target y∗by a wider margin. This is because the forward process x →y is only learned
implicitly during cVAE training. See appendix for quantitative analysis and details.
4.2
Real-world applications
After demonstrating the viability on synthetic data, we apply our method to two real world
problems from medicine and astronomy. While we focus on the medical task in the following,
the astronomy application is shown in Fig. 5.
In medical science, the functional state of biological tissue is of interest for many applications.
Tumors, for example, are expected to show changes in oxygen saturation sO2 (Hanahan and
Weinberg, 2011). Such changes cannot be measured directly, but influence the reflectance of
the tissue, which can be measured by multispectral cameras (Lu and Fei, 2014). Since ground
truth data can not be obtained from living tissue, we create training data by simulating
observed spectra y from a tissue model x involving sO2, blood volume fraction vhb, scattering
magnitude amie, anisotropy g and tissue layer thickness d (Wirkert et al., 2016). This model
constitutes the forward process, and traditional methods to learn point estimates of the
inverse (Wirkert et al., 2016; 2017; Claridge and Hidovic-Rowe, 2013) are already sufficiently
reliable to be used in clinical trials. However, these methods can not adequately express
uncertainty and ambiguity, which may be vital for an accurate diagnosis.
Competitors. We train an INN for this problem, along with two ablations (as in Fig. 2),
as well as a cVAE with and without IAF (Kingma et al., 2016) and a network using the
method of Kendall and Gal (2017), with dropout sampling and additional aleatoric error
terms for each parameter. The latter also provides a point-estimate baseline (classical NN)
when used without dropout and error terms, which matches the current state-of-the-art
results in Wirkert et al. (2017). Finally, we compare to ABC, approximating p(x | y∗) with
the 256 samples closest to y∗. Note that with enough samples ABC would produce the true
posterior. We performed 50 000 simulations to generate samples for ABC at test time, taking
one week on a GPU, but still measure inconsistencies in the posteriors. The learning-based
methods are trained within minutes, on a training set of 15 000 samples generated offline.
Error measures. We are interested in both the accuracy (point estimates), and the shape
of the posterior distributions. For point estimates ˆ
x, i.e. MAP estimates, we compute the
deviation from ground-truth values x∗in terms of the RMSE over test set observations y∗,
RMSE =
p
Ey∗[∥ˆ
x −x∗∥2]. The scores are reported both for the main parameter of interest
sO2, and the parameter subspace of sO2, vhb, amie, which we found to be the only recoverable
parameters. Furthermore, we check the re-simulation error: We apply the simulation s(ˆ
x) to
the point estimate, and compare the simulation outcome to the conditioning y∗. To evaluate
the shape of the posteriors, we compute the calibration error for the sampling-based methods,
based on the fraction of ground truth inliers αinl. for corresponding α-confidence-region of
7
Published as a conference paper at ICLR 2019
Table 1: Quantitative results in medical application. We measure the accuracy of
point/MAP estimates as detailed in Sec. 4.2. Best results within measurement error are bold,
and we determine uncertainties (±) by statistical bootstrapping. The parameter sO2 is the
most relevant in this application, whereas error all means all recoverable parameters (sO2,
vhb and amie). Re-simulation error measures how well the MAP estimate ˆ
x is conditioned on
the observation y∗. Calibration error is the most important, as it summarizes correctness of
the posterior shape in one number; see appendix Fig. 11 for more calibration results.
Method
MAP error sO2
MAP error all
MAP re-simulation error
Calibration error
NN (+ Dropout)
0.057 ± 0.003
0.56 ± 0.01
0.397 ± 0.008
1.91%
INN
0.041 ± 0.002
0.57 ± 0.02
0.327 ± 0.007
0.34%
INN, only Ly, Lz
0.066 ± 0.003
0.71 ± 0.02
0.506 ± 0.010
1.62%
INN, only Lx
0.861 ± 0.033
1.70 ± 0.02
2.281 ± 0.045
3.20%
cVAE
0.050 ± 0.002
0.74 ± 0.02
0.314 ± 0.007
2.19%
cVAE-IAF
0.050 ± 0.002
0.74 ± 0.03
0.313 ± 0.008
1.40%
ABC
0.036 ± 0.001
0.54 ± 0.02
0.284 ± 0.005
0.90%
Simulation noise
0.129 ± 0.001
ABC
INN
cVAE -IAF
0
1
sO2
Dropout
0.0
0.1
vhb
0
2k
4k
amie
0.6
0.8
1.0
d
0.8
0.9
g
Correlation
Matrix of x
−1.00
−0.75
−0.50
−0.25
0.00
0.25
0.50
0.75
1.00
Figure 4: Sampled posterior of 5 parameters for fixed y∗in medical application.
For a fixed observation y∗, we compare the estimated posteriors p(x | y∗) of different methods.
The bottom row also includes the point estimate (dashed green line). Ground truth values
x∗(dashed black line) and prior p(x) over all data (gray area) are provided for reference.
the marginal posteriors of x. The reported error is the median of |αinl. −α| over all α. All
values are computed over 5000 test-set observations y∗, or 1000 observations in the case of
re-simulation error. Each posterior uses 4096 samples, or 256 for ABC; all MAP estimates
are found using the mean-shift algorithm.
Quantitative results. Evaluation results for all methods are presented in Table 1. The
INN matches or outperforms other methods in terms of point estimate error. Its accuracy
deteriorates slightly when trained without Lx, and entirely when trained without the
conditioning losses Ly and Lz, just as in Fig. 2. For our purpose, the calibration error is the
most important metric, as it summarizes the correctness of the whole posterior distribution
in one number (see appendix Fig. 11). Here, the INN has a big lead over cVAE(-IAF) and
Dropout, and even over ABC due to the low ABC sample count.
Qualitative results. Fig. 4 shows generated parameter distributions for one fixed measurement
 y∗, comparing the INN to cVAE-IAF, Dropout sampling and ABC. The three former
methods use a sample count of 160 000 to produce smooth curves. Due to the sparse posteri8

Published as a conference paper at ICLR 2019
Ionizing
Luminosity
Ionizing
Emission Rate
Cloud
Density
Expansion
Velocity
Age of
the Cluster
Correlation
Matrix of x
−1.0
−0.5
0.0
0.5
1.0
Figure 5: Astrophysics application. Properties x of star clusters in interstellar gas clouds
are inferred from multispectral measurements y. We train an INN on simulated data, and
show the sampled posterior of 5 parameters for one y∗(colors as in Fig. 4, second row). The
peculiar shape of the prior is due to the dynamic nature of these simulations. We include
this application as a real-world example for the INN’s ability to recover multiple posterior
modes, and strong correlations in p(x | y∗), see details in appendix, Sec. 5.
ors of 256 samples in the case of ABC, kernel density estimation was applied to its results,
with a bandwidth of σ = 0.1. The results produced by the INN provide relevant insights:
First, we find that the posteriors for layer thickness d and anisotropy g match the shape of
their priors, i.e. y∗holds no information about these parameters – they are unrecoverable.
This finding is supported by the ABC results, whereas the other two methods misleadingly
suggest a roughly Gaussian posterior. Second, we find that the sampled distributions for the
blood volume fraction vhb and scattering amplitude amie are strongly correlated (rightmost
plot). This phenomenon is not an analysis artifact, but has a sound physical explanation: As
blood volume fraction increases, more light is absorbed inside the tissue. For the sensor to
record the same intensities y∗as before, scattering must be increased accordingly. In Fig. 10
in the appendix, we show how the INN is applied to real multispectral images.
5
Conclusion
We have shown that the full posterior of an inverse problem can be estimated with invertible
networks, both theoretically and practically on problems from medicine and astrophysics.
We share the excitement of the application experts to develop INNs as a generic tool, helping
them to better interpret their data and models, and to improve experimental setups. As a
side effect, our results confirm the findings of others that the restriction to coupling layers
does not noticeably reduce the expressive power of the network.
In summary, we see the following fundamental advantages of our INN-based method compared
to alternative approaches: Firstly, one can learn the forward process and obtain the (more
complicated) inverse process ‘for free’, as opposed to e.g. cGANs, which focus on the inverse
and learn the forward process only implicitly. Secondly, the learned posteriors are not
restricted to a particular parametric form, in contrast to classical variational methods. Lastly,
in comparison to ABC and related Bayesian methods, the generation of the INN posteriors is
computationally very cheap. In future work, we plan to systematically analyze the properties
of different invertible architectures, as well as more flexible models utilizing cycle losses, in
the context of representative inverse problem. We are also interested in how our method can
be scaled up to higher dimensionalities, where MMD becomes less effective.
Acknowledgments
LA received funding by the Federal Ministry of Education and Research of Germany, project
‘High Performance Deep Learning Framework’ (No 01IH17002). JK, CR and UK received
financial support from the European Research Council (ERC) under the European Unions
Horizon 2020 research and innovation program (grant agreement No 647769). SW and LMH
received funding from the European Research Council (ERC) starting grant COMBIOSCOPY
(637960). EWP, DR, and RSK acknowledge support by Collaborative Research Centre (SFB
881) ‘The Milky Way System’ (subprojects B1, B2 and B8), the Priority Program SPP 1573
‘Physics of the Interstellar Medium’ (grant numbers KL 1358/18.1, KL 1358/19.2 and GL
668/2-1) and the European Research Council in the ERC Advanced Grant STARLIGHT
(project no. 339177)
9
Published as a conference paper at ICLR 2019
Introduction
Although rare, massive stars (M∗> 8−10M⊙) play a crucial role
in multiple astrophysical domains in the Universe. Throughout
their life they continuously lose mass via strong stellar winds
that transfer energy and momentum to the interstellar medium.
As the main engines of nucleosynthesis, they produce a series of
elements and shed chemically processed material as they evolve
through various phases of intense mass loss. And they do not
simply die: they explode as spectacular supernovae, significantly
enhancing the galactic environment of their host galaxies. Their
end products, neutron stars and black holes, offer the opportunity
to study extreme physics (in terms of gravity and temperature)
as well as gamma-ray bursts and gravitational wave sources.
As they are very luminous, they can be observed in more distant
 galaxies, which makes them the ideal tool for understanding
stellar evolution across cosmological time, especially for interpreting
 observations from the first galaxies (such as those to be
obtained from James Webb Space Telescope).
While the role of different stellar populations on galaxy evolution
 has been thoroughly investigated in the literature (Bruzual
Article number, page 1 of 27
arXiv:2203.08125v2  [astro-ph.SR]  14 Sep 2022
A&A proofs: manuscript no. assess-ml
& Charlot 2003; Maraston 2005), a key ingredient of models, the
evolution of massive stars beyond the main sequence, is still uncertain
 (Martins & Palacios 2013; Peters & Hirschi 2013). Apart
from the initial mass, the main factors that determine the evolution
 and final stages of a single massive star are metallicity,
stellar rotation, and mass loss (Ekström et al. 2012; Georgy et al.
2013; Smith 2014). Additionally, the presence of a companion,
which is common among massive stars with binary fractions of
∼50 −70% (Sana et al. 2012, 2013; Dunstall et al. 2015), can
significantly alter the evolution of a star through strong interactions
 (de Mink et al. 2014; Eldridge et al. 2017). Although
all these factors critically determine the future evolution and the
final outcome of the star, they are, in many cases, not well constrained.

In particular, mass loss is of paramount importance as it determines
 not only the stellar evolution but the enrichment and
the formation of the immediate circumstellar environment (for a
review, see Smith 2014 andINTRODUCTION
Deep learning methods for image denoising are dependent
 on the ground-truth data provided in the training
set, and most efforts have been directed toward refining
neural network (NN) architectures (e.g., Vojtekova et al.
2021; Gheller & Vazza 2022). To generate training data,
we either need a thorough and robust understanding of
our astronomical objects to simulate the ground-truth
signal or real data with high signal-to-noise garnered
from long exposures in observations.
Lehtinen et al. (2018) demonstrate that denoising images
 with only noisy images – a self-supervised process –
is possible. Several works (Batson & Royer 2019; Krull
et al. 2018) have explored the feasibility of blind denoising
 using self-supervision. Astronomical imaging often
generates multiple exposures of the same objects, which
can be used with Noise2Noise. By exploiting the selfsimilarity
 in natural images, the Noise2Noise algorithm
introduces a general method for finding an optimal denoiser
 for a given dataset.
For a given dataset with
Corresponding author: Yunchong Zhang
aruba19th@uchicago.edu
noisy image pairs, suppose each image pair contains two
noisy images x1 and x2 of the same dimensions, such
that x1 = y + n1 and x2 = y + n2, where y is the
ground truth, and n1 and n2 are two different additive
noise components. Assuming each noise component ni
is independent from the ground truth, one can find an
optimal transformation f from x1 to x2 among an entire
class of transformations fθ, where the transformation is
parameterized by θ, by minimizing the self-supervised
loss between the two noisy images:
L = E||fθ(x1) −x2||.
(1)
Due to the independence of the noise components, one
expects the transformation f to fail in predicting the
noisy component n2 in x2 when only given x1 as input.
Therefore, the optimal transformation f would only predict
 the ground truth component y and become an effective
 denoiser to images within the distribution of the
training data.
2. METHOD
For Experiment 1, we applied the algorithm to two
architectures: U-net (Ronneberger et al. 2015) and a denoising
 convolutional neural network (DnCNN) (Zhang
et al. 2017).
arXiv:2209.07071v1  [astro-ph.IM]  15 Sep 2022
2
Zhang et al.
Experiment with Gaussian Noise
Experiment with Poisson Noise
Figure 1. Upper panels in top and bottom row: morphological parameters comparison between fitted results and ground
truths; Lower panels in top and bottom row: the distribution of morphological parameters Parameterfit/Parametertrue. The
filled contours reflect the bin counts of instances. The darker the color, the denser the distribution of instances.
We simulate training and test data. The signal components
 of each simulated image pair are generated as
S´
ersic profiles (S´
ersic 1963) using the parametric fitting
 tool GALFIT (Peng et al. 2010) by inputting the
chosen S´
ersic index n, half-light radius Re, positional
angle PA, semi-major-axis to semi-minor-axis ratio ba,
and magnitude M. We randomly sample from a range
for each parameter except for the magnitude, which we
randomly sample from the DES public catalog (Abbott
et al. 2018) processed by the Weak-lensing-Deblending
software (Sanchez et al. 2021; Kirkby et al. 2020). We
simulate the noise components using GALSIM (Rowe
et al. 2015) and combine them with signal components
for the training set.
To train networks with self-supervision, we generate a
pair of images with the same signal but different noise
as one instance. For Experiment 1, we generate 1000
128pix × 128pix instances with Poisson noise, and we
choose relatively wide ranges of morphological parameters
 (n ∈[0.5, 6]; ba ∈[0.01, 1]; Re ∈[4, 20]) for the sigNoise2Astro

3
nal. For Experiment 2, we generate 1000 256pix×256pix
image instances with narrower ranges of morphological
parameters (n ∈[1.0, 1.6]; ba ∈[0.9, 1]; Re ∈[200, 320])
to simulate low-surface brightness signal components.
We generate two train-test sets for Experiment 2: one
has entirely Gaussian noise components, and the other
has Poisson noise and the same signal components as
the former one. The Gaussian noise is simulated with a
sigma taken from the value of mean sky-level per pixel
from the DES public catalog (Abbott et al. 2018). For
all experiments, we use the first 800 instances for training
 and all 1000 instances for testing.
3. RESULTS
We evaluate Experiment 1 by measuring the bias image:
 Ibias = Ioutput
Itrue . Out of the two network architectures,
 the U-net produces the least bias. While all instances
 in Experiment 1 tend to have high biases in the
image region where the signal tends to be peaky (relatively
 high surface brightness), the network output in
the image region where the signal is smooth (relatively
low surface brightness) converges to the ground truth.
In Experiment 2, we implement the U-net and examine
 the recovery of flux and signal morphology. To assess
 the morphological accuracy, we performed 2D S´
ersic
function fitting on our outputs with SciPy (Virtanen
et al. 2020). We mask out pixels with a relatively large
bias for fitting by choosing a circular mask with radius of
5pix centered at the peak of the signal. We also applied
constraints to the x and y positions of the 2D S´
ersic
function, while other parameters are allowed to vary.
For instances with Poisson (Gaussian) noise, the network
 recovers 98.13
+0.77
−0.90% (96.45
+0.80
−0.96%) of the flux.
We compare outputs from our analysis (network denoising
 and S´
ersic fitting) with the ground truth in Figure
 1. In the lower panels, we show the bias (Pbias =
Parameterfit/Parametertrue) versus ground truth for
each parameter.
For each parameter, if the biases of
experiment instances have a narrower distribution, the
fitted values from the overall routine are in better agreement
 with the ground truths. The fitted ba agrees with
ground truths in both Gaussian and Poisson noise experiments
 (babias ≃0.96 ∼1.04). For n, fitted values
agree better with ground truths when the noise is Gaussian
 (nbias ≃0.86 ∼1.1) than when the noise is Poisson
(nbias ≃0.7 ∼1.14). For Re, the fitted values poorly
agree with ground truths in both Gaussian (Re bias ≃
0.72 ∼1.2) and Poisson cases (Re bias ≃0.6 ∼1.16),
and few instances are on the line where Pbias = 1. In
the case of Poisson noise, the Re tends to be significantly
underestimated (median(Re bias) ≃0.84). Considering
that the ground-truth Re is much larger than the size of
images in the test set, such a result can be expected.
We distinguish between the distribution of trainingset
 and test-set instances in Figure 1, where “test-set”
refers to the 200 instances of the total 1000 testing instances
 that are not exposed to the model during training.
 In the two experiments, we find no obvious deviation
 of the “test-set” instance distribution from that of
the training-set.
We conclude that NNs with self-supervision can
achieve photometric accuracy within 5% of the ground
truth in limited scenarios: the self-training set has to
contain images with sufficient resemblance and the objects
 should have light profiles with low flux gradients.
Therefore, this algorithm would potentially be applicable
 to denoise faint, diffuse objects.
ACKNOWLEDGEMENTS
We acknowledge the Deep Skies Lab as a community
 of multi-domain experts and collaborators who’ve
facilitated an environment of open discussion, ideageneration,
 and collaboration. This community was important
 for the development of this project.
This manuscript has been authored by Fermi Research
 Alliance, LLC under Contract No.
DE-AC0207CH11359
 with the U.S. Department of Energy, Office
of Science, Office of High Energy Physics.
Introduction
Convolutional neural network (CNN) as a machine learning (ML) technique
is becoming more and more applicable for astronomical tasks. Its success has
been proven sufficiently for big data observational sky surveys: galaxy classification
 by various properties, pattern recognition image description, celestial
body’s peculiarities identification, anomalies, transient object detection, etc.
The CNNs are very helpful for finding and discovering previously unknown gravitationally
 lensed quasars [1, 2, 3], identifying gravitational lenses [4, 5, 6, 7],
galaxy-galaxy strong gravitational lenses [8] including in the Dark Energy Survey
 (DES) imaging data [9] and weak gravitational lensing analysis to create
galaxy images as an input [10]. The distance moduli estimates benefit from
the CNNs utilization in the big data sets, which provide a wide number of
galaxy features for learning (see review by Salvato et al.
[11]).
Bonnett et
al. [12] adopted the multiple ML methods for determining photometric redshifts
 with implications for weak lensing from the DES catalogue. Amaro et
al.
[13] compared ANNz2 [14], Bayesian photometric redshift method, and
METAPHOR (Machine-learning Estimation Tool for Accurate PHOtometric
Redshifts) for KiDS-ESO-DR3 and GAMA DR2 surveys. Similarly, Pasquet et
al. [15] used deep learning (DL) for classifying, detecting, and predicting photometric
 redshifts of quasars in the SDSS. ML and generative adversarial networks
(GAN) were used to assign and predict photometric/spectroscopic redshifts
within large-scale galaxy surveys with good accuracy [16, 17, 18, 11, 9, 19, 20].
The ML approach serves as a basis for restoring galaxy distribution in the Zone
of Avoidance [21, 22] and generating dark matter structures in cosmological
models [23, 24, 25], for extraction information from noisy maps [26] and image
reconstruction in the whole [27, 28], for the task of deblending overlaps between
foreground and background galaxies with GAN as CNN technique [29, 30] (see,
also, scalable ML algorithms and frameworks in [31]). The review on recent
2
trends of ML applicability in cosmology and gravitational wave astronomy can
be found in work by Burgazli et al. [32].
The CNN models have expanded the “optical” range of applications becoming
 useful for multiwavelength sky surveys. Among recent studies are as follows:
search for blazar candidates in the Fermi-LAT Clean Sample [33]; boosted decision
 tree for detecting the faint γ-ray sources with future Cherenkov Telescope
Array [34, 35]; infrared colour selection of Wolf-Rayet candidates in our Galaxy
using the Spitzer GLIMPSE catalogue [36]; cosmic string searches in 21-cm temperature
 CMB maps [37]; neural network-based Faranoff-Riley classifications of
radio galaxies from the Very Large Array archive [38] and DL classification of
compact and extended radio source from Radio Galaxy Zoo [39]; CNN for morphological
 assignment to radio-detected galaxies with active nuclei [40]. Scaife
et al. [41] presented the first application of group-equivariant CNNs to radio
galaxy classification and explored their potential for reducing intra-class variability
 by preserving equivariance for the Euclidean group on image translations,
rotations, and reflections.
The merging galaxies are among the objects to be missclassified. Finding
comprehensive samples of such galaxies in different merger stages is significant
for studying these long-term processes. In this context, the adversarial training
with Domain Adversarial Neural Networks (DANNs) altogether with the Maximum
 Mean Discrepancy (MMD) method was proposed by Ciprijanovic et al.
[42]. Such adaptation techniques allowed these authors to demonstrate a great
promise to classify galaxy mergers across domains. As well, to identify peculiar
galaxies, an ML system needs to identify forms of galaxies that are not present
in the dataset. For such identification of outlier galaxies, the unsupervised ML
is proposed by Shamir et al. [43].
Our work follows the previous paper by [44] (Paper I below), where the
photometry-based approach for a binary morphological classification was applied
 to the SDSS DR9 set of low-redshift ∼315 800 galaxies. Using various
galaxy classification techniques (human labeling, multi-photometry diagrams,
and five supervised ML methods), we found that the Support Vector Machine
gives the highest accuracy (96.1 % early E and 96.9 % late L types). Determining
 the ability of each method to predict the galaxy morphological type, we
verified various dependencies of the method’s accuracy on redshifts, celestial coordinates,
 human labeling bias, the overlap of different morphological features,
etc.
The aim of this paper is to obtain the image-based classification of 315 782
galaxies with absolute stellar magnitudes of −24m < Mr < −19.4m at 0.003 <
z < 0.1 redshifts (with velocities correction on the velocity of Local Group,
VLG > 1500 km/s). For this, we exploited the annotated data of the Galaxy
Zoo 2 (GZ2) project with their crowd-sourcing strategy for volunteers to classify
images by answering a series of questions. The sample of the GZ2 galaxies, which
overlap with the studied galaxies, was served as the training data set for the
CNN classifier.
As compare to the paper by [45] (Paper II below), this work investigates the
problem of differences in the data sets in detail and suggest ways to overcome
3
adversarial validation. We also use a neural network to predict some structural,
morphological features that can help to classify galaxies with ware used by
Walmsley et al. [46]. We analyze the obtained samples of galaxies with different
morphological features to obtain their quantitative/qualitative properties and
to estimate an efficiency of CNN classifier.
We describe briefly the target, training, and inference galaxy data sets in
Section 2.
Methodology consisting of the data preparation, adversarial validation,
 CNN morphological classification with intelligent train-test split via
adversarial scores is given in Section 3 (see, also, Paper II). The general results
and discussion are in Section 4, and the conclusion is presented in Section 5.
2. Galaxy data sets
2.1. Target data set
One of the most crucial principles of ML is comprehending the data you are
working with. These design principles are most important at the stage when
the data are fed into the chosen algorithms (see, for example, [47]). That is why
we used a representative data set of the 315 782 SDSS DR9 galaxies at z < 0.1
with the absolute stellar magnitudes −24m < Mr < −13m, which we name as
the target data set (see, in detail, Paper II [45]).
It was studied by us practically as “galaxy by galaxy” in previous works
for various tasks ([48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58], including the ML
photometry-based approach for binary galaxy morphological classification [44]
and the catalog of their morphological types [59] obtained with the Support
Vector Machine and Random Forest methods. The paper II [45] describes a
general methodology for the CNN morphological classification as well as a morphological
 catalog of galaxies classified into five classes according to the Galaxy
Zoo 2 labeling annotation is published through VizieR [60].
2.2. Training and inference data sets
To provide the image-based approach for morphological classification of
galaxies from the target data set, we used the GZ2 annotated data. To train the
neural network, we should have a large number of labeled galaxies images. The
target data set of the SDSS galaxies is tightly overlapped with the data from
GZ2 [61]. For this reason, we divided our target data set into two data sets.
Hereafter, we determine the data set of 143 410 galaxies, which do not match
the GZ2 galaxies, as the “inference” data set. The data set of 172 372 galaxies,
which match the GZ2 galaxies, is the “training” data set. The sample from
GZ2 contains all the well-resolved galaxies essentially in DR9 with N = 11 923
galaxies from the Stripe 82 (11.6 ≤mr ≤17.7, 0.003 < z < 0.09), where about
of 6 800 are at 0.07 < z < 0.09. We considers galaxies only in normal-depth
SDSS imaging and with DR9 spectroscopic redshifts.
We consider two types of morphological classification. The first type is the
classification, which includes clearly separable five classes: completely rounded,
4
rounded in-between, cigar-shaped, edge-on, and spiral galaxies. This classification
 is based on the combinations of precisely labeled GZ2 parameters and,
obviously, includes only some part of the training data set.
Unlike the first
type, the second type of classification works with the 37 galaxy morphological
features from the GZ2 and covers all galaxies presented in the training data set.
To form the first type of classification, we used specific criteria which allow
us to separate different morphological classes of galaxies [61]. These criteria
were listed in the Paper ii. Besides, we removed seven galaxies which fit in two
or more criteria listed in this Table.
1
So, we exploited only those galaxies
for training for which the most votes of GZ volunteers was collected.
Such
constraints are not all-inclusive. The more complete and severe criteria could
be used to determine the morphological type of a galaxy as clearly as possible.
However, as we discussed in the Paper II, the criteria in use are good enough
to provide reliable image-based classification.
To form the second type of classification (classification by the morphological
features, down panel in Fig. 3), we used at least one of 37 features of galaxies
from the training data set, which are described in the first column of Table 2
and Table 3. Also, we removed three very sparse classes from the consideration
“bulge prominence dominant”, “odd feature lens or arc”, “bulge shape boxy”)
each containing of < 10 galaxies. In total, we obtained the training data set
of 160 471 galaxies (down panel, Fig. 3). To test the accuracy of the detailed
morphological classification on the faint magnitude end, we also used 16 626
galaxies from the DECaLS (see, subsection 3.5).
There is a principal difference between galaxy images in our inference data
set and training data set matching the GZ2 catalog. One can see in Fig. 1a
and Fig. 1b that the inference data set is much shallower than the training one.
This is occurred because the galaxies from the target data set of 315 782 galaxies
were pre-selected via mr < 17.7 limitation by stellar magnitude in r-band. This
limitation is related to the 90 % Petrosian flux parameter [62, 63, 44]. So, the
galaxies, which do not match the GZ2 catalog from the target data set, are,
on average, fainter and smaller than galaxies from the training GZ2 data set.
In total, 24 547 galaxies from the inference data set have mr < 17.7 (Fig. 1a).
The CNN classifier knows nothing that it will works with the inference data set,
where galaxies are fainter and smaller than in the training data set. So, it gives
us an additional case to study performance of the image-based classification
providing some additional steps.
Namely, to understand how crucial the shift between training and inference
data sets is for the CNN classifier, we use additional test data set. It is based
on the image morphological classification of 314 000 galaxies from DECaLS and
includes revealed fine morphological features, which are not seen with the SDSS
images [64]. With this additional test data set, we identified 16 626 galaxies
in our inference data set, which further are used for the approach testing. We
1The criteria with ‘* count’ prefix indicate the number of votes; other criteria correspond
to the debiased fraction of votes signed in the GZ2 catalogue as ‘* debiased’.
5
(a) The stellar magnitude.
(b) The Petrosian radius (90 % of the flux).
Figure 1: Histograms of the stellar magnitude and Petrosian radius (90 % of the flux) distributions
 in r-band for the training (green) and inference (brown) SDSS galaxy data sets at
z < 0.1.
note that the morphological classification scheme for the DECaLS is slightly
different from the one for the GZ2, namely it is biased towards increasing the
detection of bars, measuring bulge size, and distinguishing types of merging
galaxies. To align the GZ2 classification used in our study and the DECaLS
morphological classification, we removed 15 classes from this data set because
the DECaLS morphological classification does not contain some of the GZ2
classes (see, Table 2 and Table 3). After this data preparation, we obtained 28
GZ2 features labels in our additional test data set. Hereafter in the paper, we
name it as the “deep” test data set.
Other relevant observational parameters are better overlapped among two
data sets, see, for example, Fig.2 with distributions by redshift and u −r color
indices.
2.3. Images of galaxies
Images of the training and inference galaxies were requested from the SDSS
cutout server2. We have retrieved 315,782 RGB images (in PNG format) composed
 of gri bands according to [65] color scaling, each of 100×100×3 pixels3.
Unfortunately, some of the images were not retrieved by technical reason (including
 dead pixels), slightly reducing the training and inference data sets
to 172 251, and 136 342, respectively.
We note that scientific image format (likely FITS) may be preferable in our
task due to the higher amplitude ranges, in respect to 256 values per band in
the simple PNG image. But such a flux sampling is more required for detailed
2http://skyserver.sdss.org/dr15/en/help/docs/api.aspx#cutout
3Corresponding to 39.6 × 39.6 arcsec in each channel of the RGB image.
6
Figure 2: Histograms of the redshifts (left) and u −r colour indices distributions for the
training (green) and inference (brown) SDSS galaxy data sets at z < 0.1.
image analyses, for example, gravitational lens modeling, while most of the deeplearning
 models are working on images with 8-bit amplitudes (see, for example,
[66]). Additionally, FITS files from the SDSS may be composed into 5-band
images, expanding spectral information, while PNG files are restricted to have
3 bands only (gri in our case). Investigation of this issue is out of scope for our
paper, and we used standard approach of utilizing the SDSS image cutouts for
galaxy morphological classification [61].
2.4. Implementation
All the deep-learning models were implemented using PyTorch4 and pytorchimage-models5
 libraries. To train the models, we used GPU GeForce GTX
1080Ti.
3. Methodology, CNN image-based galaxy classifier
We exploited CNNs to reveal the morphological classification of galaxies by
their images. With this technique, we solve two different classification problems
and handle a shift between training and inference data sets.
Usually, CNN consists of layers represented by a sequence of convolutional
operations, activation functions, and pooling operations. The principal aim of
the CNN is to find such convolutional kernels that are the result of applying
the whole CNN to the image finalized in some target value. In our case, the
morphological classes and features of galaxies are target values. The CNN architectures
 use the fully connected layers (instead of convolutional blocks) at the
tail. This tail corresponds to the neural network classifier, which transforms the
4https://github.com/pytorch/pytorch
5https://github.com/rwightman/pytorch-image-models
7
output of the convolutional part into the dense layer, the number of neurons,
which is equal to the number of classes6
Figure 3: Scheme of the image-based approach for morphological classification of galaxies.
Methodology consists of the data preparation, adversarial validation, five-class CNN morphological
 classification with intelligent train-test split via adversarial scores, and detailed image
feature morphological classification.
3.1. General approach
The scheme of our approach is shown in Fig. 3. First, we divide the studied
data set into the training and inference parts (Section 2). Since the inference
data set is enormously different from the training one, we have to apply some
6A good practical overview can be accessed through http://cs231n.stanford.edu/. We
address readers also to works [67, 68, 27, 69], where the feature extraction power of CNNs was
illustrated in numerical experiments for improving the classification performance, including
astronomical image reconstruction.
8
necessary procedure with a final classification, namely the adversarial validation7.
 It allowed us not only to probe the difference between the galaxy images
in training and inference data sets (middle panel in Fig. 3) but to derive the
most suitable method of testing the CNN classifier, which will produce a representative
 estimation of quality on inference data set. This procedure is also
significant in our approach for two reasons: the labeled galaxy data sets are
biased in stellar magnitude distribution for the training data set (Fig. 1a); such
a difference could led to bias of the final prediction of galaxy classification in
the inference data set.
At the second stage of the pipeline, we use CNN to solve the five-class
problem described in Section 2. We test our model with the data set defined by
the adversarial validation.
Finally, we train a second model to predict the detailed morphological features
 (likely bar, bulge, merging, ring, etc.), which is tested with the adversarial
validation and deep test data sets. As the result of a pipeline, we obtain five
morphological classes and 34 detailed morphological parameters for galaxies
from the inference data set (down panel in Fig. 3).
3.2. Data preparation and augmentation
Stable CNN learning presumes the right scaling or normalization of the input
data [71]. We scaled each image I (pixels of which contain values between 0
and 255: Ii,j ∈{0, 255} ) to the range [−0.5, 0.5] using the scaling equation as
follows:
˜
Ii,j = Ii,j −127.5
255
(1)
Also, we defined many affine transformations for applying to images of galaxies
 during the CNN learning (so-called image augmentation). In our case, the
augmentation helps to introduce the variative nature of galaxies to the CNN
methods (because the standard CNNs are not fully invariant to any transformation
 of the images and have a strong ability to over-fitting). In most cases,
this trick improves the generalization ability of CNN producing a less over-fitted
model on the training data set (see, e.g. [72]).
As augmentations, we used random rotation (0◦, 90◦, 180◦, or 270◦), random
zoom (varying at 100÷120 pixels in each axis) with further random cropping of
the 100 × 100 region, and random vertical/horizontal flipping of the images of
galaxies. This process was applied randomly to each image of a galaxy so that
each image of a certain galaxy was put in the CNN as a “new” one reducing the
sensitivity of CNN to any galaxy orientation.
These augmentation steps were exploited during the adversarial validation
with the CNN classification. We note in advance that after the adversarial val7This
 method is commonly used in data science competitions, see, e.g., http://fastml.
com/adversarial-validation-part-one/; [70].
9
idation was produced, we conducted additional data augmentation procedures
that helped to learn the CNN classifier better (Section 3.3).
3.3. Adversarial validation
Having the training and inference data sets (Section 2), we can investigate
how the images of galaxies “vary” between these data sets. We trained the CNN
on all of these images, passing the class “0” for inference data set and class “1”
for the training one (second panel, Fig. 3).
In this case, the CNN classifier tried to distinguish the training images from
images of galaxies from the inference data set, returning the “adversarial score”
– the probability of the galaxy being in the training data set. If such a classification
 accuracy is close to random guessing, one could assume the similarity of the
training galaxy images with the inference ones. Moreover, vice versa, when the
adversarial classification accuracy largely differs from random guessing (tends
to the 100%), one has to investigate the difference between the training data set
and the inference one to predict the classes of inference objects correctly. Adversarial
 score is a measure of how an individual galaxy is similar to the training
data set (larger scores correspond to larger similarities with galaxies from the
training data set). The effect of dissimilarity is due to the different observed
parameters of galaxies from the training and inference data sets. We used the
full GZ2 data set as a training data set (comprising of 172 372 galaxies) with
adversarial class “1”.
We employed ResNet-101 [73] as a model, where the convolutional part
was completed by the two layers of neurons with 128 and 2 neurons in each
layer correspondingly. After the first layer of neurons, we put on the Leaky
Rectified Linear Unit activation function. The last layer that returns the
probabilities of being in the training or inference dataset was supplemented by
the softmax activation function. As an optimizer, we used Adam with initial
learning rate 5×10−3; the optimizer minimized the categorical crossentropy
loss function. In this way, we tried a single ResNet-101 model as a baseline
approach and obtained a good accuracy for GZ2 vs inference classification. We
did not vary models, because the aim is not to have a performance as higher as
possible. The trained model is just a key-performance indicator for each galaxy,
and its outputs were used as the proxy metric to understand similarity between
the target (not GZ) data set and each galaxy or its augmented version.
The whole input set consisted of ∼170 000 galaxies from the GZ2 training
data set and ∼136 000 galaxies from the inference one. We have trained the
model on 75 % of input data and validated it on the rest part of the galaxies.
We applied standard data augmentation procedures to the training images described
 in Section 3.2. The model was learned during 12 epochs. If the overall
classification accuracy of galaxy images from the validation data set did not
increase during three epochs, we decreased the learning rate by a factor of 0.1.
Finally, we used the model that provided the best overall accuracy (91.28 % on
the validation data and 91.67 % on the training one).
For our task, we obtained the accuracy of adversarial classification above
90 %. So, the inference dataset contains galaxies with morphological properties
10
which are not inherited to the training set. One can see in Fig. 4a that the
adversarial score is relatively high for a few galaxies only from the inference
data set. This agrees with our observation that inference galaxies are fainter
(Fig. 1a and smaller (Fig. 1b) than galaxies from the training data set.
(a) The inference galaxy data set (brown) and for
elliptical and spiral galaxies from the GZ2 training
data set.
Adversarial score is close to 1 if the
galaxy is similar to the galaxy from GZ2 training
data set.
(b) A random subset of 3 000 images from the
training data set revealed from original SDSS images
 (green) and images with modified sizes and
intensities of galaxies as k = 0.8, m = 0.7 from
Eq.2 (brown).
Figure 4: Histograms of adversarial score distributions.
We highlight that the resulting adversarial classification accuracy is not a
result of over-fitting.
Specifically, we randomly split the GZ2 training plus
inference data sets into two parts. One of which was used to train the adversarial
CNN and another to validate it. The CNN scored the same adversarial accuracy
for these subsets (91 %).
So, according to the adversarial result, we can conclude that our training
data set contains galaxies, properties of which are not common with the inference
 one. This means that any validation of the morphological classifier has to
be done with the galaxies from the training data set, which have a low adversarial
 score.
This is a typical danger case of over-fitting, when a ML model is well performed
 on the training data set but is not able to generalize to new, previouslyunseen
 data. This effect may be controlled through the train-test splitting. In
such a way, a portion of the data (called the test data) is set aside for using
only to assess the performance of the trained model and is not included into
the training data set. To do so, we randomly choose 9 000 galaxies with an
adversarial score higher than 0.7 from the training data set of 72 738 galaxies
(comprising five different morphological classes). We picked up the best threshold
 0.7 with a simple search taking into account the largest accuracy (see, Fig.
4a); other thresholds result in lower separation quality. Within this train-test
split, the test part of training galaxies (9 000) was used to validate the morpho11

logical CNN classifier, and the rest part of the galaxies (63 738) to train CNN
classifier (middle panel, Fig. 3). It allows to understand the CNN ability to
generalize on data it has never seen before, namely on the galaxies, which are
similar to the inference dataset according to their adversarial score.
To train the CNN classifier for the prediction of the classes of fainter and
smaller galaxies, we have added the following transformations of images to the
defined data augmentation procedures (see subsection 3.2):
˜
Ii,j = k × S(Ii,j, m) −127.5
255
(2)
where S(Ii,j, m) is a function changing the size of the image in m times, and
k is an intensity-scaling coefficient.
We implemented the size-changing function as simple zooming out of the
image (into the new image with axes (100 × m) × (100 × m) pixels, where
0 < m < 1), followed by mirror reflection of the image to fill up the missing
100 × (1 −m) pixels along the borders. In turn, the intensity of pixels for each
image was reduced by a factor of 0 < k < 1.
The augmentation procedures we implemented allow us to transform the
image of the galaxy, simulating a decrease in magnitude and size as well as veiling
it as the galaxy image from the inference dataset. For example, applying these
transformations (k = 0.8, m = 0.7) to the 3 000 random images from the training
data set with adversarial score > 0.7, we observed the shift of the adversarial
score distribution towards zero value (see Fig. 4b). The histogram of adversarial
score distribution, especially for lower values, gives a direct confirmation in
the support of such transformations.
This trick with image transformations
improves the accuracy of the result emulating the training galaxies to be more
similar to the galaxies from the inference data set according to the adversarial
scores. In this way, we do not investigate effects caused by different “modalities”
(training / inference); instead, we built a technique to prevent prediction biases.
In other words, we solved the domain adaptation problem but with manually
in-built heuristics (changing angular sizes and intensity of images of training
galaxies).
3.4. CNN five-class morphological classifier
The next step of our pipeline was the morphological classification with CNN
on training galaxy images. The principal difference between our approach and
the existing ones (see, for example, recent works [46, 74, 75, 76]) is the usage of
(third panel, Fig. 3)
1) the pre-defined training-test split through adversarial validation of the
classification accuracy on the inference-like test set, and
2) the specific data augmentation, which allowed us to decrease the difference
 in galaxy images related to the stellar magnitudes between the GZ2 and
inference data sets.
The procedure of training the CNN with the overall accuracy of 89.3% on
the test data set of 9 000 galaxies is described in the Paper II. As for the data
12
Architecture
Accuracy
ResNet-50a
0.821
ResNet-101a
0.832
ResNet-152a
0.826
InceptionV3b
0.937
InceptionResNetV2c
0.962
DenseNet-121d
0.960
DenseNet-169d
0.959
DenseNet-201d
0.966
NASNetLargee
0.929
VGG16f
0.909
Xceptiong
0.956
Table 1: Accuracy scores of backbone models for the five-classes of CNN morphological classification
 on the validation data.Introduction
Massive stars (M >
∼8 M⊙) play a very important role in the life of the
Universe. However the process of their formation is still puzzling in many
respects.
Both theoretical and observational studies of this process face
serious difficulties. The process of formation of massive stars seems to be
more complicated than the formation of low-mass stars, and there are still
many unclear points in it (e.g. McKee and Ostriker, 2007; Zinnecker and
Yorke, 2007; Tan et al., 2014; Motte et al., 2018; Rosen et al., 2020) related
to the fact that nuclear reactions in massive protostars begin much earlier
than they reach the final mass. Radiation pressure can stop further influx of
matter. It is also not entirely clear how to explain the fact that massive cores
do not break up into smaller fragments. Observational studies of HMSF
1
arXiv:2211.15586v1  [astro-ph.GA]  28 Nov 2022
regions are hampered by the fact that they are rare and are located much
farther from us than the dark clouds in which stars of small mass are formed.
The nearest such region is at a distance of ∼500 pc, and typical distances
are several kiloparsecs. Interferometers are required for their detailed study.
Here we present a brief review of observational studies of high-mass star
formation with an emphasis on our own results.
2
Surveys of star-forming regions in the Milky
Way galaxy
Studies of the general characteristics of star-forming regions are based on
surveys of these objects. To date, quite a few such surveys have been carried
out. A good example of such work is the survey of the Galactic plane in the
CO J = 1 −0 line (Dame et al., 2001), which served as the basis for many
further studies. Such a survey gives a general idea of the distribution and
kinematics of interstellar matter, but has a rather low angular resolution and
makes it difficult to identify and study compact star formation regions. For
such problems, surveys of significant parts of the Galactic plane with a much
higher resolution in the continuum and in the lines of some molecules, carried
out with the help of ground-based and space instruments, are very useful.
Among them, one can note ground surveys in the continuum at wavelengths
∼1 mm ATLASGAL (The APEX telescope large area survey of the galaxy
at 870 µm) (Schuller et al., 2009; Csengeri et al., 2014) and BOLOCAM
(Aguirre et al., 2011), as well as the survey in the 13CO J = 1 −0 line
GRS (The Boston University-Five College Radio Astronomy Observatory
Galactic Ring Survey) (Jackson et al., 2006). A lot of useful information
was given by spacecraft operating at wavelengths from the far IR to the near
IR ranges (for example, Spitzer Galactic Legacy Infrared Mid-Plane Survey
Extraordinaire — GLIMPSE Benjamin et al. 2003 and MIPS Inner Galactic
Plane Survey — MIPSGAL Carey et al. 2005, Herschel Pilbratt et al. 2010
infrared Galactic Plane Survey — Hi-GAL Molinari et al. 2016, Wide Field
Infrared Survey Explorer — WISE Wright et al. 2010). The results of these
surveys are now actively used in the study of star-forming regions.
Another type of such work is surveys of samples of objects selected according
 to certain criteria, which may represent various types of star-forming
regions or may be indicators of such regions. Surveys are carried out in the
continuum at millimeter and submillimeter wavelengths, as well as in the
lines of common molecules such as CO, CS, NH3, HCN, HCO+, N2H+ and
some others. As a prominent example of such studies, one can note a series
2
of works by Philip Myers and co-authors on the study of dense cores in dark
clouds, carried out quite a long time ago (Myers et al., 1983; Myers and Benson,
 1983; Myers, 1983; Benson and Myers, 1983; Myers et al., 1988, 1991;
Fuller and Myers, 1992; Goodman et al., 1993; Vilas-Boas et al., 1994; Ladd
et al., 1994; Benson et al., 1998; Vilas-Boas et al., 2000; Caselli et al., 2002;
Myers, 1985; Benson and Myers, 1989; Goodman et al., 1990). As a result
of these works, the main physical characteristics of such cores were determined,
 the chemical composition was studied, and the correlations between
the parameters were studied.
In these dark clouds, stars of low mass form, of the order of the mass
of the Sun and less. Similar work has been carried out and is being carried
out in the direction of HMSF regions. Among the many works on surveys
of such areas, we note a series of our studies that began in the 80s of the
last century on the RT-22 of the Crimean Astrophysical Observatory (Burov
et al., 1988; Zinchenko et al., 1989, 1990) and then continued on various instruments
 worldwide (Zinchenko et al., 1994, 1995; Zinchenko, 1995; Pirogov
et al., 1996; Zinchenko et al., 1997; Lapinov et al., 1998; Zinchenko et al.,
1998, 2000; Pirogov et al., 2003, 2007; Zinchenko et al., 2009; Zinchenko and
Henkel, 2018). In these papers, surveys were made of several dozen HMSF
regions in the lines of such molecules as HCN, HCO+, CS, NH3, N2H+,
HNCO, C18O, SO, etc. An example of such a survey is presented in Fig. 1.
This made it possible to obtain statistical distributions of the main physical
parameters for these objects, in particular, sizes, masses, density, velocity
dispersion. The kinetic temperature of the gas was estimated from the observations
 of NH3 and CH3CCH (Zinchenko et al., 1997; Malafeev et al.,
2005; Malafeev and Zinchenko, 2006).
One of the interesting results was the discovery of a decrease in the average
 cloud density with increasing galactocentric distance (Zinchenko, 1995;
Zinchenko et al., 1998). Similar changes in the properties of the interstellar
gas were also noted in other papers. For example, Sakamoto et al. (1997)
found a strong decrease in the ratio of CO line intensities J = 2 −1 and
J = 1 −0 with distance from the center of the Galaxy, which most likely
indicates a decrease in gas density (and possibly temperature). Such studies
are best, of course, carried out on the basis of observations of neighboring
 galaxies.
Observations of HCN and HCO+ in M31 (Brouillet et al.,
2005) demonstrate a noticeable drop in the intensity ratios I(HCN)/I(CO)
and I(HCO+)/I(CO) with increasing galactocentric distance, which is interpreted
 as a result of changing the excitation conditions of molecules. With
the advent of new tools, such work can give new important results.
3
L. Pirogov et al.: Chemical differentiation in regions of high-mass star formation I.
525
Fig. 1. Continuum 1.2 mm maps (in color) together with CS(5–4) (solid blue contours) and N2H+(1–0) (dashed yellow contours, taken from
Paper I) integrated intensity maps (color figures are available in the online version). Intensity contours range from 10% to 90% of the peak values
with 10% step plus 5% contour (continuum), from 20% to 90% of the peak values with 10% step (CS), and from 30% to 90% of the peak values
with 20% step (N2H+). The CS peak integrated intensities are given in Table 2. The peak continuum fluxes (in Jy beam−1) are: 1.46 (G264.28), 2.32
(G265.14), 7.43 (G268.42), 3.44 (G269.11), 3.34 (G270.26), 4.39 (G285.26), 18.83 (G291.27), 1.64 (G294.97), 3.37 (G316.77), 3.93 (G345.01),
3.39 (G345.41), 12.54 (G351.41). The continuum clumps are marked by numbers as in Table 4. The IRAS point sources are marked by red stars.
The uncertainty ellipses corresponding to 95% confidence level in the IRAS point-source position are also shown. The SEST beam size at the
CS(5–4) frequency is shown on the G 264.28 map.
and line width) are given in Table 2 with the corresponding
1σ errors, as defined by the fits, in parenthesis.
The CS(5–4) and continuum maps were deconvolved into individual
 clumps using our 2D Gaussian fitting program and the
method described in Paper I. No attempts to separate individual
clumps have been made in G264.28, where local emission peaks
of nearly equal intensities are located too close to each other. We
did not process the CS(5−4) map in G267.94 as it had not been
completed. The parameters of individual CS(5−4) clumps, including
 relative coordinates of clump centers, aspect ratios (the
ratios of the extents of the fitted elliptical Gaussians), and deconvolved
 angular (∆Θ) and linear (d) sizes estimated as the geometric
 mean of the extents of the elliptical Gaussians at the
half-maximum intensity level are given in Table 3 (Cols. 2−6).
The clumps that belong to the same object are marked by
numbers.
In Cols. 7 and 8 of Table 3, the CS(5−4) mean line widths
and virial masses are given. For homogeneous sphericallysymmetric
 clumps with no external pressure and no magnetic
field, virial masses are given by:
Mvir(M⊙) = 105 ⟨∆V⟩2 · d,
where ⟨∆V⟩is the CS(5–4) mean line width (in km s−1), defined
 as the weighted average of line widths at different positions
within half-maximum intensity region; d is the CS(5−4) emission
 region size in pc. Virial masses calculated according to the
Figure 1: Continuum 1.2 mm maps (in color) together with CS(5–4) (solid
blue contours) and N2H+(1–0) (dashed yellow contours, taken from Pirogov
et al. 2003) integrated intensity maps. The IRAS point sources are marked
by red stars. The uncertainty ellipses corresponding to 95% confidence level
in the IRAS point-source position are also shown. The SEST beam size at
the CS(5–4) frequency is shown on the G264.28 map. Adopted from Pirogov
et al. (2007).
4
3
The earliest phases of massive star formation
Various criteria can be used to identify the early stages of massive star
formation. Shortly after the appearance of IRAS survey data, Wood and
Churchwell (1989) proposed a method for identifying massive stars embedded
 in molecular clouds (i.e., at a relatively early stage of evolution) by their
emission spectrum in the far IR range (based on the so-called “two-color diagrams”.
 A characteristic spectrum is given by the ultracompact H ii zones
associated with these stars.
Further it was shown that earlier stages can be marked by maser emission
of some molecules (H2O, CH3OH) (Plume et al., 1997; Walsh et al., 1997).
A number of surveys of maser sources in the lines of various molecules,
including ours (Zinchenko et al., 1995, 1998), have been carried out, which
made it possible to determine the main characteristics of molecular clumps
associated with these masers.
A number of authors (e.g. Molinari et al., 1996; Sridharan et al., 2002)
proposed to use approximately the same IR colors criterion, but with the
additional condition of the absence of radio emission in the continuum at
relatively low frequencies (which is usually generated due to bremsstrahlung
of ionized gas). Thus, one can hope to identify objects that are at the stage
preceding the formation of the ultracompact H ii zone.
Samples of objects that meet these criteria have been actively studied,
but it is obvious that in all of them the process of star formation is already
 underway. And one would like to find for massive stars some kind
of pre-stellar cloud, where it has not yet begun. For low-mass stars, such
prestellar objects are dark cold clouds, which are located relatively close to us
(∼100 pc) and are observed in optics as dark dips against the background of
stars. More than 20 years ago, infrared dark clouds were discovered, which
are probably the objects where stars of large mass will be formed in the
future or are already beginning to form.
In much of the infrared range, observations from the Earth’s surface
are practically impossible.
Infrared astronomy began to develop actively
only with the advent of appropriate space facilities. In the mid-1990s, images
 of a significant part of the Galactic plane were obtained in the mid-IR
range. These images revealed a large amount of dark details (Perault et al.,
1996; Egan et al., 1998), which, obviously, were created by fairly dense cold
clouds that absorb background radiation from the disk of the Galaxy. It
was immediately suggested that they are the sought-after massive prestellar
 objects in which stars of high mass can form. In recent years, infrared
dark clouds (IRDC) have been the subject of detailed studies in various
5
wavelength ranges, thanks to which their main physical characteristics and
chemical composition have been determined.
The first molecular observations of infrared dark clouds (in formaldehyde
lines (Carey et al., 1998)) showed that they are far from us – at distances
from 1 to 8 kpc, and their sizes range from 0.4 to 15 pc.
Formaldehyde
excitation analysis gave density (n > 105 cm−3) and temperature (T < 20 K)
estimates.
Further studies in the continuum and in molecular lines made it possible
to refine the values of the physical parameters of the clouds. It was found,
in particular, that their masses are from hundreds to thousands of solar
masses, the H2 column density is from 2 to 10 × 1023 cm−2 (e.g. Rathborne
et al., 2006; Vasyunina et al., 2009; Ragan et al., 2009).
Reliable temperature estimates (10–20 K) have been obtained from observations
 of lines of ammonia (Pillai et al., 2006), which, like a number of
other molecules of the symmetrical top type, is a good indicator of temperature
 in dense interstellar clouds. The linewidths, which are determined by
the dispersion of gas velocities, range from ∼0.5 to ∼3 km s−1 in IRDC (e.g.
Vasyunina et al., 2011). In terms of this parameter, infrared dark clouds
occupy an intermediate position between cold dark clouds of low mass and
warm massive clouds that already contain high-luminosity young stars.
Much attention is paid to the study of the chemical composition of infrared
 dark clouds. Features of this composition may indicate their evolutionary
 status, since this composition must change over time. The results of
these studies are somewhat contradictory so far. Based on very low values
of the abundance ratio CCS/N2H+, Sakai et al. (2008) concluded that infrared
 dark clouds are at a later stage of chemical evolution than prestellar
low-mass clouds. At the same time, Gibson et al. (2009), from the analysis
of data on the abundance of C18O, CS and N2H+, found that the chemical
age of clouds is small and in some cases does not exceed 100 years. Studies
of 15 infrared dark clouds in the lines of 13 different molecules Vasyunina
 et al. (2011) have shown that they are closer in chemical composition
to low-mass prestellar clouds than to massive protostellar objects (clouds
containing young massive stars).
Many Infrared Dark Clouds are filamentous (Schisano et al., 2020). Filamentous
 structures have long been observed and studied in the interstellar
medium (see, for example, reviews in Andr´
e et al., 2014; Myers, 2009). They
are visible in optical images of dark nebulae, in the structure of clouds of
neutral atomic hydrogen observed in the 21 cm line, in molecular clouds of
various types.
In recent years, thanks to the emergence of a large amount of new ob6

servational data, primarily obtained from the Herschel space observatory
(Pilbratt et al., 2010), it has become clear that interstellar filaments play
a key role in the formation of stars (Andr´
e et al., 2014). The formation
of filaments apparently precedes the onset of active star formation, since a
filamentous structure is also observed in clouds where there are no signs of
this process (for example, Polaris Flare – Ward-Thompson et al., 2010).
Studies of filaments at the Herschel observatory were limited to objects
relatively close to us. Subsequently, investigations of filamentous structures
on the scales of the Galaxy were carried out, in particular, based on the
analysis of data from the ASTROGAL survey (Li et al., 2016).
In this
work, about 500 filamentous structures were identified at distances up to
∼12 kpc. To select filaments on extended maps of interstellar clouds, automated
 algorithms such as getfilaments (Men’shchikov, 2013) are usually
used.
The observed filaments exhibit a wide range of physical parameters. At
the same time, a characteristic feature of filaments in clouds close to us is the
constancy of their width (∼0.1 pc) in different objects (Andr´
e et al., 2014).
However, the more distant filaments identified in the Li et al. (2016) survey
mentioned above have, on average, a substantially larger width ∼0.5 pc. At
the same time, much narrower structures with a width of ∼0.035 pc have
also been identified in the Orion Nebula (Hacar et al., 2018). In addition,
some filaments have been found to be composed of many smaller fibers
whose properties vary considerably (Hacar et al., 2013).
Some of these
small filaments are actively star-forming, while others are not.
Almost perpendicular to the main filaments, thinner similar formations
often adjoin, which are called striations. Polarization measurements show
that the magnetic field, as a rule, is oriented perpendicular to the main
filaments and, accordingly, parallel to the striations (Andr´
e et al., 2014). It
is assumed that along these striations there is an influx of substance onto
the filaments. There are even smaller similar formations that can be called
“strands” (Cox et al., 2016).
For the Musca filament studied in detail,
the column density of hydrogen is N(H2) > 2.7 × 1021 cm−2 for the main
filament, N(H2) < 1.8 × 1021 cm−2 for striations, while for strands it takes
intermediate values N(H2) ≈(2 −5) × 1021 cm−2 (Cox et al., 2016).
The radial filament density profile is well described by the Plummer
function:
ρ(r) =
ρc
h
1 + (r/R0)2ip/2 ,
(1)
where ρc is the central density and R0 is the radius of the central flat part.
7
Such a profile is obtained by solving the problem of hydrostatic equilibrium
of an infinite self-gravitating isothermal cylinder (Stod´
olkiewicz, 1963; Ostriker,
 1964).
The theoretical value of p for an isothermal cylinder is 4.
At the same time, observations give values close to 2 (Andr´
e et al., 2014).
The reason for the discrepancies may be the non-isothermal nature of the
filaments. The value of R0 is
R0 =
c2
s
GΣ0
,
(2)
where cs is the speed of sound, G is the gravitational constant, Σ0 is the
surface density (Larson, 1985; Hartmann, 2002).
The gravitational stability of filaments is determined by the amount of
mass per unit length. The critical value of this parameter is
Mline,c = 2c2
s
G .
(3)
Taking into account non-thermal motions, the speed of sound should be
replaced by σtot =
q
c2
s + σ2
NT (Fiege and Pudritz, 2000). Filaments whose
mass per unit length exceeds the critical value fragment and collapse. Jeans
length along the axis is (Larson, 1985; Hartmann, 2002)
λc = 3.94 c2
s
GΣ0
.
(4)
For a more realistic description of filaments, it is also necessary to take
into account the external pressure (Fischera and Martin, 2012). In some
cases, the observations are well described by the model of a pressure-limited
filament surrounded by a low-density shell (Kainulainen et al., 2016).
It was noted above that when the critical value of mass per unit length
is exceeded, the process of its fragmentation can begin to develop in the
filament. Such a phenomenon is actually observed in interstellar filaments at
different scales (for example, Andr´
e et al., 2010; Offner et al., 2014; S´
anchezMonge
 et al., 2014; Beuther et al., 2015; Samal et al., 2015; Kainulainen
et al., 2017; Lu et al., 2018; Ryabukhina et al., 2018). In some cases, there
are signs of longitudinal collapse of the substance in the filaments (Hacar
et al., 2013; Peretto et al., 2014; Hacar et al., 2017; Kirsanova et al., 2017;
Ryabukhina et al., 2018; Ryabukhina and Zinchenko, 2021). Fragmentation
of filaments may be the key to understanding the initial mass function of
stars, since it allows explaining the position of the peak and the shape of
this function (Andr´
e et al., 2010, 2017).
8
An example of our study of the filamentous IRDC G351.78–0.54 is shown
in Fig. 2 (Ryabukhina and Zinchenko, 2021). The total mass of the filament
is estimated at ∼1800 M⊙. The mass per unit length (Mline = 529 M⊙/pc)
is close to the critical value. However, both values represent upper limits.
The presence of several dense clumps along the filament shows that the
process of fragmentation is going on. Six dense clumps are identified in the
N2H+ (3–2) map. All clumps except one appear gravitationally unstable.
A multiline study of the IRDC G351.78–0.54
729
Figure 2. Integrated intensity of the lines 13CO (2–1), 13CO (3–2), C18O (2–1), C18O (3–2), and N2H+ (3–2). The red circles in the lower left corners indicate
the beam size (HPBW).
abundance of N2H+ decreases. Taking into account the uncertainties
in the dust temperature and integrated intensity of the C18O and
N2H+ lines, we find that the N(C18O) uncertainty does not exceed
5 per cent and in the direction of dense clumps with a high signal-tonoise
 ratio it decreases to 3 per cent. Taking into account the negative
feature in the C18O (2–1) observations caused by the emission at the
reference position (Section 2), the column density is underestimated.
Since the integrated intensity of this feature is ∼0.3 K km s−1, the
corresponding column density is 1.5 × 1014 cm−2, while the median
N(C18O) is 6.7 × 1015 cm−2. Hence, the average underestimation
does not exceed 2 per cent. The uncertainty in N(N2H+) does not
exceed 20 per cent in the direction of dense clumps, in other directions
it reaches 50 per cent.
By integrating the column density map of hydrogen we obtain the
total mass of the filament as 1800 ± 50 M⊙. The integration area is
limited by the integrated intensity of the C18O (2–1) line of 5 K km
s−1 (Fig. 1). It roughly corresponds to the signal-to-noise ratio of
about 5 for the most noisy C18O (2–1) spectra.
The part of the filament we are studying has a length of 3.4 pc,
and the mass-to-length ratio Mline = 529 M⊙pc−1. According to
Dewangan et al. (2019), the virial (or critical) line mass for a filament
with non-thermal gas motions is calculated as
Mline,vir =
!
1 +
"σNT
cs
#2$
×
%
16M⊙pc−1 ×
" T
10K
#&
,
(3)
where cs is the sound speed, T is kinetic temperature, and σ NT is the
non-thermal velocity dispersion, which is defined by
σNT =
'
"V 2
8 ln 2 −
kT
30mH
,
(4)
where "V is the C18O line width, k is the Boltzmann constant,
and mH is the mass of a hydrogen atom. The average over the
entire filament C18O (2–1) line width is 2.5 km s−1, and the average
temperature is 18 K. For our filament the critical line mass is
Mline, vir = 512 M⊙pc−1. Taking into account the uncertainties, the
mass-to-length ratio Mline is practically equal to the critical value.
However, under the conditions of a possible falling motion inside the
filament the velocity dispersion shows larger values than under virial
equilibrium, therefore the Mline, vir artificially increases (BallesterosParedes
 et al. 2011). Hence, the presented estimate is the upper limit
of the linear critical mass. On the other hand, the derived mass-tolength
 ratio is also an upper limit since it does not take into account
a possible inclination of the filament. In any case the observations
show that the process of fragmentation is going on.
3.3 Clumps
The GaussClumps algorithm, first proposed in Stutzki & Guesten
(1990), was used to identify molecular clumps. In the position–
position–velocity data cube, the absolute maximum of the emission is
allocated, then a three-dimensional Gaussian is fitted into the position
of this maximum, which is subtracted from the original cube. After
MNRAS 505, 726–737 (2021)
Downloaded from https://academic.oup.com/mnras/article/505/1/726/6273141 by Institute of Applied Physics of the RAS user on 15 November 2021
Figure 2: Integrated intensity maps of IRDC G351.78–0.54 in the lines 13CO
(2–1), 13CO (3–2), C18O (2–1), C18O (3–2), and N2H+ (3–2).
The red
circles in the lower left corners indicate the beam size (HPBW). Adopted
from Ryabukhina and Zinchenko (2021).
Observations show that in some cases the process of star formation proceeds
 faster at the ends of filaments (Beuther et al., 2015; Kainulainen et al.,
2016; Dewangan et al., 2019), which may be due to the acceleration of matter
in these regions (Clarke and Whitworth, 2015).
In many cases, the most active star formation is observed at the intersections
 of the filaments. There are indications that this process may be
initiated by filament collision (e.g. Nakamura et al., 2014; Fukui et al., 2015;
Dewangan et al., 2017). In addition, Myers (2009) drew attention to the
9
fact that many star-forming regions have a structure that can be described
as a “hub” (an object with an increased radial density of matter and an
axes ratio close to unity) and filaments. In this work, a model was proposed
 for the formation of such structures, in which it develops from an
initially inhomogeneous medium of low density, which is compressed into a
self-gravitating layer under the influence of external factors. The filamentous
structure arises under the action of shock waves associated with compression
or gravitational instabilities.
In general, numerous studies show that filaments naturally arise as a result
 of supersonic turbulence and shock waves (e.g. Andr´
e et al., 2014; Inoue
et al., 2018). They can also arise as a result of fragmentation of planar structures
 (for example, shells around H ii zones, old supernova remnants, etc.).
A number of papers consider the mechanisms of formation of “striations”
adjacent to filaments. A recent analysis of several possible mechanisms has
shown that the most probable is the nonlinear interaction of MHD waves
(Tritsis and Tassis, 2016).
4
General structure of HMSF regions
The general structure of HMSF regions is usually very complicated. They
may contain many dense cores, filamentary structures, H ii regions, outflows.
There are numerous investigations of such regions. Here we briefly describe
several regions covered by our studies.
4.1
S187
The S187 H ii region (Fig. 3) at a distance of 1.4±0.26 kpc from photometry
 (Russeil et al., 2007) or ∼0.9 kpc from Gaia DR2 data is surrounded by
a molecular and atomic gas shell (Joncas et al., 1992; Arvidsson and Kerton,
 2011). A number of young stellar objects and molecular masers were
detected towards the shell (Kang et al., 2017; Richards et al., 2012; Engels
and Bunzel, 2015; Valdettaro et al., 2001), indicating ongoing star formation.
The 1.2 mm continuum map and data on C18O, CS, C34S, HCN, H13CN,
HNC, HN13C, HCO+, H13CO+, N2H+ molecular emission are presented by
Zinchenko et al. (2009).
Recently we performed a detailed high resolution study of this region
in the H i line at 21 cm with the Indian Giant Metrewave Radio Telescope
(GMRT) (Zemlyanukha et al., 2022). The achieved angular resolution is
8 arcsec (0.06 pc), which is the highest resolution available of the H i emission
 observations of Galactic regions. Such observations are challenging due
10
Figure 3: Left panel: the structure of the S187 complex. The 1420 MHz
GMRT continuum is in red contours, tracing the ionized gas. Bright red
spots are related to radio galaxies (S187-1(a&b) and S187-2(a&b)). The red
contours near S187-1(a&b) are caused by limited dynamical range.
The
12µm WSSA image is shown in grayscale tracing the dust in shocked gas.
White contours represent SCUBA 850µm emission tracing cold dust in
molecular material. The water maser is marked as a triangle and the OH
masers from Engels and Bunzel (2015) are marked as reversed triangles.
S187 NIRS 1 is shown as a circle and S187 Hα as the star. Right panel:
The distribution of the YSOs near S187. The background image represents
the H i averaged emission. The blue contours represent the C18O emission.
Adopted from Zemlyanukha et al. (2022).
11
Figure 4: Maps of the S255 area at 610 MHz (thin green contours) and at
1.2 mm (thick cyan contours) overlaid on the 8 µm Spitzer image. Adopted
from Zinchenko et al. (2017b).
to a large amount of atomic hydrogen on the line of sight. Main parameters
 (mass, spin temperature) of the atomic gas were determined. It was
found that the atomic shell is highly inhomogeneous (Fig. 3) and contains
∼100 fragments of median mass around ∼1.1 M⊙. The index of the masssize
 power-law relationship is 2.33–2.6, which is close to values for molecular
gas clumps and clouds. Two molecular cores at different stages of evolution
are identified. The data indicate an interaction between the atomic shell
and the molecular core.
4.2
S255
The distance to the S255 star-forming region derived from the annual parallax
 measurements of water masers is 1.78+0.12
−0.11 kpc (Burns et al., 2016). It
looks as a ridge of the molecular and dust emission sandwiched between the
two evolved H ii regions S255 and S257 (Fig. 4.
The NIR observations show that the sources associated with the gas ridge
are younger than the sources outside the gas ridge, which hints at induced
star formation (Ojha et al., 2011). This ridge contains two major clumps,
12
S255IR and S255N (e.g. Wang et al., 2011; Zinchenko et al., 2012). Both of
these clumps represent sites of massive star formation and contain several
dense cores. Detailed studies of these clumps are presented in Zinchenko
et al. (2015, 2018a,b, 2020); Liu et al. (2018, 2020); Zemlyanukha et al.
(2018).
In S255IR the ALMA observations reveal a very narrow (∼1000–1800 AU)
and dense (n ∼3×107 cm−3 assuming the cylindrical geometry) filamentary
structure with at least two velocity components (Zinchenko et al., 2020).
The mass estimated from the continuum emission is about 35 M⊙. Two
star-forming cores are apparently associated with this structure. There are
molecular outflows originating in these cores (see Sect. 5.2). The most massive
 core, S255IR-SMA1, contains a 20 M⊙protostar, which shows signs of
episodic accretion. It is surrounded by a rotating and infalling envelope.
Several new low-mass prestellar cores are discovered.
The S255N clump contains several large fragments at different velocities
 (Zemlyanukha et al., 2018). The central core, S255N-SMA1, is resolved
into two components with significantly different temperatures (∼150 K and
∼25 K). The bipolar outflow is associated with the hot source. It is surrounded
 by a large torus (Sect. 5.2). There are several other cores with very
young outflows in this area.
4.3
W40
The nearby H ii region W40 was investigated in detail by Mallick et al.
(2013); Pirogov et al. (2013). The data include the dust continuum, line
molecular emission and observations of the ionized gas. A clumpy dust ring
is revealed (Fig. 5), which is probably formed by the collect-and-collapse
process due to expansion of the neighbouring H ii region. Nine dust clumps
in the ring have been identified. The distributions of the dust and molecular
emission are very different and a strong molecular chemical differentiation is
observed. Molecular and electron abundances in different parts of the source
are estimated. There are signs of triggered star formation in a part of the
ring.
4.4
W42
The W42 region at a distance of 3.8 kpc contains a rare O-type protostar
W42-MME (mass: 19±4 M⊙). The area around this protostar was investigated
 in various molecular lines and in continuum with the Atacama Large
Millimeter/ submillimeter Array (ALMA), Submillimeter Array, and Very
13
Figure 5: Left panel: the high-resolution 1280 and 610 MHz maps (spatial
resolutions ∼2.4 and ∼5 arcsec, respectively) and the CS(5–4) integrated
intensity map (red, cyan and blue contours, respectively).
Right panel:
Molecular-line integrated intensity maps overlaid on1.2-mm dust continuum
emission (grey-scale). HCN(1–0) (crimson dashed contours), HCO+(1–0)
(blue contours), N2H+(1–0) (red contours) and C34S(2–1) (black contours).
The figures are from Pirogov et al. (2013) where the other symbols are
explained.
14
Large Array at a high angular resolution of ∼0.
′′3–3.
′′5 (Dewangan et al.,
2022).
The data show no H ii zone around W42-MME, which confirms its protostellar
 nature. There is an elongated structure with a signature of Keplerian
 rotation in the center, associated with the bipolar molecular outflow
observed in the CO and SiO lines. However the angular resolution is insufficient
 to resolve the probable disk. Several knots of the SiO emission
hint at episodic ejections.
The temperature estimates from the CH3CN
observations (∼220 K) indicate the presence of a hot core. The core hosting
 W42-MME appears to gain mass from the envelope and also from the
immediate surrounding cores.
5
Prestellar and protostellar cores, disks and bipolar
 outflows
5.1
Properties of dense cores
Ultimately, the process of star formation occurs in the so-called dense cores,
which can be formed, for example, as a result of the fragmentation of interstellar
 filaments. In Section 2 we described the search and study of such
cores. At present, a certain classification of such cores has been developed,
based on the data on the presence of (proto)stellar objects in them and
on their spectral characteristics. It has been developed in most detail for
cores in low-mass star formation regions. They are usually divided into several
 main categories: starless, prestellar, protostellar (di Francesco et al.,
2007). Prestellar, unlike stellarless ones, are gravitationally bound and can
later form a protostar. In protostellar, such a protostar already exists. For
protostellar cores, there is a well-established division into 4 classes - from
Class 0 to Class III, based on their spectral characteristics and obviously
corresponding to the evolutionary sequence (Lada, 1987; Andre et al., 1993,
2000).
A lot of effort has gone into searching for massive prestellar cores (with
a mass of ∼30 M⊙within a radius of 0.03 pc) that could form a massive
protostar. The discovery of such cores could serve as an argument in support
of the monolithic collapse model during the formation of massive stars. So
far, only a few candidates for such cores have been discovered (Louvet,
2018). The absence of a noticeable number of massive prestellar cores can
be explained by their short lifetime, on the order of free fall time.
Many works are devoted to the study of statistical distributions of the
15
parameters of cores. In particular, the mass distribution of low-mass prestellar
 cores is very similar to the initial mass function of stars (Andr´
e et al.,
2010). This indicates an approximately constant star formation efficiency
across the mass spectrum. The core mass function itself can be explained by
filament fragmentation, taking into account turbulence (Andr´
e et al., 2017).
Of great importance for understanding the processes in interstellar clouds
are the so-called Larson’s laws, obtained by him from the analysis of observational
 data in the early 80s (Larson, 1981). The first one is the relation
between velocity dispersion and size, σ ∝Lα, where α ≈0.5. The second
law says that clouds are gravitationally bound, the virial parameter αvir ∼1.
According to the third law, the column density in clouds is approximately
the same. These relations are not independent, each of them follows from
the other two. These ratios are most likely a consequence of turbulence in
interstellar clouds.
Larson’s laws were originally derived for giant molecular clouds and their
applicability to dense clumps was investigated separately. It was found in
Fuller and Myers (1992); Caselli and Myers (1995) that the Larson relation
between nonthermal velocity dispersion and size is well satisfied for dense
cores in dark clouds.
As for massive cores, the results here are rather contradictory. Caselli
and Myers (1995) derived the exponent for (σ −L) α ≈0.2. Plume et al.
(1997) did not find any relationship between velocity dispersion and size,
while Pirogov and Zinchenko (1998) obtained the exponent α ≈0.5.
The radial density profile for cores in dark clouds is well described by the
Bonnor-Ebert model, with starless cores close to the Bonnor-Ebert critical
sphere, and protostellar cores corresponding to the supercritical case (Alves
et al., 2001; Kirk et al., 2005; McKee and Ostriker, 2007). Similar results
were also obtained for massive cores (Pirogov, 2009).
The radial gas temperature profile for several massive cores was investigated
 by Zinchenko et al. (2005); Malafeev and Zinchenko (2006) on the
basis of CH3CCH observations. They found that it can be fitted by a power
law with –0.3 ... –0.4 indices. This dependence is in agreement with the theoretically
 expected one for a centrally heated optically thin cloud. The dust
temperature profiles were analyzed recently by Pirogov (2022). He found
that they are also consistent with heating by the central source.
5.2
Observations of disks and bipolar outflows
At present, it is generally accepted that the formation of stars with a mass
of the order of the sun occurs by disk accretion of matter, accompanied by
16
bipolar outflows. There are observations of a large number of disks in low
mass star formation regions (e.g. Andrews and Williams, 2005, 2007). There
are also observations of disk candidates or toroidal structures around several
dozen massive protostars (Beltr´
an and de Wit, 2017), although convincing
cases are still very rare. High-velocity bipolar outflows are observed everywhere.
 A detailed review of their characteristics and models is presented in
Arce et al. (2007).
Of particular interest are observations of disks and outflows in HMSF
regions, since they allow a better understanding of the mechanism of formation
 of such stars. This mechanism is still unclear and is actively debated
(e.g. McKee and Ostriker, 2007; Tan et al., 2014). The main models discussed
 are the monolithic collapse of a massive dense core and competitive
accretion.
Quite exotic models are proposed, in which massive stars are
formed by merging stars of smaller mass (Bonnell et al., 1998).
Recently, several events have been recorded that support disk accretion
as a mechanism for the formation of stars with masses up to at least ∼20 M⊙.
The first two are outbursts of the luminosity of objects NGC6334I-MM1
(Hunter et al., 2017) and S255IR NIRS3/SMA1 (Caratti O Garatti et al.,
2017; Liu et al., 2018). They were accompanied by maser bursts (Fujisawa
et al., 2015; Moscadelli et al., 2017; Zinchenko et al., 2017a; Hunter et al.,
2018). These events have been interpreted as the result of episodic accretion
 of matter onto a central massive protostar, similar to that observed in
the formation of low-mass stars, but on a much larger scale. This roughly
corresponds to some theoretical models of fragmented disks around massive
protostars (Meyer et al., 2017).
Another example of a disk-outflow system around a massive YSO, which
shows signs of episodic accretion, is the O-type protostar W42-MME (Dewangan
 et al., 2022).
For S255IR NIRS3/SMA1, modeling with radiative transfer calculations
the kinematics of the CH3CN gas shows that the CH3CN emission is best
described by a flattened rotating envelope with infalling motion (Liu et al.,
2020). A mass infall rate of a few ×10−4 M⊙yr−1 is derived. This object
drives a fast collimated jet and a molecular outflow with a wide opening
angle, surrounded by dense walls observed in the C34S line (Zinchenko et al.,
2020). There is another outflow from the nearby SMA2 core. The large-scale
view of these outflows is presented in Fig. 6.
A combination of a fast jet and a slower outflow has been rarely observed
in HMSF regions (e.g., Torrelles et al., 2011), while it is known in low-mass
stars (e.g., Arce et al., 2007) and theoretical models of such event have
been developed. In addition to S255IR NIRS3/SMA1, another example of
17
Figure 6: Maps of the CO(3–2) high velocity emission as observed with
the IRAM-30m telescope (blue and red thick contours) in the S255IR area
overlaid on the continuum image at 0.8 mm. The thin contours show the
SMA maps. The dashed line indicates the axis of the jet (P.A. = 67°). The
orange contours show the N2H+(3–2) integrated line emission obtained by
combining the SMA and 30m data. The cross marks the position of the
high-velocity dense clump.
The 30m beam and the SMA beams for the
CO and N2H+ observations, respectively, are shown in the lower left corner
(from left to right) Adopted from Zinchenko et al. (2015).
18
such combination was discovered recently in MYSO G18.88MME (Zinchenko
et al., 2021). The gas density in the fast component is very high since a
rather strong HC3N J = 24−23 emission is observed in the high velocity gas.
The critical density for this transition is ∼3 × 106 cm−3. Both components
seem to be rotating and, if this interpretation of the transverse velocity
gradient is correct, the specific angular momentum for the fast component
is very high, ∼104 AU km s−1.
Rotating structures around very massive stars may represent toroids (e.g.
Cesaroni et al., 2007; Beltr´
an et al., 2011; Beltr´
an and de Wit, 2016). A large
torus with the inner radius of 8000 AU and the outer radius of 12000 AU was
identified in the S255N region by Zemlyanukha et al. (2018). They argue
that it plays an important role in the process of mass accumulation by the
central protostar.
6
Chemistry in high-mass star-forming regions
6.1
Chemical differentiation
Maps of star-forming regions (and HMSF regions in particular) in lines of
different molecules are frequently very different. Although these differences
can be partly caused by different excitation of these molecules and opacity
effects, in most cases they reflect variations of relative molecular abundances.
This molecular chemical differentiation can be related to variations of the
physical parameters and to evolution of the chemical content with time. Examples
 of such differentiation in our observations are presented in Zinchenko
et al. (2005, 2009, 2011, 2018b, 2022); Lintott et al. (2005); Pirogov et al.
(2007, 2013).
In particular, it was found that the CS emission correlates well with the
dust continuum emission, while the N2H+ intensity drops towards the CS
peaks (associated with luminous IR sources) for most of the HMSF regions,
which can be due to an N2H+ abundance decrease (Pirogov et al., 2007).
A drop of the N2H+ abundance towards the luminous IRAS source in the
filamentary IRDC G351.78–0.54 was reported recently by Ryabukhina and
Zinchenko (2021). Zinchenko et al. (2009) found that the abundances of CO,
CS and HCN are more or less constant, while the abundances of HCO+, HNC
and especially N2H+ strongly vary in HMSF regions. They anticorrelate
with the ionization fraction and as a result decrease towards the embedded
YSOs. For N2H+ this can be explained by dissociative recombination to be
the dominant destroying process.
19
A strong chemical differentiation in the W40 region (Sect. 4.3) was reported
 by Pirogov et al. (2013). The CS abundance is enhanced towards the
eastern dust clump 2, while the NH3, N2H+ and H13CO+ abundances are
enhanced towards the western clumps. HCN and HCO+ do not correlate
with the dust, probably tracing the surrounding gas.
6.2
Deuteration
The effect of deuterium fractionation in dense interstellar clouds (i.e., an
increase of the relative abundance of deuterated molecules) has been investigated
 for a long time already. It is explained by the exothermicity of the
reactions of replacing a proton with deuteron in molecules, which underlie
the chains of the chemical reactions leading to the formation of most other
molecules, at first H+
3 (e.g. Roueffet al., 2007). In addition, at low temperatures,
 freezing of molecules which destroy H2D+, in particular CO, on
dust grains is important, as well as the decreased ionization degree which
reduces the recombination rate of H2D+.
This effect is temperature dependent and has been mostly investigated
in cold clouds.
however recent studies show that it is rather efficient in
warmer clouds, where massive stars form (e.g. Gerner et al., 2015). In order
to investigate it in HMSF regions in more detail we performed a survey of
about 50 such regions in the lines of deuterated molecules at 3–4 mm with
the 20-m Onsala radio telescope (Trofimova et al., 2020). The J = 1 −0
transitions of DCN, DNC, DCO+, N2D+ and the ortho-NH2D 111 −101
line were observed. DCO+, DCN, DNC and NH2D were detected in about
1/3 of the observed sources, while N2D+ was only seen in two. The dependencies
 of the abundances of these molecules on temperature and velocity
dispersion were analyzed taking into account data represented by upper and
lower limits. A statistically significant decrease of the DCO+ abundance
with increasing temperature was found, while the DCN abundance remains
nearly constant. There is a noticeable decrease of the DCO+ abundance
with increasing line width. The DCN/HCN ratio is ∼10−2 for the sources
detected in the DCN line and remains nearly constant in the temperature
range 15 −50 K. The NH2D/NH3 ratio also remains practically constant
(∼10−2) in this temperature range (Trofimova et al., in preparation), which
contradicts the chemical model for ammonia deuteration presented in Roueff
et al. (2005), predicting its drop to ∼2 × 10−3 at 50 K.
Later several sources were mapped in these lines and in the lines of higher
transitions of these molecules at 2 mm with the 30-m IRAM radio telescope
(Zinchenko et al., 2022). These maps show significant differences between
20
distributions of the targeted molecules (see an example in Fig. 7).
Figure 7: Maps of L1287 in the DCN, DCO+ J = 2 −1 and NH2D 111 −101
lines (from left to right) obtained with the 30-m IRAM radio telescope.
The contours represent the H2 column density. The plus sign indicates the
position of the IRAS source. The telescope beam is indicated in the lower
left corner. Adopted from Zinchenko et al. (2022).
In general, the DCN peaks are observed towards the temperature peaks,
which coincide with locations of luminous IR sources, while other deuterated
 molecules trace colder regions. We derived the gas volume density and
molecular column densities from the J = 1 −0 and J = 2 −1 transitions of
DCN, DNC and DCO+ by non-LTE modeling with RADEX. Then, deuteration
 degrees for these species were obtained. The deuteration degrees for
HCO+ and HNC drop with increasing temperature, while for HCN it is more
or less constant.
7
Conclusions
Studies of high mass star formation remain a hot topic of astrophysical research.
 There are many open questions in this area and the general scenario
of this process is still under debate. New facilities provide an inflow of new
important data, which creates good prospects for new discoveries.
This research was partly supported by the IAP RAS state program 00302021-0005
 and by the Russian Science Foundation grant No. 22-22-00809
(Sect. 6).
INTRODUCTION
The search for molecules in massive outflows is partly motivated
by the observed enhancement of certain molecules within shocked
regions of well known low-mass outflows and their particular shockinduced
 chemistry. The prototype among these objects is the outflow
driven by the low-mass protostar L1157-mm (Bachiller et al. 2001),
which has revealed a rich chemistry induced by shocks. Inhabiting
this scenario, large molecules have also been observed, in particular
those formed by at least six atoms, known as Interestellar Complex
Organic Molecules (iCOMs; van Dishoeck & Blake 1998; Lefloch
et al. 2017). The presence of iCOMs tracing shocked regions suggests
a relation between the shocks and iCOM formation or desorption
(Lefloch et al. 2017). The proposed two mechanisms to explain the
abundances of iCOMs in several interstellar environments are dust
grain chemistry and warm gas-phase reactions (Garrod & Herbst
2006; Taquet et al. 2012).
A recent systematic study of the intermediate- to high-mass protostellar
 object IRAS 20126+4104 (Palau et al. 2017), indicates that
iCOMs in this source may arise from the disc and dense/hot regions
along the outflow. In fact, the abundances of some iCOMs show an
★E-mail: sergio.rojas@inaoep.mx
enhancement at the outflow positions. iCOM enhancement has also
been related to shocks in the accretion disc of HMSFR G328.25510.5321,
 a pre-Hot Core source (Csengeri et al. 2019a,b; Bouscasse
et al. 2022). Recently, a sample of 11 massive protostars was investigated
 by means of single-dish mapping observations, revealing
iCOM lines with faint broad profiles possibly related with large-scale
low-velocity outflows (Rojas-García et al. 2022). In the present paper,
we extend the study of iCOMs from massive outflows reporting the
high-angular resolution observations of a prominent outflow system
within the NGC6334 giant molecular cloud.
This paper is organized as follows: section 2 describes physical
parameters obtained from the literature of G351.16+0.70. Section 3
describes our observations and the ancillary surveys used in our analysis.
 In section 4 we describe the LTE modeling used to catalog the
observed iCOMs along with the strategy to look for their emission
related to outflows. Section 5 describes the integrated emission (moment
 0) and velocity field (moment 1) maps for the more elongated
iCOM emissions. Additionally, we compare our computed iCOM
abundances with reported literature values, and spanning a range of
star formation regimes, from low to high mass. Finally, section 6
presents a summary and the conclusions of this work.
© 2015 The Authors
arXiv:2303.02527v1  [astro-ph.GA]  4 Mar 2023
2
O. S. Rojas-García et al.
2 THE SOURCE
G351.16+0.70 (G351, hereafter) is a relatively well-studied source,
especially at infrared and centimeter wavelengths. It is related to the
infrared source NGC 6334 V (McBreen et al. 1979; Kraemer et al.
1999a), with a bipolar reflection nebula (likely related to a bipolar
outflow driven by an unidentified, possibly massive, protostar (e.g.
Chrysostomou et al. 1994; Simpson et al. 2009)), with a B-type zeroage
 main sequence and a massive embedded Young Stellar Object
(YSO) (Hashimoto et al. 2007). It has been cataloged as an Extended
Green Object (EGO) in the study of Chen et al. (2013). This Infrared
(IR) Nebula had been associated with four IR cores (Simon et al.
1985; Kraemer et al. 1999b), but after high-resolution polarimetric
observations, Hashimoto et al. (2007) explain that these IR sources
could be explained with only three YSOs and two massive outflows.
This EGO has a bright core of 𝐿∼105𝐿⊙(Loughran et al. 1986)
and is located at a distance of 1.3 ± 0.3 kpc (Chibueze et al. 2014),
with a 𝑉𝐿𝑆𝑅of −5.65 ± 0.65 kms−1 (Alvarez et al. 2004). Fischer
et al. (1982) reported a high-velocity 12CO outflow coming from an
embedded OB star; this was later reinforced by the combined analysis
of mid-IR, far-IR, and radio-continuum observations of Harvey &
Wilking (1984); Hashimoto et al. (2007).
Other evidence for the existence of a massive protostar includes a
photo-dissociated region (e.g. Burton et al. 2000), CO high-velocity
emission tracing a complicated structure, suggesting up to three outflows
 (Juárez et al. 2017), and several previous studies suggesting that
G351 harbors sources at several stages in the formation of massive
stars (Fischer et al. 1982; Harvey & Wilking 1984; Kraemer et al.
1999b; Hashimoto et al. 2007).
3 OBSERVATIONS, DATA REDUCTION, AND ANCILLARY
DATA
In this study, we used observations of two published surveys, the
Spitzer Galactic Legacy Infrared Midplane Survey Extraordinaire
(GLIMPSE1) and the APEX Telescope Large Area Survey of the
Galaxy (ATLASGAL2), along with our own observations with the
Submillimeter Array (SMA3).
3.1 Submillimeter Array
Our observation was carried out on May 11 of 2011, pointing toward
G351 (R.A 17:19:57.70, Dec -35:57:50.0 J2000) with the SMA, a
facility of the Smithsonian Astrophysical Observatory, on Mauna
Kea, Hawaii.
We used the SMA compact configuration, with baselines ranging
from 16.4 m to 77.0 m. The 230 GHz receiver was configured in the
8 GHz Dual Rx mode, and tuned to 217.105 GHz for a simultaneous
 SiO (5-4) and CO (2-1) observation. The bandwidth coverage
goes from 216.75 to 220.75 in the lower sideband (LSB) and from
228.75 to 232.75 GHz in the upper sideband (USB), and has a spectral
 resolution of ∼812 KHz (∼1.1 kms−1), with a mean rms of
90 mJy beam−1channel−1. At these frequencies, the primary beam
size (𝜃𝐻𝑃𝐵𝑊) of each 6 m diameter antenna is ∼54′′. The data is
currently available for public use in the SMA archive4. The visibility
 data were calibrated using the MIR software package, which was
1 https://irsa.ipac.caltech.edu/data/SPITZER/docs/irac/
2 http://atlasgal.mpifr-bonn.mpg.de/cgi-bin/ATLASGAL_DATABASE.cgi
3 https://lweb.cfa.harvard.edu/sma/
4 https://lweb.cfa.harvard.edu/cgi-bin/sma/smaarch.pl
originally developed for the Owens Valley Radio Observatory (Scoville
 et al. 1993) and adapted for the SMA5. The absolute flux density
scale was determined from observations of Neptune. A pair of nearby
compact radio sources, 1626-298 and 1802-396, were used to calibrate
 the relative amplitude and phase. We used 3C279 to calibrate
the bandpass.
The image map conversion from UV visibility data was conducted
using the Robust weighting method, through INVERT task in the
Miriad software. This weighting is a compromise between Natural
and Uniform weightings and is commonly used to image faint extended
 emission, therefore applicable to the outflow nature of our
source, to avoid the loss of extended emission and also get good
suppression of the side lobe contribution. The functional parameters
 of this weighting were defined as follows: Tapering of the
data (FWHM)= 1′′, Suppression area (SUP)= full coverage of the
map, Robust parameter (Robust)= 2, Visibility weight= 1/𝜎. After
 this inversion, we obtained a map with an angular resolution of
𝜃𝑠𝑦𝑛𝑡ℎ= 5.3′′ × 3.6′′ with a position angle of 74.1◦.
During the image deconvolution process, we smoothed the spectral
resolution to 2.2 kms−1 (two channels wide), to reduce our RMS
level to 68 mJy beam−1channel−1. We take this conservative value
considering to keep good spectral resolution to avoid blending in the
emission lines but improving the signal to noise ratio, as we expected
that wing profile features were weak. To convert the flux density (Jy)
to 𝑇𝑚𝑏, we used the conversion factor obtained from the IMSTAT
miriad task for each datacube (∼1.25𝐾/(𝐽𝑦/𝑏𝑒𝑎𝑚)).
3.2 Continuum observations at 870𝜇m
Dust continuum maps at 870𝜇m were obtained from the ATLASGAL
survey (Schuller et al., 2009), through The ATLASGAL database
Server, that provides FITS format maps with a size of 5x5 arcmin
centered on the peak continuum source. The details of these survey
observations are presented in Schuller et al. (2009).
3.3 Spitzer IRAC
Images of 3.6𝜇m, 4.5𝜇m and 8.0𝜇m IRAC bands, in the framework of
the GLIMPSE survey, were retrieved from the NASA/IPAC Infrared
science data archive. We used the post-basic calibrated data (BCD)
images for our study. The mean FWHM of the point spread functions
are 1.66′′, 1.72′′, and 1.98′′ for bands 1, 2, and 4, respectively.
4 XCLASS LTE MODELING IMPLEMENTATION
For our spectral line analysis we take the emission spectrum of a single
 synthesized beam pointing (𝜃𝑠𝑦𝑛𝑡ℎ= 5.3′′ × 3.6′′) at the brightest
 core position (Ra 17h 19m 57.373s; Dec -35d 57m 52.00s), and,
from the lower to the upper sideband we searched for line emission
included in the XCLASS (Möller, T. et al. 2017) molecular database6
(CDMS/VAMDC) by means of their GetTransitions() task. We listed
all molecules within a 𝑉𝐿𝑆𝑅maximum offset of ±2 kms−1 and a
𝑇𝑅𝑜𝑡from 10 to 950 K and visually selected molecular candidates
considering their frequency coincidence, upper state energy, and line
velocity offset.
To reinforce our line catalog, we implemented an LTE synthetic
modeling employing the XCLASS task myXCLASSFit(). The grid
5 https://lweb.cfa.harvard.edu/∼cqi/mircook.html
6 https://xclass.astro.uni-koeln.de/
MNRAS 000, 1–13 (2015)
iCOMs in outflows from G351.16+0.70
3
was computed with T𝑅𝑜𝑡(rotational temperature in K), 𝑁𝑡𝑜𝑡(total
column density in cm−2), 𝑉𝑤𝑖𝑑𝑡ℎ(velocity line width in km s−1) and
𝑉𝑜𝑓𝑓(velocity offset in kms−1) as free parameters.
The T𝑅𝑜𝑡were limited from 10 to 900 K, the 𝑉𝑤𝑖𝑑𝑡ℎwent from 1
to 7 kms−1 for the narrow emission lines and from 5 to 15 kms−1 for
the wider ones. The 𝑁𝑡𝑜𝑡values varies with the species, with lower
and higher limits of 1×1013 and 1×1017 cm−2, according to their
extreme reported values (Csengeri et al. 2019a; De Simone et al.
2020).
To set the velocity offset, we take the velocity of the core tracer
CH3OH. As we see an asymmetrical distribution of the peak of its
lines we take the outer values of 𝑉𝑜𝑓𝑓= −3.8 to 2.2 kms−1 away
from the 𝑉𝐿𝑆𝑅.
Finally, the source size parameter was fixed to 5′′, as this is the
spatial extent covered by the 𝜃𝑠𝑦𝑛𝑡ℎof our data and the emission fills
the beam, therefore we could assume a beam filling factor Ω𝑆/Ω𝐴=
1.
The resulting physical parameters were found computing an algorithm
 chain, consisting of a particle swarm optimization method
named Bees (Pham et al. 2005), linked to the Levenberg-Marquardt
method (Marquardt 1963), an optimization of Gauss-Newton and
Descendent Gradient methods (Möller, T. et al. 2017).
The Goodness of fit between our models against the observed
spectra was tested by a classic 𝜒2 test. Using the number of channels
in each bandwidth as our degree of freedom, we computed a Critical
𝜒2 corresponding to a significance level of a p-value = 0.05 and set it
as our goal. All of our models have successfully passed this threshold,
strengthening our line classification. Illustratively, we show a plot of
our computed modeled spectra over-plotted on the observed one
in Figure 1. In the lower part of the plot we show the residuals
(𝑒= 𝐼𝑚𝑜𝑑𝑒𝑙−𝐼𝑜𝑏𝑠).
After the species identification, we looked for broad iCOM emission
 and computed the moment 0 and moment 1 maps in the stronger
emission lines in order to find outflow tracers considering their elongated
 spatial extent.
5 RESULTS
5.1 The structure of G351: envelope, cores and outflows
5.1.1 Mid-Infrared emission
Considering the GLIMPSE three color images presented by
Cyganowski et al. (2008, blue: 3.6𝜇m, green: 4.5𝜇m, red: 8.0𝜇m)
we infer a partially bipolar structure with the emission showing a
green excess, oriented in the east-west direction with a very clear
bow shock structure in the western lobe (Figure 2). This structure is
located inside a region that is dark at 8𝜇m and was previously shown
in Juárez et al. (2017).
Additionally, a collimated structure is seen in the 8𝜇m image, but
pointing towards a slightly different direction to the 4.5𝜇m bowshock
 (see Fig. 2). This may indicate that either the east-west outflow
is precessing or the collimated 8𝜇m structure is tracing an outflow
different to the one that produced the 4.5𝜇m bow-shock. Also, at
the tip of this collimated structure there is a compact 8𝜇m emission
peak, which coincides with a dust continuum core (see below).
5.1.2 Millimeter dust continuum: envelope and cores
The continuum millimeter emission from G351 is presented in Fig
3 over the 3 color composite GLIMPSE image. The 1.4 millimeter
Table 1. Parameters of the 1.4 mm continuum two main peaks obtained using
a Gaussian fit by imfit task in miriad.
Component 1
Component 2
Peak intensity (Jy/beam)
0.85±0.08
0.56±0.04
Total integrated flux (Jy)
1.77±0.18
1.45±0.11
R.A. (J2000)
17ℎ19𝑚57.41𝑠
17ℎ19𝑚57.73𝑠
DEC (J2000)
−35◦57′52.3′′
−35◦57′52.27
Deconvolved Major axis (arcsec)
4.1±0.97
4.9±1.15
Deconvolved Minor axis (arcsec)
3.4±0.53
4.3±0.81
Deconvolved Position angle (degrees)
-46.3
-7.2
continuum shows at least two peaks that are separated by a few arcsec,
 and agrees with the two confirmed cores by Hashimoto et al.
(2007); Juárez et al. (2017). Its extended emission is seen mainly
toward the north of these continuum peaks. The 1.4 mm emission
coincides with peak contour at 870 𝜇m and both peaks are very
close to the brightest core KDJ4. However, the extended emission
at 870𝜇m is not seen in the 1.4 mm continuum image, but this may
be because this emission is outside the primary beam along with the
change in sensitivity for these observations. In Table 1 the results of
Gaussian fits to the two peaks at 1.4 mm, component 1 and 2, are
presented.
5.1.3 High-Velocity and Extremely High-Velocity emission in G351
We detected CO (2-1) emission going from ∼−65 to +27 km s−1,
which therefore reaches the classification of an Extremely High Velocity
 outflow (EHV: |𝑉𝑀𝑎𝑥−𝑉𝐿𝑆𝑅| ∼65 km s−1, Tafalla et al.
2010). Figure 4 shows the CO (2-1) emission integrated over the
high-velocity wings (blue: -65.0 to -55.0 km s−1, red: +17.0 to +27.0
km s−1), overlaid on the three color GLIMPSE image. The red- and
blue-shifted wings are oriented in a north-south direction, with the
outflow center closer to continuum component 2 than to component
1, i.e. located ∼6′′ to north-east from the core KDJ4 (Kraemer et al.
1999b) and coinciding with the near- to far-IR core WN-A2. The
spatial extent of this emission is ∼22.6×103 AU. This size and an
assumed constant velocity of 60 km s−1 suggets a dynamical age of
𝑡𝑑𝑦𝑛= 1800𝑦𝑟.
We also detected emission at High Velocities employing the highdensity
 tracer 13CO (2-1) (HV: |𝑉𝑀𝑎𝑥−𝑉𝐿𝑆𝑅| ∼35 km s−1 Tafalla
et al. 2010). This outflow seems to emerge from the core KDJ4
(Kraemer et al. 1999b) and nearly follows the east-west path presented
by Juárez et al. (2017), as it shows a P.A. of 155.4◦, and is spread
away for ∼23.2×103 AU with an observed maximum velocity of
|𝑉𝑀𝑎𝑥−𝑉𝐿𝑆𝑅| ∼20 kms−1. Taking these values and following
the same assumptions as before, this object has a dynamical age of
𝑡𝑑𝑦𝑛= 5500𝑦𝑟. Figure 4 shows a labeled scenario of G351 including
both the CO (2-1) EHV and the 13CO (2-1) HV outflow.
The SiO (5-4) emission was detected in a narrower velocity range
than the CO (2-1) emission but still having a blue-shifted component
of HV (blue: -23.2 to -18.0 km s−1, red:-2.4 to +0.2 km s−1). The
velocity integrated emission map is shown in Fig 5; it shows blue
shifted emission that agrees with the P.A. of the HV outflow traced
by 13CO. Nevertheless, the red-shifted emission shows a completely
different orientation than the other red-shifted emissions, but seems
to follow the blue shifted HV of 13CO. Thus, the interpretation of the
SiO emission is not straightforward, but it is possible that it traces
an additional outflow. In fact, the red- and blue-shifted SiO emission
has a similar sky position with the southern region of the converging
flow traced by H13CO+ (Juárez et al. 2017), but in this case at lower
velocities (blue: -9.2 to -7.1 km s−1, red:-5.0 to -2.9 km s−1).
MNRAS 000, 1–13 (2015)
4
O. S. Rojas-García et al.
Figure 1. G351 spectrum with identified iCOMs (labeled) towards the brightest core KDJ4 and their corresponding fit modeling using XCLASS. The Black
solid line shows the observed spectrum, the Orange solid line shows the modeled spectrum obtained using XCLASS. In the lower subplot, we show the residuals
(𝑒= 𝐼𝑚𝑜𝑑𝑒𝑙−𝐼𝑜𝑏𝑠).
Figure 2. The 4.5 𝜇m (green contours) and 8.0𝜇m emission (grey scale and
red contours) in G351. Contour spacing and first contour is 10% of the flux
peak (2135 and 4653 MJy sr−1, for 4.5 𝜇m and 8.0 𝜇m, respectively). Arrows
show the axes of the two possible ejection events. Also indicated by an arrow
is the bow-shock structure.
Previous studies have shown differences between the structures
traced by CO and SiO. Examples of similar cases include the OrionS
 region (Zapata et al. 2006) and IRAS 05358+3543 (Beuther et al.
2002), which were also observed with interferometers. Apart from
observational effects such as spatial filtering, the difference between
the SiO and CO outflow emission can be attributed to shock chemistry
effects (Gusdorf et al. 2008). For example, from shock models in lowmass
 systems it is known that the shock velocity required to form
SiO may not be reached in all outflows (Gusdorf et al. 2008). In
addition, observational evidence in low-mass outflows shows that
evolved outflows do not present prominent SiO emission (Bachiller
1996). However, it is important to point out that models to explain
the SiO emission in massive systems are scarce, and therefore it is
Figure 3. Map of the continumm emision towards G351. The red contours
show the 1.4 millimeter continuum emission, whereas the green contours
show the 870 𝜇m emission. In both contour maps the first contour starts at
20% of the peak emission with a contour spacing of 10%. The background
shows the 3 color mid-IR image from Spitzer.
not obvious whether a similar explanation as in low-mass systems
can be applied to massive outflows (Leurini et al. 2013).
5.1.4 Low-Velocity emission in G351
In our interferometric observations, emission at Low Velocity in CO
(2-1) was not detected (LV: |𝑉𝑀𝑎𝑥−𝑉𝐿𝑆𝑅| ∼10 km s−1 Tafalla et al.
MNRAS 000, 1–13 (2015)
iCOMs in outflows from G351.16+0.70
5
Figure 4. G351 Integrated map of the two bipolar outflows traced by 12CO
(EHV) and 13CO (HV). The star markers show the near- to far-IR confirmed
cores by polarimetric observations (Kraemer et al. 1999b; Hashimoto et al.
2007). The background color image is a three band composite for 3.6, 4.5,
and 8.0𝜇𝑚, coded as blue, green, and red, respectively (Cyganowski et al.
2008). The blue and red contours show the blue- and red-shifted Extremely
High Velocity outflow (|𝑉𝑀𝑎𝑥−𝑉𝐿𝑆𝑅| ∼60 kms−1) traced by 12CO.
Correspondingly, the sky blue and orange contours display the blue- and
red-shifted emission for High-Velocity outflow traced by 13CO (|𝑉𝑀𝑎𝑥−
𝑉𝐿𝑆𝑅| ∼20 kms−1). Contour spacing is 3𝜎and first contour is 6𝜎.
Figure 5. G351 Integrated map of the outflow wings traced by SiO (5-4)
emission. Contour spacing and first contour is 4𝜎(𝜎=0.199 and 0.174
Jy beam, SiO blue-shifted and red-shifted, respectively). The background
color image is three bands composite for 3.6, 4.5, and 8.0𝜇𝑚, coded as
blue, green, and red, respectively (Cyganowski et al. 2008). The blue and
red contours shows the blue- and red-shifted HV outflow traced by SiO
(|𝑉𝑀𝑎𝑥−𝑉𝐿𝑆𝑅| ∼20 kms−1).
2010), but this is possibly due to a combination of spatial filtering
and contamination from the diffuse emission that hides the CO (2-1)
low velocity emission. In general, we have noted missing structures
going southwest from KDJ4, especially in the extended emission of
the simplest molecules such as SiO, CO, and their isotopologues (see
below).
It is relevant to note that the outflow emission revealed by the SMA
maps of the CO (3-2) line presented by Juárez et al. (2017) actually
Table 2. Detected iCOM species sorted by complexity.
Main species
Isotopologue/Isotopomer
CH3COCH3
aGg’-(CH2OH)2
CH3OCH3
C2H5OH
C2H5CN
C2H5C15N, C2H513CN
CH3OCHO
CH3O13CHO
C2H3CN
NH2CHO
CH3CHO
CH3OH
CH3CN
CH313CN, 13CH3CN
trace the LV component of the east-west and north-south outflows,
but not the high-velocity component of the north-south outflow that
dominates the outflow emission in our CO (2-1) wings-map. The fact
that the CO (3-2) line reveals the east-west outflow indicates that,
similar to other High-J CO lines, the low-velocity outflow emission
is not severely affected by the ambient emission in these transitions.
The non-detection of the high-velocity emission of the north-south
outflow in the CO (3-2) line may be due to a combined effect of
sensitivity and excitation.
5.2 XCLASS identification catalogue
The iCOM identification was conducted in the spectrum of the brightest
 core, historically named KDJ4 (Kraemer et al. 1999b; Hashimoto
et al. 2007). From our analysis, we identified 11 iCOM main isotopologues,
 five secondary isotopologues and two vibrationally excited
states7 in G351, most of them having already been detected in multiple
 SFRs from low to high mass regimes (Ospina-Zamudio et al.
2018). The chemical iCOMs species observed in this Core are listed
in Table 2. The simpler molecules’ emission in G351 will be discussed
 in a separate paper.
After the modeling, we were able to discriminate some lowintensity
 lines from several line candidates, so that the complete
chemical transition list increased. We have observed about 175 emission
 lines with intensities over 𝑇𝑀𝐵> 0.5 K within our 8 GHz
bandwidth. The complete list of detected transitions for all the identified
 iCOMs is reported in Table 3.
5.3 iCOMs along the outflows
We have observed that although most of the iCOMs peak at KDJ4
core, several of them have emission spread along the High-Velocity
outflow direction, but also tracing Low Velocity (LV) gas |𝑉𝑀𝑎𝑥−
𝑉𝐿𝑆𝑅| < 10 kms−1.
As the velocity space covered by iCOMs and the simpler molecules
shows a discrepancy of tens of kms−1, we tried to establish the association
 of iCOMs with the outflows, looking for coincidence in the
sky-plane locations. For this, we analyzed the moment 0 and moment
1 maps of the stronger iCOM emission, finding 10 iCOM species presenting
 an elongated extension (with a major axis longer than ∼10′′),
and five transitions tracing the bow shock EGO’s structure (Figure
4). Since this emission departs from the spherical geometry expected
for a compact core, and because the extended emission direction
7 For CH3OH and CH3OCHO
MNRAS 000, 1–13 (2015)
6
O. S. Rojas-García et al.
Table 3. Modeled lines with T𝑚𝑏> 0.8. by means of the XCLASS identification
 model. The columns shows: (1) The molecular name and the vibrational
excited state, (2) the rest frequency, (3) the spontaneous emission coefficient
A𝑖𝑗and (4) the Upper State degeneracy. In this table we only present an
example of the format of detected transitions, the complete list of the 260
high intensity transitions is reported in appendix C.
iCOM species
Frequency
A𝑖𝑗
g𝑢𝑝
[GHz]
[s−1]
C2H5CN;v=0;
216.8281
6.9446×10−7
159
CH3OCHO;v=0;
216.8302
1.4796×10−4
74
CH3OCHO;v=0;
216.8389
1.4800×10−4
74
CH3OH;v=0;
216.9456
1.2135×10−5
44
aGg’-(CH2OH)2;v=0;
216.9466
5.1108×10−6
525
CH3OCHO;v=0;
216.9630
2.4448×10−5
82
CH3OCHO;v=0;
216.9642
2.4436×10−5
82
CH3OCHO;v=0;
216.9648
1.5313×10−4
82
CH3OCHO;v=0;
216.9659
1.5315×10−4
82
CH3OCHO;v=0;
216.9662
1.5313×10−4
82
overlaps with the bipolar outflows traced by simpler molecules, we
concluded that the iCOM emission is coming from the outflow itself.
The iCOMs found to trace the outflow are CH3OH, CH3OCHO,
C2H3CN and C2H5CN. In some cases, these lines are blended with
CH3OCH3, CH3COCH3 and aGg-(CH2OH)2. We recall that these
iCOMs’ emission were visually inspected to avoid the emission lines
blended with simpler molecules, i.e. the analyzed emission lines,
even when blended, are only produced by iCOM species. It is also
important to note that, similar to the diatomic molecules, spatial
filtering seems to affect the low-velocity emission of more extended
iCOMs, such as Methanol and Vinyl cyanide. The details of the
molecular emission are described in Table 4.
5.3.1 Methanol (CH3OH)
Our observations show that the simplest iCOM, CH3OH, is located
along the 13CO HV outflow away from the KDJ4 core. This behavior
is observed in two unblended transitions, at 220.080 and 229.766
GHz, and also in blended emission at 230.027 GHz (Figure 6 a, b
and c, respectively).
The CH3OH emission covers an extension from 18′′ up to 37′′,
for 220.080 and 229.766 GHz transitions, respectively. It extends
along with the EGO 4.5𝜇m emission tracing the brightest knots,
e.g. the EN-A2 and the WN-A2 cores and the bow-shock structure.
Nevertheless, we recall that this extended area is not symmetrical; it
is enhanced preferentially in the blue-shifted emission of the 13CO
HV outflow (see Figure 6).
At 230.027 GHz, the methanol emission is blended with
CH3OCH3 and CH3COCH3. We diagnose this mixture due to our
LTE modeling, but the contribution to the emission line from these
two secondary iCOMs is not as dominant as Methanol. This, together
with the fact that CH3OCH3 and CH3COCH3 are expected to trace
mainly the Core, leads us to consider the extended contours of these
lines are traced by methanol. Additionally, this transition also traces
the G351 Bow-shock. This kind of methanol distribution inhabiting
outflows has been reported in other objects (Ospina-Zamudio et al.
2018; Orozco-Aguilera et al. 2018; Palau et al. 2017).
The physical conditions at KDJ4 according to our methanol LTE
modeling are displayed in Table 5. However, we point out that these
values must be taken carefully, as they represent the densest and
hottest region, not precisely related with the outflows, for which the
density and temperature decrease. This is shown in the Methanol
populated states, that for the cores can reach the highest 𝐸𝑢𝑝energy
 levels, whereas in the outflow the populated energy levels are
commonly 𝐸𝑢𝑝< 100 K (Ospina-Zamudio et al. 2018).
Also, our reported physical parameters are a lower limit for the
physical state of the gas, since in our interferometric observations
the amount of filtered flux can vary significantly. Further single-dish
observations should help to quantitatively estimate the proportion of
missing flux.
5.3.2 Vynil Cyanide (C2H3CN)
The most extended iCOM emission observed in G351 is Vinyl
Cyanide at 218.433 GHz (38.7′′). The emission covers all the EGO
extension, including the Bow-Shock; however, its P.A. is more consistent
 with the 13CO HV outflow than with the EGO (Figure 7). As
with the methanol emission, the vinyl cyanide traces the WN-A2 and
the EN-A2 cores, but its elongation is broader than the methanol one
in both axes.
The enhancement of this molecule along with other N-bearing
species appears to be more density selective than the O-bearing
ones. This is shown as an increase of the abundance with the mass of
the system by Ospina-Zamudio et al. (2018). Other proposed factors
to produce this selectivity are the accretion rate and age of the star
formation system, but there is not an established consensus yet
(Lykke et al. 2017; López-Sepulcre et al. 2017; Watanabe et al. 2017).
5.3.3 Ethyl Cyanide (C2H5CN) and Methyl formate (CH3OCHO)
In our observations, the Ethyl cyanide is observed in three emission
lines 229.405, 231.313, and 231.990 GHz, but in all these cases is
mixed with CH3OCHO. The transition at 229.405 GHz is the more
elongated one, and is tracing the blue-shifted region of the 13CO HV
outflow over 25.43′′ (Figure 8 a).
Considering the nature of these two molecules, we speculate that
the Ethyl Cyanide emission is mainly contributing to the central
core emission at KDJ4, as enhancement of N- bearing molecules has
been found in massive and hot compact regions. On the other hand,
Methyl Formate (MF, hereinafter) has been proven to trace also the
outflowing gas knots (Palau et al. 2017; Orozco-Aguilera et al. 2018).
Hence, it seems likely that the extended emission is mostly traced by
MF.
The emission at 231.313 and 231.985 GHz is more compact than
at 229.405 GHz and is located at the KDJ4 core. Its P.A. is more
north-south and seems to agree with the HV outflow traced by SiO
for over 16.6′′. A small extension on the emission line at 231.985
GHz seems to trace the north-east direction of the 13CO HV outflow,
but could be just tracing the cores (see Figure 8 c). This small lobe
extends for 17.9′′ and is tracing the EN-A2 and WN-A2 cores.
5.3.4 Methyl formate (CH3OCHO); Ethylene glycol
aGg’-(CH2OH)2
These two iCOMs are responsible for two elongated emissions at
216.945 and 218.280 GHz. In this case, the covered area traces
similar components centered in the KDJ4 core with inner contours
north-south orientated (Figure 9). This extension is also similar to the
C2H5CN, CH3OCHO, and CH3OH. Methanol and methyl formate
are expected to inhabit similar regions, as methyl formate is directly
produced after the processing of Methanol (Ceccarelli et al. 2017).
MNRAS 000, 1–13 (2015)
iCOMs in outflows from G351.16+0.70
7
Table 4. List of iCOMs detected in the outer regions of the Core, their corresponding transition frequency is shown in the second column, whereas the third
column shows their corresponding transition.
Species
Frequency [MHz]
Transition
CH3OH
216945.6000
v12 = 0; J = 5 - 4
aGg’-(CH2OH)2
216946.5593
vibInv = s-a; J = 378 - 369
CH3OCHO
218280.9000
v18 = 0; J = 173,14 - 163,13
CH3COCH3
218281.3692
J = 4822,26 - 4821,27 (AA)
aGg’-(CH2OH)2
218283.0917
vibInv = s-a; J = 97,3 - 86,3
C2H3CN
218421.8013
J = 238,16 - 228,15
CH3OH
220078.5610
v12 = 0; J = 80 - 71
CH3CN
220641.0839
J = 125 - 115
CH3OCHO
229405.0210
v18 = 0; J = 183,15 - 173,14
CH3OH
229758.7560
v12 = 0; J = 81 - 70
CH3OH
230027.0470
v12 = 0; J = 32 - 41
CH3COCH3
230028.3815
J = 1916,4 - 1913,7
C2H5CN
231313.2412
J = 242,23 - 231,22
CH3OCHO
231315.0300
v18 = 0; J = 294,27 - 293,26
C2H5CN
231990.4098
J = 270,27 - 260,26
CH3OCHO
231985.3570
v18 = 0; J = 209,12 - 208,13 (A)
a)
b)
c)
Figure 6. G351 Methanol integrated emission maps at 220.078, 229.758, and 230.027 GHz. The magenta contours go from 20 to 90% of the emission peak
with a 10% increasing steps. These contours are displayed over a three-band color image (3.6, 4.5, and 8.0𝜇𝑚, coded as blue, green, and red, respectively
(Cyganowski et al. 2008)). The star markers shows the near- to far IR confirmed cores (Kraemer et al. 1999b; Hashimoto et al. 2007)
Figure 7. G351 Vinyl Cyanide integrated emission map (218.421 GHz). The
contours, labels, and background image are the same as in Figure 6.
Also, their enhancement in outflow regions has been previously confirmed
 (Rojas-García et al. 2022).
5.3.5 Other iCOMs
We also found several other iCOMs associated with elongated emission
 such as Acetone (CH3COCH3 at 218.281 GHz) and Dimethyl
ether (CH3OCH3 at 230.027 GHz), but as they were blended with
simpler molecules, and have high energy levels, they may be tracing
the compact core. Additionally, as a result of our line identification
methodology, we were able to detect several other iCOMs shuch
as C2H5OH, NH2CHO and CH3CN along with the isotopologues
C2H5CN15, C2H5C13N, CH3OC13HO, CH3C13N and C13H3CN,
but as they only trace the compact core, they were excluded from this
analysis. The full list of iCOMs is displayed in Table 5.
5.4 Velocity field maps of iCOMs tracing the bow shock
We analyzed the moment 1 maps for the iCOMs that trace the bowshock
 signature in their integrated emission maps to visually inspect
the velocity gradient. It should be pointed out that due to the multiple
core nature of G351, the velocity gradient field is not smooth but
incoherent; therefore, the precise association of the moving gas traced
by iCOMs with a particular core is not easy.
Nevertheless, we have analyzed the velocity field mainly focused
MNRAS 000, 1–13 (2015)
8
O. S. Rojas-García et al.
a)
b)
c)
Figure 8. G351 Ethyl Cyanide and MF integrated emission maps at 229.405, 231.313, and 231.985 GHz. The contours, labels, and background image are the
same as in Figure 6.
a)
b)
Figure 9. G351 MF and Ethylene Glycol integrated emission map at 216.945
and 218.280 GHz. The contours, labels, and background image are the same
as in Figure 6.
on two outflow signatures previously mentioned: the blue-shifted HV
13CO outflow, and the bow shock structure (Section 5.1).
5.4.1 Methanol
In the unblended emission lines at 220.078 and 229.758 GHz,
methanol M1 maps show the blue-shifted emission located just over
Table 5. Physical parameters obtained for iCOMs detected into the brightest
core KDJ4. The parameters have been determined by the XCLASS LTE
modeling, i.e. this quantities represent the physical parameters corresponding
to one beam coverage (𝜃𝑠𝑦𝑡ℎ= 5.3′′ × 3.6′′). The last column shows the
molecular abundances relatives to H2 column density of 4.0×1023, in order
to facilitate comparisons with literature values.
iCOM
T𝑟𝑜𝑡
N𝑇𝑜𝑡
𝑣𝑤𝑖𝑑𝑡ℎ
𝑋
specie
[K]
[cm−2]
[kms−1]
aGg’-(CH2OH)2
146
1.98×1015
3.21
2.95×10−9
C13H3CN
82
2.83×1014
2.01
4.21×10−10
C2H3CN
546
2.31×1015
6.04
3.44×10−9
C2H5C13N
160
1.65×1013
7.10
2.46×10−11
C2H5CN15
25
3.72×1016
4.97
5.54×10−8
C2H5CN
743
8.00×1015
3.38
1.19×10−8
C2H5OH
177
1.50×1016
4.00
2.23×10−8
CH3C13N
155
2.78×1014
3.53
4.14×10−10
CH3CHO
57
4.28×1014
1.35
6.37×10−10
CH3CN
200
4.32×1015
3.72
6.43×10−9
CH3COCH3
286
2.20×1017
8.51
3.28×10−7
CH3OC13HO
221
1.55×1016
3.60
2.31×10−8
CH3OCH3
289
3.69×1016
5.02
5.49×10−8
CH3OCHO
251
3.77×1016
4.67
5.61×10−8
CH3OH
296
1.52×1017
4.21
2.26×10−7
NH2CHO
32
5.32×1014
4.47
7.92×10−10
the bow shock structure and pointing to the west, with a center near
to WN-A2; whereas the red-shifted emission spreads from east to
west (Figure 10 a and b). The velocity field traced by Methanol at
230.027 GHz shows an "S" shape (dashed magenta line in Figure 10
c), which agrees with the location of the near- to far-IR cores WN-A2
and KDJ4. This phenomenon may be caused by the secondary emitting
 iCOMs blended in this emission (CH3OCH3 and CH3COCH3),
which are more related to compact emission. Therefore, the velocity
 field could be tracing the location of the innermost regions of
the compact cores, whereas the other maps only traced by Methanol
show a wider emission.
Around the bow shock structure, we observe a gradient from
red- to blue-shifted emission, going from south to north, with a
velocity width of |𝑉𝑀𝑎𝑥−𝑉𝐿𝑆𝑅| < 4 kms−1 for the lowest frequency
 methanol line (Fig. 10a). Due to its location and the noncorrespondence
 with the mm continuum peak, we speculate that the
observed gradient could be related to the bow shock itself and the
nearby SiO outflow. In the case of the 229 GHz line (Fig. 10b), the
MNRAS 000, 1–13 (2015)
iCOMs in outflows from G351.16+0.70
9
a)
b)
c)
Figure 10. G351 Methanol first order moment maps at 220.078, 229.758, and 230.027 GHz. The maps were generated by Kpvslice software from KARMA
using an median algorithm with lower clips of 4𝜎. The star markers show the near- to far IR confirmed cores (Hashimoto et al. 2007). In c) the dashed magenta
line highlights the rest velocity towards this blended emission line.
Figure 11. G351 MF first order moment map at 216.945 GHz. The map
generation and the mark labels are the same as in Figure 10
south to north gradient is more clearly related to the SiO outflow
(see, in comparison, Figure 5).
Another signature in the Methanol emission is that its velocity
gradient is not coherent along the path of the HV outflow. This could
indicate that methanol is tracing the low-velocity component of the
HV outflow. During this exchange of kinetic energy, the reactions are
boosted only in the densest layers and chemically richest knots, but
not all the way along the outflow path (as the simplest molecules).
In these places, the increase of temperature and density trigger extra
iCOM emission. This phenomenon also explains the low velocity in
the iCOMs at these locations.
5.4.2 Methyl formate
Another iCOM which seems to trace the bow shock structure is MF at
216.945 GHz. Nevertheless, this emission is contaminated with aGg(CH2OH)2,
 but according to our LTE modeling the main contributor
for this emission should be MF.
As in the M1 map of contaminated Methanol, this blended emission
 shows an "S" shape in the closest vicinity to the near- to far-IR
cores (Figure 11). Also, the bow shock gradient shows a red- to blueshifted
 emission, going from south to north, but as we previously
mentioned for the case of methanol, this could be due to the bow
shock itself and the nearby SiO outflow.
Figure 12. G351 VC first order moment map at 218.421 GHz. The map
generation and the mark labels are the same as in Figure 10
5.4.3 Vinyl Cyanide
The vinyl cyanide velocity field is mostly close to rest velocity, in
comparison to other iCOMs. This emission is extended east to west,
covering and spreading further away from the extension of the EGO,
and also tracing the extension of the HV 13CO outflow (Figure 12).
The maximum red- and blue-shifted velocities show agreement with
the south-west peak emission of the red- and blue-shifted emission
of the SiO HV outflow. As this emission is elongated to the southwest
 from the KDJ4 core, and has a wide extension, the velocity
maps overlap with the bow-shock, preventing its association with
one structure or another.
5.5 Molecular abundances
To put in context our results along the star formation scenario from
low to high mass, we compute the relative abundances of iCOMs with
respect to H2, using the computed column densities. The H2 column
density was computed using the Hernández-Hernández et al. (2014)
procedure, given the similar frequency ranges. The first assumption
is optically thin dust emission and a constant gas-to-dust mass ratio
(100, in this case). The opacity per unit of dust (𝜅𝑣) goes from 0.2
to 3.0 at 1.3 mm, and it is scaled with 𝜈𝛽. Following HernándezHernández
 et al. (2014), we took 𝛽= 1.5, leading to 𝜅1.3𝑚𝑚=
MNRAS 000, 1–13 (2015)
10
O. S. Rojas-García et al.
0.74 cm−2g−1. Therefore, the column density of molecular hydrogen
could be written as
"
𝑁𝐻2
𝑐𝑚−2
#
= 2.35×1016
𝜃2
"
𝑆𝜈
𝐽𝑦
# "
𝑇
𝐾
#−1
(1)
Here 𝑆𝑣is the flux density, 𝜃is the source size in rad, and 𝑇is the
dust temperature. In this case, we take the rotational temperatures
average value from the optically thin isotopolgues of 13CO (𝑇𝑅𝑜𝑡=
24.88 K) and CO18 (𝑇𝑅𝑜𝑡= 24.35 K), resulting in a 𝑇𝑅𝑜𝑡∼25
K. This temperature is similar to the one assumed by Juárez et al.
(2017) for the north and southeast cores (that is also compatible with
to the average temperature in protostellar cores 𝑇𝑅𝑜𝑡∼30 K). The
continuum was taken from our continuum data, 464.16 mJy beam−1.
After these considerations, we obtain a 𝑁𝐻2 = 6.72×1023 cm−2. The
column density ratios are listed in Table 6.
MNRAS 000, 1–13 (2015)
iCOMs in outflows from G351.16+0.70
11
Table 6. Molecular abundances with respect to H2 measured from low to high mass SFRs reported in literature along our own results for G351 into the brightest core KDJ4. The sources are ordered by increasing
luminosity from left to right. (𝑎) López-Sepulcre et al. (2017), Taquet et al. (2015), (𝑏) Jørgensen et al. (2016), Coutens et al. (2016), Lykke et al. (2017), Calcutt et al. (2018), (𝑐) Ospina-Zamudio et al. (2018), (𝑑)
Fuente et al. (2014), (𝑒) Beuther et al. (2009), ( 𝑓) Pagani et al. (2017), Beuther et al. (2009), (𝑔) Palau et al. (2017), (ℎ) Belloche et al. (2013). (*) Obtained from the 13C isotopologue. (+) Average value from the
reported range.
iCOM
specie
𝑋
Low Mass
Intermediate Mass
High Mass
IRAS4A2𝑎

IRAS16293B𝑏

IRAS- 2A𝑎
Cep E-A𝑐
NGC7129𝑑

G29.96𝑒
Orion- Kl 𝑓
IRAS
20126+4104𝑔
disc
IRAS
20126+4104𝑔
outf
G351.16
+0.70
SgrB2
(N1)ℎ
CH3OH
4.3×10−7
1.7×10−6
1.0×10−6
1.2×10−6*
1.0×10−6*
6.7×10−8
9.3×10−8
9.3×10−7
1.4×10−6
2.3×10−7
1.4×10−6
CH3OCHO
1.1×10−8
3.3×10−8
1.6×10−8
2.6×10−8
2.0×10−8
1.3×10−8
4.4×10−9
9.3×10−8
1.0×10−7
5.6×10−8
3.4×10−8
CH3CHO
4.3×10−9+
5.8×10−9
——–
1.1×10−8
2.0×10−9
——–
1.3×10−11
——–
——–
6.4×10−10
1.1×10−8
CH3OCH3
1.0×10−8
——–
1.0×10−8
3.6×10−8
1.0×10−8
3.3×10−8
2.6×10−9
3.9×10−8
1.5×10−7
5.5×10−8
1.5×10−7
CH3COCH3
——–
1.4×10−9
——–
5.4×10−9+
5.0×10−10
——–
——–
9.7×10−8
3.2×10−8
3.3×10−7
1.2×10−8
NH2CHO
4.0×10−10+
8.3×10−10
2.4×10−9
4.5×10−10
——–
——–
1.9×10−10
———
———
7.9×10−10
1.0×10−7
CH3CN
8.5×10−10+
3.3×10−9
4.0×10−9
3.5×10−9
6.0×10−9*
1.7×10−9
8.5×10−10
7.7×10−9
7.2×10−9
6.4×10−9
1.5×10−7
C2H5CN
3.7×10−10+
3.0×10−10
3.0×10−10
7.8×10−10+
1.4×10−9
1.7×10−9
1.3×10−9
——–
——–
1.2×10−8
1.4×10−7
MNRAS 000, 1–13 (2015)
12
O. S. Rojas-García et al.
As Ospina-Zamudio et al. (2018) have previously shown, N- bearing
 iCOMs seem to have a clear increasing abundance with the mass
of the system, with a three order of magnitude increase from low to
high mass regimes, observed in CH3CN and C2H5CN species. We
took the compiled information of Ospina-Zamudio et al. (2018) and
complemented it with the iCOM abundances of Palau et al. (2017)
and in this context, our object N-bearing abundances fits with previous
 results.
Additionally, we also found a two order of magnitude enhancement
 of the O-bearing CH3COCH3 molecule from low to high mass
regimes. However, a comparison of this iCOM is hard to make, as it
is only reported for one low-mass, two intermediate mass and three
high-mass SFR in our reviewed sample.
6 SUMMARY AND CONCLUSIONS
G351 shows a peculiar outflow morphology based on the CO, SiO,
and mid-IR images. The high-velocity CO emission traces a northsouth
 outflow, most prominent in the interferometric CO map, and
without a mid-IR counterpart. Additionally, a jet-like structure that
dominates in the mid-IR at 8.0 𝜇m, is mostly traced by the SiO
emission and the high-velocity CO emission.
The intermediate- and high-velocity CO emission overlaps with
the main mid-IR structures. In particular, the intermediate-velocity
blue-shifted emission traces the west lobe that is prominent in green
excess. The red-shifted intermediate-velocity emission has only a
mid-IR counterpart towards its inner region. On the other hand, as
revealed more clearly in the CO emission, the high-velocity blue- and
red-shifted emission does not show a mid-IR counter part, and indeed
such high-velocity emission seems to trace an outflow perpendicular
to the mid-IR east-west outflow. Interestingly, the SiO emission that
is only detected at low velocities, has been found clearly tracing the
jet-like structure revealed by the 8𝜇m emission. In addition, the SiO
emission may be tracing a third outflow structure to the south of the
main western lobe, which also lacks a counterpart in the mid-IR.
Our data shows an iCOM rich environment toward G351. This
enrichment is, as expected, mainly tracing the brightest core, previously
 associated with the dust continuum peak KDJ4 (Hashimoto
et al. 2007). Away from it, most of the iCOM emission decreases
drastically. Nevertheless, some of these molecules have proven to
trace thinner gas which we have associated with the outflows, as their
coverage area shows association with the observed bipolar structures.
This was also verified in the first moment maps.
The iCOMs tracing the outflow are mostly O-bearing, and are also
mainly tracing the HV (∼20 kms−1) blue-shifted lobe. This lobe
is also revealed by 4.5 and 8.0𝜇m emission in the near-IR IRAC
bands, and has been previously related to two dust continuum peaks
(Hashimoto et al. 2007). This fact also indicates that this iCOM
extended emission could be tracing local emission from the nearby
cores in their slightly shifted 𝑉𝐿𝑆𝑅. Nevertheless, some iCOMs trace
the 4.5𝜇m bow shock structure, a region which is not related to any
dust continuum and is separated from KDJ4 by more than 7′′ (9000
AU) and therefore disconnected from the core emission.
Due to the wide angular bipolar outflow behavior, G351 could be
an example of a Circulation Flow (Arce et al. 2007), in which the
green fuzzy emission is more related to the Low Velocity and HighVelocity
 gas |𝑉𝑀𝑎𝑥−𝑉𝐿𝑆𝑅| < 20 kms−1, whereas the Extremely
High velocity (|𝑉𝑀𝑎𝑥−𝑉𝐿𝑆𝑅| ≥20 kms−1) emission have a near-IR
counterpart just in their southern blue-shifted and in their norther red
shifted- lobe. Another plausible option is that there is a precessing
jet.
Not only do the N-bearing species have a large discrepancy along
the Intermediate-Mass vs High mass Star Formation scenario, but
also we found two orders of magnitude difference in column density
in the O-bearing species Acetone (CH3COCH3) from low to high
mass regime objects. Also, our detection is one order of magnitude
higher in T𝑅𝑜𝑡, pointing to the sensitivity of this molecule to changes
in temperature, which are expected in the inner regions of these more
massive cores.
All things considered, this long-scale outflow could give more
hints in the description of this wide-angle outflow and its several
lobes and the role of multiple cores in HMSFRs.
ACKNOWLEDGEMENTS
We thank the support of researchers from the National Institute of
Astrophysics, Optics and Electronics (INAOE), the Large Millimeter
Telescope (LMT) and the Institute of Radio Astronomy and Astrophysics
 (IRyA) during the development of this investigation. We are
also grateful to the Mexican funding agency Consejo Nacional de
Ciencia y Tecnología (CONACYT) for its support to the INAOE’s
graduate program in Astrophysics. A.P. acknowledges financial support
 from the UNAM-PAPIIT IN111421 and IG100223 grants, the
Sistema Nacional de Investigadores of CONACyT, and from the
CONACyT project number 86372 of the ‘Ciencia de Frontera 2019’
program, entitled ‘Citlalcóatl: A multiscale study at the new frontier
of the formation and early evolution of stars and planetary systems’,
México.
DATA AVAILABILITY
The
data
underlying
this
article
are
available
in
the
article

and
the
datasets
were
derived
from
sources
in
the
public
domain:
https://irsa.ipac.caltech.edu/data/SPITZER/GLIMPSE/index_cutouts.html,

http://atlasgal.mpifrbonn.mpg.de/cgi-bin/ATLASGAL_DATABASE.cgi

and
https://lweb.cfa.harvard.edu/cgi-bin/sma/smaarch.pl.
Introduction
Over the last decade, it has become clear that Class CH3OH
and H2O maser emission is closely associated with the earliest
 stages of massive star formation. Much research has been
focused on both maser species, but most high-resolution studies
 have concentrated on only one type. Little is known about
the associations and connections of the CH3OH and the H2O
maser emission. Motivated by this lack of information, we conducted
 high-resolution observations of both maser types in a
large sample of high-mass protostellar objects (HMPOs) and
discuss them in the context of different other probes of massive
star formation.
So far, high-resolution investigations, focused either
on H2O or on CH3OH maser emission, indicate independently
that both maser types are found in outflows as well as in
circumstellar disks. Examples of these studies on the H2O
side are, e.g., Torrelles et al. (1997, 1998), Codella & Felli
(1995), and Codella et al. (1996, 1997), whereas recent studies
 of CH3OH masers include Walsh et al. (1997, 1998),
Send offprint requests to: H. Beuther,
e-mail: beuther@mpifr-bonn.mpg.de
Phillips et al. (1998), Minier et al. (2000a, 2001), and Codella
& Moscadelli (2000). Reviews on this subject are found in
Menten (1996), Garay & Lizano (1999), Norris (2000), and
Kylafis & Pavlakis (1999).
Another finding is that both maser types are occasionally
spatially coincident with ultracompact Hregions, but more
often with hot molecular cores and/or massive molecular outflows
 (Hofner & Churchwell 1996; Codella et al. 1996, 1997;
Walsh et al. 1998; Garay & Lizano 1999; Minier et al. 2001).
Recent studies by Walsh et al. (2001) indicate that CH3OH
masers often are associated with mid-infrared sources that
should be luminous enough to produce strong ionizing radiation.
 In spite of that, a number of those maser sites is undetected
 in the radio continuum, and Walsh et al. (2001) conclude
that these might be in an evolutionary stage prior to forming an
ultracompact Hregion.
For sources in which both maser species are observed
(mostly single-dish data with low spatial resolution), the velocity
 spread is far higher in the case of H2O maser emission
 than known for CH3OH masers. For example, Sridharan
et al. (2002) found in a sample of high-mass protostellar
Article published by EDP Sciences and available at http://www.aanda.org or http://dx.doi.org/10.1051/0004-6361:20020710
290
H. Beuther et al.: CH3OH and H2O masers in high-mass star-forming regions
candidates that the CH3OH emission is confined always to a total
 radial velocity extent of at most 15 km s−1, whereas the H2O
maser emission is found extending up to 70 km s−1. In spite of
the similarities outlined above, these different spectral features
show that the two maser types are subject to different excitation
conditions and likely occur in separate spatial regions around
the evolving massive protostars.
The current status of CH3OH maser excitation studies favors
 a scenario in which the CH3OH maser emission is produced
 by radiative pumping in small, moderately hot regions
(∼150 K) with CH3OH column densities >1015 cm−2 and hydrogen
 number densities <108 cm−3 (Hartquist et al. 1995;
Sobolev et al. 1997; Cragg et al. 2001). While it was suggested
 that CH3OH maser could be produced in disks (e.g.,
Norris et al. 1998), this is not unambiguously confirmed, and
other scenarios like expanding shock waves or outflows have
been proposed as well (e.g., Walsh et al. 1998; Minier et al.
2000b). It is quite possible that the same maser species in different
 sources have different origins.
In contrast, most H2O maser models explain the excitation
by collisional pumping with H2 molecules within shocks associated
 with outflows and/or accretion (Elitzur et al. 1989; Garay
& Lizano 1999). For example, the model by Elitzur et al. (1989)
requires dissociative shocks in dense gas (preshock densities
around 107 cm−3) with temperatures up to ∼400 K. In many
sources, it is believed that the H2O masers form within outflows,
 but there are also examples claiming that the H2O masers
are produced in disks (Garay & Lizano 1999).
The high-resolution study of H2O and CH3OH maser emission
 in 29 high-mass star-forming regions presented here intends
 to compare the characteristics of these important signposts
 of massive star formation. The study is part of a long-term
project studying very early evolutionary stages of massive star
formation, prior to, or during the formation of an ultracompact
Hregion. The entire sample of 69 sources presented first by
Sridharan et al. (2002) is distributed mainly between 1 kpc and
10 kpc distance from the sun. For many sources, only kinematic
distances are known, and the data suffer from the distance ambiguity
 of this approach (Sridharan et al. 2002). The bolometric
luminosities of the sources range roughly between 103.5 L⊙and
105.6 L⊙, and the core masses vary between a few 100 M⊙and
a few 104 M⊙. Detailed analyzes of different sample properties
(luminosities, density distributions, outflows) are presented in
Sridharan et al. (2002) and Beuther et al. (2002a, b). In spite
of the non-detection in Galaxy-wide single-dish cm surveys,
more sensitive interferometric studies revealed that in some of
the sources cm emission occurs, whereas in others we do not
find any free-free emission down to 1 mJy. This makes the sample
 ideally suited for the study of associations of masers with
different kinds of sources and evolutionary stages. The basic
source properties of the sub-sample analyzed in this paper are
summarized in Table 1. We compare the maser emission mainly
with mm dust emission tracing the massive core (Beuther et al.
2002a), cm wavelength emission being believed to be due to
free-free emission in those sources where it had been detected
(Sridharan et al. 2002), and mid-infrared emission likely due to
warm dust around embedded objects.
2. Observations
2.1. Single-dish H2O and CH3OH maser data
An H2O (22.2 GHz) and Class CH3OH Class (6.7 GHz)
maser survey of the the whole sample of 69 high-mass protostellar
 objects, as introduced by Sridharan et al. (2002), was
conducted with the Effelsberg 100 m telescope in two runs in
1998. Altogether, 29 H2O and 26 CH3OH masers were found.
The observations are described and statistically analyzed in
Sridharan et al. (2002). Follow-up observations of the maser
detections were conducted with high spatial resolution with the
VLA and the ATCA.
2.2. H2O maser observations with the VLA
High-resolution images of the 22.2 GHz H2O maser line were
obtained with the Very Large Array (VLA) in the B configuration
 with a spectral resolution of 0.65 km s−1, a synthesized
HPBW of ≈0.4′′, and a primary beam FWHM of ≈2′. The snapshot
 mode was used with 3 × 5 min integrations spread over
the transit of each source. We reduced the data with the AIPS
software package using standard procedures. The typical 1σ
sensitivity is 1 Jy.
For 22 out of 26 observed sources, the signal-to-noise ratio
and the UV coverage were sufficiently good to derive absolute
positions to an accuracy better than 1′′. The accuracy of relative
positions of different maser features is around 0.1′′.
2.3. CH3OH maser observations with the ATCA
To get high-resolution images of the Class 6.7 GHz maser line
of CH3OH, we employed the Australian Telescope Compact
Array (ATCA) which is part of the Australia Telescope
National Facility. From the 26 sources initially found to be associated
 with CH3OH maser emission, 21 are south of declination
 20◦which is necessary to be observable with the ATCA.
Six of the 21 sources had already been observed with the ATCA
by Walsh et al. (1998). Thus, we observed the remaining 15 objects
 in the snapshot mode with a series of 6 short integration
cuts of 5 min for each source. Phase calibrators were observed
every 20 min. The field of view of the ATCA at this frequency
is ∼(8′)2, and the effective HPBW of the synthesized beam is
∼1.9′′. Observations near the equator result in elongated, elliptical
 beams because of the east–west elongation of the array.
The spectral resolution was ∼0.2 km s−1, and the 1σ sensitivity
was typically 0.5 Jy.
In 10 out of the 15 sources the data are sufficiently good
to derive positions. The data reduction was performed with
the MIRIAD software package using standard procedures.
Absolute positions are estimated to be accurate to 1′′ whereas
the relative positions should be accurate to ∼0.1′′. In 4 sources
the signal was too weak to be detected, whereas in 1 source the
signal was strong enough, but so close to the equator that no
positions could be derived.
H. Beuther et al.: CH3OH and H2O masers in high-mass star-forming regions
291
2.4. Other observations
Dust emission at mm wavelengths
The 29 sources presented in this paper were observed as part
of the large sample of 69 high-mass protostellar objects introduced
 by Sridharan et al. (2002) with the MAMBO array
 in the 1.2 mm continuum. A detailed description of the
data reduction and analysis can be found in Beuther et al.
(2002b). For a few sources even higher resolution mm data
were obtained with the Plateau de Bure Interferometer and the
BIMA array at 2.6 mm. Plateau de Bure data are used here for
05358+3543 and 19217+1651, whereas the BIMA data were
used in the cases of 18089 −1733, 18264−1152, 18566+0408
and 23033+5951. Details of the Plateau de Bure observations
are presented in Beuther et al. (2002c) and Beuther et al.
(in prep.), and the BIMA observations will be published by
Wyrowski et al. (in prep.).
The pointing accuracy of the MAMBO array is estimated to
be around 5′′ and the BIMA and Plateau de Bure data should
be accurate to approximately 1′′.
Continuum emission at cm wavelengths, likely produced by
free-free emission
To know whether faint cm emission is present in some of the
sources, we obtained 3.6 cm continuum images with the VLA
down to a 1σ sensitivity of 0.1 mJy with a spatial resolution of
0.7′′. For more details see Sridharan et al. (2002). The positions
of these data are correct to within 1′′.
Mid-infrared data
The Midcourse Space Experiment (MSX) point source catalog
was searched for mid-infrared sources in the respective fields
of view. For details on MSX see, e.g., Egan et al. (1998) and
the MSX Web site1. In most fields, mid-infrared sources were
found (Sridharan et al. 2002). For the few sources, for which
the point source catalog had no entries, we examined the most
sensitive MSX images at 8 µm and extracted source positions.
The spatial resolution of MSX is approximately 18′′, and the
sensitivity varies between the different bands between 0.1 and
30 Jy/beam. Egan et al. (1998) quote the positions to be accurate
 within 4′′−5′′. For 05358+3543, we use a mid-infrared
source position observed by McCaughrean et al. (in prep.) with
the Keck observatory at 11.7 µm.
3. Results
3.1. The database
Figure 1 presents maps of the 29 maser sources observed with
high spatial resolution. For 6 sources the CH3OH data are
taken from Walsh et al. (1998), for 19410+2336 the CH3OH
maser positions are presented by Minier et al. (2000a), and
for 05358+3543 no high-resolution CH3OH maser position is
known (single dish detection by, e.g., Sridharan et al. 2002
and Menten Menten 1991). Of the 6 sources in our sample
 north of 20◦declination, Effelsberg 100 m data show
that three (19410+2336, 20126+4104 & 23139+5939) contain
 CH3OH masers (Table 1), but because the ATCA is only
capable of observing sources below 20◦declination, we have
1 http://www.ipac.caltech.edu/ipac/msx/msx.html
accurate CH3OH maser positions only for 19410+2336 and
20126+4104, both of which were observed with the European
VLBI network (EVN) by Minier et al. (2000a, 2001). Table 2
lists the positions of the maser features.
As we want to understand what kind of source is powering
the masers, Fig. 1 also shows other features characterizing the
massive star-forming regions:
(1) mm dust continuum data, tracing the massive molecular
cores in which the stars form,
(2) mid-infrared data, indicating warm dust around an embedded
 protostar,
(3) and cm continuum emission, probably due to optically thin
free-free emission signposting recently ignited massive stars
belonging to the same cluster. But as we do not have spectral
index information in the cm regime, it is also possible that some
of the cm features are still optically thick or could be due to jets
(see also Sridharan et al. 2002).
Table 1 presents more characteristic source properties, such
as the total luminosities, distances and core masses (Sridharan
et al. 2002; Beuther et al. 2002a).
It is of major interest to see how the different maser
types are associated with other observable features. Because
of the positional accuracy of the maser and cm observations
of ≈1′′, we cannot reliably separate features that are closer
than 1.5′′ to each other. On linear scales at the given distances
 of a few kpc, this is still a large separation (e.g., at
4 kpc distance, 1.5′′ correspond to ≈6000 AU ≈0.03 pc), and
we cannot be certain whether sources within 1.5′′ of each
other are associated or not. It has also to be taken into account
 that those separations are projections on the plane of
the sky, and there are probably spatial offsets along the line
of sight as well. If more than one maser feature is detected
we derived the separations using the nearest positions (except
 of the H2O maser spots in 19217+1651 because clearly
two different groups exist). Lada (1999) report a mean separation
 between stellar objects in clusters around 0.1 pc, and
McCaughrean & Stauffer (1994) find mean separations in the
center of the Orion Nebula Cluster of ∼0.03 pc. The scenario
of merging intermediate-mass protostars within the innermost
center of star-forming cores requires even higher protostellar
densities between 106 pc−3 and 108 pc−3, corresponding to
mean separations between 0.01 pc and 0.002 pc (Bonnell et al.
1998; Stahler et al. 2000). Taking all these different estimates
into account, it is possible that a significant fraction of features,
 that seem to be associated within our observational accuracy,
 are powered by the same underlying source, but we
cannot be certain, and it is possible that multiple features are
powered by separate multiple sources. Within these powering
sources, different maser origins are possible, e.g., outflows,
disks or expanding shock waves (e.g., Garay & Lizano 1999).
Furthermore, separate components of a binary or multiple system
 might account for the maser emission, because multiple
system are more common in high-mass than in low-mass starforming
 regions (Preibisch et al. 1999). Due to the lower spatial
resolution and lower positional accuracy, mm and mid-infrared
sources cannot be separated from the maser features when they
are located within 5′′.
292
H. Beuther et al.: CH3OH and H2O masers in high-mass star-forming regions
Fig. 1. CH3OH (squares) and H2O (triangles) maser positions are presented. The grey-scales with contours show the mm continuum images
(thermal dust emission), the black (on white) contours present the cm observations tracing the free-free emission and the stars mark the midinfrared
 point source positions. The axes show offsets in arcseconds from the IRAS position with varying scales for the different sources.
As the sample is distributed throughout the whole Galactic
disk with largely different distances, we calculate linear separations
 between the masers and the other observable quantities
 (mm, cm and mid-infrared emission). For sources, where
the separation is below the pointing accuracy of the observations,
 the derived values have to be taken cautiously because
the errors are larger. As we only know kinematic distances for
many of the sources, Tables 3 and 4 list the separations derived
for the near and the far distance, respectively. Table 5 presents
the mean separations; for sources with distance ambiguity we
choose the near distance for this calculation. Additionally, a
summary of the features which are, within the observing accuracy,
 associated with each other is given in Table 5.
3.2. Associations and (non-)correlations
Regarding the sources south of declination 20◦, which were
in the observable range of both telescopes (the ATCA and the
VLA), and including 19410+2336 and 20126+4104 (EVN and
VLA data from Minier et al. 2000a, 2001), in 11 sources both
maser types are detected, in 7 just the CH3OH masers, and
in 6 only the H2O masers. Thus, ∼38% of the CH3OH maser
sources do not show H2O maser emission, and ∼35% of the
H2O maser sources do not emit in the CH3OH maser line.
This shows that both maser types could be powered by similar
sources, but that finding one does not necessarily imply finding
 the other as well. It rather confirms significant differences
in the emission process as already expected by the different
velocity ranges (e.g., Garay & Lizano 1999; Sridharan et al.
2002). As we are dealing with low-number statistics, we estimate
 the error by 1/
√
N with N being the number of sources
we are investigating. Thus, the approximate statistical errors of
our analysis are in the 20% range (relative to the percentages
of associations and (non-)correlations.) In sources with both
maser types, the masers seem to be always associated within
the accuracy of 1.5′′, except for 18 151−1208, the only field
of view where both types are detected but in two separate mm
cores, 80′′ apart. In contrast, in many sources just one of both
maser types is present.
Both maser species are always found close to a mm core,
traced by the dust continuum peak, with an average projected
separation of 0.03 pc (Table 5). Considering the mean spatial
H. Beuther et al.: CH3OH and H2O masers in high-mass star-forming regions
293
Fig. 1. continued.
separations within star-forming cluster (see 3.1), it is possible
that both masers are amplified by the same powering source.
Interestingly, 6 out of 22 H2O masers (27 ± 5%) are, within the
observing accuracy, also associated with cm emission, while
only 3 out of 18 CH3OH masers (17 ± 5%) are nearby the
cm peaks. The statistical difference between both maser–cm
associations is only weak. It is quite possible that some of
the maser/cm associations are even chance alignments due to
projection effects, but we cannot quantify that more precisely.
We note that we do not find any source with CH3OH and cm
294
H. Beuther et al.: CH3OH and H2O masers in high-mass star-forming regions
Table 1. Characteristic parameters of the maser associated massive star-forming regions. The distances, luminosities, 3.6 cm fluxes and singledish
 maser fluxes are taken from Sridharan et al. (2002), the core masses and peak column densities of the main mm core are derived from
1.2 mm dust continuum data (Beuther et al. 2002a). If no near-values are given, the distance ambiguity is solved (Sridharan et al. 2002).
source
dfar
dnear
Lfar
Lnear
Mfar
Mnear
NH2
cm
CH3OH
H2O
[kpc]
[kpc]
[L⊙]
[L⊙]
[M⊙]
[M⊙]
[1023 cm−2]
[mJy]
[Jy]
[Jy]
05358+3543
1.8
–
3.8
–
610
–
5.8
<1
162
45
18089−1732
13.0
3.6
5.6
4.5
31900
2400
17
0.9
54
75
18090−1832
10.0
6.6
4.5
4.1
4600
2000
2.4
?
82
–
18102−1800
14.0
2.6
5.3
3.8
24000
800
2.9
44
9
–
18151−1208
3.0
–
4.3
–
1100
–
4.4
<1
50
0.8
18182−1433
11.8
4.5
5.1
4.3
20700
3000
9.4
<1
24
18
18264−1152
12.5
3.5
5.1
4.0
55300
4300
16
<1
4
50
18290−0924
10.5
5.3
5.0
4.4
6500
1600
3.3
7.0
15
4
18306−0835
10.7
4.9
4.8
4.1
16400
3400
6.9
82
–
0.7
18308−0841
10.7
4.9
4.9
4.2
12800
2700
4.6
<1
–
1.5
18310−0825
10.4
5.2
4.8
4.2
15300
3800
1.8
7.0
–
–
18345−0641
9.5
–
4.6
–
6900
–
2.4
27
5
3
18372−0541
13.4
1.8
5.3
3.5
10200
200
2.6
80
9
1.5
18385−0512
13.1
2.0
5.3
3.7
13400
300
4.5
29
–
200
18440−0148
8.3
–
4.7
–
1700
–
0.4
<1
4
?
18488+0000
8.9
5.4
4.9
4.5
6100
2200
2.9
194
17
1
18521+0134
9.0
5.0
4.6
4.1
3000
900
2.0
<1
1
–
18553+0414
12.9
0.6
5.1
2.4
15800
35
3.6
<1
–
50
18566+0408
6.7
–
4.8
–
2100
–
2.9
<1
7
3
19012+0536
8.6
4.6
4.7
4.2
3900
1100
2.9
<1
1
2
19035+0641
2.2
–
3.9
–
390
–
1.9
4.0
14
9
19217+1651
10.5
–
4.9
–
9500
–
5.3
32
1
9
19282+1814
8.2
1.9
4.9
3.6
2700
150
2.4
<1
3
–
19410+2336
6.4
2.1
5.0
4.0
7800
800
5.7
1
30
110
20126+4104
1.7
–
3.9
–
500
–
5.2
<1
36
15
20293+3952
2.0
1.3
3.8
3.4
500
200
1.9
7.6
–
100
23033+5951
3.5
–
4.0
–
2300
–
3.7
1.7
–
4
23139+5939
4.8
–
4.4
–
1800
–
4.0
1.4
3
400
23151+5912
5.7
–
5.0
–
1200
–
1.8
<1
–
60
emission without an H2O maser nearby, whereas in three
sources H2O and cm peaks are coincident within our accuracy,
but no observed CH3OH maser is found in the same region.
An interesting example, which illustrates the different maser
properties, is 19 217+1651: some H2O and CH3OH features
are associated with the massive mm core, whereas another H2O
feature is found near the cm source approximately 6′′ apart
(Fig. 1). As the mm data are from interferometric Plateau de
Bure observations (accuracy 1′′), the separation of the cm and
mm peaks is real.
The mid-infrared sources stand somewhere between all the
other features. In some cases, they seem to be associated with
the mm sources and in other objects with the cm sources. The
same is observed for their spatial associations with both maser
species, in some sources their positions coincide within the
observing accuracy, in others they do not. A very peculiar
example is 18 488+0000, where an archetypical cometary ultracompact
 Hregion is at the edge of the mm core, but most
surprising, the mid-infrared source as well as the H2O maser
feature do not coincide with any of them, but are located at a
small secondary mm peak that looks insignificant from the mm
point of view (but is still massive, ∼400 M⊙at the near kinematic
 distance of ∼5 kpc, Beuther et al. 2002b).
To get a quantitative understanding of the spatial associations,
 we tried to find correlations between the linear separations
 of the different observed tracers and other quantities of
our sample (the luminosities, core masses, H2 column densities
and densities, as taken from Sridharan et al. 2002 and Beuther
et al. 2002a). We did not find any correlation among all those
different quantities.
3.3. Internal maser structure
To investigate whether the maser features show linear or arclike
 structures indicative of specific emission regions (disks,
outflows, or expanding shock waves, e.g., Walsh et al. 1998;
Garay et al. 1999; Norris 2000; Kylafis & Pavlakis 1999;
Minier et al. 2000a), we focused on the 6 sources for which
we have at least 3 spatially separate maser features in one
or both species. Outflows are ubiquitous features in massive
star-forming regions (Sridharan et al. 2002; Richer et al. 2000;
Churchwell 2000), therefore we additionally present the bipolar
 outflow directions found by Beuther et al. (2002b). Figure 2
shows the results.
Morphologically, one can find rings, arcs or linear structures
 in all cases, even between different maser species. But
H. Beuther et al.: CH3OH and H2O masers in high-mass star-forming regions
295
Table 2. Positions of the CH3OH & H2O maser. For the sources with citation we took the CH3OH maser data from 1Walsh et al. (1998) and
2Minier et al. (2000a, 2001).
source
CH3OH
vLSR
H2O
vLSR
[J2000.0]
[km s−1]
[J2000.0]
[km s−1]
05358+3543
Menten (Menten 1991),
05:39:13.0 35:45:48.7
−17
single-dish obs.
18089−1732
18:11:51.4 −17:31:30.21
39
18:11:51.5 −17:31:28.8
32
18090−1832
18:12:01.9 −18:31:55.01
108
18102−1800
18:13:11.3 −17:59:57.8
25
18:13:11.3 −17:59:58.0
24/23
18151−1208
18:17:58.1 −12:07:25.4
28
18:17:50.3 −12:07:52.9
22/25/32
18182−1433
18:21:09.2 −14:31:48.61
62
18:21:09.1 −14:31:48.7
60
18:21:09.1 −14:31:47.8
65
18:21:09.0 −14:31:48.5
57
18:21:09.0 −14:31:47.9
50/53
18:21:09.1 −14:31:48.6
68
18264−1152
18:29:14.4 −11:50:22.4
47
18:29:14.2 −11:50:22.6
45/52
18:29:14.4 −11:50:24.5
61/68/74
18:29:14.3 −11:50:22.5
52
18290−0924
18:31:44.2 −09:22:12.51
80
18:31:44.1 −09:22:12.1
88
18306−0835
18:33:23.9 −08:33:31.6
105
18:33:17.1 −08:33:24.3
82
18308−0841
18:33:33.2 −08:39:15.1
69/73/86
18310−0825
18:33:43.8 −08:21:20.51
88
18345−0641
18:37:16.9 −06:38:30.4
97
18:37:17.0 −06:38:30.3
94
18372−0541
18:39:55.9 −05:38:45.1
25
18:39:55.9 −05:38:44.1
23
18:39:55.9 −05:38:44.9
24
18:39:55.9 −05:38:44.6
26
18:39:56.0 −05:38:45.9
23
18:39:56.0 −05:38:45.8
18
18385−0521
18:41:13.2 −05:09:00.5
19
18:41:13.2 −05:09:01.0
11
18:41:13.2 −05:09:01.1
26
18:41:13.2 −05:09:01.2
30
18:41:13.2 −05:09:01.3
37
18440−0148
18:46:36.7 −01:45:22.21
105
18488+0000
18:51:24.5 00:04:33.7
80
18521+0134
18:54:40.8 01:38:04.5
77
18553+0414
18:57:53.4 04:18:17.4
4
18:57:53.4 04:18:17.3
12
18566+0408
18:59:10.0 04:12:14.7
87/86
18:59:10.0 04:12:15.6
88
18:59:10.0 04:12:14.1
84
18:59:10.0 04:12:15.7
68
18:59:10.0 04:12:14.0
79
19012+0536
19:03:45.3 05:40:42.8
63
19035+0641
19:06:01.6 06:46:35.9
37/31
19:06:01.6 06:46:36.3
21
19217+1651
19:23:58.9 16:57:41.8
7
19:23:58.5 16:57:41.4
18
19:23:58.8 16:57:41.5
11
19:23:58.8 16:57:41.1
8
19282+1814
19:30:23.0 18:20:27.1
19
19410+2336
19:43:11.3 23:44:03.32
27
19:43:11.2 23:44:03.0
27
19:43:11.2 23:44:03.02
17
19:43:11.2 23:44:03.1
19
20126+4104
20:14:26.0 41:13:33.42
−6
20:14:26.0 41:13:32.6
0
20:14:26.0 41:13:32.7
−8
20293+3952
20:31:12.9 40:03:22.8
2/−28
23033+5951
23:05:25.0 60:08:14.1
−49/−55/−62
23139+5939
23:16:10.3 59:55:28.7
−48/−53
23:16:10.3 59:55:28.6
−44
23:16:10.4 59:55:28.8
−33
23151+5912
23:17:20.8 59:28:47.0
−52
23:17:20.3 59:28:47.3
−69
296
H. Beuther et al.: CH3OH and H2O masers in high-mass star-forming regions
Table 3. Separations of the CH3OH masers from H2O, mm, cm and mid-infrared sources. Far and near values correspond to the far and
near distance, respectively. For sources without near values, the distance ambiguity is solved (Sridharan et al. 2002). The uncertainty of the
CH3OH/H2O column is ∼1.5′′ and scales with the distances for the linear separations. The uncertainties of the other columns are ∼5′′, scaling
with the distances as well.
source
CH3OH/H2O
CH3OH/mm
CH3OH/cm
CH3OH/MIR
far
near
far
near
far
near
far
near
[′′]
[pc]
[pc]
[′′]
[pc]
[pc]
[′′]
[pc]
[pc]
[′′]
[pc]
[pc]
18089−1732
1.5
0.1
0.03
1.5
0.1
0.03
1.5
0.1
0.03
11
0.69
0.19
18090−1832
0.5
0.02
0.02
0.5
0.02
0.02
18102−1800
4
0.27
0.05
30
2.04
0.38
30
2.04
0.38
18151−1208
80
1.16
0.5
0.01
12
0.16
18182−1433
1
0.06
0.02
1
0.06
0.02
12
0.67
0.26
18264−1152
1
0.06
0.02
1
0.06
0.02
9
0.55
0.15
18290−0924
1
0.05
0.03
2
0.1
0.05
20
1.02
0.51
1
0.05
0.03
18310−0825
4
0.2
0.1
16
0.81
0.40
18345−0641
0.5
0.02
3
0.14
18372−0541
0.5
0.03
0.004
1
0.07
0.01
1
0.07
0.01
1
0.07
0.01
18440−0148
1
0.04
4
0.16
18521+0134
1
0.04
0.02
4
0.18
0.1
18566+0408
1
0.03
1
0.03
1
0.03
19035+0641
0.5
0.01
2
0.02
7
0.08
1
0.01
19217+1651
0.5
0.03
1
0.05
6
0.3
1.5
0.08
19282+1814
1
0.04
0.01
20
0.80
0.18
19410+2336
0.5
0.02
0.01
5
0.16
0.05
1
0.03
0.01
5
0.16
0.05
20126+4104
1
0.01
1
0.01
3
0.03
Table 4. Separations of the H2O masers from mm, cm and mid-infrared sources. Far and near values correspond to the far and near distance,
respectively. For sources without near values, the distance ambiguity is solved (Sridharan et al. 2002). The uncertainties are ∼5′′, scaling with
the distances for the linear separations.
source
H2O/mm
H2O/cm
H2O/MIR
far
near
far
near
far
near
[′′]
[pc]
[pc]
[′′]
[pc]
[pc]
[′′]
[pc]
[pc]
05358+3543
2
0.02
3
0.03
18089−1732
0.5
0.03
0.01
0.5
0.03
0.01
10
0.63
0.18
18151−1208
0.5
0.01
18182−1433
1
0.06
0.02
12
0.67
0.26
18264−1152
1
0.06
0.02
7
0.67
0.26
18290−0924
2
0.1
0.01
20
1.02
0.51
1
0.05
0.03
18306−0835
0.5
0.03
0.01
12
0.62
0.29
12
0.62
0.29
18308−0841
4
0.2
0.1
7
0.36
0.17
18372−0541
1
0.07
0.01
1
0.07
0.01
1
0.07
0.01
18385−0512
1
0.06
0.01
3
0.19
0.03
1
0.06
0.01
18488+0000
4
0.17
0.11
20
0.89
0.54
3
0.13
0.08
18553+0414
1
0.06
0.003
18
1.13
0.05
3
0.19
0.01
18566+0408
0.5
0.02
1
0.02
19012+0536
0.5
0.02
0.01
7
0.29
0.16
19035+0641
2
0.02
7
0.08
1
0.01
19217+1651
1
0.05
6/1
0.3/0.05
2
0.1
19410+2336
5
0.16
0.05
1
0.03
0.01
5
0.16
0.05
20126+4104
2
0.16
2
0.16
20293+3952
2
0.19
0.13
18
0.18
0.11
22
0.21
0.14
23033+5951
1
0.02
1.5
0.03
4
0.07
23139+5939
1
0.02
1
0.02
0.5
0.01
23151+5912
1.5
0.04
7
0.19
none of them has a coherent velocity structure and therefore
cannot easily be interpreted in terms of disks, outflows or expanding
 shock waves. There is also no obvious correlation with
the outflow direction. With only one set of observations, it is
very difficult to interpret these morphological and kinematic
signatures, but it is well possible that follow-up observations,
H. Beuther et al.: CH3OH and H2O masers in high-mass star-forming regions
297
Table 5. Frequency of associated features within the spatial resolution
as given in Sect. 3. The third column gives the percentage of associations
 with respect to the total number of sources where CH3OH or
H2O masers were detected. The last column presents the mean separations
 and their uncertainties.
association
number
%
mean
[pc]
CH3OH/H2O
10
56
0.02 ± 0.03
CH3OH/mm
18
100
0.03 ± 0.10
CH3OH/cm
3
17
0.19 ± 0.03
CH3OH/MIR
11
61
0.13 ± 0.10
H2O/mm
22
100
0.03 ± 0.10
H2O/cm
6
27
0.13 ± 0.03
H2O/MIR
13
59
0.09 ± 0.10
and thus proper motion studies, might be capable of setting better
 constraints on the regions where the maser emission is produced.
 Such studies were successful in a number of cases, e.g.,
Alcolea et al. (1992) and Minier et al. (2000b).
4. Discussion
The observations presented in Sect. 3 confirm that both maser
species – CH3OH and H2O – are signposts of very early stages
of massive star formation. While 100% of the maser detections
are clearly associated with massive molecular cores traced by
mm dust continuum emission, only about 20% are also associated
 with cm continuum emission that is indicative of recently
ignited, and thus more evolved stars. These observations confirm
 results obtained for each maser species separately over the
last few years, that CH3OH and H2O masers are signposts of
very early stages of massive star formation, and that both seem
to cease emission soon after the ignition of a central object
(e.g., Tofani et al. 1995; Codella et al. 1996, 1997; Walsh et al.
1998; Minier et al. 2001). Here we show for the first time the
similarities and differences of both maser types within a consistent
 study of a homogenous sample.
In spite of the small separations around 0.03 pc within
many sources, there are clear differences between both maser
types. In addition to their large velocity differences (Sridharan
et al. 2002), in approximately 30% of the sources just one
maser species is found. We do find a few sources with nearby
H2O maser and cm emission, but not showing CH3OH maser
emission. In contrast, every source, where CH3OH maser emission
 is associated with a cm source, has an H2O maser nearby.
This difference suggests tentatively that CH3OH maser emission
 might be more sensitive to the ignited central object, and
may cease emitting in somewhat earlier evolutionary stages
than H2O maser emission. However, it has to be noted that
counterexamples exist, e.g., the W3(OH) region, where the
CH3OH masers are associated with the ultracompact Hregion,
 and the H2O masers are approximately 6′′ to the east associated
 with the hot core W3(H2O). For a summary of the
results in that region see Menten (1996).
Fig. 2. Zoom into some maser distributions. The triangles show H2O
masers and the squares CH3OH masers. The numbers mark the radial
 velocities at which each feature emits, and the arrows indicate the
overall directions of the molecular outflows (solid: blue wing, dashed:
red wing) as found by Beuther et al. (2002b). The axes show the offsets
in arcseconds from the IRAS position.
CH3OH maser models propose that the maser emission
is produced by radiative pumping in moderately hot regions
(∼150 K) with CH3OH column densities >2 × 1015 cm−2 and
hydrogen number densities <108 cm−3 (Hartquist et al. 1995;
Sobolev et al. 1997; Cragg et al. 2001). The data presented here
as well as other studies (e.g., Walsh et al. 1997; 1998; Phillips
et al. 1998; Minier et al. 2000a; 2001) indicate that the ignition
of a massive star, and thus the formation of an ultracompact H
region, alters these conditions swiftly and stops further CH3OH
maser emission very soon.
In contrast, H2O maser models mostly explain the excitation
 by collisional pumping with H2 molecules in shocks associated
 with outflows (Elitzur et al. 1989). Such collisional
pumping can also occur by accretion shocks in accretion disks
(Garay & Lizano 1999). These processes may not depend as
strongly on the influence of the Hregion as the radiative
pumping of the CH3OH maser, and H2O maser emission might
continue some time in more evolved stages of evolution. But
298
H. Beuther et al.: CH3OH and H2O masers in high-mass star-forming regions
obviously, the statistics of the observations are not sufficient
for a stronger statement.
The percentage of associated maser and mid-infrared
sources (∼60%) lies in a similar regime as found recently by
Walsh et al. (2001). They propose that the mid-infrared objects,
which are likely to be embedded luminous protostellar objects,
could be the pumping sources of the maser sites. This might
be true in the associated sources of our sample as well, but
the percentage of associations clearly shows that detections in
the mid-infrared regime are not necessary to produce the maser
emission. It is possible that for high obscuration the sources are
not detectable in the mid-infrared – only the maser shows up.
Additionally, we do not find strong correlations between
the spatial separations of the different observed quantities and
other characteristic quantities of the sources, e.g., the luminosities,
 core masses, column densities, and volume densities.
Thus, it seems likely that both maser species need a similar environment
 of dense and warm gas, but that, due to the different
excitation processes (radiative pumping for CH3OH and collisional
 pumping for H2O), no real correlation exists. Spatial
associations of both maser species might be just coincidences
caused by insufficient spatial resolution and projection effects.
We cannot determine accurately in any source of this sample
 whether the maser emission is produced in disks, outflows
or shock waves. This stresses that kinematic interpretations of
different maser features are difficult and not as straightforward
as sometimes supposed in the past (e.g., Garay & Lizano 1999;
Norris et al. 1998). CH3OH and H2O masers are excellent signposts
 of massive star-forming regions, but the detailed interpretation
 of the different kinematic and spatial features has to
be treated with caution. There are definitely cases where the
kinematic information gives deep insights in special sources,
e.g., the H2O maser in W3(H2O) (Alcolea et al. 1992), or some
of the linear structures found in CH3OH by, e.g., Walsh et al.
(1998), Minier et al. (2000a), Norris et al. (1998), and Phillips
et al. (1998), but as stressed by Minier et al. (2000a), proper
motions and VLBI observations are needed to derive conclusive
 answers for such sources. We believe that the approach of
kinematic interpretation of different maser features works only
in a limited number of sources with a favorable geometry with
respect to the observer, and then especially when proper motion
observations are available. With this regard, the data presented
in this paper are a well suited basis for follow-up proper motion
studies of both maser species. Except for this, for most sources,
the main and highly important outcome of maser observations
in massive star-forming regions is their characteristics as signposts
 for high-mass star formation.
Acknowledgements. We like to thank the referee Dr. G. Fuller for
detailed comments on the first draft, which improved the quality
of the paper significantly. H. Beuther got support by the Deutsche
Forschungsgemeinschaft, DFG project number SPP 471.
Introduction
The CASA package (McMullin et al. 2007) provides a powerful
tool for data post-processing for ALMA and JVLA, but contains
only rudimentary functions for modeling the data. But modeling
astronomical data is essential to derive physical parameters such
as column densities and rotational temperatures, as well as information
 on the location and the kinematics of the emitting gas
component for each observed molecular species.
The toolbox described in this paper offers not only the
possibility to model data by using the myXCLASS program
(Schilke et al. 2001; Comito et al. 2005; Zernickel et al. 2012;
Crockett et al. 2014a,b; Neill et al. 2014), which computes synthetic
 spectra by solving the detection equation similar to software
 packages like Weeds (Maret et al. 2011) and CASSIS1, but
also makes use of the optimization package MAGIX (Möller et al.
2013). MAGIX provides a framework of an easy interface between
 existing codes and an iterating engine that attempts to
minimize deviations of the model results from available observational
 data, constraining the values of the model parameters
 and providing corresponding error estimates. In addition to
the myXCLASS program many external model programs2 such
as RADEX (Van der Tak et al. 2007), RADMC-3D3 or LIME
(Brinch & Hogerheijde 2010) can be plugged into MAGIX to
⋆http://www.astro.uni-koeln.de/projects/schilke/
myXCLASSInterface
⋆⋆A copy of the code is available at the CDS via anonymous ftp to
cdsarc.u-strasbg.fr (130.79.128.5) or via
http://cdsarc.u-strasbg.fr/viz-bin/qcat?J/A+A/598/A7
1 http://cassis.irap.omp.eu/
2 Here, the phrase “external model program” means the external program
 that calculates the model function depending on several input parameters.

3 http://www.ita.uni-heidelberg.de/~dullemond/
software/radmc-3d/
explore their parameter space and find the set of parameter values
 that best fits observational data. Most of the optimization
algorithms included in the MAGIX package are available as an
OpenMP4 and an MPI5 version to speed up the computation. Furthermore,
 the toolbox includes two new functions which provide
a simplified interface for MAGIX in conjunction with myXCLASS
to model single spectra and complete data cubes, respectively.
Once installed, it is seamlessly integrated into CASA, so the
tasklist command within CASA lists all the new functions. In
addition, the help command followed by the name of the function
 provides a short description of the corresponding function
with a short overview of all input parameters. In addition, the
XCLASS interface can be used without CASA, wherefore the
following python packages has to be installed: numpy, scipy,
pyfits, matplotlib and sqlite3.
The Splatalogue database6 is accessible from within the
viewer in CASA. We have opted to use our own SQLite3
database based on the VAMDC7 implementation, mostly because
 this allows the user to augment the data by providing the
partition function between 1.072 and 1000 K at 110 different
temperatures in contrast to seven temperatures in the Splatalogue
 database, which is derived from the traditional JPL8 and
CDMS9 catalogs. It is hoped that the content of Splatalogue and
the VAMDC database will at some point be homogenized.
The XCLASS interface for CASA is mostly written in
python, whereas the myXCLASS program and most of the algorithms
 included in the MAGIX package are written in Fortran 90.
All required Python modules are already included in the CASA
4 http://openmp.org/wp/
5 http://www.open-mpi.org/
6 http://www.splatalogue.net
7 http://www.vamdc.eu
8 http://spec.jpl.nasa.gov
9 http://www.cdms.de
Article published by EDP Sciences
A7, page 1 of 20
A&A 598, A7 (2017)
package, so no further software package except the GNU compiler10
 (gfortran and gcc) with OpenMP/OpenMPI extension
has to be installed. The XCLASS interface for CASA is available
 for Linux and Mac OS 10.11 (64 bit).
In the next sections we describe the myXCLASS program and
its algorithms, assumptions, and shortcomings in detail. Afterwards,
 we describe the SQLite3 database used for the myXCLASS
program and the related functions provided by the XCLASS interface.
 In the following we briefly present the MAGIX package
with a short overview of the included algorithms. Finally, we
give a detailed description of the new functions myXCLASSFit
and myXCLASSMapFit used for modeling data with myXCLASS
and MAGIX.
2. myXCLASS
The XCLASS interface for CASA contains the myXCLASS
program, originally developed by P. Schilke (Schilke et al.
2001; Comito et al. 2005; Zernickel et al. 2012; Crockett et al.
2014a,b; Neill et al. 2014) based on the GILDAS11 package
CLASS, which models a spectrum by solving the radiative transfer
 equation for an isothermal object in one dimension, the detection
 equation (Stahler & Palla 2005). Here, LTE is assumed,
that is, the source function is given by the Planck function of an
excitation temperature, which does not need to be the physical
temperature, but is constant for all transitions. The myXCLASS
function is designed to describe line-rich sources which are often
 dense, so that LTE is a reasonable approximation. Also, a
non-LTE description requires collision rates which are available
only for a few molecules.
The myXCLASS function is able to model a spectrum with an
arbitrary number of molecules where the contribution of each
molecule is described by an arbitrary number of components.
The 1d assumption imposes a very simplistic geometrical structure.
 We recognize two classes of components.
One, the core objects (in earlier implementations called
emission component), consists of an ensemble of objects centered
 at the middle of the beam. These could be identified with
clumps, hot dense cores etc. which overlaps but do not interact
 either because they do not overlap in physical or in velocity
 space. For computational convenience, they are assumed to
be centered in the beam, as shown in Fig. 1. It is also assumed
that the dust emission emanates (partly) from these components.
Their intensities are added, weighted with the beam filling factor,
see Eq. (2).
The second class, foreground objects (in earlier implementations
 called absorption components), are assumed to be in layers
in front of the core components. In the current 1d implementation,
 they would have a beam averaged intensity of the core
sources as background, and would fill the whole beam. Examples
 for such structures would be source envelopes in front of
dense cores, or absorption components along the line-of-sight.
As shown in Fig. 1, we assume that core components do not
interact with each other radiatively, that is, one core layer is not
influenced by the others. But the core layers may overlap to offer
the possibility to model sources consisting of several molecules
and compounds. The solution of the radiative transfer equation
10 https://gcc.gnu.org/
11 http://iram.fr/IRAMFR/GILDAS/
beam
1
1
4
4 3
3 2
2
Fig. 1. Sketch of a distribution of core layers within the Gaussian beam
of the telescope (black ring). Here, we assume three different core components
 1, 2, and 3, centered at the middle of the beam with different
source sizes, excitation temperatures, velocity offsets etc. indicated by
different colors. Additionally, we assume that all core components have
the same distance to the telescope, i.e., all core layers are located within
a plane perpendicular to the line of sight. Furthermore, we assume that
this plane is located in front of a background Layer 4 with homogeneous
intensity Icore
bg (ν) over the whole beam. Core components do not interact
with each other radiatively.
for core layers is12,
T core
mb (ν) =
X
m
X
c
"
η (θm,c)
h
S m,c(ν)

1 −e−τm,c
total(ν)
+ Icore
bg (ν)

e−τm,c
total(ν) −1
i #
+

Icore
bg (ν) −JCMB

,
(1)
where the sums go over the indices m for molecule, and c for
(core) component, respectively. In the following we briefly describe
 each term in Eq. (1).
The beam filling (dilution) factor η(θm,c) of molecule m and
component c in Eq. (1) for a source with a Gaussian brightness
profile, see below, and a Gaussian beam is given by13
η(θm,c) =
(θm,c)2
θt(ν)2 + (θm,c)2 ,
(2)
where θm,c and θt represents the source and telescope beam full
width half maximum (FWHM) sizes, respectively. The sources
beam FWHM sizes θm,c for the different components are defined
by the user in the molfit file, described in Sect. 2.1. Additionally,
we assume for single dish observations, that the telescope beam
FWHM size is related to the diameter of the telescope by the
diffraction limit
θt(ν) =

1.22 · λ
D

· ξ =

1.22 · clight
ν D

· ξ,
(3)
where D describes the diameter of the telescope, clight the speed
of light, and ξ = 3600 × 180 π−1 a conversion factor to get the
12 A derivation of the expression can be found in Appendix B.1.
13 Derivations of the beam filling factor Eq. (2), are described in Appendix
 B.2.
A7, page 2 of 20
T. Möller et al.: XCLASS
telescope beam FWHM size in arcsec. For interferometric observations,
 the user has to define the interferometric beam FWHM
size directly. In contrast to single dish observations we assume
a constant interferometric beam FWHM size for the whole frequency
 range.
In general, the brightness temperature of radiation temperature
 J(T, ν) is defined as
J(T, ν) = h ν
kB
1
eh ν/k T −1·
(4)
The expression JCMB used in Eq. (1), describes the radiation temperature
 Eq. (4) of the cosmic background Tcbg = 2.7 K, that is,
JCMB ≡J(Tcbg, ν).
In Eq. (1), the expression S m,c(ν) represents the source function
 and is according to Kirchhoff’s law of thermal radiation
given by
S m,c(ν) =
ϵm,c
l
(ν) + ϵm,c
d (ν)
κm,c
l
(ν) + κm,c
d (ν)
=
κm,c
l
(ν) J(T m,c
ex , ν) + κm,c
d (ν) J(T m,c
d , ν)
κm,c
l
(ν) + κm,c
d (ν)
=

1 −δγ,0

·
"τm,c
l
(ν) J(T m,c
ex , ν) + τm,c
d (ν) J(T m,c
d , ν)
τm,c
l
(ν) + τm,c
d (ν)
#
+ δγ,0 J(T m,c
ex , ν),
(5)
where ϵm,c
l,d (ν) and κm,c
l,d (ν) are the core and foreground coefficients
for line and dust, respectively. Additionally, the optical depth is
given by τm,c(ν) =
R
κm,c(ν) ds = κm,c(ν) s. This assumes that
molecules and dust are well mixed, that is, it would not be correct
if the molecule exists only in part of the cloud, but the dust everywhere.
 In older versions, the background temperature could only
be defined as the measured continuum offset, which corresponds
to the beam-averaged continuum brightness temperature. At the
same time, the dust, as agent of line attenuation, was described
by column density and opacity. This is practical, because the observable
 Tbg is used, but does not constitute a self-consistent and
fully physical description. Therefore, we now use optionally either
 a physical (γ ≡1) or phenomenological (γ ≡0) description
of the background indicated by the Kronecker delta δγ,0, that is,
S m,c(ν) ≡J(T m,c
ex , ν) for γ ≡0. (Here, the phrase “background”
means the “layer” with intensity Icore
bg (ν) which is located behind
the core components, that is, the background of the core layers,
see Fig. 1.) We note that, if γ ≡0, the definition of the dust
temperature T m,c
d (ν), Eq. (13), is superfluous.
The total optical depth τm,c
total(ν) of each molecule m and component
 c is defined as the sum of the optical depths τm,c
l
(ν) of all
lines of each molecule m and component c plus the dust optical
depth τm,c
d (ν), that is,
τm,c
total(ν) = τm,c
l
(ν) + τm,c
d (ν),
(6)
where the dust optical depth τm,c
d (ν) takes the dust attenuation
into account and is given by
τm,c
d (ν) = τm,c
d,ref ·
 ν
νref
!βm,c
=

Nm,c
H
· κm,c
νref · mH2 ·
1
ζgas−dust
!
·
 ν
νref
!βm,c
·
(7)
Here, Nm,c
H
describes the hydrogen column density, κm,c
νref the dust
mass opacity for a certain type of dust (Ossenkopf & Henning
1994) at the reference frequency νref, and βm,c the spectral index
of κm,c
νref . These parameters are defined by the user, see Sect. 2.1.
In addition, νref = 230 GHz indicates the reference frequency
of the reference dust opacity τm,c
d,ref, mH2 describes the mass of a
hydrogen molecule, and ζ−1
gas−dust describes the dust to gas ratio
and is set here to (1/100) (Hillebrand 1983). The equation is valid
for dust and gas well mixed.
The optical depth τm,c
l
(ν) of all lines for each molecule m and
component c is described as14
τm,c
l
(ν) =
X
t
" c2
light
8πν2 At
ul Nm,c
tot
gt
u e−Et
l/kB T m,c
ex
Q  m, T m,c
ex


1 −e−h νt/kB T m,c
ex 
× φm,c,t(ν)
#
,
(8)
where the sum with index t runs over all spectral line transitions
 of molecule m within the given frequency range. The Einstein
 Aul coefficient15, the energy of the lower state El, the upper
 state degeneracy gu, and the partition function Q  m, T m,c
ex

of molecule m are taken from the embedded SQLite3 database,
described in Sect. 3. (Because the database usually does not describe
 the partition functions at the given excitation temperature
T m,c
ex , the value of Q  m, T m,c
ex
 is computed from a linear interpolation.
 With the new catalog, extrapolation should not be necessary
 for most conditions encountered in molecular cores.) In addition,
 the values of the excitation temperatures T m,c
ex and the column
 densities Nm,c
tot for the different components and molecules
are taken from the user defined molfit file, see Sect. 2.1.
In order to take broadening of lines caused by the thermal
motion of the gas particles and micro-turbulence into account
we assume in Eq. (8) a normalized Gaussian line profile, that is,
R ∞
0 φ(ν) dν = 1, for a spectral line t:
φm,c,t(ν) =
1
√
2π σm,c,t · e−(ν−(νt+δνm,c,t
LSR))
2
2(σm,c,t)2
.
(9)
The source frequency δνm,c,t
LSR for each component c of a molecule
m is related to the user defined velocity offset

δvm,c
offset

taken from
the aforementioned molfit file, by the following expression
δνm,c,t
LSR = −
δvm,c
offset
clight
· νt,
(10)
where νt indicates the frequency of transition t taken from the
SQLite3 database mentioned above. Additionally, the standard
deviation σm,c of the profile is defined by the velocity width

∆vm,c
width

described in the molfit file for each component c of a
molecule m:
σm,c,t =
∆vm,c
width
clight ·

νt + δνm,c,t
LSR

2
√
2 ln 2
·
(11)
The beam-averaged continuum background temperature Icore
bg (ν)
is parametrized as
Icore
bg (ν) = Tbg ·
 ν
νmin
!Tslope
+ JCMB
(12)
14 A derivation of the expression is given in Appendix B.3.
15 The indices u and l represent upper and lower state of transition t,
respectively.
A7, page 3 of 20
A&A 598, A7 (2017)
to allow the user to define the continuum contribution for each
frequency range, individually. Here, νmin indicates the lowest frequency
 of a given frequency range. Tbg and Tslope, defined by the
user, describe the background continuum temperature and the
temperature slope, respectively. Here, the treatment of the dust
is not entirely self-consistent. To amend that, we would need to
define the sub-beam scale structure of the source, which we consider
 to be outside the scope of the current effort, although it is
envisioned to provide this as an option in the future.
In Eq. (1), the continuum contribution is described through
the source function S m,c(ν), Eq. (5), by an effective dust temperature
 T m,c
d
(through J(T m,c
d , ν)) for each component which is
given by
T m,c
d (ν) = T m,c
ex (ν) + ∆T m,c
d (ν)
= T m,c
ex (ν) + T m,c
d,off·
 ν
νmin
!T m,c
d,slope
,
(13)
where T m,c
d,offand T m,c
d,slope can be defined by the user for each component
 in the molfit. If T m,c
d,offand T m,c
d,slope are not defined for a
certain component, we assume T m,c
d (ν) ≡T m,c
ex (ν) for all components.
 For a physical (γ ≡1) description of the background intensity,
 see Eq. (5), the user can define the dust opacity, Eq. (7),
and dust temperature, Eq. (13), for each component.
Finally, the last term JCMB in Eq. (1) describes the OFF position
 for single dish observations, where we have an intensity
caused by the cosmic background JCMB. For interferometric observations,
 the contribution of the cosmic background is filtered
out and has to be subtracted as well.
In contrast to core layers, foreground components may interact
 with each other, as shown in Fig. 2, where absorption takes
places only, if the excitation temperature for the absorbing layer
is lower than the temperature of the background.
Hence, the solution of the radiative transfer equation for foreground
 layers can not be given in a form similar to Eq. (1). Foreground
 components have to be considered in an iterative manner.
 The solution of the radiative transfer equation for foreground
layers can be expressed as
T fore
mb (ν)m,c=1 = η

θm,c=1 
S m,c=1(ν) −T core
mb (ν)
 
1 −e−τm,c=1
total (ν)
+ T core
mb (ν)
T fore
mb (ν)m,c=i = η

θm,c=i 
S m,c=i(ν) −T fore
mb (ν)m,c=(i−1)

×

1 −e−τm,c=i
total (ν)
+ T fore
mb (ν)m,c=(i−1),
(14)
where m indicates the index of the current molecule and i represents
 an index running over all foreground components c of all
molecules. Additionally, we assume that each foreground component
 covers the whole beam, that is, η

θm,c=1
≡1 for all foreground
 layer. Thus, Eq. (14) simplifies to
T fore
mb (ν)m,c=1 =
h
S m,c=1(ν)

1 −e−τm,c=1
total (ν)
+ T core
mb (ν)e−τm,c=1
total (ν)i
T fore
mb (ν)m,c=i =
h
S m,c=i(ν)

1 −e−τm,c=i
total (ν)
+ T fore
mb (ν)m,c=(i−1)e−τm,c=i
total (ν)i
,
(15)
where T core
mb (ν) describes the core spectrum, see Eq. (1), including
 the beam-averaged continuum background temperature
Icore
bg (ν). For foreground lines the contribution by other components
 is considered by first calculating the contribution of core
objects and then use this as new continuum for foreground lines
beam
1
1
3
3
4
4
2a
2a
2c
2c
2b
2b
Fig. 2. Sketch of a distribution of core and foreground layers within
the Gaussian shaped beam of the telescope (black ring). Here, we assume
 three different core components 2a, 2b, and 2c located in a plane
perpendicular to the line of sight which lies in front of the background
layer 1 with intensity Icore
bg (ν), see Eq. (12). The foreground layers 3 and
4 are located between the core layers and the telescope along the line of
sight (black dashed line). Here, each component is described by different
 excitation temperatures, velocity offsets etc. indicated by different
colors. The thickness of each layer is described indirectly by the total
column density Nm,c
tot , see Appendix B.3. For each foreground layer we
assume a beam filling factor of one, i.e., each foreground layer covers
the whole beam.
reflecting the fact that cold foreground layers are often found
in front of hotter emission sources. We assume, that the cosmic
 background describes together with the core components
one end of a stack of layers. Additionally, the foreground components
 are located between this plane and the telescope, see
Fig. 2. The total column density Nm,c
tot depends on the abundance
of a certain molecule and on the thickness of a layer containing
the molecule. The order of components along the line of sight is
defined by the occurrence of a certain foreground component in
the molfit file.
By fitting all species and their components at once, line
blending and optical depth effects are taken into account. The
modeling can be done simultaneously with isotopologues (and
higher vibrational states) of a molecule assuming an isotopic ratio
 stored in the so-called iso ratio file, see Sect. 2.2. Here, all
parameters are expected to be the same except the column density
 which is scaled by one over the isotopic ratio for each isotopologue.

In order to correctly take instrumental resolution effects into
account in comparing the modeled spectrum with observations
myXCLASS integrates the calculated spectrum over each channel.
 Thereby, myXCLASS assumes that the given frequencies ν
describe the center of each channel, respectively. This is particularly
 important if the instrumental channel width is in the order
of, or even larger, than intrinsic line widths. The resulting value
is than given as
Tmb(ν) =
1
∆νc
Z ν+ ∆νc
2
ν−∆νc
2
Tmb(˜
ν)d˜
ν,
(16)
where ∆νc represents the width of a channel. Due to the complexity
 of Eqs. (1) and (15) the integration in Eq. (16) can not
A7, page 4 of 20
T. Möller et al.: XCLASS
484240.0
484260.0
484280.0
484300.0
484320.0
Rest Frequency (MHz)
12.28
12.30
12.32
12.34
12.36
12.38
12.40
12.42
Tmb (K)
step size 0.5 MHz
step size 2.0 MHz
step size 10 MHz
Fig. 3. myXCLASS function used to calculate a spectrum for three different
 step sizes.
be done analytically. Therefore, myXCLASS performs a piecewise
integration of each component and channel using the trapezoidal
rule and sums up the resulting values to get the final value used
in Eq. (16). Internal resampling guarantees that even if the line
width is smaller than the channel width the integration is done
correctly, see Fig. 3.
2.1. The molfit file
Within the molfit file the user defines both which molecules
are taken into account and the number of components for each
molecule. Additionally, the user has to define for each component
 the source size θm,c in arcsec (size), the excitation temperature
 Tex in K (T_ex), the column density Ntot in cm−2 (N_tot),
the velocity width (FWHM) ∆ν in km s−1 (V_width), the velocity
 offset in km s−1 (V_off), which is via Eq. (10) connected to
the source velocity νLSR, and the flag (CFFlag) indicating if a
component is considered for core c or foreground f. The definition
 of the source size θm,c for a foreground component will be
ignored, because we assume that all foreground layers cover the
whole beam. So, the definition of this parameter is not necessary.
Example of a molfit file:
% Number of molecules = 2
% size:
T_ex:
N_tot: V_width: V_off:
CFFlag:
CS;v=0;
3
48.47
80.00
3.91E+17
2.86 -20.56
c
21.80
51.03
6.96E+17
8.07
30.68
c
81.70
68.11
1.46E+17
5.16 -10.12
c
HCS+;v=0;
2
150.00
1.10E+18
5.00
-0.15
f
200.00
2.20E+17
3.10
-2.15
f
The definition of parameters for a molecule starts with a line describing
 the name of the molecule, which must be identical to
the name of the molecule included in the database, see Sect. 3,
followed by the number of components N for this molecule.
The following N lines describe the parameters for each components,
 separately. Generally, all parameters have to be separated
by blanks, comments are marked with the % character.
In order to define the dust temperature for each component,
the molfit file has to contain two additional columns between
columns V_off and CFFlag, describing the parameters T m,c
d,offand
T m,c
d,slope, Eq. (13), respectively.
Additionally, the myXCLASS program allows to define a hydrogen
 column density NH (in cm−2), dust mass opacity κνref (in
cm2 g−1), and the spectral index β for each component or globally,
 that is, Nm,c
H
→NH, κm,c
νref →κνref, and βm,c →β. In order
to define these parameters individually for each component, the
molfit file has to contain additional columns on the left side of
column CFFlag.
For globally defined dust parameters, the myXCLASS program
assumes that all core components do not contain dust except the
core component with the largest beam filling factor, see Eq. (2).
This avoids an overestimation of the dust contribution caused by
the overlap of the core components.
2.2. The iso ratio file
As mentioned above, the myXCLASS program offers the possibility
 to define isotopologues of a molecule and their abundance ratios
 to reduce the number of input parameters. For that purpose
the user has to create an iso ratio file which consists of three
columns, where the first two columns indicates the isotopologue
and the corresponding molecule, respectively. The third column
defines the assumed isotopic ratio. The columns are separated by
blanks and comments are marked with the % character.
Example of an iso ratio file:
% isotopologue:
molecule:
ratio:
S-33-O2;v=0;
SO2;v=0;
30.0
S-34-O2;v=0;
SO2;v=0;
5.0
SO2;v2=1;
SO2;v=0;
1.0
SOO-17;v=0;
SO2;v=0;
750.0
SOO-18;v=0;
SO2;v=0;
500.0
Here, we assume that the abundance of molecule "SO2;v=0;"
is 30 times higher than the abundance of its isotopologue
"S-33-O2;v=0;".
2.3. The myXCLASS function
The myXCLASS function calculates a synthetic spectrum for a
user defined frequency range, see Fig. 4. The function returns the
calculated myXCLASS spectrum, a list of all transition frequencies
within the defined range, and the intensities and optical depths
for each molecule and component as python arrays, which can
be used for further analysis. An example call of the myXCLASS
function is given in Appendix A.2.
3. Database
The XCLASS interface contains a SQLite3 database including
 spectroscopic data from CDMS (Müller et al. 2001, 2005)
and JPL (Pickett et al. 1998). Data can be retrieved and updated
 via VAMDC, which is an interoperable e-Infrastructure
for the exchange of molecular and atomic data between different
databases. In principle, all databases which support the VAMDC
standard and which contain the required spectroscopic information
 can be accessed via myXCLASS. A local database was chosen
to be able to run the program without network access. CDMS
also provides the latest version of the SQLite3 database, which
is updated when new entries to the CDMS or JPL are made. In
addition, the XCLASS interface allows in principle to add private
 entries (e.g., unpublished new spectroscopic data) to the
database. New functions which facilitate adding private entries
A7, page 5 of 20
A&A 598, A7 (2017)

Tmb (K)
0
1
4
5

Rest Frequency (MHz)
559000
560000
561000
 data
 fit
1st component of SO2
2nd component of SO2
3rd component of SO2
1st component of SO
1st component of HNO
Fig. 4. myXCLASS function used to model HIFI data of Sgr B2m (black)
using SO2 (with three different components), SO (with one component),
and HNO (with one component). The intensities of each component are
shown in the bottom half.
will be included in one of the next releases of the XCLASS
package.
The spectroscopic data is stored in two tables: The
table partitionfunctions contains the partition functions
Q(m, Tex) for more than 1000 molecules for 110 different temperatures
 between 1.072 and 1000 K, which widely extends
the standard range of the CDMS/JPL entries. This feature was
deemed desirable because particularly for foreground lines with
an excitation temperature Tex of 2.7 K, extrapolation from the
canonical values (lowest calculated temperature of the partition
function 9.75 K) could be wrong in either direction by large factors.
 Additonally, the table transitions contains more than
5 415 000 transitions and includes the frequency νt (in MHz)
with its uncertainty, the Einstein Aul coefficient (in s−1), the upper
 state degeneracy gu, the energy of the lower state El (in K),
and the quantum numbers for each transition.
Entries in the tables are related by the species name, which
are different from the names used in the Splatalogue catalog, for
example, we use "HC-13-N;v=0;" instead of "HC(13)N v=0"
(Splatalogue). In one of the next releases the Splatalogue names
will be usable as well.
Furthermore, the XCLASS interface provides functions
to update and manage the myXCLASS database: the function
UpdateDatabase updates the existing database file by downloading
 the latest changes from the databases via VAMDC or
by downloading a complete new database file from the CDMS
server. The first option adds new entries to the tables and overwrites
 existing entries with new data. Private entries remain
unchanged. The second option is much faster but removes all
private entries by overwriting the database file with the most
recent file from the CDMS server. In addition the function
DatabaseQuery offers the possibility to send an user defined
SQL query string to the database, for example, to add private
entries or query about species names, content etc. Also, the interface
 contains functions ListDatabase, see Appendix A.1,
and GetTransitions, see Fig. 5, to display information about
transitions within an user defined range. The GetTransitions
function allows the user to select a region on the displayed spectrum,
 and prints out all the lines from the catalog around the
Fig. 5. Graphical user interface (GUI) of the GetTransitions function.
 Here, the user has to define a frequency range by selecting a single
frequency in the shown spectrum. This frequency represents the central
frequency of the range. The width of the range is given by an user defined
 parameter. XCLASS prints out informations (name of molecule,
transition frequency, uncertainty of transition frequency, Einstein A coefficient,
 quantum number for lower and upper state, and energy of
lower state) of all transitions in the selected molecule list located in the
given frequency range, see screen output of ListDatabase described
in Appendix A.1.
region selected. Additionally, the function offers the possibility
to set filters in frequency and energy range.
4. MAGIX
So far, we have discussed how to use XCLASS to produce synthetic
 spectra. In fact, what the user usually desires is a description
 of data that provides a fit to a set of observational data. In
many packages, this is done by manually changing the parameters
 until the fit looks good. In XCLASS, we use an optimizer
that provides the parameter set for a given model which best
matches the data. Due to the large number of input parameters required
 by the myXCLASS program it is essential to use a powerful
optimization package to achieve a good description of observational
 data by the myXCLASS program. Therefore, the XCLASS
interface contains the MAGIX package (Möller et al. 2013) which
is a model optimizer providing an interface between existing
codes and an iterating engine. The package attempts to minimize
 deviations of the model results from observational data,
constraining the values of the model parameters and providing
corresponding error estimates.
MAGIX offers the possibility to model physical and chemical
 data using an arbitrary external model program, not only
myXCLASS, explore their parameter space and find the set of parameter
 values that best fits observational data. The goodness of
a fit is described by the χ2 distribution which is a function of
relative quadratic differences between observational and model
values. MAGIX is able to explore the landscape of the χ2 function
without the knowledge of starting values. Additionally, MAGIX
can calculate probabilities for the occurrence of minima in the
χ2 distribution and give information about confidence intervals
for the parameters. The package provides optimization through
one of the following algorithms or via a combination of several
of them (an algorithm chain or tree, see Fig. 6): the LevenbergMarquardt
 (conjugate gradient) method, which is fast, but can
A7, page 6 of 20
T. Möller et al.: XCLASS
Start
Tree
LM
Error
LM
LM
Error
Error
R2
R3
R1
Chain
Bees
Error
LM
R1
a)
b)
Bees
Start
Fig. 6. Example of an a) algorithm chain and b) algorithm tree. In both
cases, we start with the bees swarm algorithm and use the best a) and
the three best results b) as starting values for the Levenberg-Marquardt
local optimization algorithm (LM), respectively. Afterwards, we apply
the error estimation algorithm (Error) to the result(s) of the LevenbergMarquardt
 algorithm. In case of an algorithm chain we get one final
result (R1), whereas we get three different results (R1, R2, R3) for an
algorithm tree.
get stuck in local minima, simulated annealing, which is slower,
but more robust against local minima. Other global optimization
algorithms, such as bees, genetic, particle swarm optimization,
nested sampling, or interval nested sampling algorithms are included
 as well for exploring the solution landscape, checking
for the existence of multiple solutions, and giving confidence
ranges. Additionally, MAGIX provides an interface to make several
 algorithms included in the scipy16 package available.
Using an algorithm chain or tree offers the possibility to
send the results of the optimization process performed by one
algorithm to another optimization loop through some different
algorithm. The simulated annealing as well as the LevenbergMarquardt
 algorithm require starting values of the parameters
that are not too far from the final solution, otherwise the algorithm
 might stray so far away from the solution that it never
converges, that is, the user has to find an acceptable fit by hand
before applying these algorithms produces useful results. Often,
the location of the minimum can be guessed with sufficient accuracy
 to give good starting values, but sometimes one is completely
 in the dark. Using an algorithm chain or tree, the user can
first apply one of the swarm algorithms, for example, the bees
or interval nested sampling algorithm, to determine the starting
 values for the subsequent local optimization algorithm using
simulated annealing or the Levenberg-Marquardt algorithm, see
Fig. 6a. But MAGIX does not only allow one to use the best but
also the second best etc. result of a swarm algorithm as starting
values for other algorithms (algorithm tree), see Fig. 6b. Therefore,
 MAGIX is able to find multiple minima of models.
Since this can, depending on the data set and the number
of free parameters, be quite computing intensive, OpenMP and
OpenMPI parallelization for simultaneous evaluations of the external
 program is available for most of the algorithms. In addition
to the normal MAGIX package which can be used with an arbitrary
 external model program, the XCLASS interface contains
16 http://www.scipy.org/
a further MAGIX version optimized for the usage with the
myXCLASS program. This optimized MAGIX version is used by the
myXCLASSFit and myXCLASSMapFit (myXCLASSMapRedoFit)
functions and we are exploring the use of graphics processing
units (GPUs).
Generally, MAGIX is controlled by different XML files: The
so-called instance file includes the names, initial values (and
ranges) for all model parameters. Additionally, the instance file
indicates the parameters which should be optimized by MAGIX.
In addition the experimental XML file containing settings for the
import of observational data, that is, path(s) and name(s) of the
data file(s), format(s), range(s) etc. Furthermore, the algorithm
control file, defining the algorithm or algorithm sequence which
should be used for the optimization together with the settings for
each algorithm.
The new MAGIX function offers the possibility to use MAGIX
within CASA with a previously registered external model program.
 For that purpose, the user has to provide the XML files, described
 above, and passes their path and file names to the MAGIX
function, see Appendix A.3.
In general, XCLASS creates job directories for some functions
 (MAGIX, myXCLASSFit, and myXCLASSMapFit) where all
log and output files are stored. The job directories are created in
the XCLASS run directory defined by the environment variable
myXCLASSRunDirectory. The name of a job directory contains
the date and time of the function execution followed by a unique
job number.
5. Other functions
The XCLASS interface for CASA includes two new functions
(myXCLASSFit and myXCLASSMapFit) which provide a simplified
 interface for MAGIX using the myXCLASS program.
The myXCLASSFit function offers the possibility to fit multiple
 ranges in multiple files from multiple telescopes simultaneously
 using MAGIX in conjunction with the myXCLASS program.
It starts MAGIX using the Levenberg-Marquardt algorithm to optimize
 the input parameters defined in an extended molfit file to
achieve a good description of the observational data. The user
has to specify the maximum number of iterations, the path and
file name of the observational data file (or of a MAGIX experimental
 XML file, see Sect. 4), and the path and name of an extended
molfit file. In contrast to the molfit file described in Sect. 2.1,
the extended molfit file, see Appendix A.4, contains one additional
 column on the left side of each parameter (except for the
core/foreground flag) of each component. The additional column
defines the range for each parameter. The definition of ranges
guarantees that the fits does not run out of the defined parameter
ranges. The limits, that is, the lowest and highest allowed values,
 for the parameters source size θm,c, column density Ntot, and
hydrogen column density NH are determined by
lower limit = |parameter value|/(range value)
upper limit = |parameter value| × (range value).
The limits for the other parameters are calculated by simply
adding or subtracting the value of the additional column to or
from the value itself. All calculated lower limits which are less
than zero are set to zero (except for velocity offset). If the range
of a certain parameter is set to zero, the corresponding parameter
is kept constant and is not optimized by the myXCLASSFit function.
 Additionally, the myXCLASSFit function offers the possibility
 to fit the iso ratios in the same fit process as well. For that
A7, page 7 of 20
A&A 598, A7 (2017)
purpose, the user has to add two additional columns in the iso
ratio file on the right side of the third column. The fourth and
fifth column defines the lower and upper limit for each iso ratio,
 respectively. If the lower limit is equal to the upper limit or
if the lower limit is higher than the upper limit, the corresponding
 iso ratio is not optimized by the myXCLASSFit function. In
general, the fit procedure stops, if the maximum number of iterations
 is reached, or if χ2 drops below 10−7 (or an user defined
value). Additionally, the myXCLASSFit function offers the possibility
 to use another algorithm or an algorithm chain or tree
by defining the path and name of a MAGIX algorithm XML file,
see Sect. 4. Furthermore, the function offers the possibility to
fit multiple frequency ranges simultaneously by using a MAGIX
experimental XML file, see Sect. 4. Finally, the myXCLASSFit
function returns the optimized molfit file from the best fit and
the corresponding modeled spectra as python arrays. (Here, the
phrase “best fit” is connected to the application of an algorithm
chain or tree: using an algorithm chain or tree offers the possibility
 to use more than one algorithm to fit the data. Each application
 of an algorithm is connected with a fit represented by
a certain χ2 value. The myXCLASSFit function reads in the χ2
values of all optimization loops of all applied algorithm and determines
 the lowest χ2 value. The result of the “best fit” is than
given by the parameter vector which belongs to the lowest χ2
value.)
In addition to the myXCLASSFit function which is useful
to fit single spectra, the XCLASS interface for CASA contains
the myXCLASSMapFit function which fits one or more complete
(FITS) data cubes. Here, the myXCLASSMapFit function reads in
the data cube(s), extracts the spectra for each pixel and fits these
spectra separately using the Levenberg-Marquardt (or another)
algorithm (chain or tree). The optimization procedure for each
pixel stops, if the maximum number of iterations is reached, or if
the χ2 value drops below 10−7 (or below an user defined value).
In analogous to the myXCLASSFit function the fit parameters
and their ranges for the myXCLASSMapFit function are defined
in an extended molfit (and iso ratio) file as well. Additionally,
the myXCLASSMapFit function offers the possibility to limit the
fit to certain frequency ranges of a spectrum and to an user defined
 region of the cube(s). In order to reduce the computation
effort, the user can exclude pixels by defining a threshold for
the min. intensity of a pixel, that is, if the maximum intensity
of a pixel is below the user defined threshold, the corresponding
 pixel is not fitted by the myXCLASSMapFit function. In general,
 the myXCLASSMapFit function assumes, that the first three
axes of the data cube(s) describe the right ascension, the declination,
 and the frequency, respectively. If the frequencies are not
given in MHz, the FITS header has to contain the definition of
the CUNIT3 command which defines the unit of the frequency
axis. If more than one data cube is specified in the XML file, the
data cubes must describe the same map, that is, covered spatial
area and the resolution have to be identical. The different data
cubes are allowed to differ only in the frequency axis. At the end
of the whole fit procedure, the myXCLASSMapFit function creates
 FITS images for each free parameter of the best fit, where
each pixel corresponds to the value of the optimized parameter
taken from the best fit for this pixel, see Fig. 7. Furthermore,
the myXCLASSMapFit function creates FITS cubes for each fitted
 data cube, where each pixel contains the modeled spectrum.
Finally, the myXCLASSMapFit function creates one FITS image
which describes the quality of the fit for each pixel. Here, each
pixel corresponds to the χ2 value of the best fit for this pixel.
Applications of this are temperature maps, but also first and second
 moment maps, which are based on the simultaneous fitting
Fig. 7. Example of parameter maps created by the myXCLASSMapFit
function. Here, the K-ladder structure of the CH3CN(12-11) transition
 (plus isotopologues) in G75.78+0.34 was fitted at around
220 GHz (observed with the SMA). The temperature gradient is expected
 as also seen in different NH3 lines (Sanchez-Monge 2011;
Sanchez-Monge et al. 2013).
of many lines, and are fairly robust against line confusion and
blending of single lines.
In order to improve the results of a previous application
of the myXCLASSMapFit function the XCLASS interface contains
 the myXCLASSMapRedoFit function which offers the possibility
 to redo one or more so-called pixel fits of a previous
myXCLASSMapFit run. The function performs fits for the selected
 pixels and recreates the different parameter maps using
the new optimized parameter values.
6. Example application
The XCLASS interface for CASA was used to redo the analysis
of the spectral line survey of the high-mass star-forming region
Orion KL from 325 to 360 GHz as reported by Schilke et al.
(1997), which was done without using the myXCLASS program
nor optimization packages like MAGIX.
In our fit, shown in Fig. 8, we used the following
25 molecules: C2H3CN, C2H5CN, CCH, CH3CCH, CH3CN,
CH3OCH3, CH3OCHO, CH3OH, CN, CO, CS, H2CO, H2CS,
A7, page 8 of 20
T. Möller et al.: XCLASS
325.00
333.75
342.50
351.25
360.00
Rest Frequency (GHz)
0
20
40
60
80
100
120
Tmb (K)
a)
data
fit
332.00
332.25
332.50
332.75
333.00
Rest Frequency (GHz)
0
2
4
6
8
10
12
14
Tmb (K)
b)
337.50
337.82
338.15
338.47
338.80
Rest Frequency (GHz)
0
5
10
15
20
Tmb (K)
c)
357.00
357.50
358.00
358.50
359.00
Rest Frequency (GHz)
0
5
10
15
20
Tmb (K)
d)
Fig. 8. Result of the spectral line survey of the high-mass star-forming
region Orion KL between 325 to 360 GHz using the myXCLASSFit
function. Here, we used 24 molecules in conjunction with 245 isotopologues.
 In panel a) the whole spectral line survey (back) is shown together
 with the result of myXCLASSFit function (red). Panels b), c)
and d) show fit examples around 332.5 GHz, 338.15 GHz, and
358.0 GHz, respectively.
H2O, HCCCN, HCN, HCO+, HCS+, HDO, HNCO, NO,
OCS, SiO, SO2, and SO. The different molecules were
described by 44 components in total, see Table 1. Additionally,
 we have taken 241 isotopologues and higher vibrated
states into account where we assumed the following ratios:
[12C]/[13C] = 45 (Crockett et al. 2014a), [16O]/[18O] = 250
(Crockett et al. 2014a), [16O]/[17O] = 2625 (Tercero et al. 2010),
[32S]/[33S] = 75 (Crockett et al. 2014a), [32S]/[34S] = 22.5
(Schilke et al. 1997), [14N]/[15N] = 234 (Crockett et al. 2014a),
[28Si]/[29Si] = 20 (Schilke et al. 1997), and [28Si]/[30Si] = 30
(Anders & Grevesse 1989). In order to reduce the computational
effort, we assumed a ratio of one for all vibrational excited
transitions, that is, we used the same column densities as for the
corresponding molecules.
Additionally, we were able to (partly) identify 35 of the
57 unidentified lines (U-lines) reported by Schilke et al. (1997),
see Table 2. Here, we marked an unidentified line as (partly)
identified, if the modeled integrated intensity of a component
R
T fit
R dv

covers at least 10% of the integrated line intensity
R
T Schilke
R
dv

. We note that, the majority of the unidentified lines
contain contributions from more than one component. Contributions
 of more than 100% are caused by inaccuracies in the fit.
For 19 U-lines the modeled spectrum describes less than 50% of
the integrated line intensity. Nevertheless, we are able to (partly)
describe all unidentified lines, except the line at 348 358 MHz,
with an integrated line intensity of more than 10 K km s−1. The
improved identification may caused by an updated and enhanced
line catalog.
In the following we compare our fit results, given in Table 1,
with those reported by Schilke et al. (1997). Our calculated errors
 describe the 2σ credibility interval for each parameter, respectively.
 Large asymmetric error ranges for some column densities
 (e.g., SO) are caused by the fact that some lines start to
become optically thick which prevents an accurate parameter estimation.
 For these lines we can only determine lower limits of
the corresponding column densities.
In contrast to Schilke et al. (1997) we were not able to identify
 NH2CHO, C2H5OH, and HCOOH because of their weak
lines which do not allow a distinct estimation of their contribution
 to the given spectrum. But we took CCH, CN, and NO into
account.
Our derived excitation temperatures and beam averaged column
 densities for H2CS and CH3OCHO agree (within the given
error ranges) with Schilke’s result. In order to achieve a good
description for HCCCN, HDO, and OCS we used two components,
 respectively. For HCCCN and HDO we find that the second
 components show similar temperatures and column densities
 compared to Schilke’s results. Due to the large error ranges
for OCS we are not able to identify the corresponding component
 for Schilke’s result although the temperatures as well as
column densities are comparable within the given error ranges.
Additionally, we used H2CO with two components instead
of H13
2 CO with one component. Using the aforementioned isotopologue
 ratio of [12C]/[13C] = 45 we find that the temperature
and column density for the first component of H2CO agree with
those described by Schilke et al. (1997).
As shown in Table 1, we used three components to describe
the contribution of CH3OH and SO2. Schilke’s result for CH3OH
corresponds to our second component whereas the excitation
temperature and beam averaged column density for the first component
 of SO2 agree with those reported by Schilke et al. (1997).
Furthermore, the described temperatures and column densities
(after scaling with the isotopologue ratios, mentioned above) for
34SO2 match our results nicely. For 33SO2 the derived excitation
temperature do not coincide with Schilke’s result.
In order to model the contribution of HNCO we used only
two instead of four components. We see that the temperatures
and column densities of Schilke’s first, third, and fourth component
 match our results for the first component. But, the column
density of Schilke’s second component clearly does not agree
with our column density for the second component although the
excitation temperatures are comparable.
A7, page 9 of 20
A&A 598, A7 (2017)
Table 1. Fit results of the molfit file parameters used for the Orion-KL model.
Molecule
θm,c (arcsec)
T m,c
ex (K)
Nm,c
tot (cm−2)
∆vm,c (km s−1)
vm,c
LSR (km s−1)
CH3CN
3+37.6
−2.0
245+24.1
−18.2
3.1 (14) +1.2(17)
−1.0(14)
10+4.0
−2.2
7+1.8
−1.3
–
[445+36
−36]
[1.7(15) +0.7(15)
−0.7(15)]
–
–
CH3CCH
70+9.8
−69.3
21+26.3
−14.5
4.2 (16) +8.6(17)
−6.4(15)
6+2.0
−6.1
10+1.4
−1.0
–
[65+9
−9]
[4.3(15) +2.2(15)
−2.2(15)]
–
–
HCCCN
81+37.0
−13.6
72+24.2
−15.1
1.0 (15) +7.8(16)
−2.5(14)
11+3.5
−3.1
5+1.9
−1.4
2+35.8
−1.3
330+20.0
−7.1
5.9 (14) +4.8(16)
−1.5(14)
21+4.1
−2.9
4+1.7
−1.4
–
[225+200
−200]
[5.2(15) +7.8(15)
−7.8(15)]
–
–
CCH
371+29.0
−326.1
31+265.5
−29.7
1.6 (11) +1.6(11)
−2.7(8)
3+4.3
−3.0
10+11.0
−10.3
326+63.7
−296.0
330+20.0
−6.5
7.9 (14) +3.3(16)
−1.7(14)
3+2.4
−2.7
10+2.4
−1.9
OCS
180+8.4
−179.0
65+25.8
−13.7
1.8 (16) +3.1(18)
−5.2(15)
16+3.4
−3.2
7+1.6
−1.3
261+125.2
−260.0
316+1.0
−314.9
1.1 (15) +4.9(16)
−2.2(14)
5+3.5
−3.4
8+2.2
−1.7
–
[83+30
−30]
[1.8(16) +1.8(16)
−1.8(16)]
–
–
HNCO
332+57.7
−331.0
160+25.8
−20.7
4.7 (14) +5.2(16)
−1.3(14)
6+3.6
−3.3
7+2.0
−1.3
20+29.8
−16.7
16+25.8
−14.9
7.4 (16) +1.3(18)
−1.1(16)
16+3.4
−3.3
7+1.8
−1.4
–
[160+14
−14]
[1.3(15) +2.3(15)
−2.3(15)]
–
–
–
[36+5
−5]
[5.7(15) +3.5(15)
−3.5(15)]
–
–
–
[277+100
−100]
[1.3(15) +0.8(15)
−0.8(15)]
–
–
–
[190+40
−40]
[1.2(15) +0.6(15)
−0.6(15)]
–
–
CN
42+27.9
−22.3
43+21.9
−18.1
1.7 (14) +6.2(15)
−3.7(13)
4+4.0
−2.3
10+1.7
−2.1
10+30.4
−9.5
15+22.6
−14.2
1.3 (15) +2.7(16)
−2.2(14)
22+3.7
−3.5
8+2.7
−1.1
H2CO
249+2.2
−248.0
150+24.9
−24.3
8.4 (14) +8.4(17)
−3.3(14)
24+3.8
−3.5
8+1.9
−1.3
275+112.0
−274.0
130+23.1
−24.6
1.8 (14) +1.4(16)
−5.1(13)
7+3.5
−3.5
9+2.0
−1.3
–
[H13
2 CO: 230+105
−105]
[H13
2 CO: 6.3 (14) +4.7(14)
−4.7(14)]
–
–
HDO
150+101.6
−75.4
11+171.1
−9.6
5.0 (10) +4.9(17)
−5.0(10)
4+17.0
−4.4
18+1.6
−0.7
47+12.4
−45.5
270+17.3
−268.9
5.7 (15) +6.5(17)
−1.4(15)
9+4.9
−2.7
7+1.4
−1.5
–
[272+200
−200]
[0.9(16) +1.3(16)
−1.3(16)]
–
–
H2CS
105+29.2
−19.3
105+26.7
−14.7
2.1 (14) +4.4(16)
−7.1(13)
6+3.5
−3.4
8+1.9
−1.3
–
[93+19
−19]
[8.5(14) +3.5(14)
−3.5(14)]
–
–
NO
38+299.8
−36.9
47+49.2
−15.0
3.3 (12) +6.6(14)
−3.3(12)
10+1.2
−10.4
5+3.2
−0.2
29+26.5
−24.4
196+23.9
−21.5
1.2 (17) +1.3(19)
−3.3(16)
22+3.7
−3.4
8+1.3
−0.9
SO
10+28.0
−9.5
65+24.4
−14.7
7.1 (16) +9.3(19)
−3.1(16)
25+3.9
−2.1
9+3.0
−0.9
5+30.2
−4.0
264+20.5
−20.5
2.9 (16) +3.2(19)
−1.2(16)
15+3.5
−2.4
9+1.8
−1.9
Notes. Here, we describe only those molecules, which show at least three transitions within the covered frequency range. The column densities
are given on a main beam brightness line temperature scale, i.e., each column density (exponents are described by round brackets, e.g., 1.4(16) =
1.4×1016) is multiplied with the beam filling factor of the corresponding component, to make them comparable to the results given by Schilke et al.
(1997), which were indicated here within squared brackets. Additionally, the errors of the fit parameters (indicated by the sub-(left) and superscript
(right) values) were determined using the error estimation algorithm included in the MAGIX package.
A7, page 10 of 20
T. Möller et al.: XCLASS
Table 1. continued.
Molecule
θm,c (arcsec)
T m,c
ex (K)
Nm,c
tot (cm−2)
∆vm,c (km s−1)
vm,c
LSR (km s−1)
–
[27+1
−1]
[6.3(16) +0.7(16)
−0.7(16)]
–
–
CH3OCHO
3+38.8
−2.3
117+24.0
−20.6
9.3 (15) +6.6(18)
−3.4(15)
5+3.9
−2.4
8+1.0
−1.1
–
[98+3
−3]
[1.5(16) +0.1(16)
−0.1(16)]
–
–
CH3OCH3
3+40.0
−2.0
136+24.6
−20.4
1.0 (16) +1.9(17)
−1.8(15)
3+3.9
−2.5
9+1.4
−0.9
24+25.9
−23.2
24+22.5
−22.3
2.8 (15) +10.0(16)
−4.9(14)
6+3.9
−2.5
9+1.3
−1.0
–
[89+5
−5]
[1.8(16) +0.2(16)
−0.2(16)]
–
–
C2H5CN
98+15.0
−35.5
127+23.3
−21.6
9.9 (14) +1.1(18)
−3.9(14)
13+3.5
−3.1
5+1.7
−1.4
–
[99+3
−3]
[1.3(16) +0.2(16)
−0.2(16)]
–
–
C2H3CN
15+29.1
−13.6
174+31.4
−16.1
8.7 (13) +3.4(15)
−1.9(13)
4+1.0
−0.7
6+1.0
−0.9
19+29.2
−17.2
126+23.3
−21.5
3.5 (14) +1.6(16)
−7.6(13)
12+1.0
−0.7
3+0.9
−1.2
–
[96+5
−5]
[8.2(14) +1.5(14)
−1.5(14)]
–
–
CH3OH
12+27.6
−10.5
25+25.8
−14.4
9.2 (15) +7.3(17)
−2.8(15)
5+3.7
−2.6
9+1.8
−1.4
3+37.1
−2.1
189+26.0
−20.0
4.5 (16) +1.6(20)
−2.1(16)
8+3.8
−2.5
7+1.5
−1.4
4+36.9
−2.5
161+28.1
−18.3
1.3 (16) +1.3(18)
−4.2(15)
2+3.9
−2.4
9+2.1
−1.8
–
[188+3
−3]
[7.0(16) +0.2(16)
−0.2(16)]
–
–
SO2
3+40.6
−1.9
140+29.7
−16.5
2.3 (16) +1.3(19)
−9.3(15)
6+3.9
−2.4
5+1.0
−1.1
9+29.3
−7.8
173+29.9
−18.9
4.1 (16) +3.5(21)
−2.1(16)
31+4.6
−2.8
11+0.8
−1.1
16+29.4
−14.6
23+25.4
−14.9
5.4 (16) +3.9(20)
−2.7(16)
21+4.9
−2.5
11+0.8
−1.1
–
[124+3
−3]
[7.7(16) +0.5(16)
−0.5(16)]
–
–
Although we find similar results for the majority of
molecules we derived different excitation temperatures for
CH3CN, CH3CCH, SO, CH3OCH3, C2H3CN, and C2H5CN. In
contrast to CH3CCH, SO, C2H3CN, C2H5CN, and CH3OCH3
where we find discrepancies with less than 24 K we find a striking
 difference for CH3CN. Already Schilke et al. (1999) noticed
that the value of 445 K based on rotation diagram analysis was
wrong due to a neglect of the line opacity. They presented a
corrected fit using the opacities derived from CH3CN/CH13
3 CN,
yielding 160 K, which differs from the present value because (i)
a [12C]/[13C] ratio of 60 (instead of 45) was used then – which
increases the correction due to opacity; and (ii) the correction
was done by hand, not taking the individual lines as well into account
 as the present study. Not taking into account the opacities
also underestimates the column density, by an order of magnitude
 in the present case. Additionally, we derived a column density
 for CH3CCH which is nearly an order of magnitude higher
than Schilke’s result.
For optically thin, unblended lines (like for H2S and
CH3OCHO), the rotation diagram method gives the same results
 as the XCLASS fit, but requires more effort through manual
fitting of all lines. High opacities, while they can be corrected
in rotation diagrams (Schilke et al. 1997; Goldsmith & Langer
1999), this is very cumbersome to do by hand, and is much
more robustly achieved through the use of XCLASS – in this
data set, CH3CN and CH3OH are prominent examples. Lastly,
the identification of species with weak features is only possible
 reliably in line-rich spectra if all the other species are modeled
 as well, as can be seen by the XCLASS fits reported in
Belloche et al. (2008, 2009, 2013). All this together with the
capability of producing credibility intervals demonstrates that
the methods of XCLASS give much more accurate and reliable
results than those achieved with rotational diagram methods.
7. Conclusions
We presented the XCLASS interface for CASA which provides
powerful new functions for the CASA distribution for analyzing
 spectral surveys. The toolbox includes the myXCLASS program
 which models observational data by solving the radiative
transfer equation for an isothermal object in one dimension (detection
 equation). The myXCLASS program is able to model a
huge number of molecules simultaneously, whereat the contribution
 of each molecule can be described by an arbitrary number
 of components. These can usually be distinguished by different
 radial velocities and do not interact with each other radiatively
 but superimpose in the model. The myXCLASS program
depends on a number of parameters, which are partially taken
A7, page 11 of 20
A&A 598, A7 (2017)
Table 2. New identified lines.
ν
R
T Schilke
R
dv
R
T fit
R dv
Molecule
(MHz)
(K km s−1)
(K km s−1)
330 715
1.7
3.3 (195.7%)
CH3OCHO, v18 = 1, [1]
332 789
3.8
1.0 (25.9%)
C2H3CN, [2]
333 865
8.9
1.4 (15.5%)
34SO, [1]
334 140
1.6
1.5 (91.9%)
CH3OCHO, v18 = 1, [1]
335 335
6.2
0.8 (12.7%)
C2H5CN, [1]
335 703
4.6
1.0 (22.2%)
CH3OH, [2]
335 840
2.9
0.8 (27.3%)
CH3OCHO, [1]
337 744
4.2
1.3 (31.6%)
CH3OH, v12 = 1, [2]
337 839
3.3
4.9 (149.7%)
HCCCN, v7 = 1, [2]
3.1 (94.2%)
CH3OH, [2]
0.8 (23.0%)
CH3OH, [3]
339 138
3.3
0.5 (14.0%)
13CH3CN-A [1]
339 527
8.6
1.2 (13.4%)
CN, [2]
340 496
15.9
6.9 (43.5%)
C2H5CN, [1]
340 872
4.6
0.7 (14.4%)
33SO, [1]
341 472
10.9
10.3 (94.9%)
C2H5CN, [1]
341 482
11.7
2.1 (18.1%)
C2H5CN, [1]
341 499
0.4
0.2 (54.1%)
CH3OCHO, v18 = 1, [1]
342 129
4.1
0.6 (14.7%)
C2H3CN, [2]
0.7 (16.2%)
CH3OCHO, v18 = 1, [1]
0.4 (10.3%)
C2H3CN, [1]
342 290
3.9
3.7 (96.1%)
CH3OCHO, v18 = 1, [1]
342 486
4.7
0.9 (20.0%)
CH3OCHO, v18 = 1, [1]
343 202
21.8
13.1 (60.2%)
C2H5CN, [1]
343 665
7.8
1.7 (21.4%)
CH3OCHO, v18 = 1, [1]
344 773
...
0.2
34SO2, [2]
344 788
...
1.2
34SO2, [2]
1.0
CH3OCHO, [1]
0.2
34SO2, [3]
344 796
...
2.5
34SO2, [2]
0.8
34SO2, [3]
347 446
4.7
2.2 (45.9%)
C2H3CN, [2]
0.8 (17.8%)
CH3OH, v12 = 1, [2]
0.7 (15.0%)
C2H5CN, [1]
348 084
2.4
0.5 (22.7%)
34SO2, [2]
2.3 (95.5%)
CH3OCHO, v18 = 1, [1]
348 373
...
31.0
SO2, [2]
0.2
SO18O, [3]
0.2
HCCCN, v7=3, [2]
0.2
SO18O, [2]
0.4
SO18O, [1]
0.2
CCH, v2 = 2, [2]
0.3
C2H5CN, [1]
350 170
2.8
2.3 (81.3%)
CH3CN, v8 = 1, [1]
1.5 (53.3%)
C2H5CN, [1]
351 490
7.2
1.1 (15.8%)
33SO2, [3]
351 540
10.8
5.0 (45.9%)
HNCO, [1]
3.1 (28.6%)
33SO2, [3]
1.3 (11.9%)
C2H5CN, [1]
353 166
5.0
1.2 (23.3%)
C2H3CN, [2]
354 129
7.8
5.6 (72.3%)
CH3OH, v12 = 1, [2]
1.2 (14.7%)
CH3OH, v12 = 1, [3]
355 851
3.2
0.4 (12.8%)
OC34S, [1]
356 644
5.3
1.1 (21.4%)
HCCCNv6 = 1, v7 = 1, [2]
358 356
14.1
1.6 (11.1%)
34SO2, [2]
1.9 (13.5%)
34SO2, [1]
3.3 (23.5%)
C2H5CN, [1]
Notes. Here, an unidentified line is marked as identified, if the modeled
 integrated intensity of at least one molecule covers at least 10%.
The numbers in squared brackets describe the components of the corresponding
 molecules, respectively. Due to inaccuracies in the fit we
overestimated the integrated line intensities of some weak lines.
from an embedded SQLite3 database containing entries from
CDMS and JPL through the VAMDC portal. The other input
parameters are read from an user defined ASCII file containing
 parameters for each molecule and component. In order to
achieve a reasonable description of observational data one has
to partially optimize the user defined parameters. For that purpose
 the toolbox contains an interface for the model optimizer
package MAGIX, which helps to find the best description of the
data using a certain model, that is, finding the parameter set that
most closely reproduces the data. Therefore, the toolbox provides
 two functions to model one or more single spectra or data
cubes simultaneously using the myXCLASS program in conjunction
 with one of the optimization algorithms (or combinations of
them in an algorithm chain or tree) included in the MAGIX package.
 The combination of myXCLASS and MAGIX prepare the way
for an automatic line identification routine which is essential for
a spectral survey on large spectral cubes produced by ALMA.
Additionally, the MAGIX package offers the possibility to apply
more elaborate programs (such as LIME) to model astronomical
data as well.
Enhancements are being worked on a 3d version for defining
sub-beam structure. Additionally, we work on an automatic line
identification function for XCLASS, which will be described in
a subsequent paper.
Acknowledgements. The authors would like to thank Anika Schmiedeke, Álvaro
Sánchez-Monge, and Alexander Zernickel for intensive testing and helpful suggestions.
 We acknowledge funding from BMBF/Verbundforschung through the
Projects ALMA-ARC 05A11PK3 and 05A14PK1.
Introduction
Stellar ages, masses, and radii (hereafter stellar parameters) are
indispensable basic inputs in many astrophysical studies, such
as the study of the chemo-kinematical structure of the Milky
Way (i.e. Galactic archaeology), exoplanetology, and cosmology.
 Indeed, stellar parameters have long been used to answer
questions on how stars populating the different structures, that
is the discs, bulge, and halo, in our Galaxy were formed and
evolve, and to decipher in-situ formation, migration, and mergers.
 In this context, stellar parameters are the basis of stellar
 age-metallicity and age-velocity relations, the stellar initial
mass function (IMF), or the stellar formation rate (SFR) (see
Haywood 2014 for a review). Also, the ages of the oldest stars
provide a robust lower limit to the age of the Universe. Recently,
with the discovery of several thousands of exoplanetary systems,
it has become evident that no characterisation of the internal
structure and evolutionary stage of planets is possible without
a precise determination of the radius, mass, and age of the host
stars (see e.g. Rauer et al. 2014).
Today, the availability of observations from large-scale astrometric,
 photometric, spectroscopic, and interferometric surveys
has made the demand for very precise and accurate stellar
parameters acute. With Gaia (Gaia Collaboration 2018) and
large spectroscopic surveys being conducted in parallel (see
details andIntroduction
The formation of massive stars (M > 8 M⊙) is one of the most important problems
in stellar astrophysics and is still poorly understood. Two scenarios currently dominate
the discussions, assuming that high mass stars are a) formed by accretion through a disk
(Krumholz et al. 2005); or b) via coalescence of low mass stars (Bonnell et al. 2001).
Low and intermediate mass stars are formed by the gravitational collapse of the parental
giant molecular cloud (GMC), followed by the accretion process (Palla 1996). However,
when a young stellar object (YSO) reaches 8 M⊙, the radiative flux is intenser than in
the previous case and may interrupt the accretion flow. A process that collimates the
radiation field is required to overcome this effect, such as the bipolar outflows observed in
massive YSOs (MYSO). In the second scenario, massive stars are formed by coalescence
of low-mass stars in dense clusters (Bonnell et al. 2001). Low-mass stars are formed under
the accretion scenario, interact with each other, and collide to form stars of larger masses
(Stahler et al. 2000; Bally et al. 2002).
While there is no evidence for stellar mergers in clusters, a growing number of both
observational evidences (Bik & Thi 2004; Blum et al. 2004) and simulations (Krumholz
et al. 2009) support the accretion scenario. Recently, MYSO candidates were observed
in the H2 narrow filter and collimated jets were identified, suggesting accretion discs
around these objects (Varricatt et al. 2010). Although this work presents observational
431
https://doi.org/10.1017/S1743921314007327 Published online by Cambridge University Press
432
F. Navarete et al.
evidences for the accretion scenario, only a few MYSOs were confirmed on this sample.
Although the scenario of an accretion disk may apply for all massive stars, the details are
lacking. Instead of doing detailed study of a small number of potential candidates that
might harbor a disk, we are moving toward a large statistical study which will point to
accretion signatures (or not) of a well selected sample of 354 MYSO candidates, selected
by the Red MSX Source (RMS) survey (Lumsden et al. 2002; Mottram et al. 2011, and
INTRODUCTION
1.1. Basic Issues
Massive stars play a key role in the evolution of the Universe. They are the principal
source of heavy elements and UV radiation. Through a combination of winds, massive
outflows, expanding HII regions, and supernova explosions they provide an important
source of mixing and turbulence in the interstellar medium (ISM) of galaxies. Turbulence
 in combination with differential rotation drives galactic dynamos. Galactic
magnetic fields are generated, interacting with supernova shock fronts that accelerate
 cosmic rays. Cosmic rays, UV radiation, and dissipation of turbulence are the
principal sources of heating in the ISM, whereas heavy elements found in dust and
molecules and in atomic/ionic form ultimately are responsible for its cooling. Massive
stars thus profoundly affect the star- and planet-formation process (Bally, Moeckel
& Throop 2005) as well as the physical, chemical, and morphological structure of
galaxies (e.g., Kennicutt 1998, 2005).
In spite of the dominant role that massive stars play in shaping galactic structure
and evolution, our understanding of their formation and early evolution is still sketchy.
There are many reasons for this. High dust extinction makes it difficult to observe
high-mass stars during critical early formation phases. They are rare. They evolve
quickly, and important evolutionary phases are short-lived. The theoretical problem is
extremely complex. Finally, massive stars are seldomly (if at all) formed in isolation; the
proximity of other high-mass stars compounds the complex influence of the forming
star on its local environment via gravitational interactions, powerful outflows and
winds, ionizing radiation, and supernovae.
The low number statistics of young or forming high-mass stars is only partially
offset by their higher luminosities, which allow us to study them at greater distances
thantheirlow-masscounterparts.However,insufficientspatialresolutionisanissue—
an entire OB-star cluster is often contained in a single observing pixel (e.g., Henning
& Stecklum 2002).
1.2. Definitions
Star formation typically starts with a collapsing gas condensation (core) inside a larger
subunit (clump) of a molecular cloud (cf. Williams, Blitz & McKee 2000). A protostar
forms that increases its mass by accretion (accumulation) of neighboring gas, while at
the same time some mass loss occurs through a bipolar outflow and/or a collimated
jet. Let us define some of the terminology adopted here.
One of the most misused terms in papers dealing with star formation is protostar,
which is considered the Holy Grail (Wynn-Williams 1982) of IR astronomy. Here,
we reserve the term protostar or protostellar object for a gaseous object in hydrostatic
equilibrium (gas pressure forces balance the gas’ self-gravity), which has not yet begun
hydrogen burning but which will, given time, burn hydrogen. At the point hydrogen
burning commences, we shall speak of a zero-age main-sequence (ZAMS) star; as
long as hydrogen burning occurs in the center, we shall speak of a main-sequence
star. Note that the size scale of a protostar is at most a few tens of solar radii.
482
Zinnecker· Yorke
Annu. Rev. Astron. Astrophys. 2007.45:481-563. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
Table 1
Main-sequence massive star definition (logarithmic mass ranges)
Mass
Designation
Sp. type
8–16 M⊙
Early B-type massive stars
B3V to B0V
16–32 M⊙
Late O-type massive stars
O9V to O6V
32–64 M⊙
Early O-type massive stars
O5V to O2Va
64–128 M⊙
O/WR-type massive stars
WNL-Hb
aO2V main-sequence stars have been identified by Walborn et al. (2002).
bWNL-H: N-rich late-type Wolf-Rayet (WR) stars, still on the main sequence (H-burning)
(see Crowther 2007).
We use the terms massive star and high-mass star interchangeably to denote an
OB star sufficiently massive to produce a type II supernova (M∗/M
⊙> 8 for solar
abundances). With these definitions in mind, the term high-mass protostar denotes
a >8M
⊙hydrostatic object that has not yet begun hydrogen burning. As we shall see
in the following, such objects exist only briefly during a transitory stage between “accreting
 intermediate-mass protostar” and “accreting high-mass star.” Because it will
be impossible to distinguish observationally when an accreting object begins burning
 hydrogen, we suggest that the terms massive protostar and high-mass protostar
generally be avoided.
In Table 1, we give a crude classification of massive stars in terms of logarithmic
mass intervals and the corresponding main sequence spectral types.
We reserve the terms very massive star (VMS) and supermassive star (SMS) for
stars in the mass ranges of 100 < M∗/M
⊙< 1000 and 104 < M∗/M
⊙< 108, respectively,
 and introduce the term ultramassive star (UMS) for stars in the mass range
of 103 < M∗/M
⊙< 104. SMSs are equilibrium configurations that are dominated by
radiation pressure—baryons and electron-positron pairs provide only a minor contribution
 to the equation of state. At some point during their evolution SMSs collapse
owing to a general relativistic gravitational instability. Whereas in the present epoch
VMSs, UMSs, and SMSs are unlikely to be formed except under very special conditions,
 stars with masses in excess of 100 M
⊙are expected during the first epoch of star
formation (Bromm & Larson 2004; Abel, Bryan & Norman 2000). VMSs, UMSs,
and SMSs are not discussed in this review. A recent discussion of the formation and
evolution of VMSs is given in Portegies Zwart et al. (2006) and in Belkus, van Bever
& Vanbeveren (2007).
What is accretion? The term accretion is used in a variety of senses. Measured
accretion rates often refer to the rate of mass inflow toward star-forming sites—not
the rate at which a star or protostar gains mass. Originating from a 0.1-pc scale, this
material cannot possibly fall into a sub-10−6-pc region without carrying significant
angular momentum. Instead, it either forms a disk or hits and is mixed with prior
existing disk material (see Figure 1). Thus, we distinguish between the accretion of
cloud core material onto a disk ( ˙
MD-acc) and the accretion onto a (proto)star ( ˙
MS-acc).
Analogous to accretion, mass loss is used in a variety of senses. Measured mass
loss rates from jets and outflows do not necessarily reflect the mass loss from an
isolated young star. We thus distinguish between the mass loss from the (proto)star
via a wind ( ˙
MS-wind), the mass loss launched from the accretion disk ( ˙
MD-wind), which
www.annualreviews.org • Massive Star Formation
483
Annu. Rev. Astron. Astrophys. 2007.45:481-563. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
Cloud
core
Jets and
outflows
Disk
Star
MD-wind
.
Mload
.
MD-acc
.
MS-acc
.
MS-wind
.
Figure 1
Accretion and mass loss as
exchange between
components: the accretion
disk is reservoir and
interface between the
molecular cloud core and
the forming star.
never reaches the (proto)star, and the material swept up into the outflow from the
surrounding molecular cloud ( ˙
Mload). The measured outflow could have contributions
from several stars and several disks.
The interrelation between disk accretion and disk winds is a fascinating aspect
of massive star formation (see, e.g., the recent magnetohydrodynamic models of
Banerjee & Pudritz 2007) and is at the focus of the frequently asked question: Is
high-mass star formation a scaled-up version of low-mass star formation? The answer
to this question will be better defined by the time we reach the end of this review.
1.3. Recommended Reading
The study of the origin of massive stars is a relatively new field of astrophysical
research. There is no comprehensive monograph on the subject, but there are several
conference proceedings over the past few years dedicated to the topic, of which we
recommend the following:
■
Massive Stars: Their Lives in the Interstellar Medium (Cassinelli & Churchwell
1993)
■
Hot Star Workshop III: The Earliest Stages of Massive Star Birth (Crowther 2002)
■
Massive Star Birth: A Crossroads of Astrophysics (Cesaroni et al. 2005a)
The reviews on Environment and Formation of Massive Stars (Garay & Lizano
1999), Control of Star Formation by Supersonic Turbulence (Mac Low & Klessen 2004),
The Formation of the First Stars in the Universe (Glover 2005), The Birth of Massive
Stars and Star Clusters (T
an 2005), High Mass Star Formation by Gravitational Collapse
of Massive Cores (Krumholz 2007), and The Critical Role of Disks in the Formation of
High-Mass Stars (Cesaroni et al. 2007) are also recommended. Among the reviews in
the Proceedings of Protostars and Planets V, we particularly recommend “The Formation
of Massive Stars” (Beuther et al. 2007).
484
Zinnecker· Yorke
Annu. Rev. Astron. Astrophys. 2007.45:481-563. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
There are also a few related Annual Reviews articles:
■
Compact HII Regions and OB Star Formation (Habing & Israel 1979)
■
The Search for Infrared Protostars (Wynn-Williams 1982)
■
The Dynamic Evolution of HII Regions—Recent Theoretical Developments
( Yorke 1986)
■
The Orion Molecular Cloud and Star-Forming Region (Genzel & Stutzki 1989)
■
Physical Conditions in Regions of Star Formation (Evans 1999)
■
Ultra-Compact HII Regions and Massive Star Formation (Churchwell 2002)
■
Massive Stars in the Local Group: Implications for Stellar Evolution and Star
Formation (Massey 2003)
■
The First Stars (Bromm & Larson 2004)
Except for the last, none of these earlier reviews had its focus on the formation aspect
of massive stars but rather provided a descriptive observational summary of the
properties of young OB stars and their HII regions. This review is accompanied in
the same volume by the review “Physical Properties of Wolf-Rayet stars” (Crowther
2007) and the review “Theory of Star Formation” (McKee & Ostriker 2007), the
latter of which mostly addresses low-mass star formation but includes an important
section on high-mass star formation.
1.4. The Focus of This Review
The major questions we wish to address in this review are:
1. What is the sequence of observable states leading from molecular clouds to
young high-mass stars?
2. What are the initial conditions of massive star formation (gas densities, temperatures,
 clump masses, etc.) and how do they come about?
3. Do massive stars always form in dense stellar clusters or can they form in isolation?
 What special conditions are necessary to allow coalescence, i.e., mergers
of stars?
4. Which clues to the origin can be gleaned from multiplicity observations? How
do we explain the very tight massive spectroscopic binaries and OB runaway
stars?
5. How does the forming massive star influence its immediate surroundings, possibly
 limiting its final mass and/or the final mass of its neighbors?
6. How do young massive stars influence their global environment, either by
inhibiting or by triggering further star formation? How do we get a starburst?
T
o tackle these questions, we first discuss some key observations related to massive
star formation.
2. MASSIVE STAR FORMATION: KEY OBSERVATIONS
2.1. Observable Stages
The optically visible main-sequence life of OB-type stars is preceded by an embedded
phase that lasts about 15% of their lifetime (Churchwell 2002). As summarized by
www.annualreviews.org • Massive Star Formation
485
Annu. Rev. Astron. Astrophys. 2007.45:481-563. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
Menten, Pillai & Wyrowski (2005) and van der T
ak & Menten (2005), observations
at mid-IR through radio wavelengths have shown that this embedded phase can be
subdivided into several groups of objects:
■
IR dark clouds (Perault et al. 1996, ISOCAM; Egan et al. 1998, MSX; Benjamin
et al. 2003, Spitzer). Their internal density maxima and temperature minima
likely represent the initial conditions of high-mass star formation; a compilation
of several dozens of such high-mass starless cores has been given by Sridharan,
Williams & Fuller (2005). Some of these cores probably contain low-mass and
intermediate-mass accreting protostars, which are faint and hard to detect. Protostellar
 outflow activity has been detected in one of them (Beuther, Sridharan
& Saito 2005).
■
Hot molecular cores (Kurtz et al. 2000, Cesaroni 2005). These have large masses
of warm and dense gas, and large abundances of complex organic molecules
evaporated off dust grains; they are signposted by methanol maser emission
(Menten 1991, Walsh et al. 1998, Hill et al. 2005); ground-based detectability
on the Wien part of the spectral energy distribution with sufficient spatial
resolution is difficult (Stecklum et al. 2002), but comes into reach with dedicated
8-m class telescope observations (De Buizer & Minier 2005, Linz et al. 2005).
■
Hypercompact and ultracompact HII regions (Kurtz 2005, Hoare et al. 2007).
In these regions, small but growing pockets of ionized gas have developed
that stay confined to the stellar vicinity. Whereas hypercompact HII regions
probably represent individual photoevaporating disks (Keto 2007; see also the
example in Nielbock et al. 2007), ultracompact HII regions probably represent
disk-less stars photoionizing their own cocoons and massive envelopes.
■
Compact and classical HII regions (Mezger et al. 1967, Yorke 1986). Their gas
is ionized globally, often by several ionizing sources. It expands hydrodynamically
 as a whole and disrupts the parent molecular cloud, revealing both the
embedded high-mass and lower mass stellar population for optical and nearIR
 observations (Carpenter et al. 1993; Zinnecker, McCaughrean & Wilking
1993).
2.2. Initial Conditions
Massive star formation occurs inside dense, compact clumps in giant molecular clouds
(H2 column densities are 1023–1024 cm−2). Smaller mass clumps with lower peak H2
column densities do not form massive stars. Several types of molecular cloud surveys,
predominantly near HII regions, have been carried out: CS-molecule surveys for
dense molecular gas, 1.2-mm dust continuum surveys for massive cold dust (and
hence gas) condensations, as well as OH, H2O, and methanol maser emission surveys
for shock-excited compact regions as signposts for massive star formation. (Note that
methanol maser and OH maser emission is exclusively associated with high-mass star
formation, whereas H2O masers may also be found in low-mass star-forming regions.
This is because methanol and OH masers are radiatively pumped and need an intense
far-IR source in their vicinity; H2O masers, in contrast, are collisionally pumped in
gas shocked by outflows.) These gas and dust surveys have revealed dense cold clumps
486
Zinnecker· Yorke
Annu. Rev. Astron. Astrophys. 2007.45:481-563. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
(molecular hydrogen density nH2 = 105 cm−3, gas temperature T = 10–20 K, diameter
∼0.5 pc) with gas masses ranging from a few hundred to a few thousand solar masses
(Plume et al. 1997, Shirley et al. 2003, Garay et al. 2004, Evans 2005, Motte et al.
2005). The methanol maser surveys at 6.7 GHz point to hot molecular cores with
internal heat sources and outflows, as well as protoclusters (Burton et al. 2005, De
Buizer 2003, Minier et al. 2005).
As mentioned above, large-scale observations with the ISO, MSX, and Spitzer
satellites have revealed a new class of clouds, the so-called IR dark clouds or IRDCs,
and Simon et al. (2006) have identified more than 10,000 such IRDCs from the
MSX data base. Many of these appear to be located in the 4–5 kpc Galactic molecular
ring ( Jackson, private communication; see also Bronfman et al. 2000). The IRDCs are
densecloudsseeninabsorptionagainstmid-IRbackgroundemission.Theyaremostly
filamentary structures that contain condensations of cold massive cores where massive
stars or even star clusters seem to form (Rathborne, Jackson & Simon 2006). Recent
mid-IR and millimeter-continuum observations show different evolutionary stages of
massive star formation in adjacent cores: dense millimeter-continuum sources with
and without mid-IR emission (Garay et al. 2004, their figure 4).
The origin of these structures appears to derive from supersonic turbulence in
giant molecular clouds, that is, shock compression from convergent turbulent gas
streams. Depending on the direction of the compression with respect to the direction
ofthemagneticfieldlines,themagneticfieldwillbeboostedthroughfluxfreezing,and
hence the resulting clump will be stabilized by magnetic forces against gravitational
collapse (subcritical compression). If not, the compressed clump is quickly set up
for collapse (supercritical compression), in fact so quickly that the set-up time is
shorter than the free-fall time. Magnetically stabilized clumps take much longer for
collapse to begin, and their internal turbulent structure may make the clump prone
to subfragmentation. If this is true, only supercritical compression leads to massive
star formation (cf. Shu, Adams & Lizano 1987). An interesting speculation would be
that clouds without sufficiently strong magnetic fields can form lots of massive stars
quasi-simultaneously, giving rise to gigantic starbursts.
2.3. Endproducts
2.3.1. OB clusters. The endproducts of massive star formation are either dense
gravitationally bound OB star clusters or loose unbound OB associations (Lada &
Lada 2003, Brice˜
no et al. 2007). Classical examples of OB star clusters include the
Orion Nebula Cluster, the dense compact cluster associated with the giant galactic
HII region NGC 3603, and the R136 cluster in the 30 Dor region in the Large
Magellanic Cloud (LMC; see Figure 2). These clusters roughly define a richness
sequence in powers of 10: they contain 1, 10 (21), and ∼100 massive O-type stars per
cluster, with estimated total cluster masses of 103, 104, and 105 M
⊙, respectively (e.g.,
Orion Nebula Cluster: Hillenbrand 1997, Hillenbrand & Hartmann 1998; NGC
3603: Moffat, Drissen & Shara 1994, Drissen et al. 1995; R136: Parker & Garmany
1993, Massey & Hunter 1998). Although R136 can probably be considered a small
young globular cluster (M. Andersen et al., submitted), there are more massive young
www.annualreviews.org • Massive Star Formation
487
Annu. Rev. Astron. Astrophys. 2007.45:481-563. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
Figure 2
Hubble Space Telescope
optical/IR image of the
dense massive young cluster
R136/30Dor (courtesy of
M.J. McCaughrean; FOV
∼30 arcsec × 30 arcsec or
7.5 pc × 7.5 pc). Dozens of
massive O stars are found
crowded within the
half-light radius of 2 pc
(Brandl et al. 1996).
(a) A VL
T image of NGC
3603 (Brandl et al. 1999)
and (b) a VLT image of the
Trapezium Cluster in Orion
(McCaughrean 2001) are
shown as these two galactic
clusters would be seen if
they were located at the
distance of R136 in the
Large Magellanic Cloud
(50 kpc) and imaged with
similar angular resolution
(see Zinnecker 2002).
clusters in the nearby universe, such as the very massive embedded super star cluster
in the center of the NGC 5253 dwarf galaxy (Turner et al. 2003). This cluster has
an ionizing flux equivalent to the presence of 4000–6000 O7V stars that comes from
a very compact region about 1 pc in size, measured with the VLA. How can the
formation of so many massive stars in such a small volume be possible? This question
is at the heart of understanding the origin of globular clusters.
2.3.2. OB associations. The classical examples of OB associations include the
nearby Scorpius OB2 and Orion OB1 associations (Blaauw 1964, 1991). Another
fine example of what may ultimately become an OB association is the Carina star
formation complex at 2.3 kpc (Smith & Brooks 2007). One of the best studied extragalactic
 OB associations is NGC 604 in M33 (Ma´
ız-Apell´
aniz, P´
erez & Mas-Hesse
2004). In all these cases, the OB stars are spread over the whole face of the parent giant
 molecular cloud and are not densely packed at all, with distances between massive
stars ranging from 1 to 10 pc. This then appears to be a completely different mode of
massive star formation, although it must be noted that OB associations often contain
dense clusters, too (e.g., the Carina complex harbors the well-known Trumpler 14 and
488
Zinnecker· Yorke
Annu. Rev. Astron. Astrophys. 2007.45:481-563. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
16 clusters). The question is whether OB associations are superpositions of expanded
young clusters (e.g., Kroupa, Aarseth & Hurley 2001, Bastian & Goodwin 2006).
2.3.3. Field OB stars. Do massive stars only occur in young star clusters or OB
associations, or can massive stars also be found outside these regions, i.e., in the field?
The answer is they can. It has long been realized that there exists a class of massive
stars, the so-called runaway OB stars (Blaauw 1961, Poveda, Ruiz & Allen 1967, Gies
& Bolton 1986) that are ejected from their birthplaces—clusters and associations—
with velocities in excess of 40 km s−1. About 10–25% of all O stars and about 2%
of all B stars belong to this class of massive field stars. The question whether—these
runaway stars aside—other massive stars occur in the field (implying that they would
be formed in isolation) has been studied by de Wit et al. (2004, 2005), following Mason
et al. (1998). These authors established that 43 among the 227 O stars brighter than
eighth V-magnitude are in the field. Of these, about half can be traced back to a cluster
or association origin, but about 10–20 stars (i.e., ∼5–10%) could not be assigned to
any group of origin and therefore might be true field stars, born outside clusters and
associations, an issue already raised in a pioneering paper by Roberts (1957). A case
in point is HD93521, a high-latitude O9.5V star, more than 1 kpc above the Galactic
plane, which must have formed locally in the halo (Irvine 1989)! These examples
suggest that the question of the birthplaces of massive stars is not yet completely
settled. The forthcoming Spitzer 8-micron imaging survey of the Magellanic Clouds
(see Meixner et al. 2006) can shed new light upon the question, and in particular can
pinpoint isolated massive stars in the LMC/SMC, should these objects indeed exist.
2.4. Clues from Multiplicity
The multiplicity of massive stars is believed to be higher than that of young lowmass
 premain-sequence stars (Preibisch, Weigelt & Zinnecker 2001; Duchˆ
ene et al.
2001). This means massive stars have more physical companions than low-mass stars
on average. For reference, the multiplicity or, more precisely, the companion star
fraction (csf ) of a stellar population has been defined by Reipurth & Zinnecker (1993)
to be csf = (B + 2T + 3Q + · · ·)/(S + B + T + Q + · · ·), where S is the number
of single, B the number of binary, T the number of triple, and Q the number of
quadruple systems, etc. (i.e., triple systems contribute two companions, quadruple
systems three companions, etc.). For example, the multiplicity of the four OB stars
in the Trapezium Cluster in Orion is as follows: the most massive star θ1 C is double,
the next massive star θ 1 A is triple (a hierarchical system with a close spectroscopic
binary and a wider companion), θ 1 B is at least quadruple (kind of a Trapezium system
within the Trapezium Cluster), and θ 1 D is apparently single. [Kraus et al. (2007) find
some indications that θ 1 D appears extended in their speckle images. There is a fifth
star in the Trapezium Cluster, θ1 E, which has recently been found to be a doublelined
 intermediate-mass spetroscopic binary (Costero et al. 2006, Herbig & Griffin
2006).] Putting the number of companions of θ 1 A, B, C, D into the above formula,
we get csf = 1.5 at face value (probably a lower limit). This should be compared
to the multiplicity of the low-mass stellar members in the Orion Nebula Cluster,
www.annualreviews.org • Massive Star Formation
489
Annu. Rev. Astron. Astrophys. 2007.45:481-563. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
which is csf = 0.5 (Padgett, Strom & Ghez 1997; B. Reipurth et al., submitted), i.e.,
significantly lower.
The multiplicity statistics of other OB clusters, including clusters rich in O stars
(N > 5) and poor in O stars (N < 3) has been studied by Mermilliod & Garc´
ıa (2001)
and Garc´
ıa & Mermilliod (2001), with interesting results: The spectroscopic binary
frequency in O-star rich clusters can vary enormously in different clusters, from 15%
to 80%, with no apparent correlation. If anything, there is an anticorrelation of the
binary frequency and the cluster density, but this needs to be reinvestigated and confirmed.
 The above statistics often rely on relatively poor data, and the sampling is not
complete. Recent work on higher quality data, but on a more limited number of clusters,
 tends to obtain a lower binary fraction in the range of 20% to 60% (Sana, Rauw
& Gosset 2005). The most dramatic example is the IC 1805 cluster where the binary
frequency went down from 80% to 20% based on better data (De Becker et al. 2006).
In the O-star poor clusters almost all O stars are spectroscopic binaries, often
double-lined and even eclipsing. These massive binaries are usually members of hierarchical
 triple or quadruple systems, or of trapezia, and are often located at the
cluster center. The exciting star of the Orion Nebula Cluster, θ1 Ori C belongs in
this category, although θ1 Ori C is not a massive close spectroscopic binary but a
very eccentric visual binary, with masses of 34 M
⊙(O5.5V) and 15 M
⊙(O9.5V) and
an orbital period of about 11 years (Kraus et al. 2007). The orbital periods of the
spectroscopic binaries in the O-star rich clusters are concentrated in the range of
4–5 days, whereas in the O-star poor clusters there is a pile-up of orbital periods
around 3±1 days. In NGC 6231, for example, according to Sana (private communication),
 10 out of the 16 O stars are double-lined spectroscopic binaries: 6 with
periods under 10 days (4 below 5 days); 2 with periods between 3 and 9 months,
and 2 with periods of the order of a year or greater (in addition, 1 star is probably
a triple-lined spectroscopic binary). The luminosity ratios are all in the range 1–10,
otherwise one would not detect them as double-lined spectroscopic binaries. This
implies that the secondaries are probably early B stars, and the primary-to-secondary
mass ratios must be about 3 (at maximum) or lower. It is also worth mentioning that
there is no very short-period highly eccentric O + O binary known at this time (H.
Sana, private communication). These fascinating and surprising facts challenge our
views of massive star formation and provide clues to their origin, clues too complex
to fully decipher yet but hinting at gravitational dynamics playing a role—beyond
mere disk or filament fragmentation (see Section 4, where the formation of binary
and multiple systems is extensively discussed; see also Zinnecker 2003).
Of course, it is equally important to study the multiplicity of massive stars in
OB associations where the stellar density is much lower than in OB clusters, and
dynamical interactions between the forming massive stars should be less of an issue.
For example, the Orion OB1 association contains ∼70 massive stars in its three
subgroups 1a,b,c (subgroup 1d is the Orion Nebula Cluster). Of these 70 OB stars,
20% are spectroscopic binaries with periods less than 10 days (Morrell & Levato
1991). The three subgroups show variations in their spectroscopic binary fractions:
subgroup 1a is average, subgroup 1b is a factor of 1.5 above the average, and subgroup
1c is a factor of 1.5 below the average. The situation in the nearby Scorpius-Centaurus
490
Zinnecker· Yorke
Annu. Rev. Astron. Astrophys. 2007.45:481-563. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
OB2 association is as follows: Among the 48 early B stars (B0V to B3V) there are 25
binaries, and 20 of them are spectroscopic binaries with known periods in the range
of 0.9–34.2 days, with a median of 5.7 days (Brown 2001).
In conclusion, it seems that the spectroscopic binary fraction among massive stars
in OB associations is surprisingly similar to that in OB clusters rich in O stars (about
40% on average), and the fraction of very close spectroscopic and eclipsing massive
binaries in OB associations with orbital periods below 5–10 days (about 20%, judging
from the Orion and Scorpius-Centaurus regions) is a factor of two lower than in OB
clusters. Thus OB clusters appear to contain more of a population of very tight (hard)
binaries, possibly an effect owing to dynamical encounters after birth; this is an effect
that is absent in OB associations.
The future of spectroscopic massive binary research lies in the near-IR and in
multiepoch radial velocity surveys of embedded massive stars. First results (and successes)
 have been reported by Apai et al. (2007), indicating that massive close binaries
indeed form at a very early stage.
2.5. Upper Initial Mass Function and Upper Mass Limit
The mass distribution function of massive stars at birth (the so-called Initial Mass
Function or IMF for short) is a complicated matter, because (a) massive stars quickly
lose some of their initial mass through stellar winds, (b) many of these massive stars
are unresolved binaries, and (c) massive stars tend to be born in the centers of OB
clusters or tend to sink preferentially toward the cluster center, leaving behind their
lower mass siblings that live in the cluster outskirts. This introduces a bias into the
mass distribution, flattening a power-law slope. The upper IMF from about 10 to
100 M
⊙is usually found to be a universal power-law, with logarithmic slope –1.35,
first found by Salpeter (1955) for a range of masses below 10 M
⊙. We refer here to
the early observational work of Garmany, Conti & Chiosi (1982) and the summary of
Massey (1998). The implication of a Salpeter slope or other similar slopes of the IMF
for the number of stars born in different mass intervals (for convenience spaced by a
factor of two) can be seen in Table 2, which has been normalized to contain exactly
one object in the highest mass interval. This is instructive, because it shows dramatically
 how rare the O/WR-type massive stars (interval 64–128 M
⊙) are compared
with the early B-type massive stars (8–16 M
⊙), or with the solar-type low-mass stars
(1–2 M
⊙).
The IMF of massive stars in the aforementioned OB clusters (Orion Nebula Cluster,
 NGC 3603, and R136 in 30 Dor) is discussed by Pflamm-Altenburg & Kroupa
(2006), Stolte et al. (2006), and Massey & Hunter (1998), respectively. [Other studies
of the Orion Nebula Cluster include Zinnecker, McCaughrean & Wilking (1993);
Hillenbrand & Hartmann (1998); and Muench et al. (2002). The stellar content in
the biggest galactic HII region NGC 3603 was also investigated by Drissen et al.
(1995); Hofmann, Seggewiss & Weigelt (1995); Eisenhauer et al. (1998); Brandl et al.
(1999); Moffat et al. (2004); and Sung & Bessell (2004). An important investigation
of the IMF of R136 is that of Sirianni et al. (2000).] Whereas Pflamm-Altenburg
& Kroupa (2006) find a deficit of high-mass stars in the Orion cluster, Stolte et al.
www.annualreviews.org • Massive Star Formation
491
Annu. Rev. Astron. Astrophys. 2007.45:481-563. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
Table 2
Initial mass function (dN/dlogM ∼M−x)
examples (cf. Zinnecker 1996)
Mass range
Logarithmic slope
x = 1
x = 1.35
x = 1.7
0.5–1 M⊙
128
700
3822
1–2 M⊙
64
275
1176
2–4 M⊙
32
108
362
4–8 M⊙
16
42
111
8–16 M⊙
8
16.6
34.3
16–32 M⊙
4
6.5
10.6
32–64 M⊙
2
2.55
3.25
64–128 M⊙
1
1
1
(2006) derive an excess of massive stars in the NGC 3603 cluster core, reflected by a
power-law slope of –0.9 (probably due to mass segregation). It is only in R136 that
the power-law slope is almost exactly the same as the Salpeter value. It is worth noting
here that the slope of the mass function of high-mass stars in the range of 8–40 M
⊙in
the wider field in the 30 Dor region is apparently the same as in the R136/NGC 2070
cluster (Selman & Melnick 2005). The latter authors do not find the much steeper
slope of the IMF (for the range of 25 M
⊙to 120 M
⊙) derived by Massey (2002) for the
global OB field population in the LMC. They suspect that selective incompleteness
at V = 12 owing to detector saturation and Be star contamination lies at the origin of
this discrepancy.
The question of the IMF of massive stars in OB associations was discussed long
ago by Garmany, Conti & Massey (1980) and later by Massey, Johnson & DegioiaEastwood
 (1995). They concluded that the IMF is normal, i.e., consistent with a
Salpeter power-law. A fine discussion of upper IMF slopes in various young clusters
and associations including all the caveats and selection effects was given by Scalo
(1998). He noted that individual realizations of IMF slopes can vary, but the average
slope is indeed close to the Salpeter value –1.35.
The question of whether there is a physical (rather than statistical) upper mass end
to the IMF is of great interest to anyone interested in population synthesis, galactic
evolution, and cosmology. For example, if the stellar upper mass limit were 120 M
⊙,
pair instability supernovae requiring stellar masses at the time of explosion between
140 and 260 M
⊙(Heger et al. 2003) could not happen. Larson (1982) originally
asked the observational question whether there was a correlation between the mass
of a molecular cloud and the maximum mass of a star that could form in it. His
result was that indeed the maximum stellar mass scaled with the mass of the parent
cloud, roughly with its square root. It takes a giant molecular cloud of 105 M
⊙to
form a 50 M
⊙star; a cloud of 103 M
⊙can only spawn a maximum stellar mass of
8 M
⊙.The implication is that massive stars form in clouds of mass between 103 and
105 M
⊙or more, probably because only these have sufficiently massive substructure
(clumps).
492
Zinnecker· Yorke
Annu. Rev. Astron. Astrophys. 2007.45:481-563. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
Weidner & Kroupa (2004) and Figer (2005) discussed the upper limit to the masses
of stars, based on observations of the R136 cluster in the LMC and the Arches cluster
 near the Galactic Center, respectively. They pointed out that these clusters are so
massive that given a Salpeter IMF one would expect to find stars as massive as 750 M
⊙
and 500 M
⊙, respectively, whereas the most massive stars seen do not exceed
140 M
⊙and 130 M
⊙, respectively. This suggests a firm upper mass limit of 150 M
⊙.
Otherwise, a sharp downturn of the IMF near 150 M
⊙would be required (see the
extensive discussion in Elmegreen 2000). Or the very massive stars have already exploded/imploded
 during the dust-obscured, hidden, early evolutionary stages—an
unlikely scenario. Oey & Clarke (2005) also gave a statistical confirmation of a stellar
upper mass limit around 120–200 M
⊙, if the IMF is Salpeter-like. Koen (2006) further
analyzed the upper IMF in the R136 cluster with two different statistical techniques
and suggested an upper mass limit of 140–160 M
⊙. Thus all four studies agree on the
existence of a physical upper limit in the stellar mass distribution.
2.6. Feedback and Triggering
This topic deserves its own review. The question we ask here is the following: What
does the energy and momentum input of massive stars in terms of expanding HII
regions, stellar winds, or supernova shock waves do to the parent clouds? Is the cloud
primarily disrupted, or is new star formation triggered? Which of the above agents
(HII regions, stellar winds, or supernova shock waves) provides the best trigger for
new OB star formation and for new low-mass star formation? We are only beginning
to answer these questions.
A key observation in this context is the fact that the high-mass and low-mass stellar
populations in the subgroups of OB associations appear to be coeval, i.e., the nuclear
age of the massive stars is the same as that of the lower mass premain-sequence
objects (Preibisch & Zinnecker 1999, 2007; Brice˜
no et al. 2007). This would appear
to require a fast, coherent trigger, such as a supernova shock wave. Indeed, in the
Scorpius-Centaurus association there is evidence that the shock wave of a supernova
in one OB subgroup triggered the formation of another subgroup (de Geus 1992).
However, there is also other evidence that radiation from massive stars [by a process
called radiative implosion (e.g., Kessel-Deynet & Burkert 2003)] can only trigger the
formation of low- and intermediate-mass objects (Lee & Chen 2007 andINTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
729
1.1. Motivation. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 729
1.2. Star Formation and Astrochemistry . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
729
1.3. Outline of This Review . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 731
2. RECENT ADVANCES AND NEW CHALLENGES . . . . . . . . . . . . . . . . . . . . . . . . . .
731
2.1. Advances in Observational T
echniques . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
731
2.2. Spectroscopic Identifications of New Species . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
736
2.3. Linking Observations, Chemical Modeling, and Laboratory Experiments . . . .
739
3. CHEMICAL INVENTORIES IN REGIONS OF STAR FORMATION . . . . . . . .
744
3.1. Recent Salient Results About Molecular Complexity . . . . . . . . . . . . . . . . . . . . . . . .
744
3.2. Detections in the Warm Gas of Hot Cores and Corinos . . . . . . . . . . . . . . . . . . . . .
745
3.3. Low-Density Environments and Starless/Prestellar Cores . . . . . . . . . . . . . . . . . . .
745
3.4. Outflows. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 746
3.5. External Galaxies. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 747
4. CHEMICAL DIFFERENTIATION IN THE ENVIRONMENTS
OF STAR FORMATION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
747
4.1. Sgr B2(N): The Impact of Cosmic Rays and an Extended Reservoir
of Complex Organic Molecules . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
748
4.2. Orion KL: Chemical Impact of a Past Explosion . . . . . . . . . . . . . . . . . . . . . . . . . . . .
749
4.3. Chemical Differentiation in Other Hot Cores . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
750
4.4. Spatial Differentiation in IRAS 16293-2422 . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
752
5. LINKING THE PHYSICAL AND CHEMICAL EVOLUTION
OF PROTOSTARS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
753
5.1. Chemical Changes in the Transitions from Envelopes to Disks . . . . . . . . . . . . . .
753
5.2. The Physical/Chemical Structure of Embedded Disks. . . . . . . . . . . . . . . . . . . . . . . 754
5.3. Episodic Accretion and Snow Lines in Protostellar Envelopes . . . . . . . . . . . . . . .
755
5.4. Summary . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
758
6. FRACTIONATION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
758
6.1. Water . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
759
6.2. Complex Organics . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
762
7. ORIGIN AND EVOLUTION OF CHEMICAL COMPLEXITY. . . . . . . . . . . . . . . 764
7.1. Similarities and Differences Between IRAS 16293B, Sgr B2(N2),
and Comet 67P/C-G . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
764
7.2. A Wider Census of Oxygen- and Nitrogen-Bearing Species
in Star-Forming Environments . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
768
728
Jørgensen • Belloche • Garrod
Annu. Rev. Astron. Astrophys. 2020.58:727-778. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
1. INTRODUCTION
1.1. Motivation
The environments in which young stars form show a rich and varied chemistry. In fact, most of
the molecules detected in the interstellar medium (ISM) to date have first been found in these
regions—whether in the cold starless/prestellar cores or in the warm gas surrounding young stars
of high or low masses. These species range all the way from simple diatomic and triatomic neutral
 molecules to molecular radicals and ions, to complex molecules. The latter, some with ten
atoms or more, include species containing long unsaturated chains of carbon atoms as well as saturated
 organics that can be considered the starting points for eventual prebiotic chemistry. The
chemical networks describing the formation and destruction paths for these different species are
strongly dependent on the underlying physical evolution of the star-formation processes, such as
the changes in density, temperature, and spectral shape and intensity of irradiation.
Although molecules of varying degrees of complexity have also been detected in other regions
 including the envelopes around evolved stars, photodissociation regions, well-developed
protoplanetary disks around Class II young stellar objects (YSOs)/T T
auri stars, and even distant
galaxies, the chemistry in prestellar cores of molecular clouds and embedded protostellar stages
is critical. These stages provide key laboratories for molecular astrophysics: Thanks to the characteristically
 high molecular column densities of these sources, they have yielded by far the most
complete chemical inventories of any interstellar object, including censuses of low-abundance
organics and their isotopologues. Also, these stages are likely pivotal for linking the birth environments
 of young stars and the initial conditions in the emerging protoplanetary disks in terms
of both their physics and chemistry.
However, these sources also illustrate some of the major challenges in terms of understanding
astrochemistry. In particular, recent observations with significant improvements in sensitivity and
spatial resolution have revealed that complex chemistry is taking place in a wider range of the
physical components of young protostars than considered previously (Figure 1). Understanding
how the physical structure and evolution of young protostars influences the degree of molecular
complexity that arises in their envelopes and disks, and how this may further influence chemical
 composition during the later planet-forming stages, remain some of the key challenges for
astrochemistry.
1.2. Star Formation and Astrochemistry
The canonical scenario for the formation of a solar-type protostar starts at low temperatures of
∼10 K at densities of 103–104 cm−3 with the formation of a dense prestellar core in a giant molecular
 cloud. In the denser parts of such cores, gaseous molecules collide with and stick to the surfaces
 of dust grains during their earliest stages and cold gas-phase chemistry leads to abundance
enhancements of, e.g., deuterium-containing molecules through fractionation. Star formation occurs
 when these cores collapse, leading to the formation of an opaque (second) hydrostatic core.
Further infall leads to the release of gravitational potential energy heating the infalling envelope
of dust and gas to temperatures of tens or hundreds of kelvins, whereas the densities increase to
∼108–109 cm−3 in the inner ∼100-au (astronomical unit) regions around the central protostar. As
the temperatures increase above 100 K, the water-rich ice mantles sublimate, injecting molecules
into the gas phase, giving rise to the so-called hot corino regions at high temperatures and densities,which
 are rich in saturated complex organics.These are also the scales at which protoplanetary
disks are expected to arise owing to the conservation of angular momentum, a process that also
leads to the launching of outflows and jets. Although the overall physical evolution for high-mass
www.annualreviews.org • Astrochemistry During Star Formation
729
Annu. Rev. Astron. Astrophys. 2020.58:727-778. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
Accretion shocks
Centrifugal barrier
Disk atmosphere
Nonthermal desorption
(~1,000s of au; T ~ 10 K)
Thermal desorption in hot corino
(≤ 100 au; T ≥ 100 K)
Outflow-driven
shocks
Outflow
cavity walls
Infall and warm-up
of protostellar envelope
Figure 1
Schematic representation of a young solar-type protostar and its structural components that are key to its
chemistry. Complex organic molecules are observed to be present in all of these components as the result of
thermal and nonthermal desorption: on small and large scales within the protostellar envelope and disk, in
shocks related to accretion at the disk surface and centrifugal barrier, and on larger scales associated with the
protostellar outflow. UV irradiation close to the disk and outflow cavity are also potentially important in
regulating the chemistry. The main focus of the previous review in this series by Herbst & van Dishoeck
(2009) was on the formation of complex organic species during the infall/warm-up phase (thick yellow arrow;
see Herbst & van Dishoeck 2009, their figure 14), but, as discussed in this review, in recent years a much
more complex picture has emerged. Background image by Per Bjerkeli. Abbreviation: au, astronomical unit.
stars through these stages is clearly more complex,many of the overall characteristics can be identified,
 including the extended hot cores with elevated temperatures, within which complex organics
are present in some cases. Due to the high column densities of warm material, many of the first
detections of complex organic molecules (COMs)1 were made toward these high-mass regions.
The topic of astrochemistry and its link to star formation has been the subject of previous
reviews in this journal.2 Van Dishoeck & Blake (1998) focused on the overall chemical evolution
 of star-forming regions that at the time had come within reach through advances in
(sub)millimeter wavelength single-dish telescopes, space-borne IR telescopes, and previous generations
 of millimeter-wavelength interferometers. These efforts underlined the importance of
molecular astrophysics as a tracer of the physical changes taking place during the star-formation
process. This includes the freeze-out of molecules on the surfaces of dust grains, the resulting
grain-surface chemistry leading to more complex species, and eventually the release of those
1We keep the definition proposed by Herbst & van Dishoeck (2009) and widely used in the community: a
COM is a carbon-bearing molecule that has at least six atoms. Alternative names such as large astronomical
molecule (LAM) or interstellar complex organic molecule (iCOM) have been proposed in the past decade, but
as long as the context (astrochemistry, not biology or chemistry) is clear and the definition is stated, the term
COM is adequate.
2In addition to the mentioned reviews from this journal, it is worth pointing out a number of reviews from
the past decade: Tielens (2013) described the physical and chemical processes governing the formation and
evolution of molecules in the ISM; Caselli & Ceccarelli (2012) and Ceccarelli et al. (2014) addressed the
link between astrochemistry in star-forming regions and the Solar System; Boogert et al. (2015) discussed
observations of ices; and van Dishoeck et al. (2014) investigated the water trail through the star-formation
process. A review on recent developments in millimeter/submillimeter laboratory spectroscopy in support of
observational astrochemistry was presented by Widicus Weaver (2019).
730
Jørgensen • Belloche • Garrod
Annu. Rev. Astron. Astrophys. 2020.58:727-778. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
molecules into the gas phase during the collapse due to thermal desorption close to young stars
or in outflow-driven shocks or their incorporation into protoplanetary disks.
A decade later, dedicated observational efforts, laboratory studies, and sophisticated gas-phase
and grain-surface chemical models had shifted the focus from the relatively simple species to
the formation of COMs, which was the subject of the review by Herbst & van Dishoeck (2009).
Extensive observations of hot cores had provided the first unbiased surveys providing complete
censuses of the molecular line content of individual high-mass protostars covering wide spectral
ranges of the windows where the atmosphere is mostly transparent, as well as systematic, more
focused, inventories of networks of species toward groups of sources. T
argeted observations of
low-mass protostars had started revealing the rich chemistries of these sources as well, including
the detections of saturated complex organics in the inner envelopes of deeply embedded protostars
as well as in shocks associated with their outflows.
T
oday, yet another decade later, gigantic steps forward have been taken due to the systematic
molecular studies at terahertz frequencies by the Herschel Space Observatory (Herschel); significant
upgrades to many (sub)millimeter wavelength single-dish telescopes and interferometers especially
 in terms of the receivers and correlators; and, in particular, the advent of the Atacama Large
Millimeter/submillimeter Array (ALMA) that has pushed molecular astrophysics studies by orders
of magnitude in sensitivity and spatial resolution.
1.3. Outline of This Review
In this review, we focus on the complex chemistry taking place from the point at which star formation
 is initiated by the formation of dense (prestellar) cores, through their collapse to form young
protostars and their circumstellar disks. We describe the opportunities and challenges encountered
 with recent advances in observations, modeling, and laboratory experiments (Section 2) and
provide an overview of detections of complex molecules in different environments (Section 3).
This is followed by discussions of the importance of the physical conditions on the chemistry reflecting
 both the nonhomogeneous conditions in star-forming environments (Section 4) and the
changes occurring during the formation and early evolution of stars (Section 5). The final two
sections focus on constraints on the formation of complex organic molecules and the link between
 star-forming environments and our own Solar System. Specifically, we describe the insights
that can be obtained by studies of isotopic fractionation (Section 6) and by comparing systematic
chemical inventories across samples of sources to measurements from our own Solar System and
the predictions from models (Section 7).
2. RECENT ADVANCES AND NEW CHALLENGES
2.1. Advances in Observational Techniques
Significant advances within astrochemistry have been made over the past decade thanks to new
telescopes (see the sidebar titled New Facilities) and improvements in instrumentation at existing
 facilities. The key features offered by these facilities are (a) the improvement in the large
instantaneous bandwidths covered with high spectral resolution by individual instruments, (b) the
sensitivity offered by large apertures and excellent observation sites, (c) improved spatial resolution
 with, in particular, combined array antennas, and (d ) coverage of high-frequency windows
in the far-IR with high spectral resolution using space-based telescopes such as Herschel and the
SOFIA (Stratospheric Observatory for Infrared Astronomy). Each of these aspects provides new
opportunities as well as challenges.
www.annualreviews.org • Astrochemistry During Star Formation
731
Annu. Rev. Astron. Astrophys. 2020.58:727-778. Downloaded from www.annualreviews.org
 Access provided by University of Manchester - John Rylands Library on 05/07/23. For personal use only.
NEW FACILITIES
The three main new facilities for studies of star-forming regions that have started operations in the past decade
are:
■Atacama Large Millimeter/submillimeter Array (ALMA): 66-telescope array operating at submillimeter
wavelengths. ALMA has demonstrated its métier for high-resolution, high-sensitivity imaging of the distribution
 of molecules in star-forming regions both near and far (2011–).
■Herschel Space Observatory (Herschel): 3.5-m space-based observatory operating at far-IR (THz) wavelengths.
 Key contributions concern the presence of water and organics in star-forming regions (2009–
2013).
■Stratospheric Observatory for Infrared Astronomy (SOFIA): 2.5-m airborne telescope that gives access
 to far-IR windows not observable from the ground, particularly to important cooling lines of the ISM
(2010–).
2.1.1. Increase of instantaneous bandwidth at many observational facilities. One of the key
aspects of Herschel and ALMA, as well as upgrades of receivers and correlators on facilities such
as the APEX (Atacama Pathfinder EXperiment), the Institut de Radioastronomie Millimétrique
(IRAM) 30-m telescope, the NOrthern Extended Millimeter Array (NOEMA), and the Submillimeter
 Array (SMA), has been the increase in instantaneous bandwidth obtainable while keeping
a relatively high spectral resolution. This is particularly important for performing unbiased spectral
 surveys covering large frequency ranges. For example, the HEXOS (Herschel observations of
EXtra-Ordinary Sources) survey of Orion performed a spectral scan from 480 to 1907 GHz (with
two small gaps) with 1.1-MHz spectral resolution and identified more than 13,000 spectral lines,
i.e., 10 lines per gigahertz (Crockett et al. 2014). From ALMA the Exploring Molecular Complexity
 with ALMA (EMoCA) survey of the high-mass star-forming region Sgr B2(N) (Belloche
et al. 2016) and the Protostellar Interferometric Line Survey (PILS) of the nearby low-mass protostar
 IRAS 16293-2422 ( Jørgensen et al. 2016) have been the main unbiased studies. The high
angular resolution of EMoCA revealed that the secondary hot core Sgr B2(N2), with about 6,500
lines detected above 7σ between 84 and 114 GHz (about 220 lines per gigahertz), has narrow
lines (∼5 km s−1) compared to the lines measured with single-dish telescopes toward Sgr B2(N).
This reduction in spectral confusion was decisive for the identification of new species. The main
component of PILS was a systematic survey of the 329–363-GHz range of ALMA’s Band 7 at
0.25 km s−1 spectral resolution (see Figure 2). With the narrow lines (∼1 km s−1) at selected positions
 toward the protostellar system, the line confusion is reached at low levels, and more than
10,000 lines above 5σ can be identified (about 300 lines per gigahertz).
The key advantage of large bandwidth lies in the possibility for identifications of new species as
well as accurate modeling of line emission leading to robust derivations of excitation temperatures
and column densities. In particular, secure identifications of new species need a high number of
well-isolated lines that can be assigned and modeled (see Section 2.2). Furthermore, with access
to larger bandwidths, the range of energy levels and line strengths covered by individual species
provides highly accurate constraints on their excitation. With of order 15–20 identified lines, the
typical uncertainties on excitation temperatures and column densities become less than 10–20%
when local thermodynamic equilibrium (L
TE) can be assumed (e.g., Jørgensen et al. 2018). Laboratory
 astrophysics has also benefited from these technical developments (see Widicus Weaver
2019, andINTRODUCTION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.2
2. HIGH-MASS STAR FORMATION . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.3
2.1. Evolution From HII Regions Back to Infrared-Bright Protostars . . . . . . . . . . . . . .
1.4
2.2. Infrared-Quiet High-Mass Protostars . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .
1.5
2.3. Lifetimes of High-Mass Star Precursors and Protostellar Accretion Rates . . . . . 1.10
2.4. First Magnetic Field Measurements in High-Mass Star-Forming Regions . . . . . 1.15
2.5. High-Mass Prestellar Cores, the Current Holy Grail . . . . . . . . . . . . . . . . . . . . . . . . . 1.17
2.6. The Evolutionary Scenario of High-Mass Star Formation . . . . . . . . . . . . . . . . . . . . 1.21
3. MASSIVE CLOUD AND MASSIVE CLUSTER FORMATION . . . . . . . . . . . . . . . . 1.25
3.1. High-Density Dynamical Clumps Quoted as Ridges and Hubs. . . . . . . . . . . . . . . . 1.25
3.2. Mini-Starburst Activity Within Ridges . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.28
4. TOWARD GALAXY-WIDE SURVEYS . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.30
4.1. Most Nearby, Massive Molecular Cloud Complexes . . . . . . . . . . . . . . . . . . . . . . . . . . 1.30
4.2. Combination of Galaxy-Wide Surveys and Detailed Images with ALMA . . . . . . 1.31
4.3. Extreme Molecular Cloud Complexes in the Milky Way
and Starburst Clusters . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.35
5. CONCLUSIONS AND PERSPECTIVES . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 1.36
1. INTRODUCTION
High-mass stars, also called OB stars, have luminosities larger than 103 L⊙, spectral types of B3 or
earlier, and stellar masses from 8 M⊙up to possibly more than 150 M⊙(Martins et al. 2008). From
their births to their deaths, high-mass stars are known to play a major role in the energy budget of
galaxies via their radiation, wind, and supernova events. Despite that, the formation of high-mass
stars remains an enigmatic process, being far less understood than it is for their low-mass (solartype)
 counterparts. Solving the mystery of the high-mass star-formation process is important for
itself, but it is also fundamental to fully constrain the origin of the initial mass function (IMF)
and the formation of massive star clusters and to provide accurate star-formation recipes such as
star-formation rate (SFR) and IMF for extragalactic studies and numerical simulations.
Theoretical models proposed for the formation of high-mass stars tried to solve the UV radiation
 pressure problem (Wolfire & Cassinelli 1987). Stars reaching a few 10-M⊙masses and
a few 103-L⊙luminosities were indeed supposed to develop a pressure barrier halting further
accretion. Most recent 3D modeling mostly solved this problem by showing that equatorial accretion
 can continue for ionizing protostar embryos (e.g., Krumholz et al. 2009, Kuiper et al.
2011). Competing concepts for high-mass star formation currently are (a) monolithic collapse of
a turbulent, preassembled core in virial equilibrium (e.g., McKee & Tan 2002, 2003; Hosokawa
& Omukai 2009), (b) protostar collision and coalescence in very dense systems (e.g., Bonnell et al.
1998, Bonnell & Bate 2002), and (c) competitive accretion in a protocluster environment through
Bondi–Hoyle accretion (e.g., Bonnell et al. 2001, Murray & Chang 2012) and/or gravitationally
driven cloud inflow (Smith et al. 2009, Hartmann et al. 2012). Numerical simulations are now
able to form stars with masses of up to 40–140 M⊙thanks to nonspherical accretion, improved
radiation transfer, and feedback effects such as heating and ionization (e.g., Yorke & Sonnhalter
2002; Krumholz et al. 2009; Kuiper et al. 2010, 2011). Modeling the formation of higher-mass
stars may remain a challenge (see Krumholz 2015). For a complete description of high-mass
1.2
Motte· Bontemps· Louvet
Review in Advance first posted on
December 20, 2017. (Changes
may still occur before final
publication.)
Annu. Rev. Astron. Astrophys. 2018.56. Downloaded from www.annualreviews.org
 Access provided by University of Reading on 12/24/17. For personal use only.
AA56CH01_Motte
ARI
5 December 2017
18:5
star-formation theories, readers are directed to reviews by, e.g., Zinnecker & Yorke (2007), Beuther
et al. (2007a), Tan et al. (2014), and Krumholz (2015).
The main open issues on high-mass and massive cluster formation include the following: How
different are the processes that form high-mass stars and massive clusters with respect to their lowmass
 analogs? How is high-mass star formation linked to the formation of their parental clouds
and descendant clusters? Does it vary across the Milky Way? Observational constraints take time
to gather because understanding star formation and especially high-mass star formation requires
studies over several decades of spatial scales and densities. Furthermore, studying the formation of
high-mass stars and their companion low-mass stars implies dissecting their parental protoclusters.
The latter are complex structures composed of molecular gas and stars in the making, generally
located at more than 1 kpc from the Sun, and largely embedded within high-density clouds.
Investigating high-mass star and massive cluster formation thus requires high angular resolution
imaging at far-IR to (sub)millimeter wavelengths over large areas of the Milky Way. Because
we suspect high-mass star-forming regions to be exposed to shock waves, powered by cloud
collision, infall motions, OB stellar winds, and ionization fronts, studying both cloud structures
and kinematics is mandatory.
This observational review follows those done by, e.g., Churchwell (2002), Zinnecker & Yorke
(2007), and Beuther et al. (2007a). We intentionally refrain from discussing detailed characteristics
of high-mass precursors, such as disk and binary formation or chemistry evolution, because observational
 constraints remain sparse and are based on studies of a few very luminous objects. In the
remainder of this review, we characterize the evolutionary phases of high-mass star formation as
defined from large surveys of infrared-bright (IR-bright) to infrared-quiet (IR-quiet) objects (see
Section 2), pointing out their strengths and biases. We end up proposing the most probable
evolutionary scenario for the formation of high-mass stars in relation to source statistics and
cloud kinematics. We then investigate the importance of cloud characteristics to form high-mass
stars and massive stellar clusters and present initial searches for variations across the Milky Way
(see Sections 3 and 4). Finally, we point out directions of improvement for the coming decade
(see Section 5.)
2. HIGH-MASS STAR FORMATION
Unlike the case for low-mass stars (see, e.g., Shu et al. 1987, Andr´
e et al. 2000), there is no
observational evolutionary sequence that is firmly established for high-mass star formation. One
of the main differences between high-mass and low-mass stars is that the radiation field of a
massive star plays a more important role during its whole life and already in its formation phase.
Theoretically, a massive protostellar embryo heats and eventually ionizes the gas of its surrounding
envelope, creating an HII region that develops by expanding within the cloud (see the Str¨
omgren
theory in Spitzer 1978).
Despite the lack of an evolutionary sequence, a nomenclature of high-mass star precursors
exists. Following that of low-mass stars, objects associated with the first phase of high-mass star
formation have been called massive starless clumps, high-mass prestellar cores, massive cold molecular
 cores, or even infrared-dark clouds (IRDCs). High-mass prestellar cores would be preassembled,
 gravitationally bound cores that will form individual high-mass stars or binaries. The nature
of larger-scale cloud structures remains unclear. In the subsequent phase, high-mass star precursors
 have been named massive protostars, high-mass protostellar objects (HMPOs), protostellar
massive dense cores (MDCs), or hot molecular cores (HMCs). These collapsing cloud fragments
qualify as high-mass protostars when they have the ability to form a high-mass star binary but not
a full cluster. The final phase corresponds to HII regions being from hypercompact to classical.
www.annualreviews.org • Massive Star and Cluster Formation
1.3
Review in Advance first posted on
December 20, 2017. (Changes
may still occur before final
publication.)
Annu. Rev. Astron. Astrophys. 2018.56. Downloaded from www.annualreviews.org
 Access provided by University of Reading on 12/24/17. For personal use only.
AA56CH01_Motte
ARI
5 December 2017
18:5
Table 1
Cloud structures of a few reference studies of high-mass (left columns) and low-mass (right columns) star formation
Source
HMPOs
IRDCs fragments,
MDCs,
Isolated prestellar
Clustered pre- or
protostellar
Nature
Clumps
Clumps
Dense cores
Cores
Cores
FWHM (pc)
∼0.5
∼0.5
0.1–0.2
∼0.08
∼0.007
Mass (M⊙)
∼290
∼150
∼150
∼5
∼0.15
<nH2> (cm−3)
∼6 × 104
∼5 × 104
∼2 × 106
∼2 × 105
∼2 × 107
dSun (kpc)
0.3–14
1.8–7.1
1.4
0.14–0.44
0.14
Introduction
Evolved massive stars are observed in a menagerie of exotic
evolutionary phases. While the challenge of connecting these
states with a self-consistent theory of stellar evolution has seen
rapid advancement since the original introduction of the “Conti
Scenario” (Conti et al. 1983), the effects of rotation, magnetic
fields, internal mixing processes, and binary interactions on the
evolution of massive stars are still the subject of much
theoretical effort (e.g., Ekström et al. 2012; Eldridge et al.
2017). While individual massive stars can be used as precision
probes of these processes, ensembles of evolved massive stars
can also significantly constrain stellar evolution. This can be
done by comparing the integrated spectra of massive stars (e.g.,
Levesque et al. 2012), or by studying the detailed makeup of
resolved populations of massive stars (Dorn-Wallenstein &
Levesque 2018, 2020; Stanway et al. 2020).
Using the demographics of stellar populations to constrain
stellar evolution requires large and accurately classified
samples of evolved massive stars. Such samples will be
achievable in the coming years with the launch of the James
Webb Space Telescope (Webb) and the Nancy Grace Roman
Space Telescope (Roman). Among the instrumentation on
Webb and the proposed instrumentation for Roman are
photometers equipped with filters spanning a broad wavelength
baseline from 0.5 to 28 μm. The resolution of Webb will allow
us to identify and study in detail individual luminous stars to
great distances (e.g., Jones et al. 2017), while the impressive
0.218 deg2 field of view of Roman will allow us to efficiently
survey nearby galaxies in a small number of pointings (Spergel
et al. 2013). Combined, observations from both missions will
give astronomers access to precise infrared measurements of
vast numbers of evolved massive stars. But without sophisticated
 methods of identifying and classifying these stars, the
science return afforded by such a large increase in expected
sample sizes will be significantly reduced.
Classification of stars from broadband photometry is often
done by adopting simple linear cuts in color–magnitude space
(e.g., Massey et al. 2006, 2009) and—most critically—does not
include rare emission-line objects, whose classification requires
dedicated
narrowband
surveys
(sometimes
with
customdesigned
 filters; e.g., Neugent et al. 2018b), often accompanied
by follow-up spectroscopy, both of which require extensive
telescope time. These objects are often the post-main-sequence
evolved states of massive stars, in which the effects of rotation,
binary
interactions,
and
chemical
mixing
are
the
most
pronounced; the stars that place the most valuable constraints
on unknown stellar physics are also the hardest to detect via
traditional means. Therefore, it is worthwhile to determine
whether there are alternative ways to classify massive stars that
avoid using traditional and expensive methods.
At present, we can mimic the observing capabilities of Webb
and Roman by combining data from Gaia (which has a red–
optical bandpass), the Two Micron All Sky Survey (2MASS;
Skrutskie et al. 2006; near-infrared), and the Wide Field
Infrared Survey Explorer (WISE; Wright et al. 2010; midinfrared
 [MIR]). WISE provides the additional benefit of
having scanned the sky approximately every 6 months,
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
https://doi.org/10.3847/1538-4357/abf1f2
© 2021. The American Astronomical Society. All rights reserved.
1
yielding light curves spanning a ∼7 yr baseline from which we
can extract variability metrics for most stars observed. While
Roman and Webb will not be observing the entire sky in this
fashion, determining whether variability can aid in the
classification of evolved massive stars will determine whether
observers should seek repeated observations of a stellar
population.
We wish to determine whether we can
1. assemble a sample of evolved massive stars with
available classifications as a training data set;
2. construct a machine-learning classifier that can reject
low-mass red contaminants and identify likely emissionline
 objects in order to optimize available telescope time
on the most promising targets;
3. determine whether variability metrics estimated from
WISE light curves can aid in these tasks; and
4. determine which photometric bandpasses and variability
metrics
contribute
the
most
to
making
accurate
classifications.
Here we utilize a Support Vector Machine classifier (SVC)
trained only on broadband photometry and simple metrics
derived from WISE light curves to classify a large sample of
evolved massive stars. We describe our sample selection and
labeling method in Section 2. Section 3.1 details the calculation
of the simple metrics derived from the WISE light curves and
describes the overall behavior of the stars in our sample. We
explain our classification algorithm, discuss its successes and
shortcomings, and apply it to a training sample of 2500 stars
in Section 4, before presenting our recommendations and
concluding in Section 5.
2. Sample Selection and Labeling
For any machine-learning algorithm, a high-quality training
set with accurate labels is necessary. The second data release
(DR2) of the Gaia mission (Gaia Collaboration et al. 2018a)
contains precise photometry in three bands (G, GBP, and GRP)
and geometric parallaxes (ϖ) for 1.3 billion stars in the Milky
Way (MW) and Magellanic Clouds. Because the parallax
measurements suffer from some systematics (Lindegren et al.
2018), and many objects have high fractional errors (σϖ/ϖ) or
negative measured parallax, Bailer-Jones et al. (2018) calculated
 Bayesian distance estimates for the majority of stars in
Gaia DR2, using a prior based on the spatial distribution of
stars in the MW. Figure 1 shows the difference between the
distance inferred by Bailer-Jones et al. (2018), rest, and a naive
distance derived by inverting the reported Gaia measurements
of ϖ for ∼10,000 putative massive stars (as described below).
The dashed line indicates where rest = 1/ϖ. While the two
distance estimates are roughly consistent for nearby stars, more
distant stars are biased much farther away in the naive distance
estimates.
We first perform a cross-match between the Bailer-Jones
et al. (2018) catalog and the existing cross-match between Gaia
DR2 and the ALLWISE data release. ALLWISE (Cutri et al.
2013) contains photometry in four MIR bands—W1 (3.4 μm),
W2 (4.6 μm), W3 (12 μm), and W4 (22 μm)—derived from coadded
 images obtained during the original WISE mission, as
well as W1 and W2 images obtained in the post-cryogenic
NEOWISE mission (Mainzer et al. 2011). We select all stars
with successful distance estimates (i.e., where result_flag = 1
if the distance estimate is the mode of the posterior distribution,
2 if it is the median, and 0 for a failed estimate; see Bailer-Jones
et al. 2018 for more details) that satisfy
=
+

<


M
G
r
W
5 log
5
1.5,
1
14.
1
G
est
( )
Since Bailer-Jones et al. (2018) used a Galactic prior,
stars in the Large and Small Magellanic Clouds (LMC and
SMC, respectively) have distances that are considerably
underestimated. Thus, we also match the catalog in Gaia
Collaboration et al. (2018b) to the ALLWISE/Gaia cross-match
and select stars with W1 < 14 and MG  −1.5, assuming
distance moduli of 19.05 and 18.52 for the SMC and LMC,
respectively (Kovács 2000a, 2000b), and combining the two
cross-matches while dropping duplicate stars. This results in a
total of 452,283 stars.
We then estimate the reddening in the Gaia bandpasses using
the published estimate for AG from Gaia DR2 and coefficients
from Malhan et al. (2018) to calculate E(GBP −GRP). For
Galactic stars without AG estimates, we assume AG = 0, and for
stars in the Magellanic Clouds, we assume the average value of
AG and E(GBP −GRP) using RV measurements from Gordon
et al. (2003) and E(B −V ) from Massey et al. (2007). Using
these quantities, we calculate the intrinsic GBP −GRP and MG
for all stars.
We can then construct color–magnitude diagrams (CMDs) in
the Gaia filters, which we can use to select massive stars—i.e.,
stars with initial mass Mi  8 Me. We use the MESA
Isochrones & Stellar Tracks (MIST; Dotter 2016; Choi et al.
2016; Paxton et al. 2011, 2013, 2015) isochrones with
metallicity [Fe/H] = 0, −0.5, and −1 for the Galaxy, LMC,
and SMC, respectively, and rotation speed relative to critical of
v/vcrit = 0.4. We then selected the faintest isochrone point of
any age with Mi  8 Me in 100 equally spaced bins in the
range−0.25  GBP −GRP  3. We note that the oldest MIST
time bin is 1010.3 yr (older than the age of the universe), but by
selecting points with Mi  8 Me, none of the selected points are
older than ∼40 Myr. These isochrone points form a boundary
in the Gaia CMD that represents the faintest luminosities
reached by any massive star at any point during its evolution,
and no fainter massive stars are expected to be found—note
Figure 1. Distance from Bailer-Jones et al. (2018) vs. distance inferred via
inverting the reported ϖ from Gaia DR2 for ∼10,000 putative massive stars.
The dashed line shows where rest = 1/ϖ.
2
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
that many isochrone points with Mi < 8 Me lie above this
boundary, so our sample is not constructed to be free of
contamination. The left panel of Figure 2 shows the logarithmic
density on the sky of all stars selected from the Gaia DR2
database; the Galactic plane and Magellanic Clouds are clearly
visible. The right panel shows the Gaia CMD, zoomed in to
show only stars brighter than MG = −2.75, where blue, orange,
and green points are individual stars in the Galaxy, LMC, and
SMC, respectively. The solid, dashed, and dotted black lines
show the MIST luminosity threshold for the Galaxy, LMC, and
SMC, respectively. Note that the thresholds accurately capture
the slope of the main sequence for all three galaxies, as well as
the GBP −GRP color corresponding to the Hayashi limit.
We
select
all
stars
brighter
than
the
corresponding
luminosity threshold for their host galaxy, resulting in 9784
objects. From this sample, we select all stars fainter than the
saturation limit in W1 (8) and W2 (7) with valid measurements
listed in the ALLWISE catalog for the three bluest WISE bands
(excluding W4, where the signal-to-noise ratio is often poor).
We also convert the W1 and W2 magnitudes (and uncertainties)
to fluxes and filter for stars with signal-to-noise ratio greater
than 3. This results in a final sample of 6484 objects. Table 1
lists the names, coordinates, host galaxies, distances from
Bailer-Jones et al. (2018), and Gaia photometry for these stars.
We query Vizier (Ochsenbein et al. 2000) using astroquery
 to download JHKs photometry from the Two Micron
All Sky Survey (2MASS; Skrutskie et al. 2006) for all stars.
We also query SIMBAD (Wenger et al. 2000) and download
the common name (MAIN_ID), spectral type (contained in the
MK_Spectral_Type and SP_Type fields), and object type
(OType) for each star, the last two of which we use to assign
labels.
2.1. Label Assignment
For our final sample of ∼6500 stars, we wish to assign the
best available estimate of its evolutionary state. These labels
can be used to compare to the predictions of stellar population
Figure 2. Left: density of stars selected from the Gaia database on the sky. Intensity of the color map corresponds to the logarithm of the number of stars in each bin.
Right: Gaia CMD for stars selected from the Gaia DR2 database brighter than MG = −1.5 (though we only plot stars brighter than MG = −2.75 to highlight the likely
massive stars). Galactic stars are in blue, LMC stars are in orange, and SMC stars are in green. The solid, dashed, and dotted lines represent our minimum-luminosity
criteria to select massive stars in the Galaxy, LMC, and SMC, respectively.
Table 1
Common Names, Gaia DR 2 Source IDs, Coordinates, Host Galaxies, and Gaia Measurements of 6484 Putative Massive Stars, Ordered by R.A.
Common Name
Gaia DR2
R.A. (deg)
Decl. (deg)
Host
Galaxy
rest [kpc]
G [mag]
AG [mag]
GBP −GRP
[mag]
HD 236270
420521729725089408
0.17442287
55.72245665
MW
2.162
9.07
0.94
0.24
LS I+64 10
431766950542328448
0.38838658
64.51219232
MW
5.305
11.55
1.33
0.57
LS I+60 69
429346100814866944
0.55506135
60.43828347
MW
5.866
11.85
1.23
0.61
BD+62 2353
430076176533095936
0.59458742
62.90087875
MW
5.243
9.81
0.48
0.37
HD 73
384823335942218240
1.40408512
43.40139506
MW
1.869
8.19
0.12
−0.15
HD 240496
423076307551376512
1.42175475
58.49541068
MW
2.499
9.70
1.55
0.68
WISE J000559.28
−790653.3
4635404653198890880
1.49713706
−79.11483482
SMC
L
13.94
0.21
1.05
LS I+59 30
429255116226234240
1.70503555
59.85955733
MW
4.006
10.86
1.19
0.50
BD+57 2870
423061979540546048
1.82960982
58.33785301
MW
3.893
9.84
1.42
0.82
BD+62 1
431515810905725952
1.88805102
63.08030731
MW
2.893
10.29
1.30
0.53
Note. Parameter rest from Bailer-Jones et al. (2018) is given for Galactic stars. Listed values of G and GBP −GRP are uncorrected for extinction.
(This table is available in its entirety in machine-readable form.)
3
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
models. Note that these evolutionary states (which are
theoretical concepts) are mostly tied to spectral appearance
(which is an observable quantity). Therefore, we are assuming
that, e.g., all stars with Wolf-Rayet (W-R) spectra are in the
same evolutionary state (namely, the descendants of massive
stars with high luminosities that have lost their envelopes via
strong winds) and that all stars in that evolutionary state are
observed as W-R stars. We know that at least the former is not
true, as some stars lose their envelopes owing to interactions
with a binary companion (Eldridge et al. 2017), and the latter is
also questionable since such stars may or may not appear
similar to classical W-R stars (Götberg et al. 2018). Nevertheless,
 we assume that the assigned labels are a reasonable
approximation for a star’s evolutionary state with this caveat
in mind.
At present, a database of homogeneously classified massive
stars does not exist. While all-sky spectroscopic surveys have
observed many massive stars, the machine-learning pipelines
that produce the effective temperatures, surface gravities, and
chemical compositions that would allow us to accurately
classify our sample do not cover the parameter regime in which
massive stars reside (e.g., García Pérez et al. 2016). As a result,
we must use the heterogeneous classification data available on
SIMBAD. For each star, we apply a decision tree that results in
the star receiving a single label. Figure 3 shows a flowchart that
summarizes our labeling scheme. Note that this process is
highly tailored to this data set, and some branches in the
decision tree serve only to accurately label very small numbers
of stars with unique spectral types (e.g., spectroscopically
peculiar stars or X-ray binaries). Deriving labels for known
massive stars using existing sources is not trivial, and our
labeling scheme would be entirely different if a large sample of
massive
stars
with
well-measured
temperatures,
surface
gravities, and chemical abundances were available.
We first use the common name and Gaia source_id of the
star to determine whether the star belongs to the catalog of
confirmed luminous blue variables (LBVs) presented in
Richardson & Mehner (2018). Non-LBVs are classified as
W-R stars if “W” is in the spectral type, or the SIMBAD
OType is “*WR.” Non-W-R stars with “K” or “M” in their
spectral type are classified as either red supergiants (RSGs) or
“C/S/Giant” if their SIMBAD SP_Type contains “III”—we
keep all such low-mass contaminants in our sample, as
distinguishing between RSGs and luminous low-mass giants
is still a difficult problem (Massey et al. 2009; Yang et al. 2019;
Neugent et al. 2020). The resulting sample of RSGs is pure; of
the five RSGs that do not have luminosity class I, all of them
are luminosity class Ia−II, Ib−II, or Iab−II, which are
consistent with bona fide RSGs (Levesque et al. 2005). This
is a good test of the Gaia DR2 parallaxes and Bailer-Jones et al.
(2018) distances, as cool subgiants and dwarfs with luminosity
class IV or V would have been erroneously classified as RSGs
using our criteria had they been included in our sample owing
to inaccurate distance and MG measurements.
Non-RSGs with “F” or “G” in their spectral type are
classified
as
yellow
supergiants
(YSGs).
However,
this
Figure 3. Flowchart illustrating the process by which stars are assigned labels, as described in text. Each star begins in the top left and is assigned a label by following
a series of binary decisions. This process is complex and demonstrates the difficulty in deriving useful labels for massive stars. For example, some stars with F or G in
their spectral types are actually hot OBA stars (as described in text) and require special handling.
4
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
includes a number of blue stars. Further inspection of these
stars reveals a number of objects whose MK_Spectral_Type
field contradictorily indicates that these are hot stars, with
spectral type O, B, or A. As these stars have Gaia photometry
consistent with hot stars, we classify them as such (see below).
Eight low-mass yellow stars are also included in our sample.
Stars with “III” or “V” in their spectral types are classified as
yellow dwarfs. While luminosity class III formally denotes
giant stars, only one yellow giant is in the sample, and so we
assign it the yellow dwarf label. We note that for extragalactic
samples foreground dwarfs can usually be filtered based on
proper
motions,
while
dwarfs
belonging
to
the
stellar
population under study can be excluded just based on their
apparent magnitudes. Nonetheless, we retain this class to avoid
confusion between these stars and true YSGs. All YSGs that
are not hot stars or dwarfs keep their YSG label.
Of the objects that have not yet been classified, stars with
“[e]” in their spectral type are classified as OB[e] stars, while
non-OB[e] stars with spectral types including an “e” (without
brackets, and without “pec” in their spectral type) are classified
as OBAe stars. If the star is not yet classified and O, B, or A are
in the spectral type with no additional information, they are
classified as generic OBA stars. OBA stars with “III” or “IV” in
their spectral type are classified as evolved OBA stars, stars
with “V” in their spectral type are classified as OBA mainsequence
 stars, and stars with “I” in their spectral type are
labeled as OBA supergiants. All stars that have not been
assigned a label at this stage are either C/S stars (which are
assigned the C/S/Giant class); stars labeled only as variables
in SIMBAD (e.g., LPVs, semiregular variables, or just
variables, without other spectral information), which are
assigned the miscellaneous variable classification; or stars with
no identifying information/no confirmed designation (e.g., the
SIMBAD OType is “Star” or contains “Candidate”), which are
classified as unknown/candidate.
Finally, we include an “Is Binary” flag for all stars, which is
1 for stars classified as eclipsing or spectroscopic binaries,
high-mass X-ray binaries, or ellipsoidal variables, or if they
have a compound spectral type (e.g., WN8 + O6V),5 and 0
otherwise; 102 stars are flagged as binaries. This flag is
separate from the labeling process shown in Figure 3. Because
photometry of binary systems can be misleading (Neugent et al.
2018a) and binary systems exhibit a broad range of variability
that is not intrinsic to the individual components, we exclude
these stars from our classifier.
Figure 4 shows the makeup of our sample. Approximately
30% of our sample (2550 stars) belong to the miscellaneous
variable and unknown/candidate classes, which we do not use
to train our classifier; instead, we use the classifier to assign
tentative classifications in Section 4. The rest of the sample is
dominated by luminous OBA stars and cool supergiants, with
very few LBVs, OB[e] stars, and W-R. This is unsurprising
given these stars’ high luminosity in the Gaia bandpass and the
expected lifetimes of these evolutionary phases relative to the
lifetimes of exotic emission-line objects (Ekström et al. 2012).
The imbalances in available training data across different
classes, along with the extreme sparsity of training data in the
rare classes, will impact the performance of the classifier if not
properly addressed (Chawla 2010). We discuss this issue for
this particular sample in Section 4.1.
The left panel of Figure 5 shows the MG versus G −J CMD
for all stars in our sample that are not labeled as miscellaneous
variables or unknown/candidate, colored by their label. G −J
correlates reasonably well with effective temperature in mainsequence
 stars (Davenport & Covey 2018), and in this case it is
especially useful for distinguishing from the near-vertical mainsequence/blue
 supergiants and the significantly cooler yellow
and red supergiants. From this plot, it is clear that many stars
are misclassified in SIMBAD (the worst example is one
particular red star classified as an OBA star), reducing the
effectiveness of any machine-learning algorithm, and propagating
 biases into the results. Yellow supergiants are especially
prone to this problem: 81/212 YSGs in the sample (38%) have
G −J < 1, consistent with the optical colors of much hotter
stars. Indeed, this problem would have been worse had we not
corrected for the presence of OBA stars in the initial sample of
YSGs. This issue may originate from bad distance estimates for
individual stars (which explains why our sample includes F and
G dwarfs), bad estimates of reddening (given our usage of
monochromatic extinction coefficients), previously unidentified
variability, or the fact that many of these spectral types were
determined via stellar spectra taken on photographic plates
(e.g., many spectral types for stars in the LMC come from
Ardeberg et al. 1972). We expect this issue to propagate into
our results, increasing the confusion between YSGs and hot
stars.6
Figure 4. Makeup of our sample of massive stars. Note that the sample is
dominated by OBA stars and cool supergiants. Non-OBAe emission-line stars
—OB[e] stars, W-R stars, and LBVs—are the rarest massive stars in our
sample, despite being stars of great scientific interest. For readability, we have
used a logarithmic y-axis to display our sample statistics. Note that, in practice,
differences in the number of stars per class are much larger than they might
appear here.
5
This does not include stars with the “OB+” spectral type, which is an
outdated class that describes OB stars with weaker absorption lines that would
now be classified as OB supergiants.
6
It would certainly be possible to tailor our data set by removing the “worst”
stars, thus cleaning up the boundaries between classes. However, by doing this
we would be making several assumptions about where different classes of stars
reside in our feature space, with no way of knowing whether these enforced
boundaries actually divide stars into physically different evolutionary states.
Indeed, we expect the boundaries between classes to be fuzzy, because our
discrete labels are an approximation of a continuum of evolutionary states—a
fact that we have otherwise swept under the rug. That said, a significant amount
of the overlap between classes is due to the poor quality of existing labels.
Instead of trying to guess which stars are poorly labeled, and which ones truly
reside in the overlap between classes, we instead wish to see how the quality of
existing labels impacts the performance of our classifier.
5
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
Because we expect objects in some classes—especially those
with an evolutionary link such as main-sequence, evolved, and
supergiant OBA stars—to appear similar in the training data
set, we also assign all stars a coarse label: all classes of OBA
stars excluding OB[e] and OBAe are labeled “Hot”; RSGs and
YSGs are labeled “Cool”; W-R stars, LBVs, and both OB[e]
and OBAe stars are labeled “Emission” (EM for short); C/S/
Giant stars and yellow dwarfs are labeled “Contaminant”; and
miscellaneous variables and unknown/candidates are labeled
“Unknown/Candidate.” The results of this labeling scheme are
summarized in Table 2, which shows the number of stars with a
given refined class that are assigned a particular coarse label.
The right panel of Figure 5 shows the same CMD, with points
colored by their coarse label. This leads to some improvement:
each coarse class lies in the approximate region of the CMD
that one would expect. Regardless, it is evident that selecting
any one of these classes solely from this optical photometry
would be difficult: the “cool” class has significant overlap with
the “hot” class—largely driven by the YSGs—emission-line
stars can be found at a range of GBP −GRP colors, and there is
significant overlap between low-mass contaminants that will
end their lives as white dwarfs and true massive stars that will
end their lives in supernova explosions. This point is
emphasized by the contours, which correspond to 0.5 and 0.1
times the maximum value of a kernel density estimate of the
distribution of each class, which replaces each point with a
kernel function (in this case a two-dimensional Gaussian
centered on the point) and sums the kernels to estimate the
underlying distribution. We do this using the KernelDensity
 estimator from sklearn and use a similar crossvalidation
 scheme described below to find a suitable bandwidth
for the kernel (i.e., the width parameter of the Gaussian).
We use these coarse labels to train a second classifier. While
these coarse labels lose some specificity, each coarse class
contains more stars, hopefully increasing the performance of a
classifier trained on these labels. Furthermore, they still retain
physical information while increasing the number of stars in
each class: the “cool” label contains stars with convective
envelopes, while “hot” stars contain radiative envelopes.
Meanwhile, emission-line stars are notable for their variability.
It is our hope that this second classifier will still address two of
our stated goals: to identify emission-line stars, and to reject
contaminating low-mass stars.
3. WISE Light Curves
Variability
in
evolved
massive
stars
has
been
well
characterized at timescales from minutes to decades (e.g.,
Conroy et al. 2018; Dorn-Wallenstein et al. 2019; Soraisam
et al. 2020). In a study of massive stars in the Whirlpool Galaxy
(M51), Conroy et al. (2018) found that almost half of the stars
brighter than MI = −7 were variable, with red stars nearing a
variability fraction of 1. Both red and extremely luminous blue
stars exhibited quite high amplitude (ΔI  0.3) variability. For
spectral energy distributions (SEDs) dominated by purely
stellar light, MIR flux measurements (and thus variability) are
sensitive to (variations in) the bolometric luminosity. However,
for stars with significant circumstellar dust components in their
SEDs, MIR variability is correlated with both intrinsic
bolometric variability and dust creation/destruction processes
Figure 5. MG vs. G −J for putative massive stars. Left: stars are colored by their label. While we also use shapes to distinguish between stars in different classes, this
illustrates a key difficulty faced by our classifier: the classes have significant overlap with each other in the CMD. For example, the coolest/warmest YSGs have
identical optical photometry to RSGs/OBA supergiants, respectively, while the different classes of hot stars are impossible to distinguish from one another by eye.
Right: stars are colored by their coarse label. Contours for each coarse class correspond to 0.5 and 0.1 times the maximum value of a kernel density estimate of the
distribution of each class in the CMD. Even in the coarse labels, the contours for hot stars and emission-line stars are nearly identical.
Table 2
Number of Stars in a Class That Are Assigned a given Coarse Label, Not
Including the Miscellaneous Variable or Unknown/Candidate Labels
Coarse Label
Refined Label
Hot
Emission
Cool
Contaminant
Main-sequence OBA
187
Evolved OBA
409
Supergiant OBA
798
OBA
915
OBAe
383
OB[e]
12
W-R
37
LBV
8
YSG
212
RSG
847
C/S/Giant
118
Yellow dwarf
8
Total
2309
440
1059
126
6
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
in the circumstellar medium (e.g., in RSGs, where it is
correlated with the mass-loss rate; e.g., Yang et al. 2018).
The WISE mission provides light curves from stars in all
parts of the sky, observed over a ∼7 yr baseline. Due to the
scanning law adopted by WISE (Wright et al. 2010), most stars
not on the ecliptic poles are visited approximately every ∼180
days. All stars have a ∼3 yr data gap from when WISE was
placed in hibernation in 2011 February and when it was
reactivated in 2013 December. WISE initially observed
simultaneously in four filters during its primary mission: W1
(3.4 μm), W2 (4.6 μm), W3 (12 μm), and W4 (22 μm).
However, it was reduced to using only the two bluest bands
in its post-cryogenic survey mode called “NEOWISE.” The
time, duration, and number of individual observations during
each ∼180-day visit depend on spatial geometry of the WISE
scanning program, i.e., stars closer to the ecliptic poles have
longer-duration visits (often exceeding a week) with many
epochs per visit, while stars near the equator have very short
visits (typically a couple of days) with only a few epochs per
visit. Because WISE light curves possess such nonuniform
cadence, extracting detailed physics for most individual stars is
difficult. However, the WISE light curves place fantastic
constraints on MIR variability amplitudes on longer timescales,
especially for evolved massive stars whose highest-amplitude
variability occurs over ∼year timescales. Such amplitude and
timescale estimates are related to the physical parameters of the
star, potentially aiding in classification.
For every star selected in Section 2 we queried the SingleExposure
 (“L1b”) source databases for all phases of the WISE
mission, including the original four-band, partial cryogenic
three-band, and post-cryogenic two-band NEOWISE tables.
We used astroquery to pull data in the region within 3″ of
the known source location. To ensure high-quality data for all
recovered epochs, we require the photometric quality flag to be
PH_QUAL = A, the contamination flag to be CC_FLAGS = 00,
the number of deblended sources flag to be NB = 1, and the
PSF photometry fit quality (defined as the reduced χ2) in W1 to
be w1rchi2 < 5.
Only two of our stars did not have usable data from WISE:
WISE J074911.48−102000.2 (HD 63554), which has no light
curve available online, and WISE J050128.62−701120.2,
which does not have any corresponding object nearby on
SIMBAD. When calculating each of the variability metrics
below, we instead record a value of NaN (i.e., missing data).
For the remaining stars, we ignore the W3 and W4 data here
owing to the lower signal-to-noise ratio and significantly
shorter observing baselines due to the loss of cryogenic
observations after the original WISE mission. As WISE
observes simultaneously in all bands, we can construct
W1 −W2 light curves without any interpolation and simply
subtract the W2 data from the W1 data to obtain the W1 −W2
color curve. The left panels of Figure 6 show an example set of
light curves for WISE J000536.97+432405.0 (=HD 73), a
B1.5IV star that illustrates the typical observing cadence and
variability of a bright star in our sample.
3.1. Variability Metrics
3.1.1. Amplitude
For each of the three light curves of each object, we wish to
extract simple metrics that describe the amplitude and timescale
of variability. We choose χ2 about the median defined as
å
c
s
=
M

M
2
i
i
2
2
⎜
⎟
⎛
⎝
⎞
⎠
˜
( )
and the reduced-χ2
c
c
=
N

1 ,
3
red
2
2 (
)
( )
where Mi is a magnitude measurement, M
˜ is the median of the
light curve, σi is the corresponding error on the data point, and
N is the number of points in the light curve. We also calculate
the median absolute deviation (MAD) and error-weighted
Figure 6. Example light curve for WISE J000536.97+432405.0. Top left: raw light curve, with W1 points plotted as blue error bars and W2 points plotted in orange.
Bottom left: variability in W1 −W2 plotted as green error bars. Top right: binned W1 light curve. Blue points are binned data (error bars are smaller than the points).
Black dotted line is the B-spline interpolation. Time has been adjusted so the light curve is centered on t = 0. Bottom right: first derivative of the interpolant. Vertical
blue lines show the times where the derivative crosses zero, indicated by the horizontal blue line.
7
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
MAD (EWM):
s
=
=

M

M
M
M
MAD
Median
EWM
Median
.
4
i
i
i
(∣
˜ ∣)
(∣
˜ ∣
)
( )
If the filtered and cleaned light curve only contains one good
measurement (or no good measurements), we automatically
give it c
c
=
=
=
=
MAD
EWM
2
red
2
NaN. We describe our
method for treating missing data below.
The top panels of Figure 7 show the distributions of cred
2
and
EWM derived for our sample. Values from W1 light curves are
in blue, W2 in orange, and W1 −W2 in green. The bottom left
panel shows a scatter plot of cred
2
versus EWM for all three
light curves. While the two measures correlate reasonably well
with each other, there is a branch of stars whose light curves
have high cred
2
and low EWM; because the EWM is robust to
outliers, cred
2
is an effective probe of light curves with sudden
brightening/fading events, while EWM is an effective selector
for light curves that display consistent variability. The bottom
right panel shows a scatter plot of cred
2
in W1 versus in W2,
with each point colored by its coarse label. A distinct branch of
stars that are much more variable in W2 than W1 is clearly
evident; oddly, the distributions of classes, EWM, and
broadband colors in this branch are consistent with the whole
sample, and no similar branch exists in the measured EWM
values.
Visual inspection of the light curves of stars with c
< 10
red
2
in W1 and c
> 100
red
2
in W2 shows that these stars appear to
have higher signal-to-noise ratio W2 measurements than W1
and have one observation during which the star apparently
becomes considerably redder, achieving W1 −W2 values as
high as ∼4. Examining the times at which these extreme
reddening events occur shows a preference for times during the
cryogenic WISE survey, implying that this behavior is likely
instrumental in origin, despite our filtering using the provided
quality flags. Nonetheless, we include cred
2 , as it does not map
perfectly onto EWM, and only 98 stars fall in this regime. We
do not yet know whether cred
2 , EWM, both metrics, or neither
are useful features for classification, so we keep both with the
intent of exploring their importance below.
3.1.2. Timescale
Many methods exist for estimating dominant timescales in
light curves. Conroy et al. (2018) use the Lomb–Scargle
periodogram (Lomb 1976; Scargle 1982) to search for periodic
variables. However, this approach suffers from numerous, wellknown
 issues (including accurate period recovery at low signalto-noise
 ratio), and false peaks can easily be mistaken for real
timescales, especially in highly irregularly sampled data, as is
the case for the WISE light curves. Soraisam et al. (2020) use a
Gaussian process (GP) interpolation scheme coupled with a
wavelet analysis to estimate timescales in massive stars in M31
observed by the Palomar Transient Factory (PTF). However,
with so few data points, we found it difficult to obtain a reliable
fit with a GP, and even when the fit was successful, the
resulting interpolant had a large standard deviation in between
WISE visits. The resulting measurements of the characteristic
timescale were more reflective of the kernel used.
Instead, we turn to a a spline-based interpolation method,
which is analogous to certain GP methods (Kimeldorf &
Wahba 1970). We first subtract half of the sum of the times of
the first and last available observations, so that the light curve is
centered at t = 0. We then bin the observations in each visit.
Visits are defined as sets of points separated in time by less
than a defined threshold. Due to the WISE scanning law, some
stars near the ecliptic poles have visits separated by less than
the typical ∼180 days. Therefore, we adopt 50 days as the
threshold for visits. Two stars in our sample are close enough to
the ecliptic pole to be observed nearly continuously such that
we erroneously record two “visits”: one each during the
cryogenic and post-cryogenic surveys. However, neither star is
strongly variable, and thus this small edge case does not
substantially impact our subsequent analyses.
For all observations in a given visit, we calculate the mean
time and W1/W2/W1 −W2 measurement. We use scipy.
interpolate.splrep in Python to find the third-order
basis spline (aka B-spline, which performs a spline fit using
spline basis functions; de Boor 1978) representation of the
binned light curves, adopting a smoothing factor s = 10. This
returns the knots, B-spline coefficients, and degree of the
spline. By definition, third-order splines are differentiable, so
we use scipy.interpolate.splev to evaluate the first
derivative of the spline interpolant and find the times when the
derivative changes sign—i.e., when the light curve reaches a
maximum or minimum. As metrics of the characteristic
timescale of the light curve, we calculate the frequency of
zero-crossings of the first derivative of the spline interpolant, ν0
(calculated as the number of times the derivative passes
through zero, divided by the time baseline of the light curve);
〈Δt〉, the mean of the differences between successive zerocrossings;
 and the standard deviation of the differences
between successive zero-crossings, σΔt. For stars with fewer
than four visits, we automatically assign ν0 = 〈Δt〉= σΔt =
NaN. The right panels of Figure 6 show this process on the W1
light curve plotted in the left panels. The blue points are the
binned W1 measurements (the errors are smaller than the size
of the points), and the dotted black lines are the spline
interpolant (top right) and corresponding derivative (bottom
right).
Figure 7. Top row: distribution of derived cred
2
(left) and EWM (right) values
in the W1 (blue), W2 (orange), and W1 −W2 (green) light curves. Bottom row:
scatter plots comparing different amplitude metrics. The left panel shows EWM
versus cred
2
in the W1, W2, and W1 −W2 light curves (using the same colorcoding).
 The right panel shows cred
2
in W2 vs. cred
2
in W1, with each point
colored by its coarse label.
8
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
While this is a simple method that yields multiple estimates
of variability timescale, it is important to note that it is
dependent on both the variability amplitude and the sampling.
For example, a nonvariable object whose light curve is poorly
sampled may appear to be variable owing to measurement
noise (which does not have a characteristic timescale), and the
derived timescale from this method will thus be more reflective
of the sampling than anything else. Thankfully, in many cases
such a variable would have a low EWM value. However, it is
possible that a star may enter a period of low-amplitude
variability,
resulting in false zero-crossings of the first
derivative of the spline interpolant (e.g., the first three WISE
visits in light curve in Figure 6; it is possible that the first few
zero-crossings in the bottom right panel may not be real). These
systematics are difficult to work around in sparsely sampled
light curves and are an important caveat to keep in mind.
4. Machine Learning
4.1. Classifier Selection
The problem of classification based on broadband photometry
 has a rich history in the literature. With the advent of
large surveys like the Sloan Digital Sky Survey (SDSS; York
et al. 2000), optical data could be coupled with space-based
MIR data to find the stellar locus in a 10-dimensional color
space (Davenport et al. 2014). Recent efforts to separate stars
from quasars, or perform a regression on effective temperature
with machine learning on photometric data, have been
successful (Makhija et al. 2019; Bai et al. 2019); however,
these studies are often focused on main-sequence, low-mass
stars. This is an understandable choice given the rarity of
evolved, high-mass stars, the absence of reliable distances to
calculate luminosities from which to select putative massive
stars, and the fact that follow-up spectroscopy is necessary in
order to confirm a star’s membership in many important
classes.
With the advent of Gaia DR2, luminosities can be easily
determined, and putative massive stars can be confirmed, as we
do in Section 2. We wish to train an algorithm that takes as
input the broadband photometry and variability metrics derived
for our sample and outputs spectral type classifications. Many
machine-learning classifiers exist; of these, we wish to choose a
flexible
model
with
well-understood
mathematics,
while
avoiding techniques like neural networks that can be difficult
to interpret. Of the classifiers available in the sklearn
package, we decided to test a Random Forest (RF) classifier
(which consists of a collection of decision trees trained on
random subsets of samples and features; Breiman 2001), a
Support Vector Machine (SVM) classifier (which identifies
hyperplanes in the feature space that separate different classes;
Cortes & Vapnik 1995), and a GP classifier (which models the
function determining the probability of a star being a given
class at a location in the feature space as a multidimensional
Gaussian distribution whose properties are determined entirely
by a covariance function, aka a kernel function, coupled with a
linking function, usually the logit function, to make discrete
class predictions; Rasmussen & Williams 2006). We refer the
reader to these publications, as well as to the sklearn
documentation,7 for the mathematics and implementation
details of each classifier. In the multiclass case, a collection
of classifiers are trained on each possible pair of classes (oneversus-one
 or “ovo”), generating a total of Nclasses(Nclasses −
1)/2 classifiers, where Nclasses is the number of classes. Labels
are assigned to test samples by allowing each classifier to vote,
and the label with the most votes is chosen (Knerr et al. 1990).
Each type of classifier has a number of hyperparameters that
affect the performance of the classifier. For the RF classifier,
n_estimators specifies the number of trees in the forest,
max_depth specifies how many branches each decision tree
in the forest can have, and max_features specifies the
maximum number of features each tree is trained on. We also
set class_weight=balanced, which weighs samples
when fitting to account for the different frequencies of each
class in the data.
For the SVM classifier (SVC), C is a regularization
parameter that governs the trade-off between maximizing the
margin and misclassifications in the training set. Higher values
of C will force the SVC to correctly classify every point,
resulting in poor generalization (i.e., overfitting). The SVC
requires that the distance between two points in the feature
space is defined as the inner product of two vectors in the
feature space, 〈Xi, Xj〉. Because the boundaries between classes
in our sample are not guaranteed to be linear, one can project
the samples into a much higher dimension space via a mapping
function, Φ, where distances between two vectors in this space
are calculated as 〈Zi, Zj〉= 〈Φ(Xi), Φ(Xj)〉. In reality, the
transformed feature space can be incredibly high dimensional,
and explicitly mapping the data into this high-dimensional
space is computationally inefficient. Instead, we can adopt a
kernel function, K, that defines distances in the higherdimensional
 space, e.g., K(Xi, Xj) = 〈Zi, Zj〉. Because the
kernel only takes the measured features as input and outputs a
number, using a kernel function implicitly maps the input
feature space into a high-dimensional space without specifying
 Φ.
Common choices of the kernel function include a linear
kernel (i.e., the Euclidean distance between individual samples
in the feature space) and the “radial basis function” (RBF)
kernel:
=
g
-
X
 X
K
e
,
,
5
X
X
i
j
i
j 2
(
)
( )
∣∣
∣∣
where γ governs the influence of the kernel function; lower
values result in increasingly linear boundaries, while high
values result in the decision function being entirely dependent
on individual points, creating small islands of a given class
centered on each training point. The advantage of nonlinear
models like an SVM with an RBF kernel over linear methods is
that the decision boundaries can be much more flexible; the
trade-off is that the contribution of individual features to the
classifier cannot be easily calculated without the unknown
function Φ (see Section 4.3.1). The “optimum” kernel and
hyperparameters are chosen via a cross-validation strategy
described below. Finally, we also set class_weight=balanced
 for the SVC, which automatically sets the value C for
class i to CN
N
Ni
samples
classes
(
), where Nsamples is the size of the
sample, Nclasses is the number of classes, and Ni is the number
of objects in the sample belonging to the class. This serves to
weight rarer classes more heavily. The GP classifier’s only
hyperparameter is a choice of kernel, which defines the
covariance function of the GP.
7
https://scikit-learn.org/stable/index.html
9
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
To fit our classifiers, we first remove all stars labeled as
miscellaneous variables or unknown/candidates, as well as
known binaries, and one star with bad J photometry, the Be star
HD 53032. For features, we use the intrinsic calculated value of
MG, as well as (uncorrected for extinction) G −J, J −H,
H −Ks, Ks −W1, W1 −W2, W3 −W4, and cred
2 , EWM, ν0,
〈Δt〉, and σΔt in all three light curves—we indicate the WISE
band or color that each variability metric corresponds to with a
subscript hereafter. The input features and a brief description
where relevant are listed in Table 3. Because cred
2 , EWM, 〈Δt〉,
and σΔt have significant dynamic range, we use the base-10
logarithm of these features. Feature values and labels for each
star in our sample are given in Table 4. We note that only a
subset of the features from Table 3 are listed here owing to the
number of features. The table in its entirety will be made
available in a machine-readable format.
We now randomly split our sample into a training set with
70% of the samples and a test set with the remaining 30%,
using a stratification strategy to ensure that the proportions of
the classes in both sets are equal. The test set is withheld until
we are ready to assess the performance of the chosen classifier.
We then use sklearn.preprocessing.StandardScaler
 in Python to scale the training data such that each
feature has 0 mean and unit variance. Because the data have
missing values, we then use sklearn.impute.IterativeImputer,
 which uses a Bayesian ridge regression to
predict and replace missing values.
To test the accuracy of the imputer, we select only the rows
from the training set with no missing data. For each feature
with missing data (
c
log

W
W
red,
1
2
2
, log EWMW1−W2,
s
D
log
t W
,
1,
s
D
log
t W
,
2, and
s
D
log

t W
W
,
1
2) we randomly choose 200
objects, replace the value of the feature with NaN for only
these objects, transform the data using the scaler and imputer,
and calculate the fractional error between the true value and the
imputed value. The returned fractional errors for each feature
centered around 0 and had a low scatter with the exception of
log EWMW1−W2. However, this has little impact on the
classifier, as only two objects in the actual training set have
missing values for log EWMW1−W2. We also repeated this
procedure for coarse labels: we select 200 random objects with
a given coarse label, replace a random feature from the list of
features with missing data with NaN for each object, and again
calculate the fractional error between the true and imputed
values. We find that the imputer performs poorly on Cool and
Contaminant stars. Given that all of the features with missing
data are linked to variability, a significant fraction of red
supergiants display high amplitude variability (Conroy et al.
2018), the MIR variability of AGB stars (which make up the
bulk of the Contaminants) is higher than RSGs in a given
magnitude range (Yang et al. 2018), and our sample of Cool
and Contaminant stars contains objects in quite different
evolutionary states that nevertheless have similar colors and
magnitudes, it is unsurprising that the imputer is unable to
predict the variability properties of these stars. In Section 4.3.1,
we will discuss the impact of these features on the overall
performance of our classifier.
For each classifier, we then initialize a corresponding
sklearn classifier object (e.g., sklearn.svm.SVC). To
settle on the best values for the hyperparameters, we use
sklearn.model_selection.GridSearchCV to perform
 a cross-validation search on a grid of hyperparameters,
using a stratified K-fold strategy with k = 5 to ensure that each
fold has a representative distribution of classes. For the RF, we
search for n_estimators between 10 and 150 in steps of 10,
search for max_depth between 10 and 100 in steps of 10, and
allow max_features to be either sqrt, log2, or None
(where the maximum number of features individual trees are
trained on is the square root of, is the base-2 logarithm of, or is
equal to the number of features, respectively; see the
documentation for details). We also allow max_depth to
take on the default value (None), such that individual trees can
be grown until each leaf only contains one sample.
For the SVC, we search for values of C on a logarithmic grid
with 1 dex spacing between 0.01 and 100, and for the RBF
kernel, we search for values of γ on a similar grid between 0.01
and 10. Additionally, we allow γ to be the default values of
1/n_features (where n_features is the number of
features). For the GP classifier, we only vary the kernel, as the
GaussianProcessClassifier object automatically optimizes
 the kernel hyperparameters. We let the kernel be either
linear, RBF, or the default (a special case of the RBF kernel
with the length scale equal to 1).
Each classifier object has a default method to score each set of
hyperparameters, e.g., the accuracy of predicted labels compared
to true labels. However, the classes in our training set are
unbalanced (e.g., Figure 4), so inaccurately classifying every
single LBV, for example, would have little impact on the overall
accuracy of the classifier. To account for this, we instead use the
balanced accuracy (Mosley 2013; Guyon et al. 2015), which
weighs each sample by the frequency of that sample’s class in
the training set. Other options for scoring criteria exist, including
some that help maximize the classifier’s precision such as the
weighted F1 score and Cohen’s kappa (Cohen 1960). We
experimented with using these scores and found that using the
balanced accuracy minimizes misclassifications across all classes
(reflected in the diagonal in the left panels of Figures 9 and 12).
Note that this choice implicitly selects a classifier that performs
Table 3
List of Features Passed to Our Machine-learning Classifiers, as Well as
Clarifying Definitions Where Relevant
Feature
Definition
Colors and Magnitudes
MG
Absolute magnitude in Gaia G band
G −J
From Gaia and 2MASS photometry
J −H
From 2MASS photometry
H −Ks
From 2MASS photometry
Ks −W1
From 2MASS and WISE photometry
W1 −W2
From WISE photometry
W2 −W3
From WISE photometry
W3 −W4
From WISE photometry
MW1
Absolute magnitude in WISE W1 band
Variability Metrics
c
log
red
2
Log of the reduced χ2
log EWM
Log of the error-weighted MAD
ν0
Frequency of zero-crossings of the first derivative of the
spline interpolant
áD ñ
t
log
Log of the average time between zero-crossings
s
D
log
t
Log of the standard deviation of zero-crossing times
Note. WISE photometry used to calculate colors and magnitudes is from the
ALLWISE data release (Cutri et al. 2013). All variability metrics are calculated
from the WISE W1, W2, and W1 −W2 light curves.
10
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
well across all classes and is not optimized for specific classes.
Future work will explore the possibility of tuning a classifier to
find specific classes of rare stars.
Finally, we explore three variations of a voting classifier. Such
a classifier consists of an ensemble of individual classifiers, each
of which “votes” by assigning a class to a given sample. The final
assigned class can be chosen with either a “hard” (the class with
the most votes wins) or a “soft” (class assignments are weighted
by the probabilities output by each classifier) strategy. We
construct two voting classifiers that each use a different voting
strategy, using RF, SVC, and GP classifiers as the individual
components. We refer to these as the Voting (Hard) and Voting
(Soft) classifiers. We also make a third voting classifier that also
uses a soft voting strategy, but the votes from each component
classifier are weighted by the balanced accuracy determined via
cross-validation. We refer to this as the Voting (Weighted)
classifier. We score each voting classifier by averaging the
balanced accuracy taken from five stratified folds of the data.
Figure 8 shows the balanced accuracy for the three optimized
classifiers, as well as the three voting classifiers; the SVC
performs “best,” though all classifiers return similarly low
balanced accuracies between ∼0.4 and 0.55. Both the Voting
(Soft) and Voting (Weighted) classifiers perform comparably with
the worst classifier, the GP. This is due to the fact that, while the
SVC often selects one individual class with high probability, both
the RF and GP tend to select multiple classes with high
probability (with the GP sometimes selecting all classes with
roughly equal probability, usually slightly favoring the classes
selected by the RF). This can result in both the RF and GP voting
for the wrong class with higher probability than the correct vote
from the SVC, leading to the poor observed performance.
4.2. SVC Performance
The procedure above results in values for the SVC
hyperparameters of kernel=linear and C = 0.01. With
these hyperparameters, we fit the SVC to the training set, use
the StandardScaler and IterativeImputer that were
previously fit to the training set to transform the test set, and
use the SVC to predict the labels of the test set. The left panel
of Figure 9 shows the raw number of stars in the test set, with
the true label given on the y-axis and the predicted label given
on the x-axis. The middle and right panels show this matrix,
where each row/column is normalized by the total number of
stars in that row/column, yielding the confusion/efficiency
matrices, respectively. The i, j entry in the confusion matrix
(middle panel) corresponds to the fraction of objects in the test
set belonging to class i (shown on the y-axis) that are assigned
class j (shown on the x-axis). Entries along the diagonal are the
completeness (also called the recall in some contexts), i.e., the
percentage of a given class that is accurately recovered by the
classifier. The i, j entry in the efficiency matrix (right panel) is
the fraction of objects in the test set classified as j that belong to
class i. Entries along the diagonal are equivalent to the
precision (equivalent to one minus the contamination), i.e., the
percentage of an observed class that is made up of true
members of that class. Figure 10 shows the completeness
versus the contamination for each class. Completeness is just
the diagonal of the corresponding row/column of the confusion
matrix, and contamination is one minus the diagonal of the
corresponding row in the efficiency matrix.8
Table 4
Feature Values and Assigned Labels for All Stars in our Sample, Ordered by R.A.
Common Name
MG (mag)
G −J (mag)
W1 −W2 (mag)
c
log
W
red,
1
2
áD ñ
t
log
W1 (days)
Label
Coarse Label
HD 236270
−3.54
0.35
0.14
0.389
Cool

LS I+64 10
−3.41
0.72
0.00
-
Hot

LS I+60 69
−3.22
0.88
−0.03
0.061
EM

BD+62 2353
−4.27
0.47
−0.04
0.110
2.816
Hot
HD 73
−3.29
−0.66
−0.05
3.157
2.701
Hot
HD 240496
−3.84
1.01
0.01
−0.064
2.764
Hot
WISE J000559.28−790653.3
−5.33
1.34
−0.04
0.072
3.162
Unknown/Candidate
LS I+59 30
−3.34
0.67
−0.04
0.234
Hot

BD+57 2870
−4.53
1.17
0.00
0.046
3.135
Hot
BD+62 1
−3.31
0.90
0.27
1.622
2.813
Hot
Note. Missing numbers are indicated with “-.” We note that only a subset of the features listed in Table 3 are shown here. All features are listed in the machinereadable
 version.
(This table is available in its entirety in machine-readable form.)
Figure 8. Balanced accuracy for each optimized classifier, averaged over five
foldings of the data. The SVC is the best overall, with a balanced accuracy of
0.53. Among the three voting classifiers, the Voting (Hard) classifier performs
best with a balanced accuracy of 0.49, still below the SVC.
8
We note that a variety of terms are used in the classification problem, some
of which (i.e., completeness and contamination) are familiar to astronomy,
which we briefly summarize here. The completeness (or recall) is also referred
to as the true positive rate in the binary classification case. The accuracy refers
to the sum of the diagonal in the left panel of Figure 9 divided by the number of
objects in the test set. The contamination is also called the false-positive rate in
the binary classification case; the precision refers to one minus the
contamination.
11
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
The SVC performs poorly on nonsupergiant OBA stars. This
is perhaps unsurprising given that both the observed colors and
interior structures of OBA stars as they evolve from the zeroage
 main sequence (ZAMS) to the terminal-age main sequence
(TAMS) do not change drastically compared to the much more
evolved states that we also consider. The classifier classifies
OBAe stars with somewhat lower contamination compared to
main-sequence and evolved OBA stars, though with comparably
 low completeness. True OBAe stars are misclassified
either as other types of OBA star or as W-R stars, while stars
falsely labeled as OBAe are mostly true OBA stars, with the
exception of one true W-R star. A total of 75% of W-R stars are
recovered, but only 6/30 stars identified as W-R stars in the test
set are true W-R stars; given the importance of W-R stars for
both the physics of mass loss and studying evolved massive
stellar populations (Dorn-Wallenstein & Levesque 2018, 2020),
future work will focus on developing a classifier specifically for
identifying W-R stars.
All LBVs in the test set are recovered; while such high
accuracy is often seen as a sign of overfitting, we choose not to
focus on this subclass, given both the disputed evolutionary
status of LBVs (Smith & Tombleson 2015; Humphreys et al.
2016; Aadland et al. 2018) and the fact that only two LBVs
exist in the training set. Yellow supergiants are only classified
with 27% accuracy. As discussed in Section 2 and shown in
Figure 5, the yellow supergiant label is assigned to stars with
optical colors consistent with hot stars as well as RSGs. This is
reflected in the types of stars that YSGs are mistaken for, as
well as the stars that are mistaken for YSGs. Overall, the
classifier performs best on the coolest stars in the sample. RSGs
are classified with 96% accuracy and only 10% contamination.
Meanwhile, the classifier performs exceptionally well at
identifying low-mass contaminants, at the cost of misclassifying
 four RSGs, two OBAe stars, and one OBA star.
Overall, an SVC trained on these refined labels appears to
have little use. With the exception of RSGs and low-mass
giants,
the
remaining
classes
have
low
accuracy,
high
contamination, or both. We nonetheless use the SVC to predict
labels for the 2550 stars initially labeled as “Miscellaneous
Variable” or “Unknown/Candidate.” We identify 79 candidate
RSGs and 36 candidate C/S/Giant stars, of which we expect
∼71 and 30 to be genuine, respectively, given the efficiency
matrix. We list the candidate RSGs in Table 5. A small
spectroscopic observing campaign would easily confirm the
ability of this classifier to correctly identify RSGs and lowmass
 giants.
4.3. Performance on Coarse Labeling
Examining Figures 9 and 10, we see that while the classifier
is not especially accurate except for the coolest stars, the
classifier is roughly useful for sorting the test set into broad
categories: different types of OBA stars are mostly (mis)
classified as other classes of OBA stars; the same is true for
emission-line stars (OBAe, OB[e], W-R, and LBV) and cool
stars (YSG, RSG, C/S/Giant).
Figure 9. Left: matrix showing the number of stars in the test set with true label indicated on the y-axis that are assigned the label on the x-axis. Middle: confusion
matrix for the SVC, calculated by normalizing each row of the left panel by the total number of stars in that row. Values correspond to the fraction of samples in the
test set with true label indicated on the y-axis that are assigned the label on the x-axis, such that the values along the diagonal are the fraction of each class that is
correctly classified. Right: efficiency matrix for the SVC, calculated by normalizing each column of the left panel by the total number of stars in that column. Values in
each box correspond to the fraction of samples in the test set assigned the label on the x-axis that belong to the class on the y-axis, such that the values along the
diagonal correspond to the precision (one minus the contamination). Darker colors in all panels correspond to more/a higher fraction of stars.
Figure 10. Completeness vs. contamination of each class in the test set, as
classified by the SVC. A high completeness value implies that members of that
class are accurately classified, while a low contamination value implies that an
object classified as such is likely to belong to that class. The figure is roughly
divided into four quadrants; stars with classes in the bottom right quadrant can
be considered to be well classified, in the sense that they have high
completeness and low contamination.
12
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
For this reason, we also utilize the coarse labels introduced
in Section 2. We repeat the entire process described above,
beginning with the selection of the classifier. Figure 11 shows
the balanced accuracy for each of the classifiers discussed
above, trained on the coarse labels, using a fivefold crossvalidation
 to optimize the hyperparameters of each classifier.
We find that, once again, the SVC yields the highest balanced
accuracy (0.876).
We keep the same scaled and imputed training and testing
sets and perform a fivefold cross-validation as before to find the
optimal hyperparameters, which are kernel = rbf, C = 1,
and gamma = 1/n_features. With these hyperparameters,
we fit the SVC to the training set before predicting labels for
the test set. Figure 12 shows the confusion and efficiency
matrices similar to Figure 9, while Figure 13 shows the
completeness versus the contamination similar to Figure 10. All
told, the SVC performs significantly better compared to the
classifier trained on the refined labels, recovering all classes
with 75% completeness and 30% contamination.
Of the emission-line stars that are correctly identified, 83 are
OBAe stars, 3 are OB[e] stars, 8 are W-R stars, and 2 are
LBVs. This is 73%, 75%, 100%, and 100%, respectively, of
these stars that are in the test set, implying that the performance
of the SVC on emission-line stars is not dominated entirely by
OBAe stars (which compose the majority of emission-line stars
in the test set). Of the stars mislabeled as contaminants, two are
OBA stars and two are RSGs. One true C/S/Giant star and two
yellow dwarfs are misclassified.
We then use the SVC to predict the coarse labels for the
same 2550 stars as above. Figure 14 shows the distribution of
these predicted labels. The majority (2472 stars) are labeled as
“Hot.” A total of 63 stars are labeled as “Cool,” three of which
are already identified in SIMBAD as candidate AGBs or RGBs.
A total of 14 of these stars are labeled as emission-line stars, of
which 9−10 are likely to actually be emission-line stars,
assuming 30% contamination. We list all 2550 stars’ common
names, coordinates, and predicted coarse label in Table A1.
4.3.1. Feature Importance
We can also identify which features contribute most to the
overall performance of the classifier on the coarse labels. To do
this,
we
initialize
a
new
SVC
object
with
the
same
hyperparameters and perform a “greedy search” over features,
defined as follows: For each feature in the scaled and imputed
training set, we train the SVC on just this feature across five
stratified folds of the training set and record the average and
standard deviation of the balanced accuracy. We select the
feature that yields the highest average balanced accuracy. This
has the advantage of ensuring that the contribution of each
feature to the balanced accuracy is stable across subsets of the
data. We then train the SVC on all combinations of this feature
and the remaining features, selecting which combination again
yields the highest average balanced accuracy. This process is
repeated until all features are used.
Figure 15 illustrates this process. The x-axis shows the
feature that is selected at each stage of the greedy search. The yaxis
 shows the mean balanced accuracy of the SVC at that
stage. Error bars show the standard deviation of the balanced
accuracy across the five folds of the training set. The balanced
accuracy reaches a maximum after the first seven features:
J −H, W1 −W2, MW1, Ks −W1,
EWM
log
W2,
c
log
W
red,
2
2
, and
EWM

log
W
W
1
2. However, the contribution to the balanced
accuracy from all but the first four features is small. This
suggests that variability amplitude is a useful, though not
critical, metric to obtain, while variability timescales are not
necessary. Finally, this suggests that photometry bluer than J
band is also unnecessary.
We can also examine the importance of each feature for
classifying individual classes. We perform the same greedy
search over the features, instead calculating a performance
metric that focuses on the performance on a specific class. One
option is the Fβ measure:
b
b
=
+
+
b
F
1
completeness
precision
completeness
precision ,
6
2
2
(
)
·
·
( )
where β is a free parameter that sets the relative importance
of completeness compared to precision. Common choices
are β = 1 (i.e., F1, a harmonic mean of completeness and
precision), β = 0.5, and β = 2 (Chinchor 1992). We adopt F2
(i.e., β = 2), because we prioritize generating complete samples
of rare massive stars.
The left panels of Figure 16 show the F2 measure as a
function of successively added features, calculated specifically
for hot stars (top), emission-line stars (second panel), cool stars
(third panel), and contaminants (bottom). The results for both
hot and cool stars are mostly similar to the results for the
overall classifier in Figure 15, in the sense that the best
Table 5
Common Names and Coordinates of Stars Predicted to Be RSGs by the SVC
Trained on Refined Labels
Common Name
R.A. (deg)
Decl. (deg)
SP77 48-11
81.07900941
−70.43417562
WISE J185608.58−163255.1
284.03575762
−16.54867009
W61 19-14
83.07777354
−67.52941938
OGLE BRIGHT-LMC-MISC-169
72.94711333
−69.32348227
WISE J194127.64+385155.3
295.36520609
38.86536427
NGC 2004 BBBC 431
82.69161818
−67.29036242
[KWV2015] J045626.51−692350.6
74.11062177
−69.39740804
W61 6-54
85.54018822
−69.21978048
WISE J064232.30−715243.3
100.63462144
−71.87871874
W61 6-34
85.51621031
−69.21870016
(This table is available in its entirety in machine-readable form.)
Figure 11. Similar to Figure 8, but for classifiers trained on the coarse labels.
13
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
performance is reached after including a mix of near-IR and
MIR colors and magnitudes. The main difference is that MG is
the fourth most important feature for classifying hot stars.
For emission-line stars, a maximum in the mean F2 is
reached after 11 features: W1 −W2, MW1, GJ,
áD ñ
t
log
W1,
áD ñ
t
log
W2,
s
D
log
t W
,
2, W3 −W4, W2 −W3, Ks −W1, ν0,W2,
and J −H. However, given the error bars, only the first three
features contribute meaningfully, with the remaining features
consistent with a constant value of F2. Interestingly, compared
to its contribution to the overall balanced accuracy of the
classifier, bluer photometry (signified by the presence of G −J
in the above list) is much more important for identifying
emission-line stars. While variability metrics are included in the
above list, they do not significantly contribute to the F2 score.
For contaminants, a total of 15 features are required in order
to maximize F2: J −H,
s
D
log

t W
W
,
1
2,
s
D
log
t W
,
2,
áD ñ
t
log
W1,
áD ñ
t

log
W
W
1
2, ν0,W2,
s
D
log
t W
,
1, ν0,W1−W2, MW1, H −Ks,
Ks −W1, log EWMW2,
c
log

W
W
red,
1
1
2
, log EWMW1−W2, and
c
log
W
red,
1
2
. Notably, the F2 measure first decreases as features
are added, before increasing to the maximum after MW1. This
trend is unintuitive compared to the other panels in the figure. It
may be a result of the fact that increased features improve the
precision of the classifier at the cost of completeness, resulting
in a decrease in F2 due to the increased weighting of
completeness.
To demonstrate the capabilities of the classifier using a
limited set of features, we plot the scaled and imputed test set—
which was not used in the greedy search algorithm—in the
right panels of Figure 16, using only the two most important
features in each row. Stars belonging to the corresponding
coarse class are plotted as larger, colored points, with gray
points in the background corresponding to stars in the test set
with different coarse labels. In all cases, most members of the
test set with that label are well separated from the other stars.
As expected from the left panels, most of the separation is
along the x-axis, which corresponds to the most important
feature, with the second most important feature plotted on the
y-axis providing some additional differentiation, especially for
hot stars. In the case of contaminants, the second most
important feature provides little to no additional information,
consistent with the lack of change in F2 with increased features.
We conclude that while small numbers of features can be
used to classify hot, cool, and (remarkably) emission-line stars
with high accuracy and precision (F2 0.9 for hot and cool
stars, and F2 0.8 for emission-line stars), a large number of
features are necessary in order to maximize the number of
accurately identified contaminants. This includes time domain
features, where the drastically different structures of old AGB
Figure 12. Similar to Figure 9, but for the SVC trained using the coarse labels. Note that significantly more stars fall along the diagonal of each plot, reflecting the
improved performance of the SVC on the coarse labels.
Figure 13. Similar to Figure 10, but for the SVC trained using the coarse
labels. All coarse classes have high completeness and low contamination.
Figure 14. Distribution of coarse labels assigned to 2550 stars with no
previously known class.
14
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
Figure 15. Mean balanced accuracy of the SVC for coarse labels trained on successively added features, calculated from five stratified folds of the data. The balanced
accuracy reaches a maximum after the first seven features. Error bars indicate the standard deviation of the balanced accuracy across folds.
Figure 16. Left panels are similar to Figure 15, except using the F2 measure calculated for hot stars (top), emission-line stars (second panel), cool stars (third panel),
and contaminants (bottom). The right panel in each row shows a scatter plot of only the first and second most important features (indicated with blue and red text,
respectively) drawn from the test set, with stars belonging to the corresponding class in each row highlighted. Note that the features plotted are the scaled and imputed
values, not the original values listed in Table 4.
15
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
and RGB stars compared to massive cool supergiants may be
imprinted. Already extragalactic massive star samples are
contaminated by foreground giants in the MW halo; distant
stars that can be resolved by Webb and Roman will have
comparable brightnesses to cool dwarfs that are too faint to be
filtered out using astrometry from Gaia. Developing the
infrastructure to reliably remove these contaminating objects
from massive star samples will be that much more critical.
5. Discussion and Conclusion
In the coming decades, space-based infrared observatories
like Webb and Roman will give us access to unprecedentedly
large samples of evolved massive stars. Therefore, we need to
be prepared to leverage these data to search for stars in the most
interesting evolutionary states. Obtaining spectroscopy of
individual stars does not scale well at the size of the expected
samples, while linear cuts in color–magnitude space are too
simplistic and ignore emission-line objects. Here we have
demonstrated the promising performance of an SVM trained
on ∼0.5–22 μm photometry and simple variability metrics.
However, with currently available labels, we are not able to
construct a classifier that performs well at the level of
granularity needed for many science cases.
Our main results are summarized as follows:
1. We have assembled a large sample of evolved massive
stars using distances from Gaia DR2 and Bailer-Jones
et al. (2018), with high-precision infrared photometry
from Gaia, 2MASS, and WISE.
2. Using SIMBAD, we assign labels to all stars and find that
the sample contains a number of low-mass contaminants.
3. We find that, of the classification methods we applied, an
SVC algorithm is best at accurately labeling evolved
massive stars. The SVC is fast and has the added benefit
that the underlying mathematics are well understood.
4. The SVC trained on refined labels is capable of
identifying low-mass red giant contaminants with high
accuracy. However, the overall performance of this
classifier is quite poor, and we do not recommend its
use at present.
5. The SVC trained using coarse spectral types performs
better, as measured with the balanced accuracy score. We
find
higher
completeness
and
lower
contamination
(Figures 12 and 13) compared to the SVC trained on
the refined labels (Figures 9 and 13). With this classifier,
we identify 14 candidate emission-line stars from a
sample of ∼2500 unlabeled stars. We plan to obtain
spectroscopy of these stars to confirm our results.
6. We find that the SVC performs equally as well with only
a small subset of features. These features are mostly
infrared colors and absolute magnitudes—i.e., those least
affected by reddening—with small contributions from
infrared variability metrics. However, if we change our
performance metric to one that focuses on emission-line
stars, optimal performance of the classifier requires some
red–optical photometry. We find that the added benefit of
using variability metrics may not be worth the investment
in telescope time in order to measure them. Of course,
this is only the case for the sparsely sampled light curves
in our sample; with the advent of the Legacy Survey of
Space and Time (LSST) conducted at the Vera Rubin
Observatory,
multicolor
variability
metrics
can
be
estimated from well-sampled optical light curves for a
significantly larger sample of evolved massive stars, and
this claim can be reevaluated.
Ultimately, the performance of the SVC trained on the
refined labels is poor. All stars in the sample are bright
(W1 < 14), and the input features we use are easily measured,
implying that the classifier is not limited by the quality of the
data. However, the labeling itself is not of sufficient accuracy,
as can be seen in Figure 5. Labels are derived inhomogeneously,
 and many are from spectroscopy that is now more than
50 yr old. Unfortunately, these are the best labels available for
this sample. At present, though curated lists of different
subclasses
of
massive
stars
exist
(e.g.,
Richardson
&
Mehner 2018), no unified catalog of massive stars in our
Galaxy or the Magellanic Clouds exists.
Modern all-sky surveys have already given us access to
precision photometric and spectroscopic measurements of
unprecedented numbers of stars. Massive stars are bright, and
so the existing data are of suitable signal-to-noise ratio to
perform
spectroscopic
classification.
However,
they
are
often
excluded
from
analyses
that
provide
value-added
measurements like effective temperatures, surface gravities,
compositions, radial velocities, and more that can be used to
accurately classify massive stars. In order to prepare ourselves
for the era of Webb and Roman, we must develop pipelines
specifically tuned for evolved massive stars. This is especially
true for the classes that are underrepresented in our data set,
i.e., rare emission-line stars.
Along with better labels, more data will become available
via future data releases of the Gaia mission. The recent early
third Gaia release contains modest improvements in precision
and sample size that are unlikely to affect our results given the
high quality of the photometry in our sample. However, the full
Gaia DR3 will contain low-resolution spectra, as well as epoch
photometry for a limited number of sources, which have the
potential to significantly improve the performance of a
machine-learning
classifier.
On
the
horizon,
the
LSST
conducted at the Vera Rubin Observatory will measure the
multicolor variability of massive stars at higher cadence, while
its large telescope aperture will help define a much larger
sample. As we demonstrate with Figure 16, it is possible to
select features that maximize the performance of the SVC for
specific classes. With a larger sample, we may be able to
optimize the SVC to search for specific classes of evolved
massive stars.
The authors acknowledge that the work presented was
largely conducted on the traditional land of the first people of
Seattle, the Duwamish People past and present, and honor with
gratitude the land itself and the Duwamish Tribe.
This research was supported by NSF grant AST 1714285
awarded to E.M.L.
J.R.A.D. and D.H. acknowledge support from the DiRAC
Institute in the Department of Astronomy at the University of
Washington. The DiRAC Institute is supported through
generous gifts from the Charles and Lisa Simonyi Fund for
Arts and Sciences and the Washington Research Foundation.
D.H. is supported by the Women In Science Excel (WISE)
program
of
the
Netherlands
Organisation
for
Scientific
Research (NWO).
16
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
This project was developed in part at the 2018 Gaia Sprint,
hosted by the eScience and DiRAC Institutes at the University
of Washington, Seattle.
This research has made use of the VizieR catalog access tool,
CDS, Strasbourg, France (DOI: 10.26093/cds/vizier). The
original description of the VizieR service was published in
A&AS 143, 23. This research has made use of the SIMBAD
database, operated at CDS, Strasbourg, France. This publication
 makes use of data products from the Two Micron All Sky
Survey, which is a joint project of the University of
Massachusetts and the Infrared Processing and Analysis
Center/California Institute of Technology, funded by the
National Aeronautics and Space Administration and the
National Science Foundation.
This work made use of the following software:
Software: Astropy v3.2.2 (Astropy Collaboration et al. 2013;
The Astropy Collaboration et al. 2018), Astroquery v0.3.10
(Ginsburg et al. 2019), Matplotlib v3.1.1 (Hunter 2007),
makecite (Price-Whelan & Mechev 2018), NumPy v1.17.2
(Van Der Walt et al. 2011), Pandas v0.25.1 (McKinney 2010),
Python 3.7.4, Scikit-learn v0.21.3 (Pedregosa et al. 2011),
Scipy v1.3.1 (Virtanen et al. 2020).
Appendix
Coarse Labels for 2550 Stars
Table A1 lists all 2550 stars with no known label, as well as
predicted labels generated by the SVC trained on coarse labels.
Table A1
Common Names, Coordinates, and Predicted Labels of 2550 Stars Input to the SVC Trained on Coarse Labels
Common Name
R.A. (deg)
Decl. (deg)
Predicted Coarse Label
WISE J000559.28−790653.3
1.49713706
−79.11483482
Hot
TYC 4500-1480-1
2.86210879
79.08686958
Hot
BD+61 45
5.25504760
62.77064970
Hot
NGC 104 LEE 2520
5.41170226
−72.21106679
Hot
WISE J002203.44−693554.7
5.51434821
−69.59851087
Hot
WISE J002207.43−742212.1
5.53102165
−74.37003199
Hot
WISE J002318.05−742326.4
5.82523611
−74.39068759
Hot
WISE J002340.20−750446.9
5.91756693
−75.07972556
Hot
WISE J002758.92−764527.2
6.99552600
−76.75757402
Hot
WISE J002759.32−742119.8
6.99734043
−74.35552728
Hot
(This table is available in its entirety in machine-readable form.)
17
The Astrophysical Journal, 913:32 (18pp), 2021 May 20
Dorn-Wallenstein et al.
ORCID iDs
Trevor Z. Dorn-Wallenstein
https:/
/orcid.org/0000-00033601-3180

James R. A. Davenport
https:/
/orcid.org/0000-00020637-835X

Daniela Huppenkothen
https:/
/orcid.org/0000-00021169-7486

Emily M. Levesque
https:/
/orcid.org/0000-0003-2184-1581
Introduction
The emergence of the Internet of Things (IoT) has promoted the rise of edge computing.
In IoT applications, data processing, analysis, and storage are increasingly occurring at the
edge of the network, close to where users and devices need to access information, which
makes edge computing an important development direction.
There were already applications of deep learning in IoT, for example, deep learning
predicted household electricity consumption based on data collected by smart meters [1];
and a load balancing scheme based on the deep learning of the IoT was introduced [2].
Through the analysis of a large amount of user data, the network load and processing
configuration are measured, and the deep belief network method is adopted to achieve
efficient load balancing in the IoT. In [3], an IoT data analysis method based on deep
learning algorithms and Apache Spark was proposed. The inference phase was executed
on mobile devices, while Apache Spark was deployed in the cloud server to support
data training. This two-tier design was very similar to edge computing, which showed
that processing tasks can be offloaded from the cloud. In [4], it is proven that due to
the limited network performance of data transmission, the centralized cloud computing
structure can no longer process and analyze the large amount of data collected from IoT
devices. In [5], the authors indicated that edge computing can offload computing tasks
from the centralized cloud to the edge near the IoT devices, and the data transmitted during
Electronics 2021, 10, 1892. https://doi.org/10.3390/electronics10161892
https://www.mdpi.com/journal/electronics
Electronics 2021, 10, 1892
2 of 16
the preprocessing process will be greatly reduced. This operation made edge computing
another key technology for IoT services.
The data generated by IoT sensor terminal devices need to use deep learning for realtime
 analysis or for training deep learning models. However, deep learning [6] inference
and training require a lot of computing resources to run quickly. Edge computing is a
viable method, as it stores a large number of computing nodes at the terminal location to
meet the requirements of high computation and low latency of edge devices. It shows good
performance in privacy, bandwidth efficiency, and scalability. Edge computing has been
applied to deep learning with different aims: fabric defect detection [7], falling detection in
smart cities, street garbage detection and classification [8], multi-task partial computation
offloading and network flow scheduling [9], road accidents detection [10], and real-time
video optimization [11].
Red, green, and blue (RGB) cameras mainly use red, green, and blue light to classify
objects. From the point of view of the spectrum, there are three bands that are only in
the visible band. The number of spectral bands we use has 1024, including some nearinfrared
 light bands, which is more helpful for accurate classifications. For instance, the
red-edge effect of the infrared band inside can distinguish real leaves from plastic leaves in
vegetation detection. Therefore, we believe that increasing the number of spectral channels
is more conducive to the application expansion of the system in the future.
The optical fiber spectrometer has been reported for applications in photo-luminescence
properties detection [12], the smartphone spectral self-calibration [13], and phosphor thermometry
 [14]. At present, some imaging spectrometers can obtain spatial images, depth
information, and spectral data of objects simultaneously [15]. However, most of the data
processed by deep learning algorithms are image data information obtained by these
imaging spectrometers. Deep learning algorithms are rarely used to process the reflection
spectrum data obtained by the optical fiber spectrometer.
In hyperspectral remote sensing, deep learning algorithms have been widely applied
to hyperspectral imaging classification processing tasks. For example, in [16], a spatialspectral
 feature extraction framework for robust hyperspectral images classification was
proposed to combine a 3D convolutional neural network. Testing overall classification
accuracies was 4.23% higher than SVM on Pavia data sets and Pines data sets. In [17], a
new recurrent neural network architecture was designed and the testing accuracy was
11.52% higher than that of a long short-term memory network, which is on the HSI data
sets Pavia and Salinas. A new recursive neural network structure was designed in [18],
and an approach based on a deep belief network was introduced for hyperspectral images
classification. Compared with SVM, overall classification accuracies of Salinas, Pines, and
Pavia data sets increased by 3.17%. Currently, hyperspectral imagers are mainly used to
detect objects [19]. Although the optical fiber spectrometer is easy to carry and collect the
spectra of objects, it cannot realize the imaging detection research of objects. However, deep
learning algorithms are data-driven and can realize end-to-end feature processing. If we
process spectral data by combining deep learning algorithms with fiber optic spectrometers,
it can further perform the detection and research of objects.
However, most spectrometers need to be connected to the host computer via USB,
which cannot be carried easily. In this work, we designed and manufactured a portable
optical fiber spectrometer. After testing the stability of the system, we collected the reflectance
 spectra of five fruit samples and proposed a depth called the convolutional neural
network learning method, which performs spectral classification. The accuracy of this
method is 94.78%. We boldly combined the deep learning algorithm and the system to
complete the accurate classification of spectral data. Using this portable spectrometer, we
use edge computing technology to increase the speed of deep learning while processing
spectral data.
We have designed a portable spectrometer with a screen; the system can get rid of the
heavy host computer and realize real-time detection of fruit quality.
Electronics 2021, 10, 1892
3 of 16
Our portable spectrometer is shown in Figure 1a. The spectrometer has a 5-inch
touch screen, and users can view the visualized sample spectrum information on the
spectrometer in real-time. As shown in Figure 1b, the system is equipped with an Ocean
Optics-USB2000+ spectrometer (Ocean Optics, Delray Beach, FL, USA), to ensure that the
system has a spectral resolution of not less than 5nm. As shown in Figure 1d, the system
configuration of our spectrometer is a GOLE1 microcomputer, Ocean Optics USB2000+
spectrometer, and a high-precision packaging fixture. The optical fiber can be connected
with the spectrometer through a fine-pitch mechanical thread. The overall structure is
treated with electroplating black paint, to effectively avoid external light interference
and greatly improve the signal-to-noise ratio of spectral information. When using our
spectrometer to detect samples, we connect one end of the optical fiber to the spectrometer
through a mechanical thread and hold the other end close to the test sample. The reflected
light from the sample surface enters the spectrometer through the optical fiber, and the
spectrometer converts the collected optical information into electrical signals and transmits
it to the microcomputer through the USB cable. The microcomputer visualizes the signal on
the screen. Users can view, store, and transmit spectral information through the system’s
touch screen, innovating the functions of traditional spectrometers that need to be operated
by the keyboard and mouse of the host computer.
Figure 1. (a) The GOLE1 mini-computer used in the experiment. (b) The Ocean Optics USB2000+
spectrometer that was used in the experiment. (c) Front view of the assembly of the mini-computer
and the spectrometer; (d) Integration of the spectrometer and the mini-computer through a selfdesigned
 housing.
To ensure the accuracy of the system data acquisition and to demonstrate the system’s
ability to detect various data, the team tested the stability of the entire hyperspectral
imaging system. First, we adjust the imaging to the same state as the data acquisition, then
we collect 10 sets of solar light spectral data by the spectrograph at 10 s intervals; then, we
adjust the display of the system to red, green, and blue colors in turn, and repeat the above
steps to obtain the corresponding data. Finally, we input 40 groups of data collected by the
above methods into Matlab and then use two different processing methods to demonstrate
the stability of the whole hyperspectral imaging system.
The first method is to extract one data point of the same wavelength from all 10 groups
of data of the same kind, and arrange the data points in order and draw them into the
pictures as shown below.
As shown in Figure 2, we can see clearly that the intensity fluctuation of the same
10 groups of data at the same wavelength is very small. This shows that the error of data
acquisition of the same object is very small in a short time, which proves that the system
has high accuracy.
Electronics 2021, 10, 1892
4 of 16
Figure 2. (a) Point data of the same wavelength of 10 sets of sunlight spectrum data collected every 10 s. (b) Point data of the
same wavelength of 10 sets of screen green light spectrum data collected every 10 s. (c) Point data of the same wavelength
of 10 sets of screen blue light spectrum data collected every 10 s. (d) Point data of the same wavelength of 10 sets of screen
red light spectrum data collected every 10 s.
In the second method, we plot the whole spectrum of the same 10 groups of data on
one graph and distinguish them by different colors. As shown in Figure 3, we can clearly
see two points: one is that the spectral images of 10 groups of similar data almost coincide;
the other is that the spectra of sunlight, blue light, green light, and red light shown in
the figure are very classic and do not violate the laws of nature. The above phenomenon
shows that the measurement accuracy of the hyperspectral imaging system is high, and the
detection ability of each band light is excellent, and the whole system has good stability.
We discussed the edge computing technology under IoT combined with deep learning
algorithms to realize street garbage classification, fabric defect detection, et al. We wanted
to use edge computing technology combined with deep learning algorithms, to classify
more spectral data. The current mainstream spectral data processing algorithm is still for
one-dimensional spectral data analysis. The machine learning image processing methods
widely used in these processing methods are incompatible. As mentioned previously, the
current deep learning algorithms are very in-depth in image processing research, these
algorithms have relatively high processing efficiency and classification accuracy. If we can
preprocess the spectral data, then we use deep learning algorithms for classification, which
will greatly improve the efficiency and accuracy of spectral classification.
Electronics 2021, 10, 1892
5 of 16
Figure 3. (a) 10 sets of sunlight spectrum data collected every 10 s. (b) 10 sets of screen green light spectrum data collected
every 10 s; (c) 10 sets of screen blue light spectrum data collected every 10 s; (d) 10 sets of screen red light spectrum data
collected every 10 s.
In our work, we randomly selected five kinds of fruit for testing and achieved accurate
classification results through the algorithms. Generally, as long as we obtain enough
spectral data and design effective algorithms, we can achieve accurate classification. A
large number of literature results have verified the effectiveness of classification based
on spectral data. For instance, in [20], the classification based on spectral data was also
realized for different algae.
In this paper, we designed a portable optical fiber spectrometer with a screen and
verified the stability, accuracy, and detection ability of the system through two different
experimental processing methods shown in Figures 2 and 3. We used the spectrometer
to collect one-dimensional reflectance spectrum data from five fruit samples, then we
reshaped the spectral data structure and transformed it into 2D spectral data. We used
our proposed CNN algorithm to extract and classify the 2D spectral image data of five
samples. Its maximum classification accuracy rate was 94.78%, and the average accuracy
rate was 92.94%, which is better than the traditional AlexNet, Unet, and SVM. Our method
makes the spectral data analysis compatible with the deep learning algorithm and implements
 the deep learning algorithm to process the reflection spectral data from the optical
fiber spectrometer.
The remaining paper is organized as follows: Section 2 introduces the optical detection
experiment in brief. Section 3 provides the details of the proposed spectral classification
method. Section 4 reports our experiments and discusses our results. Finally, Section 5
concludes the work and presents some insights for further research.
Electronics 2021, 10, 1892
6 of 16
2. Optical Detection Experiment
We collected one-dimensional data of grapes, jujubes, kumquats, pears, and tomatoes
through a portable optical fiber spectrometer. The pictures of the five samples are presented
in Figure 4.
Figure 4. Experimental samples.
Some reasons will affect remote sensing spectral detection in the real world. For
instance, the incident angle and reflection angle of light is not stable in the real optical
platform detection environment. Therefore, to adapt to the change of angle, we adjusted
the alignment direction of the optical fiber port of the equipment to better achieve the good
effect of the optical detection experiment.
Most two-dimensional images are processed and classified by convolution neural
network models. However, the spectral data we obtained through the spectrometer is
in a one-dimensional format, which is incompatible with the method of deep learning
algorithms to process the 2D spectral data. To transform one-dimensional data into twodimensional
 data, to realize the classification of deep learning algorithms, we finished the
transformation of the one-dimensional data through the “Reshape” function in Matlab.
After processing, we obtained five kinds of two-dimensional spectral data (32 × 32 pixels).
These images are presented in Figure 5. In Section 3, we chose a method for deep learning
called a convolutional neural network, which classifies these 2D spectral data.
Figure 5. 2D spectral data samples.
3. Proposed Method
3.1. Model Description
Using a deep learning convolutional neural network model to identify spectral data
can be divided into two steps. First, perform feature extraction on the images, and then use
the classifier to classify the images. The specific recognition process is depicted in Figure 6.
Figure 6. Convolutional neural networks (CNN) recognition process.
Electronics 2021, 10, 1892
7 of 16
In general, there are convolutional layers, pooling layers, and fully connected layers in
a convolutional neural network architecture. Compared with other deep learning models,
CNNs show better classification performance.
When CNNs perform convolution operations, the image feature size of the upper layer
is calculated and processed through convolution kernels, strides, filling, and activation functions.
 The output and the input of the previous layer establish a convolution relationship
with each other. The convolution operation of feature maps uses the following formula.
xl
j = f (
n
∑
i=1
wl
ij × xl−1
i
+ bl
j)
(1)
where f (·) is the activation function, xl−1
i
is the output value of the i-th neuron in the
(l −1)-th layer, wl
ij represents the weight value of the i-th neuron of the l-th convolutional
layer connected to the j-th neuron of the output layer, bl
j represents the bias value of the
j-th neuron of the l-th convolutional layer.
xl
j = f (ρl
jdown(xl−1
j
+ bl
j))
(2)
where f (·) is the activation function, down (·) represents the downsampling function, ρ is
the constants used when the feature map performs the sampling operation, bl
j represents
the bias value of the j-th neuron of the l-th convolutional layer.
The convolutional neural network is usually equipped with a fully connected layer
in the last few layers. The fully connected layer normalizes the features after multiple
convolutions and pooling. It outputs a probability for various classification situations. In
other words, the fully connected layer acts as a classifier.
The Dropout [21] technology is used in CNN to randomly hide some units so that they
do not participate in the CNN training process to prevent overfitting. The convolutional
layer without the Dropout layer can be calculated using the following formula.
zl+1
j
= wl+1
j
yl
j + bl+1
j
(3)
yl+1
j
= f (zl+1
j
)
(4)
The mean of w, b, and f (·) is the same as that of Equation (1).
The discard rate with the Dropout layer can be described as (5):
rl
j ∼Bernoulli(p)
(5)
In fact, the Bernoulli function conforms to the distribution trend of Bernoulli. Through
the action of the Bernoulli distribution, the Bernoulli function is randomly decomposed
into a matrix vector of 0 or 1 according to a certain probability. Where r is the probability
matrix vector obtained by the action of the Bernoulli function. In the training process of
models, it is temporarily discarded from the network according to a certain probability,
that is, the activation site of a neuron no longer acts with probability p (p is 0).
We multiply the input of neurons by Equation (5) and define the result as the input of
neurons with the discard rate. It can be described as.
e
yl
j = rl
j ∗yl
j
(6)
Therefore, the output was determined using the following formula.
e
zl+1
j
= wl+1
j
e
yl
j + bl+1
j
(7)
e
yl+1
j
= f (
k
∑
j=1
e
zl+1
j
)
(8)
Electronics 2021, 10, 1892
8 of 16
Here, k represents the number of the output neurons.
In this work, we classified 2D spectral data using AlexNet. However, the recognition
rate was not high. Mainly, the reasons were analyzed as follows:
(1)
Due to the small amount of spectral data sample set collected in this experiment,
the training data sets are difficult to meet the needs of deeper AlexNet for feature
extraction, learning, and processing. Therefore, the traditional network architecture
needed to be streamlined.
(2)
In the convolutional process, the more times of convolution, the more spectral features
 can be fully extracted. The process also uses a large number of convolution
kernels, which will bring difficulties to the calculation. The long stride affected the
classification accuracy, it was necessary to decrease the traditional parameters of the
network convolutional layer.
(3)
If a wrong pooling method was used, it would decrease the efficiency of the network
learning features and the accuracy of targets classification. The traditional network
pooling layer needed to be reduced.
Therefore, we simplified the traditional AlexNet network architecture, decreased
the parameters of the convolutional layers, reduced the number of pooling layers, and
proposed a new CNN spectral classification model. Figure 7 reveals a specific deep learning
spectral classification model framework. Additionally, we added a Dropout layer after each
convolutional layer, k represents the size of convolution kernels or pooling kernels, s is the
step size moved during convolution or pooling in the CNN operation, and p represents the
value of filling the edge after the convolutional layer operation, and generally, the filling
value is 0, 1, and 2.
Since the CNN model requires images of uniform size as input, all spectral data images
are normalized to a size of 32 × 32 as input images. We divided the spectral data into
n categories, so in the seventh layer, after the Dropout layer and the activation function
softmax were calculated, n × 1 × 1 neurons were output, that is, the probability of the
category where the n nodes were located.
Figure 7. Deep learning spectral classification model framework diagram.
Electronics 2021, 10, 1892
9 of 16
3.2. Dropout Selection Principle
Dropout can be used as a kind of trick for training convolutional neural networks. In
each training batch, it reduces overfitting by ignoring half of the feature detectors. This
method can reduce the interaction in feature hidden layer nodes. In brief, Dropout makes
the activation value of a certain neuron stop working with a certain probability p when it
propagates forward.
In a deep learning model, if the model has too many parameters and too few training
samples, the trained model is prone to overfitting. When we train neural networks, we
often encounter overfitting problems. The model has a small loss function on the training
data and a high prediction accuracy. The loss function on the test data is relatively large,
and the prediction accuracy rate is low. If the model is overfitted, then the resulting
model is almost unusable. Dropout can effectively alleviate the occurrence of over-fitting
and achieve the effect of regularization to a certain extent. The value of the discard rate
plays an important role in the deep learning model. An appropriate Dropout value can
reduce the complex co-adaptation relationship between neurons and makes the model
converge quickly.
In the training process of CNNs, when the steps of the convolution operation are
different, the number of output neurons is different, which will reduce their dependence
and correlation. If we quantify the correlation, it will increase the dependence. Therefore,
we set the discard rate to narrow the range of correlation. After we successively take values
in the narrow range, we train and predict the network model again. It will make any two
neurons in different states have a higher correlation and improves the recognition accuracy
of the model.
When we trained our proposed CNN model, we visualized the movable trend in
dropout layers. Figure 8 presents the movable trend. Figure 8 demonstrates that it is very
unstable between 0.5 and 1, which is prone to over-fitting. In (0, 0.1) and (0.2, 0.5), when
increasing the epoch, the discard rate drops rapidly, and it is prone to under-fitting. In
(0.1, 0.2), the discard rate gradually tends to a stable and convergent state, it is indicated
that the value is more appropriate in the interval.
Figure 8. Dropout change graph.
4. Experimental Results and Discussion
In the algorithms’ experiments, our hardware platform was: CPU frequency 3.00 GHz,
the 32 GB memory, a GTX 1080ti GPU graphics card, and the Cuda 9.2 (Cudnn 7.0) accelerator.
 Our software platform was Keras 2.2.4, TensorFlow 1.14.0, Anaconda 3 5.2.0, Spyder,
and Python 3.7 under win10 and a 64-bit operating system.
4.1. Data Distribution
In the experiments of the algorithm classification, the 2D spectral data of five fruit
samples were obtained from the optical detection experiment. We divided the 2D spectral
Electronics 2021, 10, 1892
10 of 16
data into the training set, the verification set, and the testing set. The number of the training
sets is about three times that of the testing set. Results are shown in Table 1.
Table 1. The data set.
Samples
Grapes
Jujubes
Kumquats
Pears
Tomatoes
Total
train
28
28
28
28
27
139
test
9
9
9
9
9
45
validate
13
13
13
13
13
65
4.2. Train Results
We trained our proposed CNN model, and the results are presented in Figure 9. From
Figure 9 we can see that the loss of the training set and the validation set is always between
0.1 and 0.5, and there are no irregular up-and-down violent fluctuations. Both the training
accuracy and the validating accuracy are rising and eventually reach a stable value; there
is no longer a trend of large value changes. It can find out that if we increase the epoch, the
training loss and the validating loss gradually become smaller, and eventually stabilizes.
To sum up, our proposed CNN can overcome vanishing gradient in the process of training
and validating, and can fully extract features of spectral data from end to end, which is
conducive to the correct classification of spectra
Through the model’s training time, accuracy, and loss curve, we can comprehensively
judge the performance of the model. If the model consumes less training time, the accuracy
and loss curves also tend to be stable and fast, and it is illustrated that the model has
good convergence performance in a short time. If the model consumes for a long time,
the accuracy and loss curve also tends to be steady and slow, and this indicates that the
model has poor performance. Through the length of time consumed and the change in
accuracy loss, some parameters of the model such as learning rate, batch processing times,
etc, can be fine-tuned to improve the performance of the model. Therefore, we not only
consider the model’s accuracy and loss changes to the training data, but also consider the
time consumption.
Figure 9. Proposed CNN iteration training change graph.
We recorded the time of training 100 times under four algorithms, Table 2 reveals the
time of the four algorithms.
Electronics 2021, 10, 1892
11 of 16
Table 2. Training time.
Algorithms Names
Proposed CNN
AlexNet
Unet
SVM
Time (s)
30.1
56.5
70.3
89.6
As shown in Table 2, our proposed method consumes the least time. It is proved that
our proposed method can adapt to the feature extraction of spectral data, and does not
bring too much parameters calculation to occupy memory.
4.3. Test Results
The SOTA image recognition model ViT-G/14 uses the JFT-3B data set containing
3 billion images, and the amount of parameters is up to 2 billion. On the ImageNet image
data set, it achieved a Top-1 accuracy of 90.45%, it has surpassed the Meta Pseudo Labels
model. Although ViT-G/14 performs well in addition to better performance, our data
volume and categories are limited. Our data cannot adapt to the parameter training and
testing of the SOTA image recognition model ViT-G/14 with more categories and large
amounts of data. Therefore, we chose AlexNet, Unet, SVM, and our proposed CNN
for comparison.
When epochs are set as 100, the testing accuracy of four algorithms under different
parameters is presented in Table 3. Table 3 reports that different parameters correspond
to different testing accuracy. For instance, the inputting shape is a batch size of 32, the
learning rate is 0.001, the optimizer is SGD, our testing accuracy is 92.57%. It is superior to
other parameters. Furthermore, the testing accuracy obtained by the values of different parameters
 also shows that our proposed CNN achieves an improvement in the classification
accuracy of 22.86% when compared to AlexNet.
Table 3. Test accuracy under different parameters.
Methods
Input
Shape
Batch
Size
Learning
Rate
Optimizer
Test
Loss
Test
Accuracy
Proposed CNN
32 × 32
32
0.0001
SGD
0.0815
0.9275
64 × 64
64
0.0005
RMS
0.1014
0.8627
128 × 128
128
0.0050
Adam
0.2571
0.8835
AlexNet
32 × 32
32
0.0001
SGD
1.3359
0.8264
64 × 64
64
0.0005
RMS
0.9954
0.7549
128 × 128
128
0.0050
Adam
1.3587
0.7918
Unet
32 × 32
32
0.0001
SGD
1.7529
0.8031
64 × 64
64
0.0005
RMS
1.0349
0.7429
128 × 128
128
0.0050
Adam
1.4681
0.7069
SVM
32 × 32
32
0.0001
SGD
3.5248
0.5317
64 × 64
64
0.0005
RMS
1.2481
0.6728
128 × 128
128
0.0050
Adam
1.5643
0.6109
Figure 8 illustrates that the discard rate is the most appropriate value in (0.1, 0.2).
We divided it into four sub-intervals to test the precision of our proposed CNN. Testing
results are revealed in Figure 10. The results in Figure 10 demonstrate that the accuracy in
(0.175, 0.200) is higher than in (0.100, 0.125), (0.125, 0.150), and (0.150, 0.175). Evidently, our
proposed CNN model has the best performance in (0.175, 0.200), it verifies the correctness
of the dropout discard rate analysis and selection principle simultaneously in Section 3.2.
Electronics 2021, 10, 1892
12 of 16
Figure 10. Accuracy in different intervals.
To verify the feasibility of ReLU and the discard rate in this work, we again used ReLU
with the Dropout layer (dropout = 0.2) and without the Dropout layer (dropout = 0) for
testing. Testing results are shown in Figure 11. The experimental results confirm that the
recognition rate is as high as 94.57% when ReLU is used and the discard rate is 0.2, which
is significantly higher than the recognition result without the dropout layer (dropout = 0).
In summary, our proposed CNN model outperforms AlexNet and SVM tested in terms of
classification accuracy, and it can perform accurate spectral classification.
Figure 11. The impact of the dropout value on the recognition rate.
As shown in Table 4, the testing time of our proposed CNN is lower than AlexNet,
Unet, and SVM. Evidently, our proposed model can quickly extract two-dimensional
spectral features and gives the prediction result in the testing process.
Electronics 2021, 10, 1892
13 of 16
Table 4. Testing times using four different methods.
Samples
Grapes
Jujubes
Kumquats
Pears
Tomatoes
Total Times
Proposed CNN
6.7 s
6.5 s
7.4 s
7.2 s
7.1 s
34.9 s
AlexNet
8.9 s
8.4 s
8.8 s
8.7 s
8.6 s
43.4 s
Unet
8.7 s
9.0 s
9.1 s
9.2 s
8.9 s
44.9 s
SVM
11.1 s
9.3 s
8.9 s
9.4 s
9.5 s
48.2 s
To compare the performance of four different classification methods, we tested five
samples one by one. Tables 5–8 show testing results. Tables 5–8 report that the testing
precision of our proposed CNN is superior to AlexNet, Unet, and SVM. Therefore, our
proposed CNN model has strong robustness to 2D spectral data.
Table 5. Testing five samples with our proposed CNN.
Samples
Grapes
Jujubes
Kumquats
Pears
Tomatoes
Num-1
0.9341
0.9346
0.9125
0.9354
0.9431
Num-2
0.9364
0.9038
0.9227
0.9209
0.9359
Num-3
0.9380
0.9265
0.9104
0.9469
0.9449
Num-4
0.9440
0.9268
0.9255
0.9307
0.9237
Num-5
0.9451
0.9110
0.9214
0.9258
0.9326
Num-6
0.9437
0.9190
0.9264
0.9185
0.9394
Num-7
0.9461
0.9283
0.9109
0.9257
0.9478
Num-8
0.9439
0.9192
0.9217
0.9426
0.9232
Num-9
0.9729
0.9173
0.9164
0.9346
0.9359
Average precision
0.9399
0.9207
0.9187
0.9312
0.9363
Table 6. Testing five samples with AlexNet.
Samples
Grapes
Jujubes
Kumquats
Pears
Tomatoes
Num-1
0.8775
0.7109
0.7516
0.8228
0.7598
Num-2
0.8806
0.7099
0.7722
0.8061
0.7567
Num-3
0.8861
0.7202
0.7417
0.7679
0.7860
Num-4
0.8879
0.7084
0.7233
0.7918
0.8048
Num-5
0.8855
0.7096
0.7213
0.8254
0.7361
Num-6
0.8821
0.7153
0.7706
0.8366
0.7559
Num-7
0.8857
0.7054
0.7512
0.7953
0.7770
Num-8
0.8827
0.7159
0.7717
0.8024
0.8041
Num-9
0.8947
0.7018
0.7669
0.8127
0.7436
Average precision
0.8859
0.7108
0.7523
0.8068
0.7693
Table 7. Testing five samples with Unet.
Samples
Grapes
Jujubes
Kumquats
Pears
Tomatoes
Num-1
0.8437
0.6859
0.7149
0.7986
0.7689
Num-2
0.8371
0.6971
0.7029
0.7961
0.7586
Num-3
0.8257
0.6782
0.7116
0.7881
0.7828
Num-4
0.8159
0.7015
0.7036
0.7989
0.7659
Num-5
0.8041
0.6985
0.7219
0.8007
0.7458
Num-6
0.8358
0.7031
0.7108
0.7896
0.7675
Num-7
0.8539
0.7007
0.7019
0.7968
0.7752
Num-8
0.8489
0.6995
0.7125
0.8027
0.7871
Num-9
0.8148
0.7037
0.7034
0.8007
0.7923
Average precision
0.8311
0.6965
0.7093
0.7969
0.7716
In Section 4.2, we considered the model training time, we also consider the speed
of the model during testing images, simultaneously. If we proposed model is slower on
Electronics 2021, 10, 1892
14 of 16
testing image speed, it is revealed that the performance of the model does not take into
account. The quality of a model not only depends on its training time, training accuracy,
and verification accuracy, etc, but also its testing accuracy and testing time.
Table 8. Testing five samples using the support vector machine (SVM).
Samples
Grapes
Jujubes
Kumquats
Pears
Tomatoes
Num-1
0.5330
0.6215
0.5309
0.6143
0.5415
Num-2
0.5371
0.5956
0.5524
0.5681
0.5319
Num-3
0.5386
0.6293
0.5300
0.6211
0.5475
Num-4
0.5356
0.6220
0.5614
0.6148
0.5606
Num-5
0.5297
0.6045
0.5315
0.6301
0.5226
Num-6
0.5268
0.6124
0.5524
0.5761
0.5270
Num-7
0.5327
0.6224
0.5772
0.6161
0.5409
Num-8
0.5295
0.6095
0.5296
0.6184
0.5578
Num-9
0.5406
0.6135
0.5650
0.6631
0.5232
Average precision
0.5337
0.6145
0.5478
0.6136
0.5392
Figure 12 shows the maximum testing precision of each sample under four different
algorithms. It can figure out if the testing effect of our proposed CNN is significantly
greater than the other three methods in Figure 12. Obviously, our proposed CNN has high
classification precision and generalization ability to 2D spectral data.
Figure 12. (a) The maximum testing results of the proposed CNN are between 90% and 95%. (b,c) The maximum testing
results of AlexNet and Unet are between 70% and 90%. (d) The maximum testing results of the SVM are between
50% and 70%.
Electronics 2021, 10, 1892
15 of 16
5. Conclusions
In this work, a new CNN architecture was designed to effectively classify 2D spectral
data of five samples. Specifically, we added a Dropout layer behind each convolutional
layer of the network to randomly discard some useless neurons and effectively enhance
the feature extraction ability. In this way, the features uncovered by the network became
stronger, which eventually lead to a reduction of the network architecture parameters
calculation complexity and, therefore, to a more accurate spectral classification. The experimental
 comparisons conducted in this work shows that our proposed approach exhibits
competitive advantages with respect to AlexNet, Unet, and SVM classification methods.
Although fiber optic spectrometers cannot directly perform spectral imaging classification
research, our work has confirmed that deep learning algorithms can be combined with
the spectral data obtained by the optical fiber spectrometer for classification research. We
will use fiber optic spectrometers to obtain more samples of spectral data and combine
edge computing technology to send to the deep learning model for data processing and
classification research in the future.
Author Contributions: Conceptualization, L.X. and F.C.; methodology, L.X., F.C. and J.W.; software,
L.X. and F.C.; validation, L.X., J.X. and J.W.; formal analysis, L.X., F.C. and J.W.; data curation, L.X.
and J.X.; writing—original draft preparation, L.X., F.C. and J.W.; writing—review and editing, L.X.,
F.C. and J.W.; supervision, J.W.; funding acquisition, F.C. and J.W. All authors have read and agreed
to the published version of the manuscript.
Funding: This work is supported by National Key Research and Development Program of China
(No. 2018YFC1407505); National Natural Science Foundation of China (No. 81971692); the Natural
Science Foundation of Hainan Province (No. 119MS001) and the scientific research fund of Hainan
University (No. kyqd1653).
Conflicts of Interest: The authors declare no conflict of interest.
Introduction
Discovering new chemical entities is a difficult and time-consuming endeavour [1], [2]. By using computers and
algorithms the belief is to shorten the process from idea to launched drug. The field of cheminformatics is one
area holding promise to enable faster and better decision-making, for example, by deriving new methods for
automated predictions of molecular properties [3]. Many of the problems in cheminformatics are focused on
how to predict properties of a molecule given the known values of these properties of several similar molecules.
Due to the nature of these problems, cheminformatics is influenced by the development and trends in machine
learning. One sub-field in machine learning that has expanded tremendously in the last years, mainly due to
the success and advancement in several fields such as image recognition [4] and speech recognition [5], is deep
learning [6]. Recently, deep learning has started to make its way into cheminformatics [7].
Several traditional machine learning algorithms have been applied for the prediction of molecular properties,
 such as random forests [8], support vector machines [9], k-nearest-neighbours classification [10] and artificial neural
networks [3], [7], [11], [12], [13]. A major difficulty when applying machine learning algorithms on molecular
data is that most machine learning algorithms require input of a fixed size, while molecules are of arbitrary
size. To circumvent this problem, the most common approach is to pre-process the molecular data into chemical
 “fingerprints”; an abstract and fixed sized representations of structural features, enabling the application of
selected machine learning algorithms [14]. This process is, for example used in Huuskonen et al. [15], Ma et al.
[16], Ekins [17] and Mayr et al. [18]. However, once encoded as fingerprints, it is not trivial to trace back which
part of the molecule gives rise to different effects, hampering interpretation.
In this paper we take a different approach and use deep convolutional neural networks (DCNN) on
molecules represented as graphs as input. The same approach has previously been used by several other authors
 [19], [20], [21]. We show that the predictive power of such networks can be improved if more information
about the atoms, bonds and molecules are added, for example chirality, bond type, the number of rotatable
bonds and the mass of the molecule. While some, but not all, of the information used in this study has been
used in previously presented papers concerning DCNN models, the reflection on how the selection of input
Niclas Ståhl is the corresponding author.
©2019, Niclas Ståhl et al., published by Walter de Gruyter GmbH, Berlin/Boston.
This work is licensed under the Creative Commons Attribution 4.0 Public License.
1
Automatically generated rough PDF by ProofCheck from River Valley Technologies Ltd
Ståhl et al.
DE GRUYTER
information affects the result is negligible. To show that this cannot be overlooked we develop a flexible model
where both global and local information easily can be incorporated or removed. Using this model, we explore
how the predictive power varies when more information is gradually incorporated. It is worth to point out that
this study does not aim to be an extensive search to find which information that contributes the most to the
predictive power. Instead, we aim to show that different types of molecular information easily can be incorporated
 into a DCNN and that this can increase the predictive power of that particular network. Another issue
that has not been given enough attention is the problem of unbalanced classes, a problem that often arises in
chemical and medical datasets [22]. We show that by customising the training process of the presented DCNN
to better handle unbalanced classes, the performance was significantly increased in one case.
There has not been any standardised way to measure the performance of predictive algorithms within cheminformatics
 against each other. However, most recently Wu et al. [21] made an effort and compiled several
datasets that can be used as benchmarks for this purpose. The presented DCNN in this paper is evaluated on
three different datasets, selected from this benchmark. A special focus is given to one of these datasets, in order
to further understand the behaviour of DCNNs, namely the SIDER dataset, which originates from the SIDER
database [23]. The reason that this dataset is selected for a closer study is that Wu et al. [21] acknowledge SIDER
to be a dataset where it is difficult to achieve a high predictive accuracy. Surprisingly, while being one of the
best performing methods on all other datasets in Wu et al. [21], their presented DCNN performed very poorly
on the SIDER dataset and was outperformed by traditional methods such as random forest and logistic regression.
However, both of these methods are less flexible and requires the use of chemical fingerprints. Therefore, in
order to be able to improve further DCNN methods, on the SIDER dataset and datasets with similar properties,
 we argue that there is a great need to study and find the reasons for why the DCNN method performed so
poorly in this case. While Wu et al. [21] argued that the reason is that the dataset consists of biological molecules,
we believe that this only partly explains the low average area under the receiver operating characteristic curves
AUC-ROC value [24]. Instead we show that a part of the poor performance of the DCNN is caused by the imbalance
 in the data for some of the side effects. By further investigating the reasons behind the bad performance of
DCNNs on the SIDER dataset, we hope to show best practices for how deep learning methods can be improved
in the future.
2
Deep Learning in Cheminformatics
While neural networks have been used in cheminformatics for several decades, deep learning has just recently
made its way into this field [7]. Several groups have applied deep neural networks on molecular fingerprints
for the prediction of many different properties, including toxicity [18] and solubility [15]. One of the most
famous applications of neural networks in cheminformatics is the work of Dahl et al. [25], which won the Merck
Molecular Activity Challenge, a competition where researchers were invited to predict how small molecules
acted on 15 different target molecules. However, deep feed forward neural networks like these are limited to
input of fixed size. Since molecules can have an arbitrary size, some feature extraction must be conducted
to reduce the molecule to a fixed set of values before the deep neural networks can be applied. This is most
commonly achieved by the creation of a fixed sized vector of descriptors for each molecule [13], leading to
information loss. Several authors overcome this flaw by either using a recurrent neural network (RNN) or a
DCNN. Lusci et al. [26] do for example use a RNN for the prediction of aqueous solubility. In their work, Lusci
et al. [26] first convert the molecular structure into directed acyclic graphs (DAGs). Each of these DAGs are
traversed by a RNN, giving a vector representation for each DAG. These vectors are then summarized into a
vector representing molecular properties, from which a prediction of the solubility can be done. Xu et al. [27]
used the same method to predict if a molecule would cause liver injury or not.
Another approach that has been used by other authors is to use a DCNN for the prediction of molecular
properties. These authors assume that low level features in the molecule will emerge due to local interactions
between neighbouring atoms in the same way as low level image features, such as edges, emerges due to interactions
 between neighbouring pixels in an image [4]. Wallach et al. [28], for example, apply a three dimensional
convolutional neural network on the spatial structure of molecules. Duvenaud et al. [19] Kearnes et al. [20] and
Wu et al. [21] use another approach and represent molecules as graphs where nodes correspond to atoms and
the edges to bonds. Several types of convolutional neural networks, which use different type of molecular information
 and with different purposes, are then applied to these graphs representing molecules. One example
of this is Duvenaud et al. [19], which use a DCNN that uses atom properties (such as the hybridization type of
the atom and if the atom is in a ring or not) and bond properties (such as the type of the bond) to automatically
 generate fingerprints. Kearnes et al. [20] use a different type of DCNN, which consists of so called “weave
modules”, where information is transferred between different atoms. Wu et al. [21] present several chemical
datasets for benchmarking of machine learning algorithms. The performance of several algorithms, among
2
Automatically generated rough PDF by ProofCheck from River Valley Technologies Ltd
DE GRUYTER
Ståhl et al.
them a DCNN for graphs, is evaluated on each dataset. However, even though these authors do not use the
same atom and bond information in their networks, none of them reflects on how this affects the result. This
is important since different molecular properties may emerge from completely different molecular attributes.
Thus the information included in a model may be crucial for its success. Deep learning has been used for more
tasks in cheminformatics than just property prediction. Segler et al. [29] do, for example, use RNNs as generative
 models to generate new SMILES strings, a way to store molecules in form of a line notation [30], (in
the same way as Graves [31] used recurrent neural networks to generate text). These generated SMILES strings
were then used to find novel drug candidates.
In the next section, our proposed network architecture is presented. It is similar to the architectures presented
 by Duvenaud et al. [19] and Wu et al. [21]. In addition, our architecture incorporates several other advances
 within deep learning, such as residual learning [32] and dropout layers [33].
3
Proposed Model
The model architecture, shown in Figure 1, is a slightly modified version of the DCNN presented by Duvenaud
et al. [19] and Wu et al. [21]. This model is also inspired by the works of He et al. [32] and uses residual learning,
something Duvenaud et al. [19] and Wu et al. [21] did not. The first step in our model is to calculate the initial
hidden representation of each atom. Let 𝐴(0)
𝑖
be a vector consisting of all information that is extracted from
atom i. Here the superscript represents the layer number. The contents of this vector vary between the different
experiments, described in Section 4.2.
Figure 1: A graphical representation of the proposed model. This figure shows an example where the model is applied
to a molecule consisting of three atoms. The equations governing the inner workings of this model are described in equations
 (1) to (5).
In the first and most simplistic experiment, 𝐴(0)
𝑖
corresponds to an “one hot” encoded vector, that is a vector
 where each elemental type corresponds to a given position in the vector. The value at the position of the
3
Automatically generated rough PDF by ProofCheck from River Valley Technologies Ltd
Ståhl et al.
DE GRUYTER
elemental type of atom i is 1 and and the value of all other positions are 0. In later experiments, 𝐴(0)
𝑖
the “one
hot” encoded vector is appended with real values, representing attributes such as the number of other atoms
atom i binds to.
Let 𝐴(1)
𝑖
be the vector representing the first hidden state of atom i, given by
𝐴(1)
𝑖
= ℱ(𝐴(0)
𝑖
; 𝑊(0)) ,
(1)
where ℱis an arbitrary activation function and W(0) is its parameters. Due to the conventions of the field, ℱ
will be defined as the leaky ReLU function [34] in the rest of this paper due to current conventions. The next
operation in the model is the convolutional steps. In these steps, information is transmitted between atoms and
their neighbours. The steps can be expressed as
𝐶(𝑙)
𝑖,𝑗= 𝒢(𝑙) (𝐴(𝑙)⌢
𝑖
ℬ(𝑖, 𝑗)⌢𝐴(𝑙)
𝑗
; 𝑊(𝑙)) ,
(2)
𝐴(𝑙+1)
𝑖
= 𝐴(𝑙)
𝑖
+ 𝑉(𝑙) [
max
𝑗∈𝑛𝑒𝑖𝑔ℎ𝑏𝑜𝑢𝑟ℎ𝑜𝑜𝑑(𝑖) 𝐶(𝑙)
𝑖,𝑗,1, … ,
max
𝑗∈𝑛𝑒𝑖𝑔ℎ𝑏𝑜𝑢𝑟ℎ𝑜𝑜𝑑(𝑖) 𝐶(𝑙)
𝑖,𝑗,𝑘] .
(3)
Equation (2) calculates how atom i is affected by having atom j in its neighbourhood. The function ℬin equation
 (2) extracts information about the interactions between atom i and j, for example if there is a single, double,
or triple bond between them. The ⌢operator represents concatenation of two vectors. 𝒢(𝑙) is an arbitrary activation
 function, witch is parametrised by W(l), and as with the function ℱit will be defined as the leaky
ReLU function in the rest of this paper. The hidden representation in each atom is then updated as described
by equation (3). Here the max function is applied element-wise to every element in the vectors and the results
are then multiplied with the square matrix V(l), which is one of the parameters that the model later on will
learn. Following the method used by He et al. [32], the result of the matrix multiplication is then added to the
previous hidden representation of atom i. It has been shown that DCNNs having such short-cut connections,
a connection where the signal is passed forward without any modification, are more stable than DCNNs not
having such connections [32].
After m convolutional and max-pooling steps a global representation for the molecule is calculated. This is
done by summing up the representation of all atoms and also adding global molecular properties. This can be
expressed as
𝑌(𝑚+1) = ∑
𝑖
(𝐴(𝑚)
𝑖
)
⌢ℳ,
(4)
where ℳis a vector of the selected molecular properties. Which molecular properties that are selected is described
 in Section 4.2. The use of the summation is arbitrary and may be replaced by any function that results in
a fixed sized vector. However, this would most likely affect the result of the model. This gives the first hidden
representation for the molecule. Standard hidden layers, which are defined as
𝑌(𝑙+1) = ℋ(𝑙) (𝑌(𝑙); 𝑊(𝑙))
(5)
are then applied to this representation, which finally gives the predicted molecular properties. The ℋin equation
 (5) represents an arbitrary activation function. In this paper the leaky ReLU function will be used for ℋ(𝑙)
except in the final layer where the sigmoid function will be used instead. The sigmoid function is selected here
since we want the output of our model to be in the range of 0–1.
In one of the experiments, conducted in this paper, the problem of class imbalance is addressed. This is
done by customizing the loss function of the network. Instead of using the standard binary cross entropy error
(described in equation (6)), which is a common practice, a weighted version is used. The weighted version, as
described in equation (7), takes the distribution of each class into account and thus rare instances will impact
the loss much more. The standard cross entropy is defined as:
𝑛
∑
𝑖=0
𝑐
∑
𝑗=0
−𝑦𝑖,𝑗𝑙𝑜𝑔( ̂
𝑦𝑖,𝑗) −(1 −𝑦𝑖,𝑗)𝑙𝑜𝑔(1 −̂
𝑦𝑖,𝑗),
(6)
4
Automatically generated rough PDF by ProofCheck from River Valley Technologies Ltd
DE GRUYTER
Ståhl et al.
while the weighted version is defined as;
𝑛
∑
𝑖=0
𝑐
∑
𝑗=0
−⎛
⎜
⎝
𝑛
∑
𝑖=0
1 −𝑦𝑖,𝑗
𝑛
⎞
⎟
⎠
𝑦𝑖,𝑗𝑙𝑜𝑔( ̂
𝑦𝑖,𝑗) −⎛
⎜
⎝
𝑛
∑
𝑖=0
𝑦𝑖,𝑗
𝑛
⎞
⎟
⎠
(1 −𝑦𝑖,𝑗)𝑙𝑜𝑔(1 −̂
𝑦𝑖,𝑗).
(7)
In equations (6) and (7), n is the number of samples in the dataset, c is the number of binary classes to predict,
yi,j is the true class j of sample i and
̂
𝑦𝑖,𝑗is the predicted probability that class j is equal to 1 for sample i. The
definition of equation (7) is selected in such a way that rare samples, that are miss classified, contribute much
more to the total loss than those that are common.
4
Experiments
In this section, the experiments conducted using the model from the previous section, are described. To demonstrate
 the improvements that can be achieved by adding more information to the model, we conduct several
experiments, each with gradually increasing level of provided molecular information. In the final experiment,
a custom version of the training method is used to increase the predictive power for unbalanced classes.
4.1
Data
An investigation of the model, presented in the previous section, is conducted on three different datasets:
SIDER, TOX21 and ClinTox. The molecules are stored as SMILES strings [30] and are read into the program
and converted into a graph structure using the cheminformatics open source software RDKit [35] and the Lipinski
 module. RDKit is also used to extract information about the atoms, bonds and molecules, such as chirality
and molecular weight. To be able to do a comparison between the achieved results presented in this paper and
in the benchmark presented by Wu et al. [21], the dataset is split into training, validation, and test set depending
on index, that is the order the samples appear in the dataset. As in the benchmark, 80% of the molecules are
used to train the model, 10% as a validation set to find the best configuration, and the final 10% are used for
testing.
4.1.1
SIDER
The SIDER1 dataset contains information on molecules, marketed as medicines, and their recorded side effects.
This data originates from the SIDER database [23] and do originally consist of 1430 molecules and 5868 different
 types of side effects. However, in the dataset presented by Wu et al. [21], similar side effects are grouped
together, leaving the dataset with 28 groups of side effects. Some of these side effects are very rare, and the
most uncommon only occur in around 1.5% of all samples. Other side effects are common and several of them
occur in more than 90% of the samples. Thus, many of the classes in the dataset are very unbalanced.
4.1.2
TOX21
The TOX21, dataset2 was collected in the “Toxicology in the 21st Century” initiative which aimed to create a
public dataset for the toxicity of compounds [36]. There are 8014 compounds in this dataset and beside information
 of the structure of the molecules it contains qualitative toxicity measurements on 12 different targets.
4.1.3
ClinTOX
ClinTox3 is a dataset that was introduced by Wu et al. [21], in effort to gather a benchmark to measure the performance
 of machine learning algorithms within chemistry. ClinTOX contains both drugs that were approved
by the US food and drug administration (FDA) and those that failed their clinical trials for toxicity reasons.
There are a total number of 1491 drug compounds in the dataset and the toxicity (binary) and FDA approval
status is recorded for each compound.
5
Automatically generated rough PDF by ProofCheck from River Valley Technologies Ltd
Ståhl et al.
DE GRUYTER
4.2
Experiments
In all experiments, the performance of the presented model is compared to the benchmark presented by [21]. In
these experiments, it is investigated how the performance of the model is affected when additional information,
about the molecule and its atoms, is added to the model. To this end, we conduct five different experiments,
each using more information about the molecules than the previous experiment. In the most simplistic experiment
 only the elemental type of the atom is used. In the latter experiments, more information is used and
information concerning the bond and the full molecular structure is also incorporated into the model. In the
final experiment, the training method is customised to further handle the unbalanced classes in the SIDER
dataset. The details of how this is done is described in the next Section. Five different experimental set-ups are
used to show how the performance of the model is affected when more information is added. One additional
set-up is used to show how the problem of unbalanced classes can be handled. The six set-ups used, are the
following:
1. The elemental type of each atom.
2. The elemental type of each atom and its hybridization type.
3. The elemental type of each atom, its hybridization type and the type of each bond.
4. Information concerning the atom, including elemental and hybridization type, chirality, the number of hydrogen
 atoms the atom binds to, if the atom is in a ring and if that ring is an aromatic ring. Information
about the type of bond will also be used.
5. The same information as used in set-up 4, adding information concerning the complete molecule. Information
 such as weight, charge and the number of rotatable bonds in the molecule.
6. The same information as used in set-up 5, but to increase the performance for skewed classes, the customised
loss function described in equation (7) is used.
4.3
Implementation
The model described earlier in Section 3 is implemented in Theano [37]. To perform a good comparison between
our model and the model presented in Wu et al. [21], we choose to use an as similar network architecture as
possible. Therefore we choose to have two convolutional layers, each with 64 neurons. These layers are then
followed by a single fully connected layer, with 128 neurons. Between each layer in our model we use a 10%
dropout rate, a method described by Srivastava et al. [33], to reduce the overfitting of the model. The models
are trained by minimizing the cross entropy error, described in equation (6), between the predicted values and
the real measured values for all molecules in the dataset. This is achieved by optimizing the values of all free
parameters (W(l) and V(l)) in the model using the ADAM optimization algorithm [38].
For each experimental set-up, ten networks with different initial parameters are trained. Each network is
trained for 200 epochs using a batch size of 20 examples. The networks are evaluated after each epoch and the
configurations that achieves the best results on the validation data are later used to evaluate the performance
on the test data. The performance of the networks is evaluated in the same way as in Wu et al. [21] by calculating
the AUC-ROC. To do a comparison, the final performance measure of each experiment is calculated as the mean
value of the AUC-ROC for the different predicted variables, averaged over the ten different networks.
4.4
Results
In this section the results from the presented models and the described experiments are compared with the
results from the Graph Convolution Network presented by Wu et al. [21]. The results of this comparison are
shown in Table 1– Table 3. In these tables it is shown that the presented model outperformed the Graph Convolution
 Network presented by Wu et al. [21] when the model had access to the most available information. A
graphical representation of these results are shown in Figure 2. The differences to the result achieved by Wu et
al. [21] are also shown in these graphs. For two of the datasets, SIDER and TOX21, it was a clear difference in
performance between the experiments when only atomic levelled features were used compared to when global
features were added. In the case with the third dataset, the model achieved a high AUC-ROC value already
in the first experiment, and hence the possibility to improve this result was very limited. The balancing of the
classes had a great impact on the obtained results when the SIDER dataset was studied. In this case, the most
6
Automatically generated rough PDF by ProofCheck from River Valley Technologies Ltd
DE GRUYTER
Ståhl et al.
significant improvement of the model was when the unbalance among the classes was handled by a weighted
loss function. Thus, a large improvement could be achieved by handling the problem of unbalanced classes,
resulting in some rare samples being correctly classified. This is shown in Figure 3, where typical views of how
the individual ROC curve may look for each target variable for the training and test data in experiment set-up
5 and 6. In this Figure, it can be seen that some of the target variables, that are unbalanced, contribute very
negatively to the mean by having low AUC-ROC values in experiment set-up 5. However, when the unbalance
is handled this is no longer the case.
Figure 2: The distribution of the achieved AUC-ROC values averaged over all target variables for each experimental setup.
 The blue dashed line represents the result achieved by the GCNN presented by Wu et al. [21]. The left plot is the
achieved results on the training data and the right plot is the achieved results on the test data.
7
Automatically generated rough PDF by ProofCheck from River Valley Technologies Ltd
Ståhl et al.
DE GRUYTER
Figure 3: The ROC curves for each target variable from a model trained using the information described in experiment
set-up 5 and set-up 6 for the SIDER dataset. The ROC curves for the five most unbalanced classes are highlighted in
red, in order to show how the performance is affected by the weighting of the loss function. The top row shows results
achieved using experiment set-up 5 and the bottom row results from experimental set-up 6. The left column shows the
ROC curves for the training data and the right column for the test data. Note that the results for the test data are almost
similar for the two set-ups while the performance for the test data increased in set-up 6. This is due to a better separation
of the unbalanced classes, something that otherwise will bring down the mean AUC-ROC value.
Using a t-test it was shown that the presented model, using the experimental set-up 5 with the most information
 available, preformed significantly better than the model presented by Wu et al. [21] on two of the
studied datasets. The p-value yielded by these two t-tests were less than 0.0001. For the third dataset the model
still performed better, but the difference in performance was not significant.
5
Discussion
The results of the model presented in Section 3 were significantly better than the results previously obtained
on the same dataset with the use of a DCNN [21] in two out of three cases. However, in the experiments with
the SIDER dataset there are still other models, such as random forest, achieving even better results than our
presented model. In this case, it is most likely that the result could be further improved by finding a better
network architecture for the presented DCNN model, something that Wu et al. [21] also point out. There is
also room for improvement given how evaluation of the models is conducted in relation to how the models are
trained. The objective of the evaluation metrics are for example not the same as the objective against which the
training procedure optimizes the models.
The information about the molecules that was used in the conducted experiments is just a small subset of all
information that can be extracted from each molecule, bond and atom. There are also a large number of network
architectures that were not tested in this study. Therefore there should be an opportunity to achieve a better
result by adding even more molecular information to the model or to finding a better network architecture. The
optimal network architecture would also most likely differ between the experiments that are conducted. The
more information that is used, the larger network is needed to make use of all information.
8
Automatically generated rough PDF by ProofCheck from River Valley Technologies Ltd
DE GRUYTER
Ståhl et al.
Any deep neural network would theoretically perform as good as or better than before when more information
 is added to the network. The reason for this is that the network can always learn to ignore the additional
information. This argumentation follows the same chain of reasoning as He et al. [32] used when arguing for
why adding more layers to a deep neural network should theoretically always improve the performance of the
network. However, while it is possible to argue that adding more information to the model always improves
the predictive power, this is not always true for practical experiments. If too much irrelevant information is
added to the network there is always a risk that the relevant information will “drown” in the heap of useless
information and thus it would be difficult to correctly train the network. Another problem that may occur when
too much information is added to the model is that the dimensionality of the input data increases, which in its
turn increases the risk of overfitting. Experiment set-up 4 for the SIDER dataset is a good example of this. When
more information is added, in comparison to previous experiments, the AUC-ROC increases for the training
data while the AUC-ROC decreases for the test data, as shown in Figure 2.
Some of the information that is added to the model is redundant and it should be possible for the network
to calculate it from the rest of the information. An example of this is the molecular weight, which could be
calculated knowing the elemental type of each atom. However, adding the information facilitates the networks
ability to learn other useful features. Having a flexible model where both local and global information, with
a minimal effort, can either be added or removed from the model lets domain experts customize models depending
 on problem.
Besides that the presented model performed better than the model by Wu et al. [21] it also suffers less from
overfitting. This is due to the introduction of dropout and residual learning to the model. These methods makes
the training and testing stable and should thus be considered when developing new models.
By customizing the loss function that is optimized during training of the model, we show that the performance
 of the presented model was greatly improved for the SIDER dataset. However, when introducing the
weighting among the different classes, we assume that the dataset captures the class distribution among new
samples, an assumption that may not always be true. Thus the improvements shown in this paper can not be
generalized to new datasets, where the distribution between the training and test set differs. This can be seen
in Figure 3 where the curves with the lowest AUC-value are those representing the prediction of variables in
the very unbalanced classes. The reason that made us believe that the classes in the dataset are unbalanced
was that Wu et al. [21] achieved a better result with the random forest algorithm, compared to both their and
our DCNN method. We hypothesised that this is a sign that the dataset contains unbalanced classes, since the
random forest algorithm is much more robust to this [39].
The problem with unbalanced classes is often present in chemical and medical datasets [40]. However, how
the model is affected by this is not always considered. The difference in how this is handled in the model is
highly dependent on the objective and the metric used as optimization objective during training. Some metrics,
such as the percentage of correctly classified samples and the cross-entropy, only measure the classification
accuracy of the model. Thus, there are no great loss in classifying rare samples wrong. However, other metrics
 such as the AUC-ROC and the F-score measures relative scores per class. Therefore, if any of these metrics
are used, it is very important to classify rare instances correctly, since these greatly affects the metric. The real
problematic case is when different metrics are used for training and evaluating a model, for example when minimizing
 the cross entropy error during training and then using AUC-ROC as the evaluation metric. Therefore,
it is of great importance to consider not only the selection of models, but also the selection of metrics. To avoid
this problem we suggest that the same objective metric should be used when both training and evaluating the
model. Besides this, it is also important to reflect on how the results are affected by the selection of metrics.
6
Conclusion
We present a deep convolutional neural network model that performs significantly better than the DCNN
model presented in [21] on two of the three studied datasets, SIDER and Clintox. Our model, which uses the
open-source cheminformatics tool-kit RDkit, is flexible and makes it easy to add further molecular properties
to the model. It is possible to add or remove any information about atom, bond or molecule from the molecule.
Using this model, we show that adding more information is mostly beneficial. However, we show and discuss
that there is no guarantee that a model will perform better when more information is added. Therefore, more
work is needed to find which information that should be incorporated into the model and how to select the
network architecture to achieve the optimal result. The optimal information used in the model is most likely
very dependent on the dataset and problem. Thus it is of great utility to have a model where it is easy to include
all sorts of information regarding molecules relevant to the given problem. As expected, the best performance
of the model was obtained when the most molecular information was incorporated into the model. More sur9

Automatically generated rough PDF by ProofCheck from River Valley Technologies Ltd
Ståhl et al.
DE GRUYTER
prising is that the performance of the model was almost the same when only the elemental types of the atoms
were used.
In the paper, we point out some weaknesses of current deep learning models used in cheminformatics,
including the presented model. These issues need to be addressed to further advance the use of deep learning
within the field of cheminformatics. By selecting datasets from the benchmarks proposed by [21], this work is
also a step in the right direction to form a standardized way to evaluate machine learning algorithms in the
field of cheminformatics.
This paper highlights several best practices of how to design DCNNs to increase the performance on a given
dataset. This includes preventing overfitting by adding dropout and residual learning to the network. It is also
shown that selecting more molecular information increases the performance. For unbalanced datasets, such as
SIDER, a large improvement in performance also came from handling the unbalance in some of the classes.
Conflict of Interest: Authors state no conflict of interest. All authors have read the journal’s publication ethics
and publication malpractice statement available at the journal’s website and hereby confirm that they comply
with all its parts applicable to the present scientific work.
Notes
1 https://github.com/deepchem/deepchem/blob/master/examples/sider
2 https://github.com/deepchem/deepchem/blob/master/datasets/
3 https://github.com/deepchem/deepchem/blob/master/examples/clintox/datasets/
LETTERS
A minimum column density of 1 g cm22 for massive
star formation
Mark R. Krumholz1,2 & Christopher F. McKee3
Massive stars are very rare, but their extreme luminosities make
them both the only type of young star we can observe in distant
galaxies and the dominant energy sources in the Universe today.
They form rarely because efficient radiative cooling keeps most
star-forming gas clouds close to isothermal as they collapse, and
this favours fragmentation into stars of one solar mass or lower1–3.
Heating of a cloud by accreting low-mass stars within it can prevent
 fragmentation and allow formation of massive stars4,5, but the
necessary properties for a cloud to form massive stars—and therefore
 where massive stars form in a galaxy—have not yet been
determined. Here we show that only clouds with column densities
of at least 1 g cm22 can avoid fragmentation and form massive
stars. This threshold, and the environmental variation of the stellar
 initial mass function that it implies, naturally explain the characteristic
 column densities associated with massive star clusters6–9
and the difference between the radial profiles of Ha and ultraviolet
emission in galactic disks10,11. The existence of a threshold also
implies that the initial mass function should show detectable variation
 with environment within the Galaxy, that the characteristic
column densities of clusters containing massive stars should vary
between galaxies, and that star formation rates in some galactic
environments may have been systematically underestimated.
Consider a simple model system: a spherical gas cloud of mass M,
column density S, radius R~
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
M= pS
ð
Þ
½

p
, and density profile
r!r{kr, with a point source ofluminosity L at itscentre,representing
the radiation output by stars beginning to form within it. In the limit
L R 0, the cloud falls to a background temperature Tb set by the
balance between cosmic-ray heating and molecular and dust cooling.
We are interested in the earliest stages of cloud collapse, so we adopt
kr 5 1. This puts most of the mass at low density, and is expected if
clouds are in rough hydrostatic balance and obey the observed linewidth–size
 relation12 s / rq for molecular clouds, where s is the velocity
 dispersion, r is the size scale and q < 0.5. However, any choice in
the range 1 # kr # 2 yields the same qualitative conclusions.
The dust in a spherical cloud with a central source of illumination
has a power-law temperature structure T~Tch r=Rch
ð
Þ{kT , where
Tch, Rch and kT are functions of the cloud column density S, the light
to mass ratio g ; L/M, and the dust opacity, which we characterize
through a parameter d that we define below13. As we show in the
Supplementary Information using a grain–gas energy exchange
code14–16, at the high densities with which we are concerned, the
gas temperature will be nearly identical to the dust temperature.
The temperature will be everywhere greater than Tb if
Tch g,S,d
ð
Þ
R
Rch g,S,d
ð
Þ

{kT g,S,d
ð
Þ
~Tb
ð1Þ
Because kT is generally close to 0.4 for strong sources of internal
illumination and large R/Rch, a cloud satisfying this condition has an
effective adiabatic index c < 1.4 throughout its volume. As even c <
1.1–1.2 is sufficient to suppress fragmentation5, equation (1) implicitly
defines a critical light-to-mass ratio ghalt above which fragmentation
willhaltina cloud with a given S, d and Tb. Wedescribeour procedure
for solving this equation in the Supplementary Information.
We approximate the infrared dust opacity as k 5 dk0(l0/l)2,
where d is a dimensionless number that we define to be unity at
solar metallicity, l is the radiation wavelength, and l0 5 100 mm.
Observations in the Milky Way indicate13,17 that, in cold regions
where dust grains are coated with ice mantles, k0 < 0.54 cm2 g21.
Under Milky Way conditions the minimum temperature for interstellar
 gas is Tb < 10 K, with a weak density dependence that we
ignore for simplicity. In addition to the Milky Way case, we also
consider d 5 0.25, Tb 5 10 K, appropriate for a low-metallicity galaxy
today, and d 5 0.25, Tb 5 15 K, typical of a galaxy at z < 6 that has
low metallicity but a temperature floor of 15 K imposed by the cosmic
microwave background. Figure 1 shows the value of ghalt calculated
for the three cases. We find that ghalt declines with S because at higher
S a cloud of fixed mass has a smaller radiating area and remains
warmer at fixed luminosity.
Clouds containing massive stars can have light-to-mass ratios of
100L[/M[ (ref. 18), more than sufficient to stop fragmentation, but
we are interested in clouds where no massive stars have yet
formed because fragmentation breaks all collapsing objects down
to small masses. For a low-mass protostar the dominant energy
source is gravitational potential energy radiated away by accreting
gas. We plot the energy released per unit mass accreted, y, in
Fig. 2. Consider a cloud converting its mass into stars at a rate
_
M with a mass distribution dn/d ln m* and a mean mass

m~
Ð
m dn=d lnm
ð
Þd ln m. Once the rate at which new stars in
a cloud begin accreting balances the rate at which other stars reach
their final mass and stop accreting, the light-to-mass ratio is
ggrav~ 1
M
_
M

m

 ð
dn
d ln m
ymd ln m
ð2Þ
~ SFRff

tff
y
h iIMF
ð3Þ
where SFRff~ _
M
tff


M is the fraction of a cloud’s mass that
it
turns
into
stars
per
mean
density
free-fall
time

tff,
and
y
h iIMF~
m{1

Ð
dn=d ln m
ð
Þymd ln m
is
the
value
of
y
averaged
over
the
initial
mass
function
(IMF).
For
a
Chabrier
IMF19
truncated
at
a
maximum
mass
of
1M[,
y
h iIMF~2:1|1014erg g{1~0:11 GM8=R8


. Observations constrain
 SFRff to be a few per cent20,21, and in the Supplementary
Information we use an analytic fitting formula22 to estimate
SFRff < 0:041 M2S0
.
T2
b,1


{0:08
, where M2 5 M/(100M[), S0 5
1Astrophysics Department, Princeton University, Princeton, New Jersey 08544, USA. 2Astrophysics Department, University of California Santa Cruz, Santa Cruz, California 95064,
USA. 3Physics and Astronomy Departments, University of California Berkeley, Berkeley, California 94720, USA.
Vol 451 |28 February 2008 |doi:10.1038/nature06620
1082
Nature


Publishing Group
©2008
S/(1 g cm22), and Tb,1 5 Tb/(10 K). Combining our estimates for
y
h iIMF and SFRff with the definition of the mean density free-fall
time (
tff~
ffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffiffi
3p= 32G
r
ð
Þ
p
~38:6M1=4
2
S{3=4
0
kyr), we find that the
light-to-mass ratio of a cloud powered by accretion onto low-mass
stars is
ggrav<3:6M{0:33
2
S0:67
0
T 0:16
b,1
L8
M8


ð4Þ
For the models shown in Fig. 2 a cloud reaches its equilibrium
light-to-mass ratio within about 3
tff after star formation begins, and
because SFRff is less than about 0.05, at most ,15% of the mass will
have gone into low-mass stars at this point. If star formation accelerates
 in time, as predicted by some models23, then ggrav will reach the
value given by equation (4) even earlier.
In Fig. 1, we show ggrav computed for some typical parameters
overplotted with ghalt. For each cloud mass M, we solve equations
(1) and (4) to find the column density Sth such that ghalt $ ggrav,
and plot the result in Fig. 3. This is the threshold required for fragmentation
 to halt. We find that thresholds of 0.7–1.5 g cm22 are
required to form stars of 10–200M[ under Milky Way conditions.
Lower-metallicity galaxies (0.25 solar metallicity) with comparable
background temperatures require column densities that are about a
factor of 3 smaller, whereas galaxies at z < 6 with 0.25 solar metallicity
 but high cosmic microwave background temperatures require
higher column densities by a similar factor.
The existence of a threshold for massive star formation both
explains current observations and predicts future ones. Regions with
column densities above about 1 g cm22 are rare even among starforming
 clouds, and contain only a small fraction of the molecular
mass in the Galaxy, but our threshold explains why all nearby regions
of massive star formation have S at or above this value6–9. We further
predict that clusters formed with S = 1 g cm22 should be deficient in
massive stars. This is probably unobservable in individual low-S
clusters because they contain too few stars, but a statistical analysis
of many clusters might reveal the effect.
Conversely, suppression of fragmentation should produce topheavy
 IMFs at high gas column densities. This prediction can be
tested by X-ray searches for low-mass protostars in high-S clouds
that are not detected by Spitzer at 24 mm and therefore contain no
massive protostars24. We predict that any low-mass protostellar
populations detected will constitute at most 15% of the total mass.
This prediction provides a sharp test for distinguishing our model
from competitive accretion models, which predict that the mass of
the most massive star forming in a cloud is related to the mass of lowmass
 stars around it by (Mmass/M[) < (Mlow-mass/M[)2/3 (ref. 23).
Thus we would predict that a cloud of mass 100M[ and
S . 1 g cm22 with no stars larger than 10M[ should have a total
stellar content below 15M[, whereas competitive accretion would
allow up to 42M[ of low-mass stars. However, because radiation
does not halt fragmentation until some low-mass stars have formed,
we do expect most massive stars to form surrounded by a cluster.
Environmental variation at the top end of the IMF has even more
profound consequences for extragalactic astronomy, as observations
of distant galaxies are generally sensitive only to massive stars. The
threshold explains why Ha emission in galactic disks ends at sharp
edges where the disks transition from gravitationally unstable to
gravitational stable10, but ultraviolet emission declines smoothly with
radius and does not show a feature at the Ha edge11. Ultraviolet and
0.25
a
b
0.20
0.15
0.10
0.05
 0.00
100
10
1
0
1013
1012
1011
1
2
3
4
0.0
1.0
1.5
2.0
0.5
= 0.1 g cm–2
S
= 1 g cm–2
S
= 10 g cm–2
S
y (GM  /R  )
y (1014 erg g–1)
m*  (M  )
tf (kyr)
tf (s)
Figure 2 | Energy per unit mass radiated and formation time versus
protostellar mass. a, The energy per unit mass, y, radiated away in the
process of forming a star of mass m*; b, the time required to form the star, tf.
The tracks shown are computed using a one-zone protostellar evolution
code9 applied to the accretion histories predicted previously9,30 using their
fiducial parameters, for protostellar cores born in environments where the
column density is S 5 0.1, 1.0 or 10.0 g cm22 as indicated. However,
alternative accretion histories give qualitatively identical results. Note that y
is nearly independent of both accretion history and final stellar mass because
the entropy distribution within a protostar and the protostellar mass–radius
relation are nearly constant on timescales that are short compared with the
Kelvin–Helmholtz time tKH, and for low-mass stars tf = tKH < 10 Myr. This
means that y, which is a measure of the gravitational energy released, is
nearly independent of accretion history. Moreover, because low-mass stars
have nearly linear mass–radius relations, y is also nearly independent of the
final stellar mass. Although our calculation of y uses a code calibrated to
solar metallicity, our results should also apply over a very wide range of
metallicities because even for low-metallicity stars tf = tKH.
100.0
10.0
1.0
0.1
0.1
1.0
10.0
h (L  /M  )
d = 1/4, Tb = 15 K
d = 1/4, Tb = 10 K
M = 20M
M = 200M
d = 1, Tb = 10 K
(g cm–2)
S
Figure 1 | Critical and equilibrium light-to-mass ratios versus cloud column
density. The plot shows the critical light-to-mass ratio ghalt (solid lines) and
the equilibrium light-to-mass ratio ggrav due to low-mass star formation
(dashed lines) as a function of the cloud column density S. The three curves
for ghalt are computed for d 5 1, Tb 5 10 K, for d 5 1/4, Tb 5 10 K, and for
d 5 1/4, Tb 5 15 K, as indicated. The two sets of curves for ggrav are
computed for M 5 20M[ and M 5 200M[, as indicated, corresponding to
the clouds that would be required to form 10M[ and 100M[ stars for a
typical star-formation efficiency27 of 50%. In each pair the lower curve
corresponds to Tb 5 10 K and the upper to Tb 5 15 K. Note that the
background temperature can be higher than our assumed Tb in regions near
massive stars, but it is unclear whether massive stars in a cluster ever form
close enough in time that the first to form can affect the formation of
subsequent ones. In the Orion Nebula28 and W3 Main29 clusters, all the stars
larger than 10M[ that remain today formed over a time spread of less than
about 105 yr. This is comparable to the formation time of a single massive
star30, so that the last massive star to form must have been well in progress by
the time the first began to heat its envelope. Even in non-coeval clusters, our
approach applies to the first massive stars.
NATURE |Vol 451 |28 February 2008
LETTERS
1083
Nature


Publishing Group
©2008
Ha emission are both tracers of recent star formation but are sensitive
 to different parts of the IMF. Outside the gravitational stability
radius, the molecular-to-atomic surface density ratio drops sharply25,
probably because purely local instabilities create small molecular
clouds but not giant complexes like those in the inner parts of disks.
Because compressing gas to column densities of Sth requires a huge
amount of weight that can only be provided by such giant complexes,
their absence will selectively suppress the formation of the most
massive stars, leading to a truncated IMF. If in such a region no stars
larger than, for example, 15M[ were to form, this would reduce
ultraviolet emission by ,50% but would eliminate more than 99%
of the Ha light26, explaining the sharp drop in Ha but not in the
ultraviolet.
An important corollary is that estimates of the star formation
rate assuming a standard IMF in regions that do not contain giant
clouds (such as much of the volume of dwarf galaxies and the outer
parts of disk galaxies) may be systematically too low. At this point
our theory is too approximate to allow a precise calculation of the
underestimate.
Our calculation of Sth also enables us to predict how the characteristic
 column densities of young clusters containing massive stars
will vary between galaxies. We predict that clusters that have cleared
their gas but not yet dynamically expanded should show a minimum
column density near Sth (probably slightly below Sth, owing to gas
removal), and this should be lower at low metallicity and higher at
high redshift, as indicated in Fig. 3.
Received 17 October; accepted 20 December 2007.
1.
Larson, R. B. Thermal physics, cloud geometry and the stellar initial mass function.
Mon. Not. R. Astron. Soc. 359, 211–222 (2005).
2.
Jappsen, A.-K., Klessen, R. S., Larson, R. B., Li, Y. & Mac Low, M.-M. The stellar
mass spectrum from non-isothermal gravoturbulent fragmentation. Astron.
Astrophys. 435, 611–623 (2005).
3.
Bonnell, I. A., Clarke, C. J. & Bate, M. R. The Jeans mass and the origin of the knee in
the IMF. Mon. Not. R. Astron. Soc. 368, 1296–1300 (2006).
4.
Krumholz, M. R. Radiation feedback and fragmentation in massive protostellar
cores. Astrophys. J. 641, L45–L48 (2006).
5.
Krumholz, M. R., Klein, R. I. & McKee, C. F. Radiation-hydrodynamic simulations of
collapse and fragmentation in massive protostellar cores. Astrophys. J. 656,
959–979 (2007).
6.
Plume, R., Jaffe, D. T., Evans, N. J., Martin-Pintado, J. & Gomez-Gonzalez, J. Dense
gas and star formation: Characteristics of cloud cores associated with water
masers. Astrophys. J. 476, 730–749 (1997).
7.
Mueller, K. E., Shirley, Y. L., Evans, N. J. & Jacobson, H. R. The physical conditions
for massive star formation: Dust continuum maps and modeling. Astrophys. J.
Suppl. Ser. 143, 469–497 (2002).
8.
Shirley, Y. L., Evans, N. J., Young, K. E., Knez, C. & Jaffe, D. T. A CS J 5 5 R 4
mapping survey toward high-mass star-forming cores associated with water
masers. Astrophys. J. Suppl. Ser. 149, 375–403 (2003).
9.
McKee, C. F. & Tan, J. C. The formation of massive stars from turbulent cores.
Astrophys. J. 585, 850–871 (2003).
10. Martin, C. L. & Kennicutt, R. C. Star formation thresholds in galactic disks.
Astrophys. J. 555, 301–321 (2001).
11.
Boissier, S. et al. Radial variation of attenuation and star formation in the largest
late-type disks observed with GALEX. Astrophys. J. Suppl. Ser. 173, 524–537
(2007).
12.
Heyer, M. H. & Brunt, C. M. The universality of turbulence in galactic molecular
clouds. Astrophys. J. 615, L45–L48 (2004).
13.
Chakrabarti, S. & McKee, C. F. Far-infrared SEDs of embedded protostars and
dusty galaxies. I. Theory for spherical sources. Astrophys. J. 631, 792–808 (2005).
14. Neufeld, D. A., Lepp, S. & Melnick, G. J. Thermal balance in dense molecular
clouds: Radiative cooling rates and emission-line luminosities. Astrophys. J. Suppl.
Ser. 100, 132–147 (1995).
15.
Young, K. E., Lee, J.-E., Evans, N. J. II, Goldsmith, P. F. & Doty, S. D. Probing preprotostellar
 cores with formaldehyde. Astrophys. J. 614, 252–266 (2004).
16.
Urban, A., Evans, N. J. II & Doty, S. D. A parameter study of the dust and gas
temperature in a field of young stars. Astrophys. J. (submitted); preprint at
AEhttp://arXiv.org/abs/0710.3906æ (2007).
17.
Weingartner, J. C. & Draine, B. T. Dust grain-size distributions and extinction in
the Milky Way, Large Magellanic Cloud, and Small Magellanic Cloud. Astrophys. J.
548, 296–309 (2001).
18.
Wu, J. et al. Connecting dense gas tracers of star formation in our galaxy to high-Z
star formation. Astrophys. J. 635, L173–L176 (2005).
19.
Chabrier, G. in The Initial Mass Function 50 Years Later (ed. Corbelli, E., Palla, F. &
Zinnecker, H.) 41–50 (Springer, Dordrecht, 2005).
20. Tan, J. C., Krumholz, M. R. & McKee, C. F. Equilibrium star cluster formation.
Astrophys. J. 641, L121–L124 (2006).
21.
Krumholz, M. R. & Tan, J. C. Slow star formation in dense gas: Evidence and
implications. Astrophys. J. 654, 304–315 (2007).
22. Krumholz, M. R. & McKee, C. F. A general theory of turbulence-regulated star
formation, from spirals to ultraluminous infrared galaxies. Astrophys. J. 630,
250–268 (2005).
23. Bonnell, I. A., Vine, S. G. & Bate, M. R. Massive star formation: nurture, not nature.
Mon. Not. R. Astron. Soc. 349, 735–741 (2004).
24. Motte, F. et al. The earliest phases of high-mass star formation: a 3 square degree
millimeter continuum mapping of Cygnus X. Astron. Astrophys. 476, 1243–1260
(2007).
25. Braine, J., Ferguson, A. M. N., Bertoldi, F. & Wilson, C. D. The detection of
molecular gas in the outskirts of NGC 6946. Astrophys. J. 669, L73–L76 (2007).
26. Parravano, A., Hollenbach, D. J. & McKee, C. F. Time dependence of the ultraviolet
radiation field in the local interstellar medium. Astrophys. J. 584, 797–817 (2003).
27. Matzner, C. D. & McKee, C. F. Efficiencies of low-mass star and star cluster
formation. Astrophys. J. 545, 364–378 (2000).
28. Huff, E. M. & Stahler, S. W. Star formation in space and time: The Orion Nebula
Cluster. Astrophys. J. 644, 355–363 (2006).
29. Feigelson, E. D. & Townsley, L. K. The diverse stellar populations of the W3 star
forming complex. Astrophys. J. 673, 354–362 (2008); preprint at
AEhttp://arXiv.org/abs/0710.0090æ (2007).
30. McKee, C. F. & Tan, J. C. Massive star formation in 100,000 years from turbulent
and pressurized molecular clouds. Nature 416, 59–61 (2002).
Supplementary Information is linked to the online version of the paper at
www.nature.com/nature.
Acknowledgements We acknowledge S. Boissier, I. Bonnell, B. Elmegreen,
E. Feigelson and C. Martin for discussions. We thank A. Urban, N. Evans and S. Doty
for providing a copy of their grain–gas coupling code. This work was supported by
NASA through the Hubble Fellowship program and by the NSF. Parts of this work
were performed while the authors were in residence at the Kavli Institute for
Theoretical Physics at UCSB.
Author Information Reprints and permissions information is available at
www.nature.com/reprints. Correspondence and requests for materials should be
addressed to M.R.K. (krumholz@astro.princeton.edu).
10.0
1.0
0.1
10
100
d = 1/4, Tb = 15 K
d = 1/4, Tb = 10 K
d = 1, Tb = 10 K
th (g cm–2)
S
m* (M  )
Figure 3 | Threshold column density versus stellar mass. The plot shows
the threshold column density Sth required to form a star of mass m* for
d 5 1, Tb 5 10 K, for d 5 1/4, Tb 5 10 K, and for d 5 1/4, Tb 5 15 K, as
indicated. In making the plot we assumed an efficiency of 50% (ref. 27), so
that the cloud mass required to make a star of mass m* is M 5 2m*.
LETTERS
NATURE |Vol 451 |28 February 2008
1084
Nature


Publishing Group
©2008
Introduction
The birth and evolution of star clusters are seamlessly tied to the
process of star formation. Most stars are formed in clustered
structures (Lada & Lada 2003), but only a fraction of them are
forming in gravitationally bound clusters, while the remaining stars
will be quickly dispersed in the stellar field of the galaxy (e.g.,
Bastian 2008; Longmore et al. 2014). The formation, the temporal
and spatial evolution, and the physical and chemical properties of
star clusters trace the dynamical evolution of galaxies and their
merger history, provide insights into the origin and persistence of
spiral arms, and constrain the mechanisms that govern and regulate
star formation. In recent years, the Hubble Space Telescope (HST)
has provided detailed observations for large samples of young
star clusters (YSCs; age<300 Myr) in nearby galaxies, allowing
detailed studies of their physical properties, which are fundamental
for understanding their formation and evolution. The distributions
of clusters’ luminosities and masses are tracers of the mechanisms
of cluster formation (e.g., Whitmore et al. 1999; Larsen 2002;
Gieles et al. 2006a, 2006b; Mora et al. 2009; Whitmore et al.
2010, 2014; Johnson et al. 2017) and of the fraction of star
formation that takes place in bound clusters (e.g., Bastian et al.
2012; Adamo et al. 2015; Chandar et al. 2015; Johnson et al. 2016;
Messa et al. 2018b), while the age distributions reveal how rapidly
clusters are disrupted (e.g., Gieles et al. 2006c; Gieles 2009;
Bastian et al. 2012; Chandar et al. 2014, 2016; Silva-Villa et al.
2014; Adamo et al. 2017; Messa et al. 2018a).
Throughout the literature, observations show that both the
initial cluster mass and luminosity functions (CMF and CLF,
respectively) are well described by a power-law slope ∼−2,
which traces the hierarchical star-forming structures from which
YSCs emerge (Whitmore et al. 1999, 2010, 2014; Larsen
2002; Bik et al. 2003; Gieles et al. 2006a, 2006c; Mora et al.
2009; Chandar et al. 2014; Adamo et al. 2017; Messa et al.
2018b, among many others). However, recent measurements
have uncovered a dearth in the number of very massive clusters
(105 Me) in nearby spirals, suggesting that the formation of
massive clusters may be disfavored in these environments
(Adamo et al. 2015; Johnson et al. 2017; Messa et al. 2018b).
This dearth, or truncation mass, may depend on the galactic
environment in a similar manner to what is observed for the
fraction of star formation in clusters and the disruption strength
of clusters. Variations in the truncation mass appear to be present
both between galaxies with different global properties (e.g.,
Johnson et al. 2017) and between subregions of the same galaxy
that trace different environments (Silva-Villa et al. 2014; Adamo
et al. 2015; Messa et al. 2018a), but the issue is far from settled
(e.g., Chandar et al. 2017; Mok et al. 2019, 2020).
The main impediment to reach a consensus on the role of
environment on clusters’ formation and evolution is the absence
of large samples of uniformly selected YSCs across a wide range
of galaxies’ properties. The HST Treasury Program Legacy
ExtraGalactic UV Survey (LEGUS; GO-13364) attempted to fill
this gap by observing 50 nearby (d16 Mpc) galaxies in five
broad bands, from the near-UV (NUV) to the I, with the goal of
extracting YSC catalogs with well-defined physical properties
(Calzetti et al. 2015). While star clusters are easily detectable up to
≈100 Mpc, at distances where individual stars are no longer so,
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
https://doi.org/10.3847/1538-4357/abceba
© 2021. The American Astronomical Society. All rights reserved.
* Based on observations obtained with the NASA/ESA Hubble Space
Telescope, at the Space Telescope Science Institute, which is operated by the
Association of Universities for Research in Astronomy, Inc., under NASA
contract NAS 5-26555.
1
their identification is challenging. The clusters, especially those
younger than a few gigayears, are projected against the uneven
background of the host galaxyʼs disk, and their colors are often
similar to those of the surrounding stellar populations or of
background galaxies. Confusion, artifacts, and isolated or chance
superposition of stars are the main reasons for the failure of
automatic approaches that rely on physical or geometrical
parameterization (source concentration, colors, luminosity, symmetry,
 etc.). These contaminants are usually culled from automatic
catalogs via visual inspection, a labor-intensive approach that
requires humans to evaluate each source individually, with often
inconsistent results among different classifiers. The need for
human intervention explains the limited number of star cluster
catalogs commonly available in the literature and the fact that the
LEGUS collaboration has released catalogs for only 31 of their 50
galaxies, two-thirds of which are for sparsely populated dwarfs
(Cook et al. 2019).
Crowdsourcing approaches (e.g., “citizen science”), while
effective when the galaxies are located in the Local Group and
the clusters are projected against a sparse stellar field (like in
the case of the galaxy M31; Johnson et al. 2015), become
ineffective once the galaxies are beyond a few megaparsecs and
the star clusters are projected against an unresolved and uneven
background. In these conditions, even human experts have
difficulties yielding reproducible classifications: the same
individual is usually able to reproduce their own classifications
less than 90% of the time, and different experts do not agree
among themselves to better than about 70%–75% of the time,
across four identification classes (Adamo et al. 2017; Grasha
et al. 2019; Wei et al. 2020). Thus, training of citizen classifiers
becomes time-consuming and low-yield; an experiment run by
the LEGUS collaboration using a citizen science platform
yielded close-to-random classifications for galaxies at about
10 Mpc distance.
Machine learning (ML) and computer vision in particular
offer tools that can potentially be game changers for the field:
they can be trained to reproduce at least the level of quality of
expert classifiers; their classifications are self-consistent and
reproducible; and they require a tiny fraction of the time, thus
enabling multiple classification trials to be applied to the same
catalog, as the training sets improve. Visual recognition is a
core research activity of the computer science community that
is finding increasing applications in astronomy, including
classification of galaxies (Domínguez Sánchez et al. 2018;
Khan et al. 2019; Barchi et al. 2020), galaxies’ mergers
(Ackermann et al. 2018; Ćiprijanović et al. 2020), and galaxy
morphology (Dieleman et al. 2015; Walmsley et al. 2018), and
will be the key tool for future petabyte-size catalogs (e.g., from
the Vera C. Rubin Observatory). ML algorithms have been
recently applied also to the morphological classification of
YSCs (Grasha et al. 2019; Wei et al. 2020). In Grasha et al.
(2019), a bagged decision tree algorithm was implemented on
the galaxy pair NGC5194+5195, after training on a small
number of LEGUS cluster catalogs. Wei et al. (2020) trained
and tested deep learning algorithms using a larger sample of
LEGUS catalogs than that of Grasha et al. (2019). We will
compare our results with these earlier papers in Section 5.
The goal of this paper is to design a deep network to classify star
cluster candidates trained on the largest and most robust catalogs
available and improve on previous approaches. We develop a
three-pathway
convolutional
neural
network
(CNN)
called
STARCNET to classify star clusters in the LEGUS five-band
images (Figure 1); our approach consists of applying a CNN to the
region surrounding each cluster candidate at three increasing
magnification levels and then combining the resulting outputs to
produce a classification using a four-class morphological scheme
(Adamo et al. 2017). For training, we use the entire collection of
identified LEGUS star clusters from all released catalogs (Adamo
et al. 2017), both to increase the number of examples and to use
catalogs classified by multiple experts.
This paper is organized as follows: In Section 2 we present
the catalogs and images from the LEGUS project used in this
work. In Section 3 we describe the architecture of STARCNET,
while we test different configurations in Section 4. We discuss
the performance of our approach in Section 5. In Section 6 we
study the average cluster properties in each of the four
morphological classes, focusing on how the classification given
by STARCNET affects them. Finally, we briefly present the
outlook for future developments in Section 7 and summarize
our results in Section 8.
2. Data and Catalogs
The LEGUS survey consists of 50 galaxies at distances
between 3.5 and ∼16 Mpc, observed in 63 pointings with the
HST in five broad bands, using either the WFC3/UVIS camera or
archival ACS/WFC images when available. The five bands are
NUV (WFC3-F275W filter), U (WFC3-F336W filter), B (either
Figure 1. Graphic sketch of the STARCNET ML pipeline used in this work to classify cluster candidates in the LEGUS images. Left: Hubble Space Telescope images
as processed by the LEGUS project through a custom pipeline to generate automatic catalogs of cluster candidates, which are part of the public LEGUS catalog release
(Calzetti et al. 2015; Adamo et al. 2017); we apply STARCNET to the LEGUS catalogs and images. Middle left: the region surrounding each candidate is selected from
the five-band images at three magnifications and is used as input to our multiscale STARCNET. Middle right and right: each of the three pathways of the CNN consists
of seven convolutional layers, which are later connected to produce a prediction for the candidate in one of four classes.
2
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
WFC3-F438W or ACS-F435W filter), V (WFC3-F555W, ACSF555W,
 or ACS-F606W filter), and I (either WFC3-F814W or
ACS-F814W filter). A full description of the project, the sample
selection, and the observing strategy is provided in Calzetti et al.
(2015). Automatically generated catalogs of star cluster candidates
were produced using a six-step pipeline as described in Adamo
et al. (2017) and are publicly available at the Mikulski Archive for
Space Telescopes (MAST) for 31 galaxies, in 37 separate
pointings.4 The six steps are described in detail in Adamo
et al. (2017); in brief, they consist of running SExtractor (Bertin
& Arnouts 1996) on the HST processed and aligned images,5
applying basic selection functions to remove as many stars and
artifacts as possible, and generating aperture-corrected photometry.
 Subsequently, spectral energy distribution fits are
performed on cluster candidates that are detected in at least
four separate bands, to derive ages, masses, and extinction and
their uncertainties. Finally, visual classification is performed
on candidates that are brighter than V = −6 mag (Adamo et al.
2017), as the automatic selection still leaves about 50%
contaminants in the catalogs (Table 1).
The visual classification was performed by at least three human
classifiers in the LEGUS team, with an additional one or two
tiebreakers for ambiguous cases, using the following morphologybased
 classification scheme (Figure 2; more details in Adamo
et al. 2017):
1. Class 1:symmetric, compact objects, with a light
distribution more extended than the stellar one.
2. Class 2:compact objects with slightly elongated density
profiles.
3. Class 3:multiple peak systems on top of diffuse underlying
 emission, referred to as compact associations.
4. Class 4:spurious detections (foreground/background
sources, single bright stars, asterisms, artifacts); this class
Table 1
Data Set Statistics
Train Set
Validation Set
Test Set
Total Data Set
Total class 1
1765
196
528
2489 (16.09%)
Total class 2
2225
247
612
3084 (19.93%)
Total class 3
2192
244
617
3053 (19.73%)
Total class 4
4956
551
1338
6845 (44.24%)
Total
11,138 (72.00%)
1238 (8.00%)
3095 (20.00%)
15,471 (100.00%)
Note. Classification statistics of the star clusters in training, validation, and test splits of the LEGUS data set. The distribution of star clusters across the 31 galaxies in
the data set is included in Appendix B.
Figure 2. LEGUS classification scheme. Examples of candidates from the LEGUS images of NGC 1566 classified as Class 1 (symmetric star cluster; top), Class 2
(elongated star cluster; middle top), Class 3 (compact, multipeak association; middle bottom), and Class 4 (spurious object; bottom). The three-color image to the left
is created using the NUV and U bands for the blue channel, the B band for the green one, and the V and I bands for the red one. The contour and 3D plots from the V
band are shown to the right of the figure.
4
https://archive.stsci.edu/prepds/legus/; the different pointings of NGC
5194 + NGC 5195 are combined into a single catalog, for a total of 34 separate
star cluster catalogs.Doi:10.17909/T9J01Z .
5
All LEGUS images are aligned and sampled to a common pixel scale,
0 04 pixel−1.
3
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
is highly inhomogeneous, as it contains everything that
the classifiers deemed a “noncluster.”
The three (or more) independent classifications were then
combined into a final class label, defined as the mode of the
classifications of each candidate. The catalogs with classified
cluster candidates for the 31 LEGUS galaxies available from
the MAST Archive include a total of around 15,000 candidates
across the four classes. The 31 galaxies span the full range of
distances of the LEGUS sample. A detailed presentation and
discussion of the classification approach for the LEGUS sample
will be given in a forthcoming paper (H. Kim et al. 2020, in
preparation), and we report in Appendix B a summary of the
distribution of cluster candidates by class for each galaxy,
along with the galaxy distance. These catalogs are the focus of
the present work, and their cumulative statistics are listed in
Table 1.
We use the location of each source as listed in the catalogs to
produce 32×32 pixel (∼1 3×1 3) cutouts from the images
in the five bands, which we use as inputs for our algorithm; we
call these cutouts “input arrays” in the remainder of the paper.
We split the data set of the classified sources in a uniformly
random fashion (as in Table 1) as follows: 80% of the total
classified sources are used for training and validation (trainval
set), and the remaining 20% for testing. From the trainval set,
we use 90% of the classified candidates for training and the
remaining 10% for validation.6
2.1. Accuracy of Human Classifications
In order to evaluate the level of accuracy we can achieve
with the ML predictions, we compare classifications from
different individuals among themselves, as a metric for the
highest possible agreement that can be reached between ML
and humans. Individual classifications (as opposed to the mode
or final classification) are available for a total of ∼6000 sources
across 13 galaxies.7 The fraction of sources with the same
classification, weighted by the number of sources in each class,
gives the agreement among the two classifiers. We take the
mean of all the possible combinations of classifiers as the mean
agreement. The resulting agreement among two separate
classifiers is 57.3%, as shown by the confusion matrix in
Figure 3 (left panel). When instead the labels given by each
classifier are compared with the final classification, the mean
agreement is 75.0% (Figure 3, right panel). The higher level of
agreement between any individual classifier and the final
classification is also due to the degeneracy that the final
classification includes the classifier’s own classification. We
can, therefore, expect that a well-constructed ML algorithm
will yield accuracies above the 57.3% level of the individualto-individual
 comparison, but not quite at the 75% level of
the individual-to-final comparison for our samples, because the
ML-to-final classification comparison does not include the
same degeneracy as the individual-to-final one.
The agreement is not uniform across classes, as it is higher
for classes 1 and 4 and is the lowest in class 3. Class3 indeed
remains the most challenging class to recognize, as the
detection of diffuse emission underlying multiple peaks
depends on the depth of the image (Adamo et al. 2017). The
agreement is not even uniform across different galaxies, as it
goes from ∼95% in NGC 3738 (over 400 sources) to less than
50% in NGC 628 (∼1800 sources). The level of (dis)agreement
highlights the difficulty of performing morphological classifications
 of sources embedded in unresolved galaxies. The
Figure 3. Consistency of human classification. Mean confusion matrices for the comparison between independent human classifiers (left panels) and for the
comparison of a human classifier with the final (mode) classification (right panels). The overall accuracies are 57.3% and 75.0% for the four-class classifications and
78.1% and 87.2% for the binary classifications, respectively.
6
The training set is the sample of data used to fit the model. The validation
set is the sample of data used to provide an intermediate evaluation of a model
fit on the training data set while tuning model hyperparameters. The test set is
the sample of data used to provide an unbiased evaluation of a final model fit
on the training data set.
7
This number is smaller than the total ∼15,000 sources visually classified, as
it is limited by the current availability of single-classifier files within the
LEGUS collaboration.
4
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
variations in the level of disagreement may be contributed by
the large number of people (>10) involved in the classification
process, which introduces personal biases. However, the
overall agreement is in line with what was found in similar
comparisons by other authors (Grasha et al. 2019; Wei et al.
2020), indicating that (1) the LEGUS classifications are as
robust as any others found in the literature and (2) we should
expect the predictive accuracy of our ML algorithm to be no
better than about 70%–75% when measured against human
labels. In Appendix A we present the most frequent cases of
misclassification along with additional examples.
2.2. Binary Classification
For a number of applications, cluster samples do not need to
have the detailed four-class morphological classification developed
 by LEGUS, and a binary (cluster/noncluster) classification
suffices. We will test the accuracy of STARCNET for binary
classifications on our samples by aggregating class 1 and 2 as the
“clusters” class and class 3 and 4 as the “nonclusters” class (as,
e.g., in Bastian et al. 2012; Adamo et al. 2015; Hollyhead et al.
2016; Messa et al. 2018b). The human agreement between
classifiers, presented in the previous section, increases noticeably
when a binary classification is adopted; the human-to-human
agreement of the LEGUS sample increases from 57.3% to
78.1%, while the human-to-mode agreement increases from
75.0% to 87.2% (bottom panels of Figure 3). There is no
consensus in the literature about excluding class3 sources from
the “cluster” class; we discuss in Section 5.2 the accuracies
resulting from considering different binary classifications. In the
same section, we discuss the results of training STARCNET
directly on binary classification.
3. Method
Our approach to star cluster classification is based on a deep
CNN. Over the past decade CNNs have emerged as the leading
model in many visual recognition tasks such as categorization
of images, semantic segmentation, and object detection. The
proposed network called STARCNET is based on networks used
for color image classification but is modified to take into
account the multiple channels, normalization, and multiscale
spatial context of the input. STARCNET chains simple building
blocks or layers to form a network, and it uses gradient-based
optimization of all the parameters of these layers using
backpropagation of a loss function, which measures how far
off the result produced by the model is from the expected result
on training data (Section 3.1). Modern libraries for deep
learning (e.g., Tensorflow, Abadi et al. 2015; PyTorch, Paszke
et al. 2019) allow a modular definition of the network
architecture and support gradient-based learning of parameters
given a data set of objects with class labels. Below we provide
an overview of the relevant building blocks.
3.1. Background
CNN.—A CNN is a parameterized function y=f (x; θ),
mapping inputs x to outputs y given parameters θ. The network
consists of layers denoting sequential operations that transform
the input to its output. We will denote the inputs to layer l as
Φ(l) and its output as Φ(l+1). Thus, a convolutional network with
n layers has Φ(1)=x and Φ(n+1)=y. Common layers for
convolutional network are as follows:
1. Convolution layer: A convolutional layer consists of
applying a set of filters over inputs with spatial
dimensions. For images, the inputs to the layer l are 3D
arrays of size F
Î
´ ´

l
h
w
c
( )
, where h and w denote the
spatial dimensions (e.g., height and width) and c denotes
the number of channels. For example, the first convolutional
 layer of our network takes an input represented as a
3D array of 32×32 pixels×5 bands. A convolutional
layer with k filters is parameterized by filter weights
Î
´ ´ ´

w l
m
n
c
d
( )
and bias
Î 
b l
d
( )
, producing an output
F
Î
+
¢´ ¢´

l
h
w
d
1
(
)
, where m and n are the filter spatial
dimensions,
c
is
the
number
of
channels
(which
corresponds to the number of channels c of the input to
the layer l), and d is the number of filters. The output
Φ(l+1) of a convolution layer is a set of d feature maps. A
feature map can be thought of as a representation of the
input or as a response of a single filter di applied to the
input Φ(l). The output at a location (x, y) for a filter d is
given by
å å å
F
=
F
-
´

+
=
¼
+
=
=
=
1
x y z
x
i y
j k
w i j k z
b
z
z
d
, ,
,
,
, ,
,
, for
1, 2,
,
.
l
i
m
j
n
k
c
l
l
1
1
1
1
( )
[
]
[
]
[
]
[ ]
{
}
(
)
( )
( )
Convolution layers are used as feature extractors of the
input array. We use three different sets of convolution
layers to extract features of each input array at three
different magnifications. The extracted features from the
three pathways are then combined using a fully connected
layer.
2. Pooling layer: Pooling replaces the value in a neighborhood
 with an overall statistic, such as the max or avg,
resulting in reduction of the spatial dimension of the input
and adding invariance to small deformations. The layer is
parameterized by the neighborhood size over which the
overall statistic is computed and stride denoting the offset
between neighborhoods. For example, pooling an input
F
Î
´ ´

l
h
w
d
( )
with a stride k leads to an output
F
Î
+
´
´

l
h k
w k
d
1
(
)
. The parameters are set manually
and are typically not learned. Our network uses a pooling
layer after the fourth convolution layer on each of the
pathways of our network as shown in Figure 1.
3. Nonlinear activation layer: These layers are based on
applying a nonlinear transformation to the input. Some
commonly used nonlinear activation layers are as follows:
rectified linear unit (Nair & Hinton 2010),
=
x
ReLU( )
x
max 0,
(
); Leaky ReLU (Maas et al. 2013),
=
x
LReLU( )
r
+
x
x
max 0,
min 0,
(
)
(
), where ρ is a positive number;
and sigmoid, s
=
+
x

x
1
1
exp
( )
(
(
)). Nonlinearities
allow the network to learn complex mappings between
inputs and outputs. These are typically applied after each
convolution and fully connected layer in a network.
4. Fully connected layer: These layers are common for
inputs with no spatial dimensions and connect all inputs
F
Î 
l
m
( )
to outputs F
Î
+

l
n
1
(
)
via a weight matrix
Î
´

w l
m
n
( )
and bias
Î 
b l
n
( )
:
F
= F
+
+
w
b .
2
l
l
l
l
1
( )
(
)
( )
( )
( )
Fully connected layers are usually used as the latter layers
to learn the classifier part of the network. In our case they
are also used to combine the features of each of the
pathways as shown in Figure 1.
5
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
5. Dropout layer: With dropout (Srivastava et al. 2014), a
vector r(l) of independent Bernoulli random variables
(each of which has probability p of being 1) is multiplied
element-wise with the outputs of the previous layer Φ(l) to
produce thinned outputs F
= F
r
l
l
l
*
( )
( )
( )

before using
them as inputs for the next layer. If dropout is used, the
output of a layer is given by
F
= F
+
+
w
b .
3
l
l
l
l
1
*
( )
(
)
( )
( )
( )
Randomly dropping activations during training has been
shown to improve generalization.
CNNs stack several blocks of convolution−pooling−nonlinear
 layers. The hierarchical nature of the network allows the
emergence of simple features such as edges and blobs in the
early layers and complex features such as a human face in
higher layers. Modern CNNs contain up to hundreds of these
blocks, totaling millions of parameters, and are highly effective
for visual recognition.
Data set and training.—A labeled data set consists of pairs
=
x
y
,
i
i
i
N
1
{(
)}
. In our case each xi is a cluster candidate and yi is its
class label (1 through 4). All the parameters θ corresponding to
the layers of the network, e.g., the filter and bias weights of the
convolutional layers, must be learned. This is done by
minimizing a loss ℓover the training set plus a regularization
term R(θ) over the parameters:
å
q
q
q
¬
+
q
=
ℓf x
y
R
arg min
;
,
.
4
i
N
i
i
1
⎛
⎝
⎜
⎞
⎠
⎟
ˆ
( (
)
)
( )
( )
The loss measures the error between the network’s prediction
and class labels, while the regularization encourages simpler
models. A common regularization is the squared ℓ2 norm of the
parameters, i.e.,
q
q
=
R
2
2
( )
∣∣∣∣. In the classification setting the
predictions
q
=
y
f x;
ˆ
(
) denote the probability of C target
classes, and class labelsy denote the one-hot encoding of the
correct class (i.e., a vector with length equal to the number of
categories in the data set with value 1 in the class position and 0
elsewhere), and we use the cross-entropy loss denoted by
å
= =

ℓy y
y
y
,
log
.
5
k
C
k
k
1
( ˆ
)
ˆ
( )
( )
( )
Training on large data sets is computationally demanding, as
computing gradients require summation over the entire data set
(Equation (4)). A common practice is to perform stochastic
gradient descent where a small batch of training examples are
selected at random at each iteration, and the gradient Δθ( t) of
the loss with respect to the current parameters θ( t) is obtained
by backpropagating the gradients of the loss:
å
q
q
q
g q
D
=
¶
¶
+
¶
¶
q
q
Î
=

ℓf x
y
R
;
,
.
6
t
x y
,
t
⎜
⎟
⎛
⎝
⎜
⎜
⎛
⎝
⎞
⎠
⎞
⎠
⎟
⎟
( (
)
)
( )
( )
(
)
( )
The parameters are updated by taking a step η in the negative
direction of the gradient:
q
q
h
q
=
D

+
.
7
t
t
t
1
( )
(
)
( )
( )
The overall training consists of initialization of the weights θ
and performing gradient updates for a number of iterations until
the loss on a validation set stops decreasing. Initialization is
either random or obtained by training the network on a different
task (e.g., in the setting of transfer learning). A number of
modifications have been proposed to this basic scheme that
include feature normalization schemes that allow larger step
sizes (e.g., batch normalization, Ioffe & Szegedy 2015; layer
normalization, Ba et al. 2016), novel layer blocks (e.g.,
highway, Srivastava et al. 2015; residual, He et al. 2015;
squeeze-excite, Hu et al. 2017; bilinear, Lin et al. 2015), and
optimization techniques (e.g., Adam, Kingma & Ba 2015;
AdaGrad, Duchi et al. 2010). These have allowed training
larger networks on bigger data sets, often leading to improved
generalization. See Goodfellow et al. (2016) for a detailed
background on CNNs.
Data augmentation.—A common practice in training deep
networks is to synthetically augment the training data by
adding random transformations to the input that do not change
the class label. These include injecting noise into the pixel
values, performing image scaling, rotations, and translations.
Our images are centered at the star cluster, so we would expect
full rotational and mirror symmetry, but not to scaling and
translations. The effect of data augmentation is described in
Section 4.
Transfer learning.—Training deep networks with millions of
parameters on small data sets poses a risk of overfitting.
Transfer learning is a strategy to alleviate this problem. In this
scheme the network is first trained on a large data set of labeled
objects and then fine-tuned by modifying a small number of the
parameters on a target data set where labels or human
classifications are limited. The efficacy of the transfer depends
on how close the source and target data sets are, as well as
the fine-tuning strategy that is employed. A key reason for the
popularity of deep networks is that CNNs trained on the
ImageNet data set (Deng et al. 2009), which consists of
millions of images of common objects (plants, flowers,
animals, etc.) taken from the internet, have been shown to
transfer well to a wide variety of visual recognition tasks.
However, such networks are trained on three-band RGB
images, which is challenging to transfer to astronomical
classifications if the latter use a larger number of bands. In
the case of star clusters from the LEGUS project, the input
arrays consist of five bands. When training a CNN from
scratch, we can directly design the convolutional layers to have
the appropriate number of channels, one per band. But when
performing transfer training, the input or the lower layers of the
network need to be adapted to enable transfer. One strategy is
to manually combine the astronomical images and reduce them
to the three-band RGB color images; a second strategy is to
learn the transformation as part of the transfer learning strategy.
We discuss these schemes in Section 4. We note that, in the
case of the present work, the ∼15,000 classified sources
available across the four classes are enough to train our deep
network, as shown by the accuracy achieved by STARCNET (in
particular see Table 3 in Section 4).
Evaluation metric.—We use the accuracy for the four-class
classification on the test set as the primary metric to compare
models. We also visualize the confusion matrices that indicate
the distribution of the errors made by the model, as well as
recall and precision. The confusion matrix of our best model is
shown in Figure 4.
6
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
3.2. STARCNET Architecture and Training
Network architecture.—The best-performing STARCNET is a
three-pathway architecture that simultaneously processes three
input arrays of the same source at three different scales.To build
the magnified input arrays, we center crop and resize them back to
32×32 pixels using nearest-neighbor interpolation, so all the
input arrays have the same pixel size despite containing visual
information at three different magnifications, as shown in Figure 1.
STARCNET is a function y=f(x1, x2, x3; θ) that receives as input
three object-centered arrays
Î
´
´

x
x
x
,
,
1
2
3
32
32
5 and outputs
Î 
y
4, the probability distribution over the four categories. The
three input arrays x1, x2, and x3 contain the photometric
information of a single object at three different magnifications
(1×, 1.6×, and 3.2×). Each input array is passed through a single
pathway or subnetwork yi=f(xi; θi) for i=1, 2, 3. Each pathway
is composed of seven modules, with each module consisting of a
convolutional layer, group normalization (Wu & He 2018), and
Leaky ReLU activation layer. All convolutional layers contain
3×3 filters. After the fourth module we add a pooling layer to
obtain a global representation of the input. The extracted features
Î 
yi
m from each pathway are then concatenated into vector
yc=[y1 y2 y3] and passed though a fully connected layer y=f(yc;
θfc) to output a probability distribution
Î 
y
4 over the target
labels.
Training.—The learnable parameters θ={θ1, θ2, θ3, θfc}
corresponding to the three pathways and the combination layer
are initialized with Xavier initialization(Glorot & Bengio 2010)
and trained using the ADAM optimizer(Kingma & Ba 2015).
Xavier initializes the weights by drawing them independently
from a Gaussian distribution
s
0,
2
(
), with σ2=1/k, where k
is the dimension of the input. The entire network is trained for
15 epochs (one epoch is a full pass over the training set) using a
learning rate of η=1E−04 and cross-entropy loss as described
in Equation (4). We determine the number of training epochs
by selecting when the best validation performance is achieved.
4. Experiments
This section is dedicated to ablation studies of STARCNET,
by altering parameters one by one in the input arrays and in the
network, to investigate their effect on the output accuracy of
the classifications.
4.1. Classification Accuracy on LEGUS
As mentioned in Section 2, the trainval set (the set used for
training and validation) contains 80% of the total number of
star cluster candidates. We use 10% of the trainval set as
validation set to conduct hyperparameter tuning and architecture
 choices. The test set, containing the remaining 20% of the
total cluster candidates, is used for testing the pipeline. We
carry out transfer learning experiments using state-of-the-art
pre-trained models. We perform the evaluation using a
confusion matrix normalized over the human classifications
(rows) and the overall accuracy for comparison between
models. In addition, we include precision−recall (PR) curves to
show the trade-off between the precision and the recall for
every possible cutoff in the prediction score for each class. The
performance of our model STARCNET described in Section 3.2
is shown in Figure 4. The overall accuracy of STARCNET
evaluated on the test set of the LEGUS data set is 68.6% when
four classes are used and 86.0% for binary classification.In
Section 4.2, we carry out hyperparameter tuning and evaluate
architecture choices experimentally using the validation set for
calculating the accuracy, which yields different (slightly lower)
accuracy values from the test set.
4.2. Ablation Studies
Here we systematically evaluate the design choices for
training STARCNET. We define a modular architecture consisting
 of blocks with a convolution layer, a normalization layer,
and an activation layer. We experimentally choose the filter
size and number of convolution layers, the type of normalization,

and
activations.
We
experiment
with
different
architecture depths, varying the number of blocks from 4 up
to 12, with filters of sizes 3×3, 5×5, and 7×7 pixels.
Furthermore, we experiment using batch and group normalization,
 with group sizes from 4 to 32, and ReLU and Leaky
ReLU activations. Our best initial model consists of seven
modules with convolution layers of 128 filters of size 3×3,
group normalization (with a group size of 16), and Leaky
Figure 4. Performance of STARCNET on the test set. Confusion matrix normalized over the classes in test set of the LEGUS data set (20% of the total sources, or about
3000 objects). The rows show the distribution of the human-classified sources, while the columns are the predictions of STARCNET. Numbers in parentheses in the
confusion matrix refer to the unnormalized values.Left: overall accuracy evaluated for four-class classification using raw bands as input. Middle: results calculated
with two classes (cluster/noncluster classification). Right: PR curves for each of the four classes, as well as for binary classification. The overall accuracy is
68.6%with four classes and 86.0% with binary classification.
7
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
ReLU activations (with a pooling layer after the fourth
module). Using our best initial model, we perform tuning of
the training hyperparameters. We experiment with batch sizes
from 16 to 256 samples and learning rate η values from 1E−5
to 1E−2. We get the best performance when training with a
batch size of 128 input arrays and a learning rate of η=1E
−04. We prevent overfitting by controlling the complexity
of our model, increasing our training set size with data
augmentation,
and
adding
regularization
techniques
like
dropout layers(Srivastava et al. 2014).
In
addition,
we
experiment
with
different
sizes
and
preprocessing of the input arrays and data augmentation
techniques. Lastly, we study the benefits of extracting features
from different scales with multipath architectures. We expand
the description of our experiments in the remainder of this
section and present a summary of the ablation studies in
Table 2.The values in this table should not be directly
compared with the accuracy quoted in Figure 4; the accuracies
in Table 2 refer to the validation set, while the accuracy of
Figure 4 refers to the test set (Table 1), which explains why the
two accuracy values are slightly different.
Size of input arrays.—We test different input array sizes
from 24×24×5 (where the first two numbers refer to the
number of pixels in the array and subtend spatial scales
∼14–82 pc, depending on galaxy distance) to 96×96×5
(∼60–330 pc). A smaller input makes for more efficient
processing but might reduce the contextual information
required to make an accurate prediction. The best result is
achieved by using input arrays of size 32×32×5 pixels
(∼20–110 pc). Results using different input sizes are shown in
Table 2(a).
Input preprocessing.—We consider various approaches to
preprocessing of the input arrays (Table 2(b)), in order to test
whether any such approach improves the output accuracy. As
mentioned in Section 3.1, transfer learning is generally applied
to RGB inputs. We reduce the dimensionality of our input
arrays from five to three, to create RGB arrays. In separate
experiments, we preprocess the input arrays by removing the
galaxy’s background, by inverting the gain, and by combining
these two. In all cases, the unprocessed input arrays produce
the highest output accuracy.
Data augmentation.—As shown in Table 1, the amount of
objects per class is unbalanced. To balance the training data set,
we apply horizontal and vertical (or both) reflections. After the
training set is balanced, we apply data augmentation using
scaling and rotations. The best-performing model was obtained
by data augmentation using scaling to a magnification of
1.07×with 50% probability and adding rotations of 90° and
270° (Table 2(c)). Resulting images after applying 180°
rotations are the same as resulting images after applying
reflections on both axes; therefore, it is not used. The
improvements provided by scaling, resizing, and rotations are
easily understood. Star clusters and compact associations do
not have fixed projected sizes, and this characteristic is
mimicked by small scaling and resizing transformations.
Furthermore, the sources do not have fixed orientations, so
adding rotations and reflections to the input arrays to increase
their numbers helps increase and diversify the input sample.
Overall the benefits of data augmentation are significant,
improving performance from 63.0% to 67.9%. After augmentation
 the training set consists of ∼115,000 sources, or about 10
times the original training set (Table 1).
Architecture choices.—Table 2(d) shows the effect of
varying the number of pathways in the network. Compared
to a single-path network, the three-path network provides a
1.6% improvement in accuracy for four-class classification,
although the accuracy of the binary classification decreases
slightly, by 0.8%.
Table 2
STARCNET Ablation Experiments on the Validation Set
Input Size
Accuracy (%)a
Preprocessing
Accuracy (%)a
24×24×5
61.8/83.7
32×32×5 w/o preprocessing
67.9/85.5
28×28×5
63.0/84.3
32×32×3 RGB image
63.3/83.1
32×32×5
67.9/85.5
32×32×5 background removed
63.1/83.7
48×48×5
65.1/83.8
32×32×5 gain inverse
64.4/84.2
64×64×5
60.1/82.6
32×32×5 gain inverse + background removed
63.1/83.3
96×96×5
57.3/80.1
(b) Preprocessing
(a) Input size
Data Augmentation
Accuracy (%)a
CNN Architecture
Accuracy (%)a
No data augmentation
63.0/83.0
1-pathway
66.3/86.3
Scaling only (×2)
64.1/84.3
2-pathway
67.2/86.3
Rotations only (×3)
65.1/84.6
3-pathway (STARCNET)
67.9/85.5
Scaling and rotations (×6)
67.9/85.5
(d) CNN architecture
Scaling, rotations, and cropping (×30)
64.8/82.6
(c) Data augmentation
Notes. Ablation experiments showing the effect of different input sizes, preprocessing of the input, variations of CNN architectures, and data augmentation techniques.
Results are presented using the overall accuracy on the validation set for both the four-class and binary (cluster/noncluster) classifications. (a) Quantitative results
using different input image sizes, expressed in number of pixels. (b) Quantitative results using different preprocessing over 32×32×5 candidates. (c) Quantitative
results using different techniques of data augmentation. Best results (in bold font) are obtained using data augmentation with scaling and rotations. Data augmentation
with cropped arrays from the original input array reduces the performance of the model. Before performing the data augmentation, we apply balancing on the training
set using reflections. The multiplication factor over “no data augmentation” is shown next to each data augmentation technique. (d) Quantitative results using a
different number of pathways for our model. 1-pathway CNN corresponds to a standard CNN.
a Values correspond to four-way (left) and binary classification (right) accuracy.
8
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
Transfer learning.—To use transfer learning with a model
trained on ImageNet, we have to adapt our input (size and
number of channels/bands) to what the models expect, which
is typically a 224×224 image with three channels (e.g.,
RGB), and replace the last layer of the CNN to predict the four
categories of our application. A commonly used strategy is to
only train the parameters of the last layer, or to allow updating
the entire network but with a small learning rate. To adapt the
input, we rescale our 32×32 input arrays of five bands to a
size of 224×224 using bilinear interpolation. To adapt the
five bands of the HST to the three RGB channels, we weight
each image by the band’s photometric zero-point and combine
them (UV with U to get blue channel, and V with I to get red
channel). Table 3 shows results using deep networks currently
popular for image understanding. The number of parameters
varies from 6.8 to 123 million, and the models have been pretrained
 on the ImageNet data set. We obtained the best results
using GoogleNet (Szegedy et al. 2015) as the network
architecture and training over the entire network parameters.
However,
the
performance
is
still
below
the
proposed
STARCNET.
As shown in Table 3, the best result using transfer learning is
worse than the best result that uses training from scratch (which
is this work’s approach). We speculate that this outcome is due
to the fact that by combining the five bands into three channels
we lose the intrinsic information of each independent band.
5. Discussion
5.1. STARCNET Accuracy
We state in Section 4 that we reach 68.6% level accuracy
when
classifying
LEGUS
sources
with
our
STARCNET
algorithm. In order to evaluate this performance, we need to
compare it to the agreement achieved by the human classifiers.
In fact, as the classification given by the LEGUS experts is
used to train STARCNET, their agreement acts as an upper value
achievable by our model. As reported in the confusion matrix
in Figure 3 (right panel), LEGUS classification experts agree
with the final classification, used to train and test the model, at
an average value of 75% for four classes and 87% for two
classes. As a reminder, this accuracy is higher than the true one,
since the final classification includes the results from individual
classifiers. For comparison, pairs of individual classifiers
generally agree at the level of 57% for four classes and 78%
for two classes (Figure 3, left panel). It is therefore reasonable
that the STARCNET model cannot surpass the 75%/87%
(four/two classes) level of accuracy, given that the training/
testing sample is itself at that level. In order to estimate a
confidence interval for the accuracy, we calculate the results of
STARCNET
using
bootstrapping
(random
sampling
with
replacement) on the training and validation sets 10 times and
average the result. We obtain an accuracy uncertainty of
±0.8% for four-class classification and of ±0.7% for binary
classification. It is worth noticing that the accuracy mentioned
is not uniform within classes or within galaxies, as we are
going to discuss more in detail in the following paragraphs.
5.1.1. Accuracy by Class
The larger difficulty encountered by human classifiers in
recognizing class2 and 3 sources (Figure 3) is reflected in a
lower accuracy given by the STARCNET predictions in those
two classes (Figure 4). A high fraction of class 3 sources
(∼40%) are misinterpreted as class 4 by STARCNET, and a
lower but considerable fraction (∼15%) as class 2. Similarly,
almost half of class 2 sources are predicted by STARCNET as
class 1, 3, or 4, with a slight preference for class 1 (∼20%). The
difficulty in classifying class 2 and 3 sources can also be traced
in the probability distributions given by STARCNET to each
classification. STARCNET assigns a score (from 0 to 1) to each
class whenever it runs a prediction (see Figure 1). We show in
Figure 5 the scores assigned to each of the predictions in the
test sample. Such scores can be interpreted as the “confidence”
of STARCNET for each classification, since when a source falls
clearly in one of the classes it will receive a score close to 1,
while when its classification is very uncertain it will have a
score distributed across more than one class, and the final
predicted class will have a score much lower than 1 (close to
Table 3
Transfer Learning Experiments on the Validation Set
Network Architecture
No. Parameters
Accuracy (%)
AlexNet (Krizhevsky et al. 2012)
61M
63.0/84.7
VGG16 (Simonyan & Zisserman 2014)
138M
65.3/84.2
VGG19_BN (Simonyan &
Zisserman 2014)
144M
65.7/86.5
ResNet18 (He et al. 2015)
12M
63.2/85.7
ResNet34 (He et al. 2015)
22M
62.3/84.5
ResNet50 (He et al. 2015)
26M
65.5/85.0
SqueezeNet1_1 (Iandola et al. 2016)
1.2M
64.6/85.4
GoogleNet (Szegedy et al. 2015)
6.8M
66.3/85.4
ShuffleNet_v2_x1_0 (Zhang et al. 2017)
2.3M
63.1/84.1
DenseNet161 (Huang et al. 2016)
29M
64.1/82.2
STARCNET (This work—no transfer
learning)
15M
67.9/85.5
Note. Results on the validation set using ImageNet pre-trained networks. The
left column indicate the network architecture used, the middle column shows
the number of parameters of each network, and the right column shows the
accuracy for the four-class and binary classification. The last row shows the
network developed in this work, on which no transfer learning was applied.
Sections 5.1 and 5.4 discuss confidence intervals for the accuracy.
Figure 5. Cumulative distribution of the scores (ranging from 0 to 1) assigned
by STARCNET, divided by class. Only the highest score of each source is
considered, which corresponds to the score of the predicted class. The vertical
lines mark the median score for each of the classes.
9
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
0.25 if there is uniform uncertainty among all classes). Figure 5
indicates that STARCNET is on average very “confident” when
assigning a class 1, with 50% of the sources predicted as class 1
receiving a score higher than 0.8. On the other hand, for 50% of
the sources classified as either class 2 or 3 the score is lower
than 0.6, indicating a high degree of uncertainty. This behavior
closely traces the accuracy retrieved by the confusion matrix in
Figure 4. In addition to revealing the level of accuracy in each
class, the scores can be used in a more practical way to select
subsamples of the catalogs, namely, selecting on the base of the
“confidence” in the classification. It must be noticed, however,
that selecting only sources with a score above a certain limit
would bias the sample against class 2 and 3 sources.
5.1.2. Accuracy by Galaxy Distance
The major difference among the galaxies of our sample, in
terms of the possible effects on the training of STARCNET, is
their distance. The distance of a galaxy is inversely proportional
to the angular size of star clusters, and therefore to the number of
pixels subtended by each source. In Section 4 we tested different
sizes in pixels for the input arrays used to train the model,
finding that images of 32×32 pixels result in the best final
accuracy. Our galaxies span the distance range ∼3–18 Mpc, and
32 pixels (at the scale of 0 04 pixel−1) are equivalent to physical
sizes ∼20–110 pc (Table 6). Clusters have on average effective
radii of 2–3 pc (Ryon et al. 2015, 2017) and are therefore fully
contained in the 32×32 pixel cutouts even in the closest
galaxies. This remain true even for the magnified arrays, which
subtend 6–7 pc in the closest galaxies. In the case of distant
galaxies it can be argued that the cutouts contain a large fraction
of the cluster surroundings, which may act as noise for the
classification process.
In order to check the impact of distance, STARCNET accuracies
for single galaxies are plotted against their distances in Figure 6.
We test for possible correlations using the Spearman’s rank
correlation test, but we do not find evidence for any (coefficient
ρ=−0.2, pvalue=0.2), not even considering a binary classification
 (ρ=−0.2, pvalue=0.3). Accuracies cover the range from
∼0.5 to 1.0, and galaxies with few sources appear to drive most of
the scatter in accuracy (Figure 6). We account for the sample size
of each galaxy by calculating a weighted accuracy in 5 distance
bins, using distance limits at 5, 7, 9, and 11 Mpc; in this way
every bin contains ∼500 sources (the first bin contains ∼1000
sources). The distance-weighted accuracies are shown as orange
stars in Figure 6. The Spearman’s test suggests the presence of a
distance−accuracy anticorrelation (ρ=−0.8), but with low
significance (pvalue=0.1), which could be caused by having
only five data points. In the case of a binary classification,
the anticorrelation is weaker (ρ=−0.5), and still with low
significance (pvalue=0.4).
One of the possible causes of the large scatter retrieved in the
accuracies is the disagreement among classifiers. Even if the
model were able, in principle, to label sources with 100%
accuracy, the measured accuracy would be lower because the
human classifiers can only achieve 75% level of internal
accuracy over four classes. Thus, galaxies with lower overall
human accuracy could result in a lower recovered STARCNET
accuracy. We tested this possibility using the Spearman’s test to
compare the STARCNET accuracy with the human agreement;
the result is a correlation coefficient ρ=0.3 with a pvalue=0.4,
indicating that the data cannot confirm the presence of a
correlation. We conclude that we have no evidence that our
results are impacted by this effect. Using the binary classification
yields a similar result (ρ=0.5, pvalue=0.1).
5.2. Accuracy for Binary Classifications (Clusters versus
Nonclusters)
Throughout the paper we mentioned binary accuracies by
merging together class 1 and 2 as “clusters” and class 3 and 4 as
“nonclusters.” To account for variations in the literature on what
is considered a YSC, we also consider the case that classes 1, 2,
and 3 are “clusters” and only class 4 are “nonclusters” (as, e.g.,
in Chandar et al. 2014). Rearranging the confusion matrix of the
binary classification in Figure 4 results in an accuracy of 80.1%,
lower than the accuracy (86.0%) obtained with our default
definition of binary classification. Finally, some studies consider
class 1 and 2 sources together as clusters and keep class 3 and
class 4 as separate classes (e.g., Adamo et al. 2017). In this case
STARCNET would result in an accuracy of 74.4%.
Figure 6. Accuracy by galaxy plotted against the galaxy distance (blue circles). The number of clusters is coded by the size of markers. Orange stars represent the
weighted averages in distance bins (delimited by vertical dotted lines). Accuracies are calculated over the test set. The left panel refers to four-class classification, and
the right panel to the binary classification.
10
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
So far, we have measured the accuracy for a binary
classification starting from an algorithm trained on four-class
labels. We can instead directly train the model using a binary
classification. For this test we keep the architecture of
STARCNET fixed and use the same training and testing samples
as described in the previous sections. The only difference is
that we aggregate the class 1 and 2 sources in the “cluster”
category and the class 3 and 4 sources in the “noncluster”
category prior to performing any training. Running our pipeline
from start to finish under these conditions yields a final
accuracy of 86.0%, identical to what we obtained when training
on four classes and only aggregating the final outputs (see
Figure 4). Repeating the experiment with classes 1, 2, and 3 as
“clusters” and class 4 as “nonclusters” yields an accuracy of
80.0%, again identical to training with four separate classes
(see above). We conclude that training our model on four- or
two-class classification does not improve its final accuracy for
binary classification, which remains 80%.
5.3. Classification Heterogeneity among Human Classifiers
The LEGUS approach of obtaining classifications from several
human classifiers raises the issue of heterogeneity in the training
catalogs. We thus test whether removing classifications with the
largest disagreement among human classifiers can lead to an
improvement of the overall performance of STARCNET. As
described in Section 2, we train STARCNET using the mode of the
various individual human classifications. In addition to the mode,
the LEGUS catalogs report the mean of the classifications for each
object. For the present experiment, we leverage both mode and
mean, to train STARCNET only on those objects where the
|mean−mode|ò. This mimics the situation of higher agreement
 among different human classifiers. We performed experiments
 varying the value of ò from 0.1 to 3.0 (the latter number is
the maximum variance we expect over four classes). For every
value of ò the classification accuracy of STARCNET was worse
than using all objects. The best result of this experiment was 65%
using a value of ò=2.0.This value is lower than the highest
accuracy we achieve when using the entire training set,
irrespective of the (dis)agreement among human classifiers. The
result in this section underscores that samples of classified clusters
are still small in size, and reducing the number of training sets
decreases the performance of automatic classification algorithms
more drastically than including discrepant classifications.
5.4. Comparison with Other Algorithms in the Literature
Grasha (2018) and Grasha et al. (2019) presented an early
attempt at developing an ML-driven cluster classification
scheme based on a bagged decision tree algorithm, trained on
a small sample of eight LEGUS catalogs (all those available at
the time) and applied to the galaxy NGC5194. The results
from the ML classifications were used in detailed analyses of
the characteristics of the star cluster population in Messa et al.
(2018a, 2018b) and Grasha et al. (2019). Messa et al. (2018b)
also compared the catalog of NGC5194 with other existing
catalogs, concluding that the main differences consisted in the
quality of the data (Bastian et al. 2005) and in the definition of
star cluster (Chandar et al. 2016).
The major drawback of the ML classification of star clusters
described in Grasha (2018) and Grasha et al. (2019) is the
incapability of the algorithm to recognize class 3 sources, which
were mostly labeled as class 4. For this reason, only class 1 and
class 2 sources were included in all analyses using that catalog.
In NGC5194 only 47 class 3 sources were found by the bagged
decision tree algorithm when classifying ∼8400 sources without
human labeling (0.6%). As a term of comparison, ∼15% of the
sources with human labels in NGC5194 were class 3 clusters.
STARCNET is an important improvement over that first attempt,
in recognizing class 3 sources with better accuracy. A test run on
NGC5194 recovered ∼10× more class 3 sources relative to the
earlier algorithm.
For a direct and internally consistent comparison between the
two approaches, we trained a bagged decision tree model as
described in Grasha et al. (2019), using our larger set of LEGUS
catalogs. The model includes 100 trees, trained on object-centered
patches of size 15×15 pixels corresponding to the HST filter
bands F336W, F555W, and F814W, and data augmentation by
rotations of 90°, 180°, and 270°. We train the model using
ensemble.BaggingClassifier of the scikit-learn
library with a decision tree base estimator using the same train
and validation set objects used to train STARCNET. We choose the
best split on each tree node using “Gini impurity” as the function
to measure its quality. The maximum depth of the tree is set to
default (i.e., the nodes are expanded until all leaves are pure or
until all leaves contain less than two samples). As in Grasha et al.
(2019), we train the model using a 1×675 vector with raw pixel
values (i.e., after reshaping the 15×15×3 patch). The accuracy
of the model evaluated over our validation set is 57.1% with fourclass
 classification (compared to 67.9% achieved with STARCNET)
 and 78.4% with binary classification (compared to 85.5%
with STARCNET). The PR curves for this model are shown in
Figure 7.
Additionally, we train bagged decision tree models by varying
the input size. First, we use a vector of size 1×3072
(32×32×3) instead, which corresponds to the input spatial
size used for STARCNET. Next, we use a 1×5120 (32×
32×5) input that includes the remaining two bands not
included in Grasha et al. (2019) (F275W and F435W). Both
cases lead to a reduction in accuracy—56.4%/81.3% and
56.8%/85.5%, respectively, for four-class/binary classification.
However, we get a small improvement (58.2%/78.6%) when
training the model using an input vector of size 1×1125
(15×15×5), which matches the spatial size as in Grasha et al.
(2019) but uses all the bands.
More recently, Wei et al. (2020) applied deep transfer learning
to the classification of star clusters. They utilized the same
LEGUS four-class classification scheme, and the training of their
model was based on LEGUS images. It is therefore worth
comparing their results with the ones achieved by STARCNET.
The Wei et al. (2020) experimental framework differs from ours
in two important aspects. First, we have included every LEGUS
galaxy with published cluster photometric catalogs, with the
classifications provided by at least three human classifiers per
source. This increases by 38% our set of human-classified
sources relative to that of Wei et al. (2020). Although larger data
sets may introduce more variability in the classifications, the
approach makes sense when training a general discriminator.
Wei et al. (2020) also used a second, smaller (10 galaxies, about
5000 sources) data set, obtained from classifications performed
by a single human classifier; this approach provides more
internally consistent classifications throughout the entire sample
but introduces the potentially systematic bias of the classifier.
The second difference between the two works is thatSTARCNET
is a custom model trained from randomly initialized weights in
11
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
contrast to the transfer learning model used by Wei et al. (2020).
Using a custom model gives us freedom regarding the
architecture design, which allows us to use directly the LEGUS
photometric information. We investigate this second aspect, by
quantifying the difference in performance between the two
architectures.
An exact comparison is not possible, as the code and
experimental setup to reproduce the experiments of Wei et al.
(2020) is not publicly available. In order to compare our
approach to theirs, we run their algorithms using our catalogs,
which provide a consistent platform for evaluating performance.
Table 3 shows results using transfer learning with different
architectures. Wei et al. (2020) tested both VGG19-BN and
ResNet18; those algorithms applied to our more diverse catalogs
yield accuracies of 65.7% and 63.2%, respectively, while
STARCNET yields an accuracy of 67.9%. Thus, the accuracy
achieved with STARCNETon a four-class classification is higher
than using transfer learning. For binary classification the
accuracies are 86.5%, 85.7%, and 85.5%, respectively, closer
to each other than the four-class case (Table 3).
Our best result for the four-class classification from transfer
learning is with the GoogleNet architecture, where we obtain
an overall accuracy of 66.3% (Table 3). We show PR curves
with the results over the validation set of STARCNET and
GoogleNet in Figure 7. As we can see, STARCNET consistently
achieves better precision for all recall values compared to
transfer learning with GoogleNet for all four classes and binary
classification.
We estimate confidence intervals for GoogleNet using
bootstrapping on the training and validation sets 10 times and
average the result, as done previously for STARCNET. We
obtain an uncertainty on the accuracy of ±0.7% for four-class
classification and ±0.6% for binary classification (to be
compared with ±0.8% for four-class classification and ±0.7%
for binary classification obtained for STARCNET).
5.5. Applying STARCNET to Galaxies outside the Training
Sample
5.5.1. Leave-one-out Test
We study how STARCNET performs on galaxies that are not
part of the training sample. As a first test, we re-train
STARCNET, with the only difference that we leave one of our
galaxies completely out of the training sample. We then use
this newly trained STARCNET to make predictions on that same
galaxy. In this way we are treating the selected galaxy as if it
were a galaxy outside the LEGUS sample. We repeat this
process, in turn, for all the galaxies in our sample. We show in
Figure 8 (left panels) the confusion matrix obtained as the mean
of the confusion matrices of all the galaxies estimated with the
new training setup. Note that the matrices in this case were
evaluated over the validation sample and the accuracy of the
mean matrix (66.6% for four classes; 84.2% for binary
classification) should be compared to the accuracy over the
validation sample for the reference training, as reported in
Table 2 (67.9% for four classes; 85.5% for binary classification).
 For 50% of the galaxies, the accuracy does not change
compared to the one obtained from the reference STARCNET
training. The accuracy decreases with the new training scheme
for 30% of the galaxies, while it actually increases for the
remaining 20% of the sample. The change in accuracy given by
the mean matrix (−1.3% with respect to the reference
accuracy) suggests that, on average, the exclusion of a galaxy
from the training sample does not heavily affect STARCNET
predictions.
We show in Figure 8 (middle panels) the confusion matrix
for one of the LEGUS galaxies, NGC 3344, which can be
considered an average galaxy of the sample, in terms of both
number of clusters (557 labeled sources; 449 used for the
trainval set) and distance (7 Mpc). The accuracy of NGC 3344
using STARCNET trained on the default set (i.e., without
excluding any galaxy from the training set) is 62.1% for fourclass
 classification, below the STARCNET overall one. Leaving
this one galaxy out of the training sample and then running
predictions on it does not change the resulting accuracy. For
other galaxies in the sample this test produces variations in
accuracies up to ±20%. In the case of galaxies with few
sources, variations are expected, due to low number statistics.
For galaxies with a numerous cluster population, their
exclusion implies losing a consistent fraction of the training
sample, and, as seen in Section 5.3, a reduction in the training
sample size leads to worse accuracies.
5.5.2. NGC 1512+1510
As a further test, we consider a galaxy in the LEGUS
sample that does not have manually classified sources and
Figure 7. PR curves for four-class classification and binary (cluster/noncluster) classification over the validation set. Shown are results using (left) STARCNET,
(middle) GoogleNet, and (right) the bagged decision tree approach of Grasha et al. (2019).
12
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
therefore is not included in the training, validation, or testing
sets. We focus on the galaxy interacting pair NGC 1512
+1510 made of a barred spiral and a dwarf galaxy at a
distance of 11.6 Mpc (Calzetti et al. 2015). We consider a
single source catalog made by the merging of the catalogs for
the two galaxies.
The total number of sources in the merged catalog is 906, all
classified using STARCNET. Independently, 300 sources in the
catalog, drawn to cover randomly the entire range of positions
and luminosities of the parent sample, were classified by three
human classifiers (coauthors of this paper). Only one of these
three classifiers had taken part in the LEGUS classification
previously; the other two were trained to classify sources
according to the LEGUS scheme described in Section 2. The
human classification was performed without any knowledge of
the ML classification, and, at the same time, each classifier
worked independently of the other two. The three independent
classifications were merged into the final human classification
using the same methodology of the LEGUS project (Adamo
et al. 2017). The overall agreement of the human classifiers
among themselves is 54.3%, 64.0%, and 65.0%, respectively
(considering pairs of two classifiers). The agreement between
each classifier and the final classification is 77.7%, 76.7%, and
87.3%, for the three humans, respectively. The agreement
percentages were calculated in the same way as in Section 4,
i.e., weighting the number of sources in each class (see, e.g.,
Figure 4). As noted before, the higher agreement between
individual classifiers and final class is due to the final class
including the classifications of all classifiers. The great majority
of sources (59.3%) are in class 4, stressing again the necessity
of cleaning automatic catalogs of spurious entries. The other
sources are distributed among the remaining classes as shown
in Table 4.
When we compare the ML predictions with the human
classification for the 300 sources in common, we find an overall
agreement of 58.7%, lower than the overall accuracy of
STARCNET but consistent with the agreement among human
classifiers (see above). The confusion matrix in Figure 8 (right
panels) reveals a lower accuracy for class 2 and 4 compared
with the one found when testing STARCNET. We stress again
the fact that, like humans, STARCNET struggles between class 3
and class 4 and between class 1 and class 2. These distinctions,
however, become less relevant when a binary classification
(cluster/noncluster) is considered, improving the accuracy to a
much higher 83.3%. We point out that while STARCNET
Figure 8. STARCNET performance on leave-one-out experiments. Confusion matrices for leave-one-out experiments on the trainval set. Left: mean confusion matrix
of all LEGUS galaxies in the leave-one-out experiments. The overall agreement is 66.6% for four classes (top left) and 84.2% for binary classification (bottom left).
Middle: confusion matrix for the human classification and the ML predictions of 449 sources in NGC 3344. The overall agreement is 62.1% for four classes (top
middle) and 85.7% for binary classification (bottom middle). Right: confusion matrix for the human classification and the ML predictions of 300 sources in NGC 1512
+1510. The overall agreement is 58.7% for four classes (top right) and 83.3% for binary classification (bottom right).
Table 4
Classifications of the Sources in NGC 1512+1510 Given by the Mode of the
Human Classification and by the STARCNET Predictions
Human
Classification
STARCNET
Prediction
STARCNET
Prediction
Class 1
42
(14.0%)
65
(21.7%)
188
(20.8%)
Class 2
55
(18.3%)
34
(11.3%)
101
(11.1%)
Class 3
25
(8.3%)
68
(22.7%)
201
(22.2%)
Class 4
178
(59.3%)
133
(44.3%)
416
(45.9%)
Total
300
300
906
Note. For the predictions we report the statistics both for the 300 sources with
human classifications (center) and for the entire sample of 906 sources (right).
13
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
accuracy for this galaxy is well below the average value, it is
consistent with the accuracies of galaxies at similar distances,
as seen in Section 5.1.2. We conclude that the tests done in this
section
suggest
that
the
accuracy
of
STARCNET
when
classifying galaxies outside the training sample is consistent
with its reference accuracy.
6. Tests on Cluster Properties
Previous LEGUS studies suggest that the morphological
classification of star clusters is linked to physical differences
among classes. Clusters show younger ages and smaller masses
with increasing class number (from 1 to 3; Grasha et al.
2015, 2017; Adamo et al. 2017; Messa et al. 2018b), on average.
In addition, class 3 sources show a stronger degree of clustering
at small spatial scales, compared to class 1 and 2, suggesting that
they are still distributed according to the hierarchical structure
typical of young (<40–50 Myr) star-forming regions (Grasha
et al. 2015, 2017). Conversely, class 1 sources are distributed
more uniformly than class 2 or 3, which indicates that the
clusters are old enough to have had enough time to disperse from
their natal area, i.e., are several tens to a few hundreds of
megayears in age. In this section we test whether the
classification performed with our network STARCNET maintains
the same observed trends in the cluster population properties as
the classifications performed by humans.
6.1. Overall Distributions of Cluster Properties
We consider the test sample, consisting of a little over 3000
classified sources across 31 galaxies, the same used to test the
performance of the STARCNET classification, resulting in an overall
accuracy of 68.6% and the confusion matrix of Figure 4. We report
in Table 5 the distribution of the source classifications in this set.
We compare the distributions of the main properties of cluster in
this set, dividing them by class according to their human label and
to the STARCNET prediction, as shown in Figures 9 and 10.
The photometric cluster properties are summarized in Figure 9,
which shows the V-band luminosity functions (LF, defined as the
number of clusters per luminosity bin, and usually modeled as a
power law, LF≡dN/dL∝L−α) and the color–color diagrams.
Classes labeled by humans and predicted by STARCNET follow
the same trends, detailed as follows:
Table 5
Classifications of the Sources in the Test Samples, Given by the Mode of the
Human Classification and by the STARCNET Predictions
Human Label
STARCNET Prediction
Class 1
528
(17.1%)
569
(18.4%)
Class 2
612
(19.8%)
575
(18.6%)
Class 3
617
(19.9%)
493
(15.9%)
Class 4
1338
(43.2%)
1458
(47.1%)
Total
3095
3095
Figure 9. Properties of the test set divided by class. Classes 1, 2, 3, and 4 are color-coded as red, yellow, blue, and green, respectively (light colors for the humanclassified
 classes and dark colors for the predictions given by STARCNET). The left panels shows color–color diagrams with contours enclosing 50% and 75% of the
sources. Stellar evolutionary tracks for Padova-AGB models with solar metallicity indicate the evolution of color with age, from 1 Myr to 9 Gyr (white dashed lines
and circles). Crosses are used for the clusters with human labeling, and plus signs are used for clusters with STARCNET predictions. The right panels show the
luminosity function both in the cumulative (top) and in the binned (bottom) form, with the best fits overplotted as dashed (STARCNET) and solid (human) lines; the fit
was performed using only the bins brighter than −7 mag (black dotted vertical lines).
14
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
1. The overall colors of the clusters move from red (bottom
right of the color–color diagrams) to blue (top left) going
from class 1 to class 3. Class 4 sources spans the entire
range of colors. Colors are related to the cluster age, as
highlighted by the stellar tracks on the color–color
diagrams of Figure 9, and therefore the evolution of
colors suggests an evolution of cluster ages with class.
2. The luminosity functions steepen going from class 1 to
class 3, meaning that there are, on average, brighter
sources in class 1 than in class 3. The luminosity function
of Class 4 sources is steep at the low-luminosity end but
then becomes the shallowest at the bright end, exhibiting
double power-law shape. As a reminder, class4 sources
are
not
star
cluster
candidates,
but
the
“rejects”
(nonclusters). Luminosity functions are plotted using
their two most popular parameterizations. The binned
luminosity functions are fitted using a power law (down
to −7 Mag), and the two slopes found for each class
agree with each other within 1σ.
The main physical cluster properties are summarized in the
top panels of Figure 10, which show the distributions of ages,
masses, and extinctions as a function of cluster class. Mass and
age functions, with equivalent definition as the luminosity
function, are shown in the bottom panels of Figure 10. Again,
the
distributions
obtained
with
human
and
STARCNET
classifications show consistent trends:
1. Class 1 clusters are older and more massive than class 2,
which in turn are older and more massive than clusters in
class 3. Class 4 distributions have median values similar
to the ones in class 3 but with larger scatter. The same
trends are retrieved using the mass and age functions. The
mass function steepens going from class 1 to class 3. In
the case of class 4 sources the shape of the mass function
is similar to that of the luminosity function described
above. Also, age functions become steeper going from
class 1 to class 3, with class 4 having a slope similar to
class 2. In the case of both mass and age functions, the
slopes obtained by fitting the human and STARCNET
classifications agree with each other within 1σin each
class.
2. Extinction distributions move to lower values going from
class 1 to class 3, in contrast to what was found for the
median values by Grasha et al. (2015). The difference in
median E(B−V ) values is, however, less than 0.1 mag.
Class 4 sources have a similar distribution to those in
class 1.
We conclude that the overall trends of cluster photometric and
physical properties are not affected by considering STARCNET
predictions.
6.2. Misclassified Clusters
Having discussed the overall distribution of properties, we
focus in detail on how the populations of false positives (FPs)
and false negatives (FNs) from STARCNET predictions are
distributed. We report, in the left column of Figure 11, the age–
mass distribution of clusters in each class, using different
Figure 10. Physical properties of the test set divided by class. The same colors as Figure 9 are used. In the top row, the distributions of ages, masses, and extinctions
are shown as box-and-whisker plots. The distributions of the extinctions have a maximum value at E(B−V )=1.5 mag in all classes. The bottom row shows the
mass functions in the cumulative form (left panel), those in the binned form (middle panel), and the age functions (right panel). Results of the best-fit slopes are
overplotted as dashed (for STARCNET-predicted) and solid (for human-labeled) lines. The mass function was fitted down to masses of 104 Me in order to avoid
incompleteness. For the same reason, and in order to avoid contaminants, the age functions were fitted in the age range between 10 and ∼300 Myr.
15
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
Figure 11. Left column: age–mass plots showing sources with correct predictions (filled circles), FPs (plus signs), and FNs (crosses). We use red color for class 1,
orange for class 2, blue for class 3, and green for class 4. The dashed black lines indicate the limit of MagV=−8. Middle and right columns: distribution of correct
classifications (solid lines), FPs (dashed), and FNs (dotted) in the age and mass spaces.
16
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
markers for the clusters correctly predicted, the FPs, and the
FNs. We also report histograms of the distributions of FPs and
FNs in both the age and mass spaces. Figure 11 suggests the
following:
Class 1:We find a relatively high fraction of misclassifications
at the lowest masses; when we consider the high-mass end
only, most of the misclassifications are with class 2
clusters (both FPs and FNs). We do not observe a clear
trend with age.
Class 2:the most massive clusters in this class are actually FPs,
from class 1 but also from the other classes, across all ages.
Class 3:we see many FPs (from class 2 and 4) also in class 3,
especially at very young ages. From the previous analysis
we already know that class 3 is the one with the lowest
accuracy.
Class 4:this class includes a number of very massive sources
(M>105 Me) with old ages (109 yr) that are correctly
classified. Visual inspection shows that they are mostly
foreground stars and background galaxies.
In order to quantify the observed trends, we focus on the
high-mass clusters and calculate the fraction of misclassified
ones. We report in Figure 12 (left panels) the confusion matrix
for clusters with

M
log
4.5;
10(
)
the deviation of the mass
function from a power law has been debated widely in the
literature (see, e.g., Bastian et al. 2012; Adamo et al. 2015;
Chandar et al. 2016; Mok et al. 2019) and is observed above
these masses in nearby galaxies (e.g., Messa et al. 2018b).
There are 77 class 1 clusters correctly classified, with the
addition of seven FPs, five of which are actually class 2; seven
class 1 clusters have been predicted as class 2. We deduce that
most of the confusion for massive clusters in class 1 is with
class 2, and therefore not crucial in studies that consider those
two classes together as “clusters.” This is supported by the
confusion matrix for binary classification in Figure 12 (bottom
panels). At the opposite end, 39 class 4 sources have been
correctly classified, with only eight inclusions from FPs (three
from class 3). Six class 4 sources have been assigned to other
classes (two of them to class 3). Again, we conclude that the
misclassification in this class is not elevated. As previously
noticed in Figure 11, misclassification at high masses heavily
affects sources of class 2 and 3. At the same time, the number
of high-mass sources in these two classes is much smaller
than in class 1 or 4. Therefore, we conclude that, overall,
misclassification will have only a small impact on the study of
the high end of the mass function, as also suggested by the high
accuracy of the binary classification in this case (90.8%, bottom
left panel of Figure 12).
Similarly, we can focus on the brightest sources only; the
confusion matrix of sources with MagV<−8 is shown in
Figure 12 (right panels). This limit is 2 mag brighter than the
one used as completeness in LEGUS catalogs and is indicated
as the black dashed lines in the left panels of Figure 11. Similar
trends to the ones observed for the high-mass sources are
recovered. The confusion matrix is not very different, in terms
of accuracy, from the one found for the entire sample
(Figure 4). We conclude that STARCNET performs similarly
for bright sources as for the rest of the sample.
Figure 12. Confusion matrix for sources with high masses (
>
M M
log
4.5
10(
)

; left panels), and with high luminosities (MagAB<−8 mag; right panels). The
accuracies, in these cases, are 79.7% and 69.6% for the four-class classification and 90.8% and 84.5% for the binary classification, respectively.
17
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
7. Future Improvements
Throughout this work, we have shown that STARCNET can
be trained to reproduce the same level of accuracy as the
human classifications. Thus, future improvements to the overall
accuracy need to include larger human-classified catalogs,
possibly with higher accuracy. While this goal can be achieved
by using the classifications of a single expert (Wei et al. 2020),
it is not a desirable path, especially if samples larger than
several tens of thousands of classifications (i.e., larger than the
LEGUS sample) need to be collected. The creation of
visualization and classification tools with easy access (e.g.,
browser-based visualization tools) that facilitate and speed up
human classifications may prove important for progress in this
area. Larger and more accurate catalogs would increase the
discriminating power of the algorithm and reduce the confusion
created by ambiguous human classifications.
Faint star clusters are an unexplored region of the luminosity
parameter space. The LEGUS collaboration classified clusters
brighter than V=−6 mag, leaving the bulk of faint clusters
untouched.
However,
faint
(low-mass)
star
clusters
are
important discriminants for evolution models. Absence of
classified faint clusters makes it difficult to train STARCNET on
these sources. Faint clusters are difficult to classify also for
human classifiers. A potential way around this problem is to
generate artificial clusters by dimming the existing, classified
(bright) clusters in the HST images and train STARCNET onto
these artificial sources. Additional applications of artificially
generated clusters include the exploration of wavelength
regimes, such as the JWST one, which are outside those
analyzed in this paper.
Finally, we point out that although STARCNET was trained
and tested on the cluster catalogs of LEGUS, it can be used to
classify sources in other nearby galaxies, at least within the
distance range covered by LEGUS (20 Mpc). The HST
archive, for example, is already a large repository of multiband
images of nearby galaxies, from which cluster catalogs to
be inspected by STARCNET can be easily created with
automatic extraction tools, like the one used by LEGUS (see
Adamo et al. 2017). The current version of StarcNet is publicly
available at github.com/gperezs/StarcNet(DOI:10.5281/zenodo.
4279715).
8. Summary and Conclusions
We developed STARCNET, a multiscale CNN, with the goal
of morphologically classifying stellar clusters in nearby
galaxies. STARCNET aims at speeding up by orders of
magnitude the process of visual cluster classification, which
currently is the single most important limitation to securing
large catalogs for studies of these sources. Availability of
reliable and fast ways to classify star clusters will become even
more critical with the advent of extremely large surveys, such
as those that will be produced by the Vera Rubin Observatory
and the Nancy Roman Space Telescope.
STARCNET is a three-pathway CNN that processes each
input source at three different magnifications. Each pathway
consists of a set of modules containing a convolutional layer, a
group normalization layer, and a Leaky ReLU activation with a
single pooling layer after the fourth module. Each of the three
pathways’ extracted features are combined into a fully
connected layer to output a probability distribution of the
corresponding source class.
The classification adopted consists of four classes, where
classes 1 and 2 are for spherical and elongated, but compact,
clusters, respectively; class 3 includes multipeaked systems
with diffuse nebular emission that may be compact stellar
associations; and class 4 is for spurious detections, i.e., all
sources that can be defined as nonclusters.
More than 15,000 sources, visually classified by at least
three experts from the LEGUS HST Treasury Project, are used
to train and test STARCNET. We test different architectures,
e.g., by changing the number of pathways in the network, and
different inputs, e.g., by changing the size of input arrays. The
final version of STARCNET reaches an overall accuracy of
∼69%, nearly matching the agreement among human classifiers.
 The accuracy is not uniform across classes, as a better
performance is achieved for classes 1 and 4; this inhomogeneity
 traces the difficulty of the human classifiers in confidently
identifying clusters in classes 2 and 3.
Since many cluster studies in the literature rely on a simpler
classification scheme than the one adopted by LEGUS, i.e.,
they simply separate clusters (what LEGUS classified as class 1
and 2) from nonclusters (class 3 and 4), we remeasure the
accuracy of our algorithm using this binary classification. The
STARCNET accuracy reaches 86% when merging the four
classes into a binary classification. Training STARCNET
directly on the binary classification does not bring improvement
 to the final accuracy, which remains around 86%.
A
low-significance
anticorrelation
between
STARCNET
accuracy and galaxy distance is found. However, we do not
find a correlation between the STARCNET accuracy and the
level of agreement among human classifiers, when different
galaxies are considered individually. We test the performance
of STARCNET on galaxies not included in the training set, first
by removing, in turn, one galaxy from the training sample and
making predictions on its sources, and second by considering
the galaxy pair NGC 1510+1512, one of the LEGUS galaxies
without a human-classified cluster catalog. These tests highlight
 that the STARCNET accuracy on new galaxies is
comparable to the reference one.
We analyze the outputs from our pipeline, paying particular
attention to whether the classifications given by STARCNET
affect the average physical properties of the sources within the
four classes. We consider color–color diagrams and luminosity
functions, as well as age, mass, and extinction distributions,
mass functions, and age functions. We find that the ML
classification does not introduce changes in the recovered
statistical properties and median distributions.
STARCNET proves to be a successful improvement over an
early LEGUS attempt to develop an ML-driven cluster
classification algorithm (Grasha 2018; Grasha et al. 2019).
This early attempt, tested on the cluster population of
NGC5194, performed poorly in recognizing class 3 sources;
conversely, STARCNET has a 10× higher recovery rate for
class 3 clusters in NGC5194 than the earlier classification
code. Recently, Wei et al. (2020) applied deep transfer learning
to the classification of LEGUS star clusters, reaching an overall
accuracy
and
per-class
distribution
very
similar
to
the
STARCNET ones. A direct comparison of the two approaches
is not straightforward, due to the absence of a publicly released
code and experimental setup by Wei et al. (2020). However, a
comparison between our algorithm and those of Wei et al.
(2020) by using our own catalogs shows that the algorithms
presented by Wei et al. (2020)reach accuracy 2.2%–4.7%
18
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
lower than STARCNET for four-class classification and 0.2%–
1.0% higher for binary classification.
Future developments of STARCNET will include applications
to the faint (low-mass) sources found in the HST images. With
training on appropriate sets, STARCNET can be readily applied
to a range of cases, from HST images of nearby galaxies to
ground-based images of Local Group galaxies.
This paper is based on work supported by the National
Science Foundation under grant No. 1815267. The authors
thank Dr. Hwihyun Kim for providing individual human
classifications for a subset of the LEGUS catalogs.
Facility: HST(ACS and WFC3).
Software:Astropy8 (Astropy Collaboration et al. 2013),
SciPy9 (Virtanen et al. 2020), scikit-image10 (Van der Walt
et al. 2014), scikit-learn11 (Pedregosa et al. 2011), PyTorch12
(Paszke et al. 2019).
Appendix A
Misclassifications
We explore here several of the reasons for classification
disagreements between different human classifiers, which the
confusion matrix of Figure 3 summarizes, by showing that the
largest disagreement is usually found for class 2 and 3 sources.
The type of classification requested by the LEGUS project’s
approach, i.e., the division of cluster candidates into three
morphological classes plus a fourth class for nonclusters,
requires high accuracy and is subject to judgment calls in many
instances. Therefore, even a single highly trained classifier
cannot always be 100% sure of their own choices and is not
able to always repeat their own classifications. This uncertainty
has been quantified at 80% repeatability across four classes
(Wei et al. 2020). This intrinsic difficulty, which is driven by
subjective evaluations of the morphology of a source, explains
the failure of crowdsourcing approaches for cluster identification/classification
 in cases where the galaxy’s background is
semiresolved or unresolved. We summarize below several of
the most common causes of misclassification.
Decreased contrast.—A secure identification of a source, of
any class, is facilitated if the contrast between the source and
the background is high. The contrast can be low under several
circumstances, including that the local galaxy background is
high, a neighboring source is bright, or the source to identify is
intrinsically faint. A few examples are given in Figure 13(a).
Compact sources.—Although most sources consistent with a
stellar point-spread function (PSF) are removed at the stage of
catalog construction, sources with PSF barely larger than the
stellar one are retained. These sources can be classified either as
class 1 or 2 (cluster) or as class 4 (noncluster) depending on the
judgment of the classifier. An example of this situation is given
in Figure 13(b). However, as implied by the confusion matrices
in Figure 3, this type of misclassification is not frequent,
occurring about 3.7% of times for class 1 to 4 confusion, and
increasing to 11.3% if both class 1 and 2 misclassifications are
included.
Diffuse light in class 3.—The main discriminant between the
multipeaked class 3 sources and random groupings of stars
(asterisms, class 4) is the presence of diffuse emission between
the peaks of the class 3 source. However, the diffuse emission
can be faint, leading to potential confusion and misclassifications.
 An example is given in Figure 13(c). The confusion
between class 3 and 4 is at the level of 13.7%.
Separating class 1 from class 2 sources.—The main
difference between class 1 and class 2 sources is that the latter
display either elongated or asymmetric light profiles. However,
there is no strict value of the ellipticity that separates the two
classes. In some cases this leads to confusion between a class 2
cluster candidate and a slightly elongated (or slightly asymmetric)
 class 1, which can be further complicated by an uneven
background causing distortions in the light profiles (an example
is given in Figure 13(d). This problem applies to approximately
7% of the sources.
Overlaps of source pairs.—Asterisms can appear as a single
distorted object when two sources align almost perfectly along
the line of sight and have similar colors; in this case the two
objects appear like a single elongated one (i.e., a class 2
source). An example is shown in Figure 13(e). This case is
different from the one shown in Figure 2, where the two
sources can be discriminated by their color difference, leading
to the correct class 4 classification.
8
https://www.astropy.org/
9
https://www.scipy.org/
10 https://scikit-image.org/
11 https://scikit-learn.org/stable/
12 https://pytorch.org/
19
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
Appendix B
Summary of LEGUS Galaxies with Cluster Classifications
We report in Table 6 the number of cluster candidates in
each of the four classes for the 31 LEGUS galaxies with
available catalogs, along with the galaxy distance and the
physical scale subtended by 1 pixel (0 04 pixel−1).
Figure 13. Examples of possible confusion and misclassifications among classes: (a) sources that are hard to classify because they are faint, lie in a region of high
background, or lie next to a much brighter source; (b) isolated sources that can have similar light profiles, barely larger than the stellar PSF, and are here classified one
as class 1 (top source) and the other as a star, class 4 (bottom source); (c) class 3 sources (top) that can be difficult to discriminate from a serendipitous collection of
stars, i.e., class 4 (bottom); (d) slightly asymmetric class 1 sources (top) that can be confused with class 2 ones with moderate elongation (bottom); (e) chance overlap
of two sources with similar colors (classified as class 4) that can resemble a class 2 source. All the light profiles, 2D contours, and 3D plots refer to the V band. All
examples are from the LEGUS cluster catalog of the galaxy NGC 1566.
20
The Astrophysical Journal, 907:100 (22pp), 2021 February 1
Pérez et al.
ORCID iDs
Gustavo Pérez
https:/
/orcid.org/0000-0003-3880-8075
Matteo Messa
https:/
/orcid.org/0000-0003-1427-2456
Daniela Calzetti
https:/
/orcid.org/0000-0002-5189-8004
Subhransu Maji
https:/
/orcid.org/0000-0002-3869-9334
Dooseok E. Jung
https:/
/orcid.org/0000-0003-2797-9979
Angela Adamo
https:/
/orcid.org/0000-0002-8192-8091
INTRODUCTION
Big Data has already changed the way we do science in nearly all
areas of research every day. Although data-driven methods have been
around since almost the very beginning of the history of science, the
meaning of the term has started to transform gradually; data are
not used only to validate our analytical formulations and hypotheses
any more, but have started taking more serious roles in defining the
problem itself, and providing non-parametric solutions to it.
The rationale behind this reform is two-fold. First, huge amounts
of new data are becoming available in many areas: from the ever
increasing number of search-able images on the web to the petabytesper-minute
 streams of data expected from future telescopes – e.g. see
SKA (Quinn et al. 2015). Secondly, and perhaps more importantly,
the scientific community has found, and is advancing, ways to handle
such big volumes of data, thanks to advances in technology. At the
core of these advances lies the recent revolution of techniques under
the broad term of machine learning.
The number of machine-learning-based solutions to problems in
astrophysics, astronomy, and cosmology has drastically increased in
⋆E-mail: nima.sedaghat@eso.org
the past years, and providing a list of them is beyond the scope of this
manuscript – we refer to Baron (2019) for a practical overview. We
believe what particularly needs to be assessed, however, is the way
learning has been utilized in these fields, and the potentials to broaden
the horizons. Concretely speaking, the so-called revolution of the
past two decades has been more about deep learning (DL, Raina,
Madhavan & Ng 2009; Krizhevsky, Sutskever & Hinton 2012): a new
family of methods forked out of classical machine learning (ML) –
the latter has already been around since as early as 1980s (LeCun
1985). But most of the solutions used by our community have been
plugin-style usages of classical ML, and the advantages deep learning
brings upon have not found enough exposure.
Classical ML can be roughly modelled as a black box that
implicitly learns how to connect input features (engineered by
humans) to desired output. Deep learning, on the other hand, is a
similar box, normally implemented as a neural network, with the
additional capability to learn and decide what features are best to be
used for the task at hand. The ability, also known as representation
learning (Rumelhart, Hinton & Williams 1986; Bengio, Courville &
Vincent 2013), is the key difference between the two methodologies
– not the depth of the neural network.
Nevertheless, deep models have proven superiority in performance
and accuracy over traditional methods in astronomy and astrophysics.
C
⃝2021 The Author(s)
Published by Oxford University Press on behalf of Royal Astronomical Society
Downloaded from https://academic.oup.com/mnras/article/501/4/6026/6121645 by Periodicals Section, UMIST Library & Information Service user on 08 August 2023
Machines learn to infer stellar parameters
6027
Applications involving classification, detection, and regression have
been extensively and successfully outsourced to neural networks in
the past years, from redshift estimation (Vanzella et al. 2004) to
morphological classification (Lukic & Br¨
uggen 2016). Yet, there
has been little work towards finding how a network is tackling a
specific problem and indeed the interpretation of what the network
has learned is still an open line of research, in all areas.
Unsupervised approaches have also been extensively studied,
especially in the field of computer vision where deep learning was
originally cultivated, e.g. see Bengio et al. (2013) for a review. Such
methods have even been attempted in other fields of science too,
including astronomy (e.g. see Baron & Poznanski 2017). However,
they have often been used to either learn proper features for initialization
 of the main supervised task (e.g. Martinazzo, Espadoto &
Hirata 2020), or simply as techniques for tasks such as dimensionality
reduction (Hinton 2006), compression (Wulff 2020), and storage
tractability.
In this work, we choose to take a fully unsupervised approach,
without defining any specific tasks for the network. The idea is to
attempt to interpret the representations by which the network decides
to perceive and describe the data, and assess whether there are traces
of (astro-)physical concepts in them.
The idea of ‘distilling data into knowledge’ in form of analytical
expressions was introduced by Schmidt & Lipson 2009, and later
adapted to astronomy (Graham et al. 2013) and cosmology (KroneMartins,
 Ishida & De Souza 2014). Our work shares the same basic
goal at the conceptual level: letting a machine learn from experimental
 data. However, we go beyond the constraints of analytical
expressions and try to capture the knowledge in a non-parametric
fashion, relying on the hierarchical feature learning capabilities of
deep neural networks.
In the past years, there have been works lying at the crosssection
 of deep learning and the broad definition of the term physics.
Most of such works implement physics-guided or physics-informed
networks, where the network is explicitly or implicitly pre-fed with
known physical laws (e.g. see Meng et al. 2020; Zhang, Liu & Sun
2020). Inspired by Hamiltonian mechanics, Greydanus, Dzamba &
Yosinski (2019) and Choudhary et al. (2020) design Hamiltonian
Neural Networks that learn to respect exact conservation laws. Raissi,
Perdikaris & Karniadakis (2017) teach neural networks to solve
tasks while respecting physical laws described by partial differential
equations. Stewart & Ermon (2017) use prior knowledge to limit
the space of possible learned mappings. Denil et al. (2017) use
reinforcement learning to pursue physical experiments. Ehrhardt
et al. (2017) use simulated motion sequences to teach a neural
network to predict motion, where Sedaghat, Zolfaghari & Brox
(2017) predict motion patterns in real videos. D’Agnolo & Wulzer
(2019) and De Simone & Jacques (2019) use neural networks to
detect discrepancy between reference models and actual (synthetic)
data. However in all of them the flow of physics knowledge is, directly
or indirectly, from human mind to the machine, whereas in this work,
we focus on observing how the machines learn; i.e. the way Big Data
enforces the machine to interpret it.
Fig. 1 outlines our implementation of the above idea. We use an
archive of stellar spectra obtained using the HARPS (High Accuracy
Radial-velocity Planet Searcher; Pepe et al. 2002; Santos et al. 2004;
Romaniello et al. 2018) instrument, as an exemplar case for study,
with easy access to a large number of samples.1 We pass the data, as
1We henceforth refer to the data set itself as HARPS.
Figure 1. A large number of stellar spectra are passed through the information
 bottleneck of a deep convolutional autoencoder, in a fully unsupervised,
physics-agnostic process. The network has zero information about the content
of the numerical vectors it receives. We use techniques based on information
maximization, to enforce learning of disentangled features, and find that the
network learns representations for astrophysical parameters such as radial
velocity and effective temperature, without being asked to do so.
a set of 1D2 numerical arrays, through the information bottleneck3
of a deep convolutional autoencoder, seeking a low-dimensional
yet informative representation of the data (Tishby et al. 1999).
The process is fully unsupervised and the network is completely
agnostic of the type of the content it is seeing. The only constraint
we apply during training is enforcing disentanglement of the learned
representations (Bengio et al. 2013), based on maximization of the
mutual information (MI; Cover 1991) between latent representations
and the main signal. This, however, is the key component of our
implementation, as we need to tune the disentanglement weight to a
lower-than-standard level, for the method to work.
We crack open the trained network, and surprisingly find that
clear traces of physical concepts, such as the effective temperature
of stars and radial velocity are captured by the network. In other
words, the network learns to identify and map such physical features
to individual dedicated latent nodes. Such correlations are identified
by seeking MI between the latent nodes and astrophysical validation
labels we manage to collect from published catalogues (through the
VizieR interface, Ochsenbein, Bauer & Marcout 2000), for a subset
of HARPS object.
In parallel, we define a purely statistical informativeness measure
and run it on the latent nodes to find probable candidates for analysis.
Although the weight we put on disentanglement affects the results,
we find in a reasonable setting that six nodes (out of 128) supposedly
capture a noticeable amount of information. Interestingly, the two
physical nodes we already identified are among the 6, leaving the
remaining 4 open for future studies. As scientifically surprising as
the identified physical nodes are, the remaining 4 are potentially even
more important in the context of the long-term goal of our studies, as
they may open doors for us to learn new patterns/correlations from
data.
Our implementation is based on autoencoders (Vincent et al.
2010): the de-facto framework for unsupervised approaches in
deep learning. The image generating capability of convolutional
encoder–decoder architectures has also been utilized in for tasks
such as transient detection (Sedaghat & Mahabal 2018) and de2The
 term 1D here is used the way it is used in the signal processing
literature, to differentiate vectors from 2D arrays, a.k.a. matrices, and higher
dimensionalities. Otherwise, from a computer scientific point of view each
spectrum in our case has a dimensionality of ∼300 000.
3We use the term ‘information bottleneck’ in a loose manner for both the
exact theory of Tishby, Pereira & Bialek (1999), as well as the architectural
bottleneck formed where the encoder and decoder of an autoencoder meet.
MNRAS 501, 6026–6041 (2021)
Downloaded from https://academic.oup.com/mnras/article/501/4/6026/6121645 by Periodicals Section, UMIST Library & Information Service user on 08 August 2023
6028
N. Sedaghat et al.
blending (Boucaud et al. 2020). However, we move from the
deterministic version to Variational AutoEncoders (VAE; Kingma
& Welling 2014), where statistical analysis is made possible. VAEs
and their extensions have been widely used to achieve (or enforce)
interpretability in latent representations – e.g. see Bengio et al.
(2013), Higgins et al. (2017), Chen et al. (2018), Zhao, Song & Ermon
(2018), Tschannen, Bachem & Lucic (2018), and Crescimanna &
Graham (2020). A comprehensive tutorial on VAEs can be found in
Doersch (2016). Information-theoretic extensions to VAEs have also
been studied recently by e.g. Crescimanna & Graham (2020) and
Rezaabad & Vishwanath (2020).
Perhaps the closest to our implementation is the parallel work
of Iten et al. (2020) where a β-VAE is used to look for traces of
physics in latent representations. However, in that work only ‘toy
examples’ based on simulations are tried, with a rather shallow nonconvolutional
 network. This makes the work orthogonal to our longterm
 goal of ‘learning from data’: simulations are created based on
simplistic mathematical models we already know. Hence, they can
teach us, at best, the things we already know.
Moreover, for a network to be able to learn semantics from data,
it needs to be (a) presented with huge amounts of real data, to
avoid overfitting and falling in the covariate shift trap (Sugiyama
& Kawanabe 2012), and (b) at the same time sophisticated and deep
enough to learn useful representations.
There have also been a few attempts towards finding physical
parameters in spectra based on typical dimensionality reduction
methods such as principal component analysis (PCA; Jolliffe &
Cadima 2016). However, PCA provides a linear decomposition of
data and hence, as expected, does not yield the desired one-to-one
mapping between the principal components and physical features –
e.g. see Bailer-Jones, Irwin & Von Hippel (1998). We illustrate such
an effect on our data set in Appendix C.
Our contributions
(i) To the best of our knowledge, this is the first work to allow
deep convolutional neural networks to learn to infer (astro-)physical
parameters just by looking at real data, with zero supervision.
(ii) We provide methods based on MI and statistics, to track true
correlation between learned representations and physical parameters,
 as well as autodiscovery of the potentially informative latent
dimensions.
(iii) We identify but leave open, cues for doing science with
potentially new patterns that neural networks discover in data.
Section 2 presents the basic deterministic convolutional autoencoder
we start our study with. Section 3 explains how we enforce interpretability
 of the learned representations via disentanglement.
Section 4 details the specifications of the data set. In Section 5,
we briefly look at reconstruction results. Finally, in Section 6, we
analyse the learned latent representations and assess traces of physics
in them.
2 A DETERMINISTIC CONVOLUTIONAL
AUTOENCODER
Although the final implementation of the proposed method involves
treatment of the input and the latent representation as statistical
variables, in this section, we start by detailing the architecture of
a deterministic deep convolutional autoencoder (Vincent et al. 2010)
and training details. This allows us to clarify the migration from
a traditional fully connected autoencoder to a convolutional one,
as well as to briefly illustrate that even the deterministic variant is
capable of learning useful information from Big Data.
2.1 Architecture
We design an autoencoder composed of a combination of convolutional,
 up-convolutional and fully connected layers (Fig. 2). A
fully detailed illustration of the network architecture is presented in
Appendix A. There are 15 convolutional layers in the encoder part
that transform the input spectrum, x, down to 512 vectors of length
20 (in case of HARPS). The vectors are then transformed to a single
vector of scalars, called code, using a fully connected layer. The
code, also referred to as the latent representation throughout this
article, contains the most compressed version of the input spectrum
throughout the network. The dimensionality of this vector is chosen
based on the desired compression rate. We experiment with different
code sizes, from 2 to 128. On the other side of the bottleneck, a second
fully connected layer transforms the code back to a similar set of 512
vectors. Then a set of up-convolutional layers take them step-bystep
 up to the same dimensionality as the original input (327 680 for
HARPS).
2.2 Reconstruction loss
Eφ and Dθ represent the deterministic encoder and decoder, respectively,
 where φ and θ are the learn-able parameters of the network.
We aim for pixel-level accuracy in the reconstructed spectrum and
so choose to minimize the per-pixel L1 loss function:
LAE(θ, φ) = Edata

||x −Dθ(Eφ(x))||1
1

,
(1)
which is empirically computed as
LAE =

i∈M |xi −ˆ
xi|
n
,
(2)
where x and ˆ
x are the input and reconstructed spectra, respectively,
i is the pixel index and n is the total number of pixels.
Set M represents a mask, constant over all the spectra in the data
set, which masks out the three information gaps in the beginning,
middle, and end of each HARPS spectrum (Pepe et al. 2002). This
is a safe procedure, because these are just instrumental artifacts that
bear no meaning for the astrophysical interpretation of the spectra.4
2.3 Median normalization
For stability of the training process, we want the input samples not to
feed extremely different value ranges into the input of the network.
Thus, without loss of generality, we normalize the spectra in the data
set according to
x =
˚
x
median
i∈M {˚
xi}
(3)
in which ˚
x is the original input spectrum before normalization.
Our initial experiments show that a deterministic autoencoder not
only can compress and reconstruct the whole data sets with as few
as eight nodes at the bottleneck and with a high quality, but also
can grasp a degree of understanding about the underlying signal
sources. This is reflected in the way the network treats the telluric
4The location of such artifacts is not exactly fixed across different spectra.
Therefore, we chose to use a single constant mask to cover all of them, at the
cost of losing a small fraction of informative pixels from each spectrum.
MNRAS 501, 6026–6041 (2021)
Downloaded from https://academic.oup.com/mnras/article/501/4/6026/6121645 by Periodicals Section, UMIST Library & Information Service user on 08 August 2023
Machines learn to infer stellar parameters
6029
Figure 2. Brief architecture of the deterministic autoencoder on top, with the schematic variational counterpart of it at the bottom. In the VAE version, the
code is not directly connected to the encoder, but is drawn from the learnable parameters of the normal distribution: reparametrization trick (Kingma & Welling
2014).
lines differently to other (stellar) lines. Details of this part of the
study will be published in a future article.
3 ENFORCING INTERPRETABILITY
Learning disentangled representations for composing factors of
observed phenomena is key to interpretability (Bengio et al. 2013).
Although our deterministic autoencoder proves to be capable of
learning interesting aspects of the observations, the de facto methods
of enforcing disentanglement in deep autoencoders are built on top of
the VAE-based family of methods, and are done by regularization of
the variational autoencoder objective, one way or another (Tschannen
et al. 2018).
We convert our classic autoencoder to a VAE, as seen in Fig. 2,
where the deterministic code is replaced by a probabilistic one and
each element of it is drawn from a normal distribution defined by a
pair of learnable parameters: mean (μ) and standard deviation (σ).
In the most basic form of a VAE, the objective is of the form:
LVAE(θ, φ) = Lreconst(θ, φ) + Edata[DKL(qφ(z|x)||pθ(z))],
(4)
where z is the latent variable, pθ(z) is the prior distribution on the
latent space. qφ(z|x) is the approximation of the posterior, learned
by the encoder and DKL represents the Kullback–Liebler divergence
(Kullback & Leibler 1951).
Higgins et al. (2017) introduce β-VAE in which more disentanglement
 is enforced by increasing the weight (λ) of the second term:
L(θ, φ) = Lreconst(θ, φ) + λEdata[DKL(qφ(z|x)||pθ(z))]
(5)
which from another perspective, pushes for maximizing the MI
between z and x – e.g. see Burgess et al. (2018). We follow the same
formulation for enforcing disentanglement in our implementation.
However, we find that pushing for too much disentanglement by
setting λ to too high a value, even values close to 1 as suggested
by Kingma & Welling (2014) and Higgins et al. (2017), results in
too much loss of reconstruction quality, rendering it against the main
goal of this work. We assess this trade-off between disentanglement
and reconstruction quality in the upcoming sections and find λ = 0.3
a reasonable choice for the current task.
4 DATA SET
The data set is built from observations using the HARPS instrument,
a fibre-fed high-resolution echelle spectrograph dedicated to the
discovery of exoplanets (Mayor et al. 2003). The spectrograph has a
resolving power of 115 000 and covers the spectral range 378–691
nm. We use the ∼270 000 HARPS fully reduced spectra available in
the ESO Science Archive5 in our investigations.
The data set consists primarily of stellar spectra, although has an
extended diversity due to the presence of Solar system objects such as
Jupiter and its Galilean moons, and asteroids. Although these objects
are potential contaminants, we decide to leave them in the data set, to
keep the degree of supervision close to zero. We only had to remove
unusable spectra: the ones containing undefined or unrealistic flux
values, reflecting instrumental errors.
The spectra are homogenized by trimming down to the same
minimum (3785 Å) and maximum (6910 Å) wavelengths, and then
zero-padded either side to the reach the same number of pixels. We
chose this length to be 327 680 = 218 + 216 – reasonably close to
a power of 2 for computational purposes. With the same resolution
(0.01 Å), the wavelengths in the spectra are therefore represented by
the index of the flux vector. The result is a one-dimensional input for
the network to train on.
5The retrieval form to access these spectra is at http://archive.eso.org/wdb/
wdb/adp/phase3 main/form
MNRAS 501, 6026–6041 (2021)
Downloaded from https://academic.oup.com/mnras/article/501/4/6026/6121645 by Periodicals Section, UMIST Library & Information Service user on 08 August 2023
6030
N. Sedaghat et al.
4.1 Imbalanced Observations
Any data set can potentially have different numbers of observations
(instances) for different objects. An extreme example in the case
of HARPS is HD128621 (α Cen B) for which there are ∼20 000
instances in the data set, whereas many other objects have been
observed only once.
Just like in any other data-driven method, ignoring this effect,
which is quite similar to a selection function, would allow dominant
objects to inject bias and prevent the learned features from being
representative of the whole data set. But in order to stay fully
unsupervised we take two parallel approaches and compare the
results: First we implement a visibility balancing technique in which
visibility weights are incorporated during training, set to be inversely
proportional to the occurrence frequency of each object in the data
set. Then we also run the same experiments ignoring the imbalance.
As we will see in the upcoming sections, the major physical
concepts that are captured by the network remain consistent across
the two experiments. However, as expected, some other nodes start
to learn features influenced by the dominant (class of) objects.
Also, in some of the test experiments, we are interested in looking
at each object only once. We extract a ‘unique’ list of objects for
this purpose, in which multiple observations of each object are
discarded and simply the first one is picked. We extract the number
of occurrences only based on the ‘target-name’ field in the database.
While the target names in HARPS are not 100 per cent reliable, we
decide to accept the error as it can only influence the results in a
negative way, and does not introduce any kind of false hope. In the
272 376 spectra queried from the data base at the start of the work,6
we get 7653 unique target names.
5 RECONSTRUCTION RESULTS
5.1 Deterministic autoencoder
Theoretically, the quality of the reconstructed spectra should heavily
depend on the size of the bottleneck, as it reflects the amount of
preserved information.
Reconstructions with various bottleneck sizes are displayed in
Fig. 3. Interestingly, with a bottleneck as low as eight dimensions,
we already get a very good reconstruction of most of the spectra.
With only two latent dimensions, the network tends to preserve
only the overall shape of the spectrum. Conversely, the higher
the number of bottleneck dimensions is, the more accurately the
output follows fine features of the input. A detailed analysis of this
behaviour is beyond the scope of this paper and will be provided in
an upcoming article.
5.2 With disentangled features
Fig. 3 also depicts reconstruction examples with disentangled features.
 As expected, disentanglement comes at the cost of losing reconstruction
 quality. Hence, to obtain a high degree of reconstruction
quality and disentanglement at the same time, the bottleneck needs
to have a higher number of dimensions.
5.3 Training set versus validatation set
We split HARPS into training and validation subsets simply based on
the index, after being sorted on the ‘ADP ID’ field. The field presents
6We make the subset available to public.
just a unique identifier and does not have any meaningful correlation
with real-world features, such as observation time or object type, and
is therefore safe for the purpose.
The split has been used to monitor the training process and
avoid overfitting. We also investigated possible differences in reconstruction
 quality across the two subsets subjectively, and found
no meaningful difference.
6 THE PHYSICS THE NETWORK LEARNS TO
INFER
The main objective is not for the network to reconstruct the input with
a high accuracy, but rather to learn a minimal useful representation of
the spectra. In this section, we try to interpret the learned features, and
seek to find traces of physical semantics. We pursue ablation study
by cracking open the network and analysing the statistical behaviour
of the latent nodes.
To this end, we forward-pass an ensemble of spectra half-way
through the network and store the ensemble of latent representations,
to form a n × d matrix of codes. This compact matrix, in practice,
contains the whole ensemble, in a compressed format, and suffices
for all statistical analyses. We use the unique subset introduced in
Section 4.1 for this purpose, since dominant objects in the data set,
like α Cen-B with ∼20 000 instances, would bias and occlude our
analyses otherwise.
6.1 Informative dimensions
Our very first analysis is to find out how many informative features
the network really has learned. To this end, we utilize median absolute
deviation (MAD), as a robust measure of statistical dispersion as an
initial score of informativeness. The score for the ith latent node (Zi)
is computed as
MADi = median
j

|Zi
j −˜
Zi|

,
(6)
where j iterates over samples (spectra) and ˜
Zi = median
j
(Zi).
Although such a dispersion measure is, by definition, tied to the
diversity of the underlying data set, still any important property of
the samples should show enough variability across different samples
– or else it contains close to zero information for our purpose, hence
deemed unimportant.
There is one degree of freedom (hyper parameter) which seems
to affect the number of informative nodes: the disentanglement
weight (λ) of equation (5). In Fig. 4, we see that, lower levels of
disentanglement simply result in too many significant dimensions,
which cannot be called informative anymore, as disentanglement is
not really happening. Fig. 5 depicts how two significant dimensions
may still be highly correlated – evidence that the disentanglement
has failed.
Too much disentanglement, on the other hand, results in fewer
significant dimensions, which may seem as a good outcome in
the first look. However, our experiments show that reconstruction
quality decays so much that fine details are discarded and the few
learned features are all centred around the overall shape of the
spectra – Fig. 6. This trade-off is a well-studied characteristic of
unsupervised disentanglement methods – e.g. see Burgess et al.
(2018). Networks with other bottle-neck dimensionalities follow the
same trend, although narrower bottlenecks inherently tend to (have
to) discard fine details.
We find that a disentanglement weight λ of around 0.3 provides
a reasonable trade-off, where no two significant dimensions show
MNRAS 501, 6026–6041 (2021)
Downloaded from https://academic.oup.com/mnras/article/501/4/6026/6121645 by Periodicals Section, UMIST Library & Information Service user on 08 August 2023
Machines learn to infer stellar parameters
6031
Figure 3. Illustration of the effects of two major factors on reconstruction quality: latent space dimensionality and disentanglement. The left two columns
illustrate reconstruction loss over the whole spectra, while on the right the same effects are depicted, in two different zoom levels, on an exemplar single
spectrum: Input (blue) and reconstructed version (orange) are overplotted. Comparing the results of the deterministic autoencoder, and that of the disentangled
variational autoencoder, we can clearly see the sacrifice in reconstruction quality, that occurs for the sake of disentanglement. On the other hand, as we increase
the number of latent dimensions (top-down direction in the figure), reconstruction quality for fine details is enhanced.
Figure 4. M.A.D. values for 128-d network on the top and 8-d network on the
bottom. From left to right, the disentanglement weight (λ) is increased. Too
low weights result in leak of information among different dimensions, while
too high values cause loss of details which causes better disentanglement, yet
less useful features. Interestingly the 128-d and 8-d networks agree on the
number of informative features at λ = 0.3.
significant correlation – i.e. good disentanglement. Interestingly,
we find exactly six informative latent dimensions in two different
networks with latent dimensionalities of 8 and 128.
In the next section, we take an information theoretic approach
towards detection of traces of physics in latent features, which
is completely independent of the informativeness indicator of this
section. But as we move forward we find a reassuring harmony
between the two methods.
6.2 Mutual information – with known physics
So far we have identified the dimensions which, from a purely
statistical point of view, seem to have captured significant features
of the stars. Now we seek to interpret the learned features and find
specific traces of physics. The search is conducted over all the latent
features, to avoid any bias from the statistical scores of previous
section.
Assuming we have access to a large number of known (astro)physical
 parameters, we seek MI between them and the latent
features the network has learned. Pearson correlation is too limited
MNRAS 501, 6026–6041 (2021)
Downloaded from https://academic.oup.com/mnras/article/501/4/6026/6121645 by Periodicals Section, UMIST Library & Information Service user on 08 August 2023
6032
N. Sedaghat et al.
Figure 5. Scatter plots illustrating mutual behaviour of pairs of latent
dimensions. On the top, there is little to no significant correlation between
the two. In contrast, the bottom two plots show clear correlation between
exemplar dimension pairs, in networks where λ has been too low, which
is a strong hint for failure of disentanglement. In such cases, a high
M.A.D. does not directly translate to possession of exclusive information.
Contrary to intuition, the less structured the plots are, the more successful the
disentanglement has been. Different colours show different spectral classes
and are used for illustration purposes only.
as it can only capture linear dependence with Gaussian noise, while
‘MI is able to quantify the strength of dependencies without regard
to the specific functional form of those dependencies’ (Kinney &
Atwal 2014).
MI of two jointly discrete random variables is defined as (Cover
1991)
I(X; Y) =

y∈Y

x∈X
p(X,Y)(x, y) log
 p(X,Y)(x, y)
pX(x) pY (y)

.
(7)
A more intuitive formulation is given by
I(X; Y) = H(X) −H(X|Y) = H(Y) −H(Y|X)
(8)
and defines MI as the amount of uncertainty lost in one of the
variables by knowing the other one. In equation (8), H(.) is the
Shannon Entropy (Shannon 2001).
Figure 6. From top to bottom, the effect of too much disentanglement
enforcement is visualized. The network loses the ability to preserve details,
i.e. narrow lines, and starts focusing on the overall shape only. In such a case,
although the significant dimensions learn disentangled representations, the
captured concepts are too simplistic and not much useful.
Given a number of data points, it is often difficult to obtain an
accurate estimate of the MI of the underlying random variables, as
it involves estimation of the underlying joint distribution. For the
task at hand, however, we are not much interested in the exact value
of the MI, as it is a relative indicator when considering all latent
dimensions.
We use joint histograms to simply approximate the joint density.
Still, the estimated MI’s turn out to be quite sensitive to the chosen
number of bins. Therefore, to have a simple, yet robust indicator, we
provide a two-step workaround: (a) sigma-clipping at 5σ, and (b)
multiscale (scan at various bin resolutions).
We extracted some of the known astrophysical features, for a
portion of our data set, from SIMBAD (Wenger et al. 2000), TIC
Stassun et al. (2019), and observation-time parameters:
(i) effective temperature (Teff)
(ii) surface gravity [log(g)]
(iii) metallicity ([M/H])
(iv) radial velocity
(v) airmass
(vi) signal-to-noise ratio (SNR)
MNRAS 501, 6026–6041 (2021)
Downloaded from https://academic.oup.com/mnras/article/501/4/6026/6121645 by Periodicals Section, UMIST Library & Information Service user on 08 August 2023
Machines learn to infer stellar parameters
6033
Figure 7. Correlation indicators based on MI at different scales. The depicted matrix at each row shows different scales (binning configurations) along the
vertical axis and different nodes are sitting horizontally. Each row of each indicator, representing a single scale, is normalized by max. For radial velocity,
effective temperature, and surface gravity, individual nodes stand out, while for metallicity, airmass, and SNR, that is not the case.
Steps of the process are detailed in Appendix B.7
We construct MI indicators as explained above, to seek traces
of these intrinsic astrophysical stellar parameters in all dimensions
of our networks. Results for the 128-dimensional network are
illustrated in Fig. 7. Clear signs of strong correlation are seen for
radial velocity at dimension {124}, and Teff, log(g) at dimension
{85}. No clear dimension stands out for [M/H] airmass and
signal-to-noise ratio (SNR).
The two detected ‘physical dimensions’ have already been identified
 by the purely statistical indicator of the previous section,
which increases the reliability of the finding. Visualization of the
direct relationship between latent features and their corresponding
validation labels in Figs 8 and 9, shows that the network has clearly
grasped a direct notion of these physical concepts.
6.2.1 Analysis
Node {85} shows correlation with both effective temperature and
surface gravity. Its correlation with the effective temperature is clear,
monotonic and tight, providing close to a one-to-one mapping from
node values to temperatures – Fig. 8, top row.
The reason surface gravity is captured with the same dimension
becomes clearer after plotting the scatter of the two physical parameters
 (not the node values) against each other – bottom row of Fig. 8. It
turns out that the input data set presents a biased view when it comes
to temperature and gravity, in that it does not sample uniformly
the general underlying stellar population. Concretely speaking, in
the objects the network has seen, temperature and surface gravity
are more or less strongly correlated. From an information theoretic
point of view, surface gravity does not provide much exclusive
information, and a big fraction of the information in it is shared
with effective temperature. In other words, the network does not
need to dedicate an independent node to store information about this
physical parameter, when it can obtain most of what it needs from
another node – especially under disentanglement pressure. Of course,
the network needs to store the exclusive part of the information about
7We re-emphasize that the learning process has been a fully unsupervised one
and such labels have been merely used post-training for validation purposes
only.
this parameter, which is reflected in the scattered points in the plot,
somewhere. That place is most likely in one of the discarded nodes.
Node {124} has captured information on the stars’ radial velocity.
The correlation is shown visually in Fig. 9. The plot shows that
the network has automatically learned a model for hypothetical,
reference, zero-velocity spectra, since it has formed a symmetric
mapping around it. The mapping is of course not a bijective function.
It is also worth noting that for colder stars the correlation is quite
tight and progressively loosens for hotter stars, until it essentially
vanishes at the highest temperature available in our data set. We
speculate that the increasing sparseness of absorption features with
increasing temperature is responsible for the observed behaviour.
The spectral absorption from the Earth atmosphere as parametrized
by the airmass affects the large-scale shape of the spectra, a prominent
feature that could be expected to be picked out by the network.
The same could be expected for metallicity. A posteriori, however,
this does not seem to be the case since neither of these parameters
are significantly correlated with any of the dimensions, as gauged
by the MI results, which may look puzzling at first glance. This
may be, however, related to the fact that HARPS has a relatively
narrow wavelength range, mostly bluewards of most telluric features.
HARPS is mostly an exoplanet hunter, and those are mostly looked
at around solar-like or cooler stars, and our sample is strongly biased
against containing early-type stars. This can be seen in Fig. 8, where
it is also clear that our data set is mostly comprising main-sequence
stars. It also covers a limited range in metallicity, while the optimized
New Short Term Scheduler used by most HARPS visitors
implies that most targets are observed at the best (i.e. lowest) airmass
possible. It is therefore not surprising that the algorithm could not
find a correlation with metallicity and airmass.
One may also expect SNR to be captured by the network as an
independent feature, since it plays a role in forming the appearance
of an spectrum. This is, however, not the case and comes as little
surprise; the noise is uncorrelated with any other type of information
in the data set and by definition does not contain any pattern
across different spectra to be learned. Thus, for a model to capture
and reconstruct pixel-accurate noise, it would need to assign one
parameter per pixel per spectrum – i.e. memorize the noise. This
advantageous limitation is a well-known feature of even the simplest
classical autoencoders, such that denoising autoencoders have been
MNRAS 501, 6026–6041 (2021)
Downloaded from https://academic.oup.com/mnras/article/501/4/6026/6121645 by Periodicals Section, UMIST Library & Information Service user on 08 August 2023
6034
N. Sedaghat et al.
Figure 8. Node {85} shows a good correlation with effective temperature
– top row. The tightness of the structure reflects the strength of the MI. The
same node shows a not-so-strong correlation with surface gravity – middle
row. Plotting log(g) versus Teff in the bottom row reveals the reason. Please
refer to the main text for a detailed analysis. It is also useful to note that
our sample is very biased towards main sequence stars, with the log g only
varying between ∼3.5 and 5.
among the first ones to be used (Vincent et al. 2010). Such behaviour
is of course seen in many other methods used for dimensionality
reduction, such as PCA – e.g. see Bailer-Jones et al. (1998).
6.3 Latent space traversal
Although we run out of available physical labels or/and automatically
detected correlations, we go further and pursue deeper investigation
based on a method known as latent space traversal. We start by
forward-passing single spectra half-way through the network, just the
way we did in the beginning of this section, to encode the spectrum
into its latent representation. Then by perturbing (or traversing, in extreme
 cases) the code and generating the corresponding spectrum, we
can have synthetic spectra which are different to the (reconstructed
version of) the original spectrum as a result of the change in the code.
So, singling out dimensions of the latent space allows for analysis of
the effects of specific dimensions on the generated spectra, hopefully
equal to interpretable features.
To this end, we create an interface with sliders which allow for
traversal over different dimensions and visualization of the effects
on the fly – Fig. 10. In the following, we list the significant findings.
Node {11} seems to be, partly, related to the rotation of the star,
which is another parameter that is known to affect the spectra – a
higher rotation will broaden the lines, making them less deep. Varying
the value of this node does not affect the shape of the continuum,
Figure 9. Node {124} learns a clear understanding of a notion of radial
velocity – top row. The symmetric shape, and the fact that the network has
automatically gained an understanding of zero velocity as a reference point
are notable observations. Different temperatures have apparently been treated
differently, as also detailed in the bottom row.
but only the depth of the lines. Thus, an increased value of the
node corresponds to much broader lines and this is clearly an effect
of increasing rotational velocities (or macroturbulence in general).
Above a given threshold, however, the situation is more complex: for
solar-like stars, the match seems to be done only on stars that have
quite a large radial velocity shift. We have not yet found a physical
reason for this. For early-type stars, the lines do not become broader
either, but instead the Balmer lines clearly become narrower. This is
likely an effect of the gravity of the star.
Node {19} is only affecting a subset of our sample, namely only
the coolest stars. It has indeed no effect on solar-like stars or earlytype
 stars, but only affects stars that have a value of node {85} above
about 0.85, that is, stars cooler than ∼4500 K. For these stars, this
node is clearly linked with the luminosity of the star. This node is
thus also physical, but confined to a subset of the stars, only the
coolest ones – see Fig. 10 for an illustration.
Node {58} has, similarly to above, no apparent effect on the
spectra of solar-like or early-type stars, but only manifests itself for
even cooler stars than node {19}, those that are characterized with a
value of node {85} above about 1.2. However, we could not find as
yet a clear explanation of the effect at play when varying the value
of node {58}, and we defer a detailed analysis to further work.
Node {99} is contrarily to node {11} affecting the continuum of
the star, more than the lines themselves. It is also, unlike the previous
two nodes, not really affecting solar-like and cooler stars, but has only
a visible effect on stars hotter than the Sun. From a phenomenological
point of view, this node appears to be looking at the inflexion point
of the continuum and whether the spectrum is thereby concave
or convex. Thus, for very negative values (e.g. −4.5), there is a
depression in the spectrum around 5800 Å, which disappears at about
−1.7, while for positive values, there is a maximum around 5300 Å.
The clear physical explanation of this apparent phenomenological
node is hard to find, but a first investigation indicates that it may
be related to the presence of a disc (such as around Be stars) or a
companion. Further studies are needed.
6.4 Discarding observation frequencies
Using the non-balanced data set, we obtain five significant nodes, two
of which correspond exactly to the major captured physical features:
{85} and {124}.
MNRAS 501, 6026–6041 (2021)
Downloaded from https://academic.oup.com/mnras/article/501/4/6026/6121645 by Periodicals Section, UMIST Library & Information Service user on 08 August 2023
Machines learn to infer stellar parameters
6035
Figure 10. Our interface for latent space traversal, showing three different experiments. All experiments share the same randomly chosen ‘reference’ star,
shown in blue. This reference is encoded by the network, the obtained code is slightly modified using the sliders, and decoded to generate the orange spectrum.
This resulting spectrum is usually an imaginary one and thus, we illustrate the closest real object to it in green. This closest object is searched for in the learned
latent space. From top to bottom, we show experiments for the effects of {85} (effective temperature), {124} (radial velocity), and {19}, respectively. For the
latter, which applies only to cool stars, we had to ‘move’ the base spectrum to a late-type star, using {85}.
MNRAS 501, 6026–6041 (2021)
Downloaded from https://academic.oup.com/mnras/article/501/4/6026/6121645 by Periodicals Section, UMIST Library & Information Service user on 08 August 2023
6036
N. Sedaghat et al.
Two nodes represent features that are also seen as in the balanced
set: {11} and {88} (the latter, corresponding to node {99} of the
balanced set).
Representations captured in nodes {19} and {58} of the balanced
net are clearly not present any more, as we cannot spot any node
specifically representing only the coolest stars. The effect of the
remaining node, {99}, is not clear cut. It seems that for the hottest
stars (>10 000 K), it is partially sensitive to the gravity of the stars:
the lowest values of this node correspond to white dwarfs (i.e. high
gravity), while the highest values correspond to solar-like stars. It
has no apparent effect for A/F/G stars, nor for M stars, but there is
an effect on K stars as well. We could not identify the physical nor
phenomenological criteria that would correlate with this node.
7 CONCLUSION
We implemented the idea of ‘letting the data speak for itself’ in
action, in the context of an astrophysical application, where we let a
deep convolutional neural network look at stellar spectra and learn
from them without any predefined objectives in mind. We showed
that the network ‘chose to’ learn how to extract and capture specific
physical parameters of stars, among other unidentified ones, as their
canonical features. The importance of the finding is in network’s
answer to ‘what is important to learn?’, and should not be confused
with the relatively trivial problem of training a network for estimation
of those parameters.
Specifically, our purely statistical measure revealed that 6 out of
128 latent nodes of our network stand out as informative ones. We
also developed an information-theoretic indicator to track true/nonlinear
 correlations between the learned features and a set of known
astrophysical parameters. We found that two latent nodes, which
interestingly turned out to be among the six informative ones, have
clearly learned a notion of radial-velocity and effective temperature.
The automatic method did not indicate correlations between the
remaining significant dimensions and the validation labels we had at
hand. This does not necessarily indicate a false alarm on those nodes.
They may have captured known physical parameters for which we
do not have labels yet, or the existing labels might have not been
quite reliable to reveal weaker correlations.
Also, it is quite possible that the other nodes have not captured direct
 representations of familiar physical parameters, but rather other
complex (or even simpler) features. Artificial neural networks do not
have to think like humans! For example, We spot nodes which capture
variations of specific absorption lines. They may have captured fine
features of chemical abundances – something that is not formulated
in classical astronomy, with this level of granularity. We believe
such features that are not directly interpretable are interesting for
follow up studies, since understanding the reasons behind a network’s
decision to prioritize more complex/simpler features, or higher level
relationships between basic features, may help advance our physical
understanding of the underlying target – stars in this case.
We continued with latent space traversal and found traces of
rotation, luminosity, presence of a disc or a companion, in the
unidentified nodes, some affecting only a subset of our sample (either
the coolest stars, or the hottest). The latter correlations were, however,
not as clear as the previous ones and were decided to be left for future
studies. We make the interface available to public for this purpose.
As mentioned earlier, our data set for this case study is very
specific, due to the particularities of HARPS usage. It is to be
expected that in more generic samples, other features, e.g. luminosity
or metallicity, may come out more easily. In general, the concepts the
network learns to capture, are dependent on the biases in the data set.
ACKNOWLEDGEMENTS
This work is in part supported by the ESCAPE project (the European
Science Cluster of Astronomy & Particle Physics ESFRI Research
Infrastructures) that has received funding from the European Union’s
Horizon 2020 research and innovation program under the Grant
Agreement no. 824064. We also acknowledge support for our
research by funding from the Science and Technology Facilities
Council. Lastly, we thank Michael F. Sterzik, Mark Allen, Henri
M. J. Boffin, and Felix Stoehr for their help in preparation of the
manuscript.
DATA AVAILABILITY
We release the code for the convolutional neural network, the list of
IDs of the spectra used for training and validation and the physical
validation labels on https://www.eso.org/∼nsedagha/universe. We
also make the ‘sliders’ interface freely accessible to the community
to facilitate study and discovery of new relationships with the
introduced framework.
INTRODUCTION
In
astrochemistry,
complex
organic
molecules
(or
COMs)
are
defined
as carbon-bearing compounds with at least 6 atoms in their structure
(Herbst & van Dishoeck 2009
). It was initially believed that COMs
could only form on dust grains in the presence of a source of
heat via hydrogenation, atom addition and radical–radical reactions
(Watanabe
&
Kouchi
2002
;
Garrod,
Weaver
&
Herbst
2008
).
Indeed,
COMs
were
firstly
detected
in
relatively
hot
sources
with
T
≳
100
K,
such as massive hot cores (Hollis, Lovas & Jewell 2000
; Hollis et al.
2006
; Belloche et al. 2008
, 2013
) or low-mass warm cores (hot
corinos; Bottinelli et al. 2004
; Jørgensen et al. 2013
). Ho
we
ver, the
detection of several COMs in the gas phase in starless/pre-stellar
cores and dark cloud cores (e.g. Marcelino et al. 2007
; ¨
Oberg et al.
2010
; Bacmann et al. 2012
; Cernicharo et al. 2012
; Vastel et al.
2014
; Jim
´
enez-Serra et al. 2016
, 2021
; Scibelli & Shirley 2020
)
indicates that there must be another chemical pathway that allows
the presence of COMs in the gas phase at temperatures as low as
10
K.
In
the
last
years,
there have been different
proposals
to
explain
the formation of these COMs under these conditions. Ho
we
ver, the
chemical pathways giving rise to COMs in cold cores is not well⋆

E-mail:
amegias@cab.inta-csic.es
understood yet, and more observations are needed to constrain the
proposed models (Rawlings et al. 2013
; Vasyunin & Herbst 2013
;
Balucani, Ceccarelli & Taquet 2015
; Vasyunin et al. 2017
; Holdship
et al. 2019
; Jin & Garrod 2020
; Punanova et al. 2022
). For example,
Scibelli et al. (
2021
) studied the starless core L1521E, claiming
that COMs are not only formed by gas-phase reactions, bus also by
surface reactions on dust grains. Other authors suggest that cosmic
rays
induce
desorption
from
icy
mantles
on
dust
grains
(Redaelli
et
al.
2021
; Sipil
¨
a, Silsbee & Caselli 2021
). It is remarkable that methanol
(CH
3
OH), which plays a central role in the formation for larger
COMs,
is
detected
systematically
in
starless
cores
(Scibelli
&
Shirley
2020
), and thought to form on the surface of dust grains, partially
returning into the gas phase upon reactive desorption (Garrod et al.
2006
; Garrod, Wakelam & Herbst 2007
; Vasyunin et al. 2017
).
In order to understand how COMs form under the cold conditions
of pre-stellar/starless cores, Jim
´
enez-Serra et al. (
2016
, 2021
) investigated
 the radial distribution of large COMs as a function of radius
in the L1544 and L1498 starless cores. Methanol tends to show a
ring-like morphology circumventing the dust continuum emission
(see Tafalla et al. 2006
; Bizzocchi et al. 2014
; Spezzano et al. 2016
;
Punanova et al. 2022
). Since mapping the emission of larger COMs
in starless cores requires large amounts of telescope time, Jim
´
enezSerra
 et al. (
2016
, 2021
) observed two positions within these cores:
© 2022
The
Author(s)
Published
by
Oxford
University
Press
on
behalf
of
Royal
Astronomical
Society
Downloaded from https://academic.oup.com/mnras/article/519/2/1601/6849986 by University of Manchester user on 10 May 2023
1602
A. Meg
´
ıas et al.
MNRAS 519, 1601–1617 (2023)
the centre, defined by the position of the dust peak, and the location
where methanol peaks. The latter position is representative of an
outer,
intermediate-density
shell
located
at
radii
between
∼4000
and
∼11
000 au from the core centre in L1544 and L1498, respectively.
Several COM precursors have been found toward both cores such
as tricarbon monoxide (CCCO) and cyanoacetylene (HCCCN), but
more complex molecules like acetaldehyde (CH
3
CHO), methyl
formate (CH
3
OCHO), or dimethylether (CH
3
OCH
3
) have only been
detected towards L1544, which is at a more advanced stage of
evolution
than
L1498
(see
Jim
´
enez-Serra
et
al.
2016
,
2021
).
However,
N-bearing
COMs
are
detected
towards
L1498
with
abundances
close
to those measured towards L1544.
In
this
work,
we
present
a
similar
study
carried
out
towards
another
starless core, L1517B, believed to be at an even earlier stage of
evolution than L1498 based on the deuterium fractionation and
the absence of infall motions (Crapsi et al. 2005
). The goal is to
compare chemical complexity measured towards L1517B with that
observed in L1544 and L1498, and to establish if the observed trend
of increasing chemical complexity is due to evolution (see Jim
´
enezSerra

et
al.
2016
,
2021
).
These
cores,
located
in
the
Taurus
molecular
cloud complex, sho
w dif
ferent observ
ational signatures that provide
information about their stage of gravitational collapse. L1544 is
classified as a pre-stellar core because it shows clear evidence of
gravitational collapse towards its innermost regions as probed by
the emission of N
2
H
+ (Caselli et al. 2002
; Redaelli et al. 2019
).
Its
high
deuterium
fractionation
(
N
N
2
D
+
/N
N
2
H
+ = 0
.
23 ± 0
.
04),
CO
depletion factor (
f
CO = 14 ± 3; Crapsi et al. 2005
; Redaelli et al.
2019
), and central H
2 density (
n
H
2 ∼10
7 cm
−3
; Caselli et al.
2022
), are also consistent with this idea. L1498 presents signatures
of infall motions in the outer envelope of the core as revealed
by the asymmetries observed in the line profiles of CS (Tafalla
et al. 2004
) but its deuterium fractionation, CO depletion factor
and central H
2 density are lower than those measured towards
L1544 (
N
N
2
D
+
/N
N
2
H
+ = 0
.
04 ± 0
.
01, f
CO = 7.5 ± 2.5, and n
H
2 ≃
9
.
4 × 10
4 cm
−3
;
Tafalla
et
al.
2004
;
Crapsi
et
al.
2005
).
For
L1517B,
the CO depletion factor and deuterium fractionation are similar to
those of L1498, f
CO = 9.5 ± 2.8 and N
N
2
D
+
/N
N
2
H
+ = 0.06 ± 0.01
(Crapsi et al. 2005
). Ho
we
ver, although L1517B sho
ws a slightly
higher central H
2 density (
n
H
2 ≃ 2
.
2 × 10
5 cm
−3
), the absence of
infall motions either towards the innermost regions or towards the
envelope (Tafalla et al. 2004
), suggests that L1517B is at a younger
evolutionary stage than L1498 and L1544. Hence, L1517B, located
at a distance of 159 pc (Galli et al. 2019
), would be the dynamically
youngest of the three cores.
The paper is organized as follows. In Section 2
, we describe the
observations
carried
out
towards
L1517B.
In
Section
3
,
we
present
the
results
of
the
analysis
of
the
COMs
and
COM
precursor
emission
and
report
the
values
of
the
derived
excitation
temperatures,
column
densities,

and
molecular
abundances.
Section
4
compares
the
abundances
obtained towards L1517B with those measured towards L1498 and
L1544. We also compare our results with those reported by Nagy
et al. (
2019
) and Scibelli et al. (
2021
) towards the young L1521E
starless core. This core has been found to be rich in COM emission
despite
its
youth.
In
Section
5
,
we
present
the
modelling
of
the
COMs
and COM precursor chemistry of the L1517B core, and compare the
model predictions with the observations. In Section 6
, we compare
the column densities ratios between the N-bearing species HC
3
N
and CH
3
CN derived towards L1517B, L1498, L1544, and L1521E
with
those
obtained
in
protostellar
systems,
protoplanetary
discs,
and
comets,
and
discuss
the
observed
discrepancies.
Finally,
in
Section
7
,
we summarize our conclusions.
Figure 1. H
2 column density map obtained from Herschel
/
SPIRE data at
0.25,
0.35,
and
0.50
mm,
using
the
same
procedure
as
the
one
used
for
L1544
in
Spezzano
et
al.
(
2016
).
Crosses
indicate
the
positions
observed
in
the
core:
the
dust
peak
(in
black)
and
the
methanol
peak
(in
red).
The
beam
size
for
each
filter is 17.9, 24.2, and 35.4 arcsec (0.25, 0.35, and 0.50 mm, respectively),
although the images of the two first filters were smoothed to the resolution
of 0.50 mm, which is marked with a circle at the bottom-left corner of the
image.
The
positions
of
the
dust
and
methanol
peaks
are
obtained
from
Tafalla
et
al.
(
2004
,
2006
).
The
beam
sizes
were
retrieved
from
the
SPIRE
Handbook:
ht
tps://www.cosmos.esa.int
/web/her
schel/spir
e-over
view
.
Table
1. Frequenc
y
ranges,
v
elocity
resolution,
and
RMS
noise
lev
el
of
our
observations.
Frequency
Resolution
RMS
noise
(mK)
(GHz)
(km
s
−1
)
Dust
peak
Methanol
peak
78.2–80.0
0.18
4
.8
3
.9
81.4–83.3
0.18
4
.2
3
.5
83.3–85.2
0.17
2
.8
3
.3
86.7–88.5
0.17
3
.0
3
.5
93.5–95.7
0.15
4
.1
3
.4
95.8–96.8
0.15
10
.8
10
.9
97.1–99.0
0.15
4
.1
3
.6
99.1–100.9
0.15
3
.0
3
.5
102.4–104.2
0.14
4
.1
4
.7
109.2–111.0
0.13
10
.1
11
.0
2  OBSERVATIONS
The observations of the L1517B starless core were carried out
from 2020 September 30th to October 4th, with the Instituto de
Radioastronom
´
ıa Milim
´
etrica (IRAM) 30-m telescope (Granada,
Spain). As for L1544 and L1498, we observed two positions within
the L1517B core: the location of the dust peak and the position
where the emission of methanol peaks. These two positions have
the equatorial coordinates (in J2000 system) α = 4
h
55
m
17
.
s
6, δ =
30
◦37
′
44
′′ for the dust continuum peak, and α = 4
h
55
m
15
.
s
7, δ =
30
◦38
′
04
′′ for the position of the methanol peak (see Tafalla et al.
2004
, 2006
). The latter is located ∼32 arcsec away from the dust
peak (see Fig. 1
), which corresponds to ∼5000 au at a distance of
159 pc.
The high-sensitivity 3-mm spectra were obtained in frequencyswitching
 mode using a frequency throw of 7.14 MHz. The EMIR
E090 receivers were tuned at 84.37 and 94.82 GHz with rejections
of ≥10 dB. The observ
ed frequenc
y ranges are shown in Table 1
. To
identify possible weak spurious features in the observed spectra, we
Downloaded from https://academic.oup.com/mnras/article/519/2/1601/6849986 by University of Manchester user on 10 May 2023
The organic molecular content in L1517B
1603
MNRAS 519, 1601–1617 (2023)
carried out part of the observations by shifting slightly the central
frequencies by ±20 MHz (see also Jim
´
enez-Serra et al. 2016
). We
used the narrow mode of the FTS spectrometer that provided a
spectral resolution of 49 kHz, equi
v
alent to 0.13–0.18 km s
−1 at
3
mm.
Typical
system
temperatures
ranged
between
75
and
110
K
and
the telescope beam size was 22–31 arcsec between 78 and 111 GHz;
as the beams are almost Gaussian and the dust and methanol peaks
of L1517B are located ∼32 arcsec away (
> 2
σ), the contamination
between both positions should be negligible (less than 5 percent).
The spectra were calibrated in units of antenna temperature, T
∗
A
,
and converted into main beam temperature, T
mb
, by using beam
efficiencies of 0.81 at 79–101 GHz and of 0.78 at 102–111 GHz.
1
The
root
mean
square
(RMS)
noise
level
of
the
original
observations
ranged between 3 and 11 mK for both observing positions (see
Table 1
), having similar values for each frequency range than the
ones obtained by Jim
´
enez-Serra et al. (
2016
, 2021
) for L1544 and
L1498.
Our observations have covered the transitions of both O-bearing
and N-bearing COMs and COM precursors, summarized in Table
 2
. For O-bearing species, we have targeted methanol (CH
3
OH),
methoxy (CH
3
O), tricarbon monoxide (CCCO), ketene (H
2
CCO),
formic acid (t-HCOOH), acetaldehyde (CH
3
CHO), methyl formate
 (CH
3
OCHO), dimethylether (CH
3
OCH
3
), cyclopropenone (cC

3
H
2
O),
and
propynal
(HCCCHO).
As
N-bearing
COMs
and
precursors,

we
have
observed
cyanoacetylene
(HCCCN),
isocyanoacetilene
(HCCNC), vinyl cyanide (CH
2
CHCN), acetonitrile (CH
3
CN), and
methyl isocyanide (CH
3
NC).
The raw spectra have been analysed and reduced with CLASS
,
from the package GILDAS
,
2 as well as with a Python
3 pipeline
written specifically for this purpose.
4 This pipeline fits baselines
to the spectra using an iterative method that first masks the strongest
lines using sigma-clips and then applies rolling medians and rolling
averages, interpolating the masked regions with third-order splines.
Finally,
we
used
the
software
MADCUBA
(Mart
´
ın
et
al.
2019
)
to
search
for the molecular transitions of all targeted species, and to carry out
the
fitting
of
the
molecular
line
profiles
under
the
assumption
of
local
thermodynamic
equilibrium
(LTE).
The
physical
parameters
derived
in the fitting are the molecular column density (
N
obs
), excitation
temperature (
T
ex
), linewidth (
v), and LSR radial velocity (
v
LSR
).
For this, we used the tool SLIM (Spectral Line Identification and
Modelling) of MADCUBA
, employing the Cologne Database for
Molecular Spectroscopy (CDMS; Endres et al. 2016
) and the Jet
Propulsion Laboratory (JPL) molecular catalogue (Pickett et al.
1998
). In addition, for the cases of CH
3
OH, CH
3
CN, and HCCCN,
we
used
the
non-LTE
code
RADEX
(Van
der
Tak
et
al.
2007
)
to
do
the
fitting of the lines.
3  RESULTS
3.1 Detected transitions
Figs 2 and 3 show the observed spectra of some representative transitions
 of the COM and COM precursors detected towards L1517B,
while Table 2 lists all the transitions co
v
ered in our observations
with their derived line parameters. The targeted transitions are the
1 https://publicwiki.iram.es/Iram30mEfficiencies
2 https://
www.iram.fr/
IRAMFR/GILDAS
3
https://www.python.org
4
https://
github.com/andresmegias/
gildasclass-
processing

same
as
in
Jim
´
enez-Serra
et
al.
(
2016
,
2021
),
and
correspond
to
those
expected to be the brightest for an excitation temperature of ∼10 K.
Besides methanol, our spectra reveal the detection of other COMs
and COM precursor species in L1517B: CH
3
O, H
2
CCO, CH
3
CHO,
HCCCN, HCCNC, CH
3
CN, and CH
3
NC although acetaldehyde
(CH
3
CHO) was only detected towards the methanol peak and
acetonitrile (CH
3
CN) and methyl isocyanide (CH
3
NC) were only
detected towards the dust peak. More complex molecules such as
CH
3
OCH
3 or CH
3
OCHO were not detected within our noise levels.
All
detected
lines
lie
abo
v
e
the
3
σ level
in
integrated
intensity
(area),
where 1
σ is calculated as T
(
v
δv)
1
/
2
, where 
T is the RMS
noise level, v is the line width, and δv is the velocity resolution
of the spectrum (see Table 1
). We are confident about the detection
of the transitions since their derived radial velocities correspond to
the v
LSR of the source (
∼5.8 km s
−1
). Moreo
v
er, e
xcept for CH
3
OH
A, CH
3
NC, and HCCNC, we have measured at least two transitions
abo
v
e the 3
σ level in integrated intensity for the detected species,
stressing the identification of the species since the linewidths are
narrow
(
∼0.3–0.5
km
s
−1
).
The
level
of
line
confusion
at
the
targeted
RMS
noise
level
is
also
very
low,
as
commonly
found
in
starless/prestellar
 cores. For the non-detections, we provide upper limits to the
integrated intensities by using 3 T
(
v
δv)
1
/
2
.
From Figs 2 and 3
, we find that the line intensities vary for each
position:
for
the
N-bearing
species
(CH
3
CN,
HCCNC,
and
HCCCN),
the emission is brighter towards the core’s centre with respect to the
methanol peak. On the contrary, for O-bearing species (CH
3
OH and
H
2
CCO) we find that the emission level is similar for both positions.
Note that in the cases of CH
3
OH, CH
3
CN and HCCCN the fits were
obtained with RADEX
. In these cases the lines were also fitted with
independent
Gaussians
using CLASS
but
they
are
not
shown
in
Figs
2
and 3
, as they are independent fits for each transition and there are
only made to obtain the parameters of the lines shown in Table 2
.
3.2 Molecular column densities and excitation temperatures
3.2.1 LTE analysis
Using
the
tool
SLIM
from
MADCUBA
,
we
performed
the
LTE
fitting
to
the observed line profiles for each species, obtaining the parameters
shown in Table 2
. As in most cases, we detected several lines of the
same molecular species, this fitting allows us to obtain its column
density
(
N
obs
)
and
excitation
temperature
(
T
ex
).
These
parameters
are
also shown in Table 3
ipt.
Ho
we
ver, there were cases in which the MADCUBA fitting algorithm
 did not converge. This can be due because the signal-to-noise
ratio is not high enough, or also because we only have one transition
detected. In these cases, we had to fix one or more parameters, so
that the algorithm could converge. Similarly, for non-detections we
had to fix the excitation temperature so that MADCUBA could fit an
upper limit for the column density.
In general, when we needed to fix the temperature, we used the
fitted value for H
2
CCO for oxygen-bearing species, and the fitted
one
for
HCCCN
for
nitrogen-bearing
species,
as
these
are
molecules
with several transitions which also have high signal-to-noise ratio.
These
values
are,
for
H
2
CCO,
7.7
and
9.7
K
for
the
dust
and
methanol
peaks,
respectively,
and,
for
HCCCN,
6.7
and
5.3
K.
For
cases
where
we had to fix the central velocity of the line, we used a value of v
LSR
= 5.8 km s
−1
.
F
or methyl isoc
yanide (CH
3
NC) towards the core centre and
isocyanoacetylene (HCCNC) towards the methanol peak, we only
detected 1 transition, so we had to fix the excitation temperature to
T
ex = 6.7 K for CH
3
NC and to T
ex = 5.3 K for HCCNC (which
Downloaded from https://academic.oup.com/mnras/article/519/2/1601/6849986 by University of Manchester user on 10 May 2023
1604
A. Meg
´
ıas et al.
MNRAS 519, 1601–1617 (2023)
Table
2. Most
of
the
COMs
and
COM
precursors
transitions
co
v
ered
in
our
L1517B
observations
and
their
derived
line
parameters.
Dust
peak
Methanol
peak
Species
Line
Frequency
Area
a
Linewidth
LSR
velocity
b
S/N
c
Area
a
Linewidth
LSR
velocity
b
S/N
c
(MHz)
(mK
km
s
−1
)
(km
s
−1
)
(km
s
−1
)
(mK
km
s
−1
)
(km
s
−1
)
(km
s
−1
)
CH
3
OH
2
0,
2
→
1
0,
1
A
96741.371
206.1 ± 1.9
0.278 ± 0.004
5.785 ± 0.002
109
241.1 ± 2.0
0.277 ± 0.005
5.788 ± 0.002
121
2
1,
2
→
1
1,
1
A
95914.310
<
7
...
...
...
>
7
...
...
...
2
1,
1
→
1
1,
0
A
97582.798
<
2.4
...
...
...
<
2.4
...
...
...
2
1,
2
→
1
1,
1
E
96739.358
150.4 ± 1.9
0.262 ± 0.008
5.786 ± 0.003
80
181.6 ± 2.0
0.262 ± 0.003
5.785 ± 0.003
92
2
0,
2
→
1
0,
1
E
96744.545
9.7 ± 1.9
0.244 ± 0.012
5.84 ± 0.04
5.1
11.2 ± 2.0
0.23 ± 0.08
5.78 ± 0.03
5.6
2
1,
1
→
1
1,
0
E
96755.501
<
7
...
...
...
<
7
...
...
...
CH
3
O
d
F =
1
→
0
, 
=
−1
82455.980
<
4
...
...
...
<
3
...
...
...
F =
2
→
1
, 
=
−1
82458.252
5.4 ± 1.2
0.41 ± 0.08
5.81 ± 0.03
4.5
4.2 ± 0.9
0.39 ± 0.08
5.82 ± 0.03
4.7
F =
2
→
1
, 
=
+
1
82471.825
5.4 ± 1.2
0.41 ± 0.08
5.81 ± 0.03
4.5
4.2 ± 0.9
0.39 ± 0.08
5.82 ± 0.03
4.7
F =
1
→
0
, 
=
+
1
82524.180
<
4
...
...
...
<
3
...
...
...
CCCO
10
→
9
96214.813
<
7
...
...
...
<
7
...
...
...
t-HCOOH
1
1,
1
→
0
0,
0
87926.863
<
1.9
...
...
...
<
2.2
...
...
...
H
2
CCO
4
1,
3
→
3
1,
2
o81586.299

11.1 ± 1.3
0.53 ± 0.10
5.89 ± 0.04
8.5
12.6 ± 1.2
0.70 ± 0.25
5.95 ± 0.11
10
5
1,
5
→
4
1,
4
o100094.510

9.9 ± 0.9
0.53 ± 0.10
5.89 ± 0.04
11
12.6 ± 1.2
0.70 ± 0.25
5.95 ± 0.11
10
4
0,
4
→
3
0,
3
p80832.189

21 ± 4
0.53 ± 0.10
5.89 ± 0.04
5.2
17 ± 4
0.70 ± 0.25
5.95 ± 0.11
4.2
CH
3
OCHO
7
2,
6
→
6
2,
5
A
84454.754
<
2.0
...
...
...
<
2.5
...
...
...
CH
3
OCH
3
3
1,
3
→
2
0,
2
EE
82650.180
<
3
...
...
...
<
2.4
...
...
...
4
1,
4
→
3
0,
3
EE
99326.000
<
2.0
...
...
...
<
2.2
...
...
...
CH
3
CHO
5
1,
4
→
4
1,
3
A
98900.944
<
3
...
...
...
4.0 ± 0.8
0.21 ± 0.05
5.765 ± 0.018
5.0
5
0,
5
→
4
0,
4
A
95963.459
<
7
...
...
...
<
6
...
...
...
4
1,
3
→
3
1,
2
A
79150.166
<
3
...
...
...
3.9 ± 0.7
0.21 ± 0.05
5.765 ± 0.018
5.6
4
1,
3
→
3
1,
2
E
79099.313
<
3
...
...
...
3.9 ± 0.7
0.21 ± 0.05
5.765 ± 0.018
5.6
c-C
3
H
2
O
6
1,
6
→
5
1,
5
79483.519
<
3
...
...
...
<
3
...
...
...
HCCCHO
9
0,
9
→
8
0,
8
83775.816
<
2.0
...
...
...
<
2.5
...
...
...
CH
3
CN
6
0
→
5
0
110383.500
6.4 ± 1.9
0.13 ± 0.13
5.902 ± 0.023
3.4
<
6
...
...
...
6
1
→
5
1
110381.372
11.8 ± 1.9
0.24 ± 0.08
5.81 ± 0.03
6.2
<
6
...
...
...
6
2
→
5
2
110374.989
<
6
...
...
...
<
6
...
...
...
CH
3
NC
5
0
→
4
0
100526.541
3.6 ± 0.7
0.4 ± 0.3
5.87 ± 0.13
5.1
<
2.2
...
...
...
CH
2
CHCN
9
0,
9
→
8
0,
8
84945.988
<
2.0
...
...
...
<
2.5
...
...
...
9
1,
9
→
8
1,
8
83207.496
<
3
...
...
...
<
2.4
...
...
...
10
0,
10
→
9
0,
9
94276.625
<
3
...
...
...
<
2.4
...
...
...
HCCCN
9
→
8
81881.461
693.6 ± 1.0
0.395 ± 0.001
5.824 ± 0.001
694
346.7 ± 0.9
0.383 ± 0.002
5.816 ± 0.001
385
11
→
10
100076.392
286.5 ± 0.7
0.318 ± 0.001
5.842 ± 0.001
409
96.3 ± 0.8
0.290 ± 0.003
5.837 ± 0.001
120
HCCNC
8
8
→
7
8
79484.131
16.1 ± 1.1
0.31 ± 0.15
5.83 ± 0.07
15
6.9 ± 0.9
0.29 ± 0.16
5.86 ± 0.06
7.7
10
10
→
9
10
99354.250
6.8 ± 0.7
0.31 ± 0.15
5.83 ± 0.07
9.7
<
2.3
...
...
...
Note.
Line
profiles
were
fitted
using
MADCUBA
,
except
for
methanol
(CH
3
OH),
cyanoacetilene
(HCCCN),
and
acetonitrile
(CH
3
CN),
where
we
used
CLASS
(see
Section
3.2
for
details).
a
Uncertainties
in
the
line
area
are
calculated
as
T
(
ν δv)
1
/
2
,
with

T
the
RMS
noise
nevel,
v
the
line
width,
and
δv
the
velocity
resolution
of
the
spectrum.
Similarly,
upper
limits
are
calculated
as
3
T
(
v
δv)
1
/
2
.
b
LSR
stands
for
local
standard
rest
.
c
This
refers
to
the
signal
to
noise
ratio
in
integrated
intensity
area.
If
a
certain
value
has
no
uncertainty,
this
means
that
it
had
to
be
fixed
so
that
MADCUBA
could
fit
the
LTE
model
d
Hyperfine
components
of
the
N =
1
→
0
, K =
0
, J =
3
/
2
→
1
/
2transition
of
CH
3
O.
Downloaded from https://academic.oup.com/mnras/article/519/2/1601/6849986 by University of Manchester user on 10 May 2023
The organic molecular content in L1517B
1605
MNRAS 519, 1601–1617 (2023)
Figure
2. Sample
of
the
COM
and
COM
precursor
lines
observed
towards
L1517B’s
dust
continuum
peak
and
their
corresponding
fits
obtained
with
MADCUBA
(LTE,
in
red)
and
RADEX
(non-LTE,
in
orange).
See
Sections
2
and
3.1
for
more
details.
are the corresponding values for HCCCN at the dust and methanol
peaks, respectively).
For ketene (H
2
CCO), we calculated the ortho-to-para ratio (we
have detected two ortho transitions and one para transition), by
carrying out a separate fit of the transitions and by dividing the
resulting column densities of the ortho and para species. We obtain
an ortho-to-para ratio of 1
.
0
+
0
.
4
−0
.
3 for the position of the dust peak and
0
.
9
+
0
.
5
−0
.
4 for
the
methanol
peak.
This
ratio
is
different
to
what
has
been
pre
viously observed to
wards the molecular cloud TMC-1 and the
pre-stellar core L1689B, where the ratio was ∼3 (Ohishi et al. 1991
;
Bacmann et al. 2012
). An exact value of 3 would correspond to the
statistical ratio due to the nuclear spin de
generac
y. Ho
we
ver, lo
wer
values are also possible for the lowest temperatures, like in the case
of formaldehyde (H
2
CO), where an ortho-to-para ratio of 1 would
indicate that this molecule is formed under thermal equilibrium at a
temperature of ∼10 K (Kahane et al. 1984
). We note, ho
we
ver, that
we
have
only
detected
two
ortho
lines
and
one
para
line
of
ketene,
and
therefore
the
derived
ortho-to-para
ratios
can
be
subject
to
significant
uncertainties.
3.2.2 Non-LTE analysis
For
some
cases,
in
particular
for
methanol
(CH
3
OH),
cyanoacetilene
(HCCCN), and acetonitrile (CH
3
CN), we have decided to use the
non-LTE code RADEX (Van der Tak et al. 2007
) to infer the column
density N
obs of the species instead of MADCUBA
. In the case of
methanol and acetonitrile, we did it because MADCUBA could not fit
properly all the transitions, and the errors were greater than 3
σ. For
the case of cyanoacetilene (HCCCN), we opted for RADEX because
it allows us to estimate the H
2 number density, as we have two
transitions. As input parameters for these calculations, we assumed
the linewidth obtained with the MADCUBA fit (
∼0.28 km s
−1
) and
a kinetic temperature of 10 K [as inferred for all radii across the
L1517B starless core; see Tafalla et al. (
2004
) and Section 5 below].
Appendix A describes the procedure used to derive the physical
properties and their uncertainties from the modelling.
In the case of CH
3
OH, we have to distinguish between the A
and E species, making a separate fit for each molecule. We used
the collisional coefficients with H
2 given by Rabli & Flower (
2010
).
In addition to deriving the column densities reported in Table 3
,
we also derived the H
2 number density from the observations of
methanol E, as this parameter can be determined by the intensity
ratio of the detected lines. Unfortunately, for the case of methanol A
we only detected one transition so the column density was estimated
by
assuming
the
H
2 number
density
obtained
by
Tafalla
et
al.
(
2004
):
2.20
× 10
5 cm
−3 for
L1517B
core
centre
and
1.23
× 10
5 cm
−3 for
the
location of the methanol peak. For methanol E, we could derive the
H
2 number density, although the uncertainties are high, obtaining
values of 5
+
8
−4 × 10
4 cm
−3 for the core’s centre and 2
.
0
+
0
.
9
−0
.
6 × 10
5
cm
−3 for the methanol peak. These values are consistent, within the
uncertainties, with those derived by Tafalla et al. (
2004
), as we have
to take into account the possible uncertainties in the determination
of the density profiles from the absorption coefficient of the dust.
Downloaded from https://academic.oup.com/mnras/article/519/2/1601/6849986 by University of Manchester user on 10 May 2023
1606
A. Meg
´
ıas et al.
MNRAS 519, 1601–1617 (2023)
Figure
3. Sample
of
the
COM
lines
observed
towards
L1517B’s
methanol
peak
and
their
corresponding
fits
obtained
with
MADCUBA
(LTE,
in
red)
and
RADEX
(non-LTE,
in
orange).
See
Sections
2
and
3.1
for
more
details.
Acetaldehyde
(CH
3
CHO)
transitions
are
quite
noisy,
but
we
could
actually
detect
it
because
we
observ
ed
sev
eral
ones.
It
seems
that
acetonitrile
(CH
3
CN)
may
show
a
transition,
but
we
could
not
properly
fit
the
two
co
v
ered
transitions
neither
with
MADCUBA
nor
RADEX
;
plus,
the
signal
to
noise
is
quite
low
(below
2
for
the
shown
transition
and
below
1
for
the
other
one).
As for the e
xcitation temperatures, the
y are close to the assumed
kinetic temperature of 10 K, consistent with those expected for the
derived
H
2 densities,
although
this
is
biased
by
the
fact
that
the
lowest
temperature for which we have collisional rates is 10 K.
For CH
3
CN, we fixed the H
2 number density to the values from
Tafalla
et
al.
(
2004
)
(as
the
signal-to-noise
ratio
was
not
high
enough
to
get
a
good
fit).
For
the
core’s
centre,
one
of
the
lines
could
be
fitted
within 2
σ, providing a better fit than the one by MADCUBA
. For the
methanol peak, we did not detect any transition, so we obtained an
upper limit to its column density from
RADEX
.
For
HCCCN,
we
have
used
the
two
transitions
to
derive
the
column
density and the H
2 number density towards both positions. We used
the
collisional
coefficients
with
H
2 given
by
Faure,
Lique
&
Wiesenfeld
 (
2016
). Fig. A3 shows the results obtained from the non-LTE
analysis for the core’s centre. As expected the derived H
2 densities
and column densities are related. We obtained the HCCCN column
densities shown in Table 3 and H
2 densities of 1
.
80
+
0
.
04
−0
.
04 × 10
5 and
5
.
56
+
0
.
19
−0
.
18 × 10
4 cm
−3 for the dust and methanol peaks, respectively.
Although these results present lower uncertainties than those of
methanol, our H
2 densities are still consistent with the prediction
by Tafalla et al. (
2004
) taking into account the beam size of our
observations
and
the
uncertainties
in
the
determination
of
the
density
from dust emission, as we previously discussed. In the following
sections, we use the values from Tafalla et al. (
2004
) because they
are more direct than the deri
v
ation through RADEX
, and because the
authors assume the same dust emissivity (
κ = 0.005 cm
2 g
−1 for
1.2 mm) as that considered by Crapsi et al. (
2005
) for inferring the
CO depletion factor of L1517B, which has been employed in our
astrochemical simulations (Section 5
).
3.3 Molecular abundances
Once we know the column densities of COMs and COM precursors
detected
toward
L1517B,
we
can
compute
the
molecular
abundances
of these species by using the H
2 column densities measured towards
the positions of the dust and methanol peaks (Table 3
). For the
position of the dust peak, the H
2 column density of (3.5 ± 0.5)
× 10
22 cm
−2 was obtained using the 1.2-mm continuum emission
observed by Tafalla et al. (
2004
) with the MAMBO 1-mm bolometer
array
at
IRAM
30-m
telescope.
For
the
position
of
the
methanol
peak,
ho
we
ver,
we
employed
the
data
from
the
Herschel
space
telescope
at
0.25,
0.35,
and
0.5
mm
assuming
a
dust
optical
depth
index
of
β =
1.5
(Spezzano et al. 2016
); the derived H
2 column density is (9.6 ± 1.0)
× 10
21 cm
−2
. As discussed in Jim
´
enez-Serra et al. (
2021
), this is
the
best
procedure
to
probe
the
total
H
2 column
density
,
respectively
,
towards
the
innermost
regions
(with
bolometers
at
1.2
mm)
and
outer
shells (with Herschel
) in starless cores.
Downloaded from https://academic.oup.com/mnras/article/519/2/1601/6849986 by University of Manchester user on 10 May 2023
The organic molecular content in L1517B
1607
MNRAS 519, 1601–1617 (2023)
Table
3. Excitation/kinetic
temperatures
(
T
),
column
densities
(
N
obs
),
and
abundances
(
χobs
)
of
COMs
and
COM
precursors
towards
the
dust
and
methanol
peaks
in
L1517B.
Dust
peak
Methanol
peak
Molecule
T (K)
N
obs
(
cm
−2
)
χobs
T (K)
N
obs
(
cm
−2
)
χobs
CH
3
OH
A
10
.0
(4.29
± 0.11)
× 10
12
1
.
23
+
0
.
21
−0
.
16 × 10
−10
10
.0
(4.96
± 0.12)
× 10
12
5
.
2
+
0
.
6
−0
.
5 × 10
−10
CH
3
OH
E
10
.0
4
.
59
+
2
.
63
−0
.
25 × 10
12
1
.
5
+
0
.
7
−0
.
3 × 10
−10
10
.0
(5.62
± 0.20)
× 10
12
5
.
9
+
0
.
7
−0
.
6 × 10
−10
CH
3
OH
10
.0
8
.
9
+
2
.
6
−0
.
3 × 10
12
2
.
7
+
0
.
7
−0
.
5 × 10
−10
10
.0
(1.058
± 0.023)
× 10
13
1
.
10
+
0
.
12
−0
.
10 × 10
−9
CH
3
O
10
± 4
(2.8
± 0.9)
× 10
11
8
.
0
+
2
.
8
−2
.
5 × 10
−12
7
± 4
(1.8
± 0.6)
× 10
11
1
.
9
+
0
.
7
−0
.
6 × 10
−11
CH
3
OCHO
7
.7
<
9
× 10
11
<
4
× 10
−11
9
.7
<
1.0
× 10
12
<
1.5
× 10
−10
CH
3
OCH
3
7
.7
<
1.0
× 10
12
<
5
× 10
−11
9
.7
<
5
× 10
11
<
7
× 10
−11
CH
3
CHO
7
.7
<
2.5
× 10
11
<
1.2
× 10
−11
9
.7
(2.1
± 0.4)
× 10
11
2
.
2
+
0
.
5
−0
.
4 × 10
−11
t-HCOOH
7
.7
<
3
× 10
12
<
1.5
× 10
−10
9
.7
<
1.9
× 10
12
<
3
× 10
−10
c-C
3
H
2
O
7
.7
<
1.5
× 10
10
<
7
× 10
−13
9
.7
<
5
× 10
10
<
7
× 10
−12
H
2
CCO
7.7
± 1.0
(8.4
± 1.3)
× 10
11
2
.
4
+
0
.
6
−0
.
4 × 10
−11
10
± 3
(7.2
± 1.9)
× 10
11
7
.
6
+
2
.
2
−2
.
0 × 10
−11
CCCO
7
.7
<
2.4
× 10
11
<
1.1
× 10
−11
9
.7
<
1.2
× 10
12
<
1.8
× 10
−10
HCCCHO
7
.7
<
1.6
× 10
11
<
8
× 10
−12
9
.7
<
1.9
× 10
11
<
3
× 10
−11
HCCNC
6
.7
(2.4
± 1.0)
× 10
11
(7
± 3)
× 10
−12
5
.3
(1.9
± 0.8)
× 10
11
1
.
9
+
0
.
9
−0
.
8 × 10
−11
CH
2
CHCN
6
.7
<
4
× 10
10
<
1.8
× 10
−12
5
.3
<
3
× 10
10
<
5
× 10
−12
CH
3
NC
6
.7
(1.6
± 0.9)
× 10
10
(5
± 3)
× 10
−13
5
.3
<
2.3
× 10
10
<
3
× 10
−12
CH
3
CN
10
.0
(2.1
± 0.6)
× 10
11
6
.
0
+
2
.
1
−1
.
9 × 10
−12
10
.0
<
2.0
× 10
11
<
3
× 10
−11
HCCCN
10
.0
(5.16
± 0.05)
× 10
12
1
.
48
+
0
.
25
−0
.
18 × 10
−10
10
.0
3
.
72
+
0
.
14
−0
.
13 × 10
12
(3.9
± 0.4)
× 10
−10
Note.
Temperatures
(
T
)
refer
to
excitation
temperatures
(
T
ex
)
for
all
the
species
except
for
methanol
(CH
3
OH),
cyanoacetilene
(HCCCN),
and
acetonitrile
(CH
3
CN),
where
they
refer
to
kinetic
temperatures
(
T
kin
).
We
used
MADCUBA
to
derive
the
molecular
parameters
from
the
observations except for methanol, cyanoacetilene, and acetonitrile, where we used RADEX
. Molecular abundances were calculated using
an H
2 column density of (3.5 ± 0.5) × 10
22 cm
−2 for the dust continuum peak and of (9.6 ± 1.0) × 10
21 cm
−2 for the position of the
methanol
peak.
For
the
non-detections
and
also
for
some
detections,
we
had
to
fix
the
excitation
temperature
(
T
ex
)
so
that
MADCUBA
could
fit
the
column
density
(
N
obs
).
From Table 3
, we can see that the abundance of the detected
species is enhanced towards the position of the methanol peak with
respect
to
the
core’s
centre.
For
methanol
(CH
3
OH),
its
abundance
is
enhanced by a factor of ∼4, while for the rest of detected species in
both
positions
(CH
3
O,
H
2
CCO,
HCCNC,
and
HCCCN)
the
factor
of
enhancement
is
∼3.
Acetaldehyde
(CH
3
CHO)
is
only
detected
in
the
methanol peak, the ratio would be ≳
2. As for acetonitrile (CH
3
CN)
and methyl isocianide (CH
3
NC) we only find lines towards the dust
peak,
and
the
ratio
would
be
࣠
6.
Therefore,
for
these
three
molecules,
the lower/upper limits for the factor of enhancement toward the
methanol
peak
are
consistent
with
those
of
the
molecules
detected
in
both
positions.
Additionally,
the
ratio
of
the
abundances
of
methanol
A and E species toward the dust and methanol peak is, respectively,
0
.
91
+
0
.
08
−0
.
32 and 0
.
88
+
0
.
04
−0
.
04
, which is similar to what has been observed
in the L1544 and L1498 cores (Jim
´
enez-Serra et al. 2016
, 2021
) and
to the expected values of ∼0.7–1.0 (Wirstr
¨
om et al. 2011
).
4  COMPARISON  WITH  OTHER  CORES
In this Section, we compare our results obtained for the starless core
L1517B
with
those
of
the
L1544
and
L1498
cores
(see
Jim
´
enez-Serra
et al. 2016
, 2021
) and also with those of the L1521E core (see Nagy
et al. 2019
; Scibelli et al. 2021
).
4.1 Comparison with L1498 and L1544
For L1517B, L1498, and L1544, the same molecular species have
been observed toward two positions (i.e. the dust peak and the
methanol peak for each of them), which allows us to obtain
information about the radial distribution of the abundances of COM
and COM precursors within the cores.
Fig. 4 presents the abundances of the COM and COM precursor
molecules observed toward these three cores and for the two
measured positions. The abundances measured towards the dust and
methanol peaks are plotted, respectively, in yellow and red for the
L1544 pre-stellar core (Jim
´
enez-Serra et al. 2016
), in light and dark
blue for the L1498 starless core (Jim
´
enez-Serra et al. 2021
), and in
light and dark purple for the L1517B starless core (this work).
Consistently
with
L1498
and
L1544,
the
abundances
of
the
species
detected towards L1517B tend to be higher toward the position of
the methanol peak than towards the dust peak (t-HCOOH towards
L1544 is an exception). Fig. 4 also shows that the L1517B core
presents a lower number of detections than L1544 and a similar
number to L1498. For the N-bearing species, we have detected
only HCCCN and HCCNC towards both positions of L1517B from
a total of five targeted species, although we have found CH
3
CN
and CH
3
NC towards the dust peak. A significant difference with
respect
to
L1498
and
L1544
is
that
vinyl
cyanide
(CH
2
CHCN)
is
not
detected toward L1517B, showing upper limits to its abundance that
are factors ≳
10 lower than the abundances measured toward L1498
and L1544. Following the same trend, for O-bearing species only
four
COMs
and
COM
precursor
species
(CH
3
OH,
CH
3
O,
CH
3
CHO,
and H
2
CCO) out of 10 have been detected toward L1517B, and
in the case of CH
3
CHO it is only detected towards the methanol
peak.
If we compare in detail L1517B and L1498, we can see that the
first one has a level of chemical complexity some
what lo
wer than
L1498. First, the abundances of the COMs and COM precursors
detected towards L1517B tend to show lower abundances than (or
are comparable to) those measured toward L1498. Secondly, if we
count the total number of detections for any position, we obtain
13 detections for L1517B and 14 for L1498, which may seem a
small dif
ference. Ho
we
ver, if we consider the detections and nonDownloaded
 from https://academic.oup.com/mnras/article/519/2/1601/6849986 by University of Manchester user on 10 May 2023
1608
A. Meg
´
ıas et al.
MNRAS 519, 1601–1617 (2023)
Figure
4. Bar
plot
of
the
abundances
of
different
COMs
and
COM
precursors
measured
for
the
cores
L1517B,
L1498,
and
L1544,
toward
the
dust
peak
(lighter
colors)
and
the
methanol
peak
(darker
colours)
for
each
of
them.
Upper
limits
are
indicated
both
with
arrows
at
the
top
of
the
corresponding
bar
and
with
stripes.
Abundances
for
L1544
are
taken
from
Jim
´
enez-Serra
et
al.
(
2016
,
2021
),
while
for
L1498
they
are
taken
from
Jim
´
enez-Serra
et
al.
(
2021
).
Note
that
this
is
not
a
cumulative
bar
plot,
so
the
upper
edge
of
each
bar,
for
both
colours
(that
is,
for
both
the
centre
and
the
methanol
peak,
for
each
core),
indicates
the
abundance
of
the
corresponding
species.
detections for each position, the lower level of chemical complexity
for the L1517B starless core becomes more apparent.
To quantitatively measure this we have calculated, for each pair
of cores, the fraction of molecules with the same state of detection
(detected or not detected). That is, for each source, we build a vector
with one entry for each molecule and position (15 molecules × 2
positions, 30 entries), whose value is 1 if there is a detection and
0 if not. Then, we build another vector with the same number of
entries, that are 1 if the two input entries (of the two cores) have
the same value and 0 otherwise. Finally, we sum up all the elements
of this vector and divide it by the number of entries, in order to
normalize it. We call the resulting number the fractional similarity
,
whose values lie between 0 and 1. In this way, if for each position
and molecule both entries have the same v
alue to
wards both sources
(either a detection or a non-detection), the fractional similarity is 1.
On the contrary, if for each position and molecule both entries are
different, the resulting similarity is 0. If we compute the fractional
similarity
between
L1517B
and
L1498,
we
obtain
0.70
± 0.03.
5 This
indicates that, although the two cores are similar in terms of number
5
The value used for the uncertainty is 1/30 ≃ 0.03, which is the difference
in the fractional similarity produced by one entry that is different in the two
vectors.
of
detections,
they
are
truly
different
regarding
their
level
of
chemical
complexity since the similarity, clearly less than 1, is produced by
9 different entries in the vectors (that is, in the detections for each
molecule and position).
For
the
sake
of
completeness,
we
have
also
computed
the
fractional
similarity between L1544 and L1517B, which is 0.57 ± 0.03, and
between L1544 and L1498, which is 0.43 ± 0.03. This indicates
that the three cores show a significantly different level of chemical
complexity in terms of detections and non-detections, and the two
more similar cores would be L1498 and L1517B.
We have used two other methods to e
v
aluate the level of chemical
complexity towards the three cores. First, we have computed for
each source and position the mean molecular mass of the species
weighted by the abundances in a logarithmic scale.
6 This can be
viewed as an estimate of the level of complexity of each source
and position, as COMs tend to have more atoms with increasing
complexity, and thus a greater molecular mass. From Table 4
, we
find that the lowest value of the mean molecular mass is obtained
for L1517B, while the greatest one is for L1544, with L1498 being
close
to
it.
This
would
indicate
that
L1517B
presents
the
lowest
level
6
We used logarithmic weights due to the range of the values of our
abundances,
which
encloses
several
orders
of
magnitude.
Downloaded from https://academic.oup.com/mnras/article/519/2/1601/6849986 by University of Manchester user on 10 May 2023
The organic molecular content in L1517B
1609
MNRAS 519, 1601–1617 (2023)
Table 4. Weighted geometric mean of the abundance with respect to H
2
,
⟨
χobs
⟩
,
and
weighted
mean
molecular
mass,
⟨
m
molec
⟩
for
the
targeted
species
in
L1517B,
L1498,
and
L1544.
Source
⟨
χobs
⟩ 
×10
−12

⟨
m
molec
⟩ (
g
/
mol
)
L1517B
dust
peak
7
.
1
+
1
.
5
−1
.
5
15
+
3
−3
45
.
5
+
0
.
3
−0
.
3
45
.
61
+
0
.
20
−0
.
27
meth.
peak
23
+
5
−5
45
.
7
+
0
.
3
−0
.
4
L1498
dust
peak
10
.
5
+
2
.
1
−2
.
1
32
+
5
−5
46
.
18
+
0
.
18
−0
.
24
46
.
25
+
0
.
15
−0
.
17
meth.
peak
53
+
10
−10
46
.
32
+
0
.
23
−0
.
24
L1544
dust
peak
19
+
4
−4
30
+
4
−4
46
.
8
+
0
.
3
−0
.
4
46
.
46
+
0
.
15
−0
.
21
meth.
peak
42
+
7
−7
46
.
13
+
0
.
16
−0
.
19
Note.
The
weights
for
the
mean
abundance
are
the
molecular
masses
for
each
molecule. The weights for the mean molecular mas are the abundance for
each molecule in logarithmic scale. The values on the second columns for
each
magnitude
are
the
arithmetic
means
of
the
magnitudes
for
both
positions.
To deal with uncertainty propagation and upper limits we made simulations
with
statistical
distributions
(see
Appendix
B
).
of chemical complexity of the three cores, followed by L1498 and
L1544. Additionally, we also computed for each source and position
the geometric mean of the abundance of the species weighted by the
molecular mass.
7 The resulting value represents a measure of the
amount of the more complex species in the core, as we are giving
larger weights in the mean to more complex species. As shown by
Table 4
, L1517B shows the lowest mean abundance, followed by
L1498 and L1544, which present barely the same quantity. All of
this indicates that the level of chemical complexity in the L1517B
starless core seems to be lower than that of L1498, and of L1544.
From all these results, we suggest that L1517B is in a less
chemically evolved stage than L1498 and L1544. This is supported
by the deuterium fractionation of L1517B, similar to that of L1498,
but
L1517B
shows
no
evidence
of
infall
motions
(Tafalla
et
al.
2004
;
Crapsi et al. 2005
). Additionally, L1517B sho
ws the lo
west le
vel
of chemical complexity within the three cores, presenting only the
simplest COMs and COM precursors and with lower abundances in
most of the cases.
If we take into account the possible time evolution between the
three cores (with L1517B being the youngest and L1544 the oldest),
we propose a scenario in which the N-bearing molecules would
form first in starless cores. Then, as the cores evolv
e, the
y would
accrete gas from the surrounding molecular cloud, becoming denser
and yielding a strong depletion of carbon monoxide (CO). At the
pre-stellar core stage, the catastrophic depletion of CO takes place,
triggering the formation of O-bearing COMs and COM precursors
as observed in L1544 (Vasyunin et al. 2017
). Therefore, chemical
complexity
would
increase
over
time.
In
the
next
section,
we
explore
this
scenario
by
modelling
the
chemistry
of
N-bearing
and
O-bearing
COMs and COM precursors towards L1517B.
4.2 Comparison with L1521E
L1521E is another well-studied starless core located in the Taurus
molecular cloud. Like L1517B, L1521E is also considered to be
young.
Indeed,
L1521E
sho
ws
no
e
vidence
of
infall
motions,
and
has
a central density of 2.7 × 10
5 cm
−3 (Tafalla & Santiago 2004
). Its
CO
depletion
factor
is
f
CO =
4.3
± 1.6
(Nagy
et
al.
2019
),
lower
than
those of L1517B and L1498. Although its deuterium fractionation
N
N
2
D
+
/N
N
2
H
+ has not been measured yet, several authors agree in
7
We
used
the
geometric
mean
due
to
the
range
of
the
values
of
our
abundances.
Figure
5. Bar
plot
of
the
abundances
of
different
COMs
and
COM
precursors
measured
for
the
young
starless
cores
L1517B
(in
light
and
dark
purple)
and
L1521E (in light and dark green). For L1517B, the values are as in Fig. 4
.
For L1521E, the abundances shown in dark green refer to the bulk COM
emission
observed
by
Scibelli
et
al.
(
2021
)
towards
L1521E
with
a
beam
size
of ∼70 arcsec. The large beam includes not only the dust peak position but
also the methanol ring (peak located at 22–29 arcsec from L1521E’s dust
peak).
Abundances
from
L1521’s
dust
peak
are
shown
in
light
green
and
are
taken from Nagy et al. (
2019
). Upper limits are indicated with both arrows
and
stripes.
the fact that this core is young (e.g. Tafalla & Santiago 2004
, Kong
et al. 2015
, Scibelli et al. 2021
). Nagy et al. (
2019
) observed the
molecular
line
emission
towards
the
dust
peak
of
this
core
(including
some COMs and COM precursors) using the IRAM 30-m telescope.
More recently, Scibelli et al. (
2021
) detected four COMs towards
L1521E (CH
3
OCHO, CH
3
OCH
3
, CH
3
CHO, and CH
2
CHCN) using
the 12-m ARO (Arizona Radio Observatory) telescope, with a much
larger beam size (
∼70 arcsec versus 22–31 arcsec for the IRAM
30-m telescope). This implies that while the observations of Nagy
et al. (
2019
) would co
v
er the location of just the dust peak, the
observations of Scibelli et al. (
2021
) would co
v
er both the dust peak
and the methanol ring, as its methanol peak is found 22–29 arcsec
away from the core centre (Nagy et al. 2019
). We thus refer to the
observations of Scibelli et al. (
2021
) as those performed toward the
bulk of the core.
Among the 15 targeted species measured towards L1517B, there
are
9
of
them
that
have
also
been
targeted
toward
L1521E:
six
towards
the
dust
peak
and
four
for
the
bulk
of
the
core
(with
just
one
molecule
in common for both positions). Fig. 5 reports the abundances of the
common species observed towards L1517B and L1521E. For the
data under the bulk label, we use the values derived by Scibelli et al.
(
2021
) assuming two source size cases: the lower limits of the error
bars refer to the values obtained assuming a beam filling factor of
1, while the error bars upper limits refer to the abundances obtained
with the best-fitting source size of 35 arcsec. Note, ho
we
ver, that
vin
yl c
yanide (CH
2
CHCN) is an exception since its abundance was
only derived assuming a beam filling factor of 1 (the source size for
this molecule could not be estimated; Scibelli et al. 2021
).
In general, there is a good agreement between the abundances
measured toward the dust peak position of the two cores (see light
Downloaded from https://academic.oup.com/mnras/article/519/2/1601/6849986 by University of Manchester user on 10 May 2023
1610
A. Meg
´
ıas et al.
MNRAS 519, 1601–1617 (2023)
purple and light green bars in Fig. 5
), with the sole exception of
cyclopropenone (c-C
3
H
2
O). In contrast, the differences are bigger
between the bulk abundances of L1521E and the abundances measured
 towards the dust and methanol peaks of L1517B. Ho
we
ver, if
we
take
into
account
the
uncertainties
with
the
error
bars
upper/lower
limits, the abundances of L1521E’s bulk are largely consistent with
those
measured
towards
both
positions
of
L1517B,
with
the
exception
of
vinyl
cyanide
(CH
2
CHCN).
A
possible
explanation
for
this
would
be that L1521E is more chemically evolved than L1517B, lying
closer to L1498 than to L1517B. Alternatively, although these cores
are located in the same molecular cloud complex, the local physical
and chemical properties of their environment could differ, causing
significant
differences
in
their
final
chemical
composition.
Studies
of
the COM chemical content toward a larger sample of starless cores
are
needed
to
establish
whether
differences
in
the
environment
affect
the COM chemical evolution in starless cores.
We finally note that calculations of the fractional similarity and of
the
geometric
means
of
the
abundance
and
of
the
molecular
mass
for
L1521E, cannot be performed since the number of data available for
this core is rather small.
5  MODELLING  THE  FORMATION  OF  COMS
AND  COM  PRECURSORS  IN  L1517B
5.1 The model
We have modelled the chemistry of COMs and COM precursors
towards
the
starless
core
L1517B
by
using
the
0D
gas–grain
chemical
code MONACO (Vasyunin & Herbst 2013
; Vasyunin et al. 2017
),
which has been successfully applied previously to the starless cores
L1544 and L1498 (Jim
´
enez-Serra et al. 2016
, 2021
). Our goal is to
compare
the
observed
molecular
abundances
with
those
predicted
by
the model, and to infer the radial distribution of COMs and COM
precursors towards L1517B and its age.
The
MONACO
chemical
code
is
a
rate
equations-based,
three-phase
(gas, ice surface, and ice bulk) numerical model that provides the
evolution of the fractional abundances of atomic and molecular
species
with
time.
To
obtain
the
radial
distribution
of
the
abundances
of
COMs
and
COM
precursors
in
L1517B,
the
code
is
run
for
a
grid
of
distances
on
the
density
and
temperature
profile
of
L1571B,
assuming
physical parameters to be constant in time. The physical structure of
the L1517B starless core is obtained from the H
2 gas density profile
by Tafalla et al. (
2004
), and the gas kinetic temperature distribution
inferred by the same authors using NH
3 observations. The assumed
H
2 gas density profile for L1517B is:
n
(
r) = 2
.
2 × 10
5
cm
−3
1 +

r
35
arcsec
2
.
5
,
(1)
where r is the angular distance (in arcsec). As for the temperature
radial profile, we have used a constant temperature of T = 10 K
(see Tafalla et al. 2004
). Fig. 6 shows both profiles as a function of
distance to the centre of the core. In our model, we assume that the
dust and gas temperatures are equal.
Given the low temperatures in starless cores (
T = 10 K), the
precursors of COMs are formed on the surface of dust grains via
hydrogenation processes. Once formed, a small fraction of these
compounds are non-thermally desorbed from dust grains into the
gas phase, where they undergo gas-phase chemical reactions that
yield the observed COMs (Vasyunin & Herbst 2013
; Vasyunin
et al. 2017
). As non-thermal desorption processes, the code includes
UV photodesorption, cosmic ray-induced desorption (Hase
ga
wa &
Figure 6. H
2 gas density and temperature profiles used for modelling the
chemistry of COMs and COM precursors towards L1517B. These radial
profiles are taken from Tafalla et al. (
2004
). The vertical grey dashed line
indicates the distance of the observed methanol peak with respect to the
centre
of
the
core.
Figure
7. Evolution
of
the
simulated
CO
depletion
factor
o
v
er
time.
The
blue
line and shaded region show the value f
CO = 9.8 ± 2.8, derived by Crapsi
et
al.
(
2005
),
while
the
grey
line
indicates
the
best-fitting
age
for
L1517B.
Herbst 1993
) and reactive (chemical) desorption (Minissale et al.
2016
).
The
chemical
network
for
the
O-bearing
and
N-bearing
COMs
and
precursors
is
the
same
as
the
one
used
for
the
L1498
starless
core
(see the details in Jim
´
enez-Serra et al. 2021
). As initial abundances,
the model employs the results of a simulation of a diffuse cloud
model
with
constant gas
density
of
100
cm
−3 and gas
temperature of
20 K for 10
7 yr, using the low metals initial abundances EA1 from
Wakelam & Herbst (
2008
).
5.2 Comparing simulations and obser
v
ations
Using the initial conditions explained in Section 5.1
, we have
simulated
the
chemical
evolution
of
L1517B
by
running
the
MONACO
code for 10
6 yr. To constrain the age of the core, we have used the
CO depletion factor of f
CO = 9.5 ± 2.8 measured by Crapsi et al.
(
2005
) towards L1517B, and the location of the methanol peak at
a distance of 5000 au. Interestingly, our model cannot reproduce
simultaneously the location of the methanol peak at 5000 au and the
CO depletion factor of ∼7–12. In Fig. 7
, we show the evolution of
the predicted CO depletion factor o
v
er time and its observed value.
Note that the
MONACO code considers the telescope beam size when
Downloaded from https://academic.oup.com/mnras/article/519/2/1601/6849986 by University of Manchester user on 10 May 2023
The organic molecular content in L1517B
1611
MNRAS 519, 1601–1617 (2023)
Figure 8. Radial distribution of the modelled abundances of the COMs and COM precursors observed for L1517B. Colour curves represent the modelled
abundances, while dots and vertical arrows represent the observed
abundances, and their upper limits, towards the two observed positions in L1517B, the dust
and methanol peaks. The position of some of the dots (observed COMs and COM precursor abundances) has been slightly shifted to enhance visibility. The
dotted–dashed
grey
line
indicates
the
position
of
the
observed
methanol
peak,
while
the
grey
dashed
line
indicates
the
position
of
the
methanol
peak
according
to
the
chemical
simulations.
calculating the CO depletion factor. By comparing the model results
with the CO and COMs and COM precursor observations, the best
agreement is reached after 1.5 × 10
5 yr. The CO depletion factor at
this
time
is
∼7.3,
which
is
on
the
lower
edge
of
the
estimated
interval
for the CO depletion factor (see Fig. 7
).
At this time of chemical e
volution, ho
we
ver, the location of the
methanol
peak
in
the
model
does
not
match
the
observed
one
towards
L1517B. This is clearly shown in Fig. 8
, where we present the
radial distribution of the abundance of COMs and COM precursors
modelled for L1517B, together with the measured values and upper
limits
(see
dots
and
vertical
arrows).
As
shown
in
Fig.
8
,
the
location
of the methanol peak in the model is at ∼15
000 au away from the
dust peak (vertical dashed line), which is a factor of 3 further away
that observed (at ∼5000 au; see dashed–dotted vertical line).
The origin of this discrepancy likely arises from the fact that
the central H
2 gas density towards L1517B is 2.2 × 10
5 cm
−3
, i.e.
significantly
lower
than
measured
towards
the
L1544
pre-stellar
core.
If this density were higher, as in L1544 (
∼10
7 cm
−3
; Caselli et al.
2022
), the CO depletion factor (9.5 ± 2.8) would be reached earlier
in the simulations, enabling a better match between the modelled
and the observed location of the methanol peak at 5000 au. This
would also help reconciling the age of the L1517B starless core
predicted by the model (of ∼1.5 × 10
5 yr) with the one expected
from observations. As already mentioned, L1517B does not show
evidence for gas accretion either towards the innermost regions or
from
the
outer
envelope,
as
observed
towards
L1498
or
L1544,
which
suggests that L1517B is at an earlier stage of evolution, or at least,
at a similar evolutionary stage as L1498 (note that they both have
similar central H
2 gas densities and deuterium fractionation values;
Tafalla et al. 2004
; Crapsi et al. 2005
). Another possible explanation
of this discrepancy would be a prominent asphericity of the core,
although from Fig. 1 it seems that L1517B is rather spherical.
For the abundances of COMs and COM precursors, Table 5
compares
the
values
between
the
modelled
and
observed
abundances
towards
the
positions
of
the
dust
and
methanol
peaks
in
L1517B.
All
the modelled and observed abundances agree within a factor of 10
except for CH
3
CN in the core’s centre and HC
3
N in both positions.
Actually, at earlier times of the simulations, where the simulated
methanol
peak
is
closer
to
the
observed
one,
abundances
of
those
two
species are closer to the observed ones. In any case, we should take
into account that astrochemical models entail intrinsic uncertainties
derived from uncertainties from some of the constants used in the
simulation,
such
as
the
chemical
reaction
rates
(Vasyunin
et
al.
2004
;
Wakelam et al. 2005
, 2010
).
Comparing
the
predicted
age
for
L1517B
(1.5
× 10
5 yr)
with
those
predicted for L1498 and L1544, we find that, contrary to what we
thought, L1517B would not be the youngest core, as the predicted
ages
for
L1498
and
L1544
are,
respectively,
9.8
× 10
4 and
1.6
× 10
5
Downloaded from https://academic.oup.com/mnras/article/519/2/1601/6849986 by University of Manchester user on 10 May 2023
1612
A. Meg
´
ıas et al.
MNRAS 519, 1601–1617 (2023)
Table
5. Observed
and
modelled
abundances
(
χobs
,
χmod
)
for
several
COMs
and
COM
precursors
in
L1517B.
Dust
peak
Methanol
peak
Species
χobs
χmod
Agreement
χobs
χmod
Agreement
CH
3
OH
2
.
7
+
0
.
7
−0
.
5 × 10
−10
1.21 × 10
−9
+
1
.
11
+
0
.
12
−0
.
10 × 10
−9
2.23 × 10
−9
+
CH
3
O
8
.
0
+
2
.
9
−2
.
5 × 10
−12
3.0 × 10
−12
+
1
.
9
+
0
.
7
−0
.
6 × 10
−11
6.6 × 10
−12
+
CCCO
< 8
× 10
−12
1.12 × 10
−11
+
< 1
.
3
× 10
−10
2.05 × 10
−11
+
t
-HCOOH
< 1
.
0
× 10
−10
8.6 × 10
−11
+
< 2
.
0
× 10
−10
1.63 × 10
−10
+
H
2
CCO
2
.
4
+
0
.
6
−0
.
5 × 10
−11
1.12 × 10
−10
+
7
.
6
+
2
.
3
−2
.
0 × 10
−11
2.17 × 10
−10
+
CH
3
OCH
3
< 3
× 10
−11
2.32 × 10
−13
+
< 5
× 10
−11
5.2 × 10
−13
+
CH
3
CHO
< 8
× 10
−12
2.09 × 10
−12
+
2
.
2
+
0
.
5
−0
.
4 × 10
−11
4.0 × 10
−12
+
HCCCHO
< 5
× 10
−12
1.62 × 10
−13
+
< 2
.
1
× 10
−11
3.2 × 10
−13
+
CH
3
CN
6
.
0
+
2
.
1
−1
.
9 × 10
−12
4.0 × 10
−13
–
< 3
× 10
−11
7.0 × 10
−13
+
CH
2
CHCN
< 1
.
2
× 10
−12
1.46 × 10
−14
+
< 3
× 10
−12
2.9 × 10
−14
+
HCCCN
1
.
48
+
0
.
24
−0
.
18 × 10
−10
1.04 × 10
−11
–
3
.
9
+
0
.
4
−0
.
4 × 10
−10
1.85 × 10
−11
–
Note.
The
modelled
and
measured
abundances
agree
(
+
)
or
not
(
−)
within
a
factor
of
10.
yr (Jim
´
enez-Serra et al. 2016
, 2021
). Therefore, according to the
chemical ages based on similar initial conditions, L1517B would be
more evolved than L1498 and less than L1544. However, although
L1517B
shows
some
concentration
of
H
2
at
its
centre,
there
is
no
clear
sign of current contraction motions towards this core. This, together
with the observed level of chemical complexity, seems to suggest
that L1517B is less evolved that L1544 and L1498. Note also that
our chemical modelling does not include the dynamical evolution of
the core and, thus, the chemical age derived by our model does not
necessarily coincide with the actual dynamical age of the core. In
fact,
if
the
initial
conditions
of
the
cores
were
different,
the
final
COM
chemical composition of the cores would be significantly altered as
compared to our chemical modelling.
For L1521E, Scibelli et al. (
2021
) also used the MONACO code
to estimate the age of the core (of ∼6 × 10
4 yr). Ho
we
v
er, the
y
could only reproduce the observed abundances of acetaldehyde
(CH
3
CHO),
out
of
a
total
of
five
modelled
COMs
(with
differences
in
the
predicted
abundances
by
factors
of
20–160).
Therefore,
additional
aspects in the chemical modelling of these young starless cores such
as
different
initial
conditions
and/or
dynamical
evolution
of
the
cores,
may be required.
6  EVOLUTION  OF  THE  HC
3
N  /  CH
3
CN
ABUNDANCE  RATIO  ACROSS  LOW-MASS  STAR
FORMATION
Recent observational campaigns have been devoted to investigate
the chemical composition in COMs (both O-bearing and N-bearing)
towards
all
stages
in
the
process
of
star
formation.
In
this
section,
we
compare
the
information
available
for
several
sources
for
two
of
these
COMs and COM precursors, the N-bearing species cyanoacetylene
(HC
3
N) and acetonitrile (CH
3
CN), with the abundances obtained
towards
our
limited
sample
of
starless
cores
(L1544,
L1498,
L1517B,
and
L1521E).
We
have
selected
these
two
molecular
species
because
the
y hav
e been measured systematically in the past few years across
a variety of objects, from Class 0/I protostars (Bergner et al. 2017
)
to
Class
II
protoplanetary
discs
(see
the
MAPS
ALMA
large
program;
e.g., Ilee et al. 2021
), and comets (Biver et al. 2021
).
Fig. 9 reports the values of the column density ratio of
HC
3
N/CH
3
CN
for
the
starless
cores
L1544,
L1498,
and
L1517B
(for
both positions measured in these cores), the starless core L1521E in
the dust peak, 12 Class 0/I protostellar systems (studied by Bergner
et al. 2017
), 4 Class II protoplanetary discs (studied by Ilee et al.
2021
), and 2 comets (studied by Biver et al. 2021
, andINTRODUCTION
Stellar evolutionary model sequences serve as input for a broad
range of astrophysical applications: from star formation (e.g. Gatto
et al. 2017
) to galaxy evolution (e.g. Weinberger, Springel &
Pakmor 2020
); from cluster dynamics (e.g. Heggie & Hut 2003
)
to gra
vitational-wa
ve (GW) studies (e.g. Vigna-G
´
omez et al. 2018
).
These sequences provide an easy and powerful way to account for
both individual stars (e.g. Schneider et al. 2014
) and stellar populations
 (e.g. Brott et al. 2011b
) in a given astrophysical environment.
1D model sequences (from now on: stellar models
) can be
computed from first principles (Kippenhahn & Weigert 1990
) and
have become a household tool in astrophysical research. Ho
we
ver,
when it comes to stars more massive than ∼9
M
⊙– those that,
despite being rare, provide the bulk of the radiation, chemical
pollution,
and
the
most
exotic
death
throes
in
the
Universe
(Woosley,
Heger & Weaver 2002
) – stellar models are still riddled with large
uncertainties.
⋆
E-mail:
pagrawal@astro.swin.edu.au
High-mass stars are born less often than their low-mass counterparts

(Salpeter
1955
)
and
have
comparatively
shorter
lives
(Crowther
2012
).
Consequently,
observational
constraints
on
their
evolution
are
more
difficult
to
obtain.
The
situation
is
further
complicated
by
many
massive stars being observed to be fast rotators (Ram
´
ırez-Agudelo
et al. 2013
), which breaks down perfect symmetry, and to have a
close-by companion star (Sana et al. 2012
), breaking the assumption
of perfect isolation. Even for isolated, non-rotating single stars, the
physical conditions both inside (Heger, Langer & Woosley 2000
)
and around (Lamers & Cassinelli 1999
) the star are so peculiar and
complex
that
developing
appropriate
numerical
simulations
becomes
highly
challenging.
This
is
why
the
evolution
of
massive
stars
remains
an actively studied field to this day.
Much progress has been made in the last few decades concerning
massive stars and their evolution. Mass-loss in the form of highvelocity
 winds from massive stars is being intensively studied and
accounted for in the models (Smith 2014
; Sander & Vink 2020
).
Observations of massive stars from the Large and Small Magellanic
Clouds are being used to constrain the efficiency of interior mixing
processes (Brott et al. 2011a
; Schootemeijer et al. 2019
). 1D stellar
models have also been updated to account for the effects of rotation
(Maeder 2009
; Costa et al. 2019
) and magnetic fields (Heger,
© 2022
The
Author(s).
Published
by
Oxford
University
Press
on
behalf
of
Royal
Astronomical
Society.
This
is
an
Open
Access
article
distributed
under
the
terms
of
the
Creative
Commons
Attribution
License
(
http://cr
eativecommons.or
g/licenses/by/4.0/),
which
permits
unrestricted
reuse,
distribution,
and
reproduction
in
any
medium,
provided
the
original
work
is
properly
cited.
Downloaded from https://academic.oup.com/mnras/article/512/4/5717/6564714 by guest on 20 January 2024
5718
P. Agrawal et al.
MNRAS 512, 5717–5725 (2022)
Woosley & Spruit 2005
; Maeder & Meynet 2005
; Takahashi &
Langer 2021
) that can significantly change their evolutionary paths
(Walder, Folini & Meynet 2012
; Petit et al. 2017
; Groh et al. 2020
).
Despite the progress, there are still many open questions surrounding
 the lives of massive (
≳
9
M
⊙) and ‘very’ massive (here
designated as ≳
40
M
⊙) stars, and in the absence of well-defined
answers, stellar evolution codes make use of different assumptions.
Earlier studies comparing models of massive stars from different
codes (e.g. Martins & Palacios 2013
; Jones et al. 2015
) have already
established that the differences in the physical parameters such as
mixing
and
mass-loss
rates
adopted
by
various
stellar
evolution
codes
can affect the evolutionary outcome of these stars.
Here, we highlight another major uncertainty arising due to the
numerical treatment of low-density envelopes of very massive stars.
These
stars
have
luminosities
close
to
the
Eddington
limit,
so
changes
in the elemental opacities during their evolution can lead to the
formation of density and pressure inversions in the stellar envelope
(Langer 1997
). The presence of these density inversions can cause
numerical instabilities for 1D stellar evolution codes. To deal with
these instabilities, the codes use different pragmatic solutions whose
interplay with mixing and mass-loss can further vary the evolution
of massive stars.
The role of the Eddington limit and the associated density
inv
ersions in massiv
e stars is well known within the stellar evolution
community but remains relatively unknown outside the field. With
the
surge
in
the
use
of
massive
star
models,
for
example,
in
GW
event
rate predictions and supernova studies, it has become important to
be aware of this issue. Our goal is to present the broader community
with a concise o
v
ervie
w, including ho
w it affects the evolutionary
properties such as the radial expansion and the remnant mass of
v
ery massiv
e stars. To this end, we compare models of massiv
e and
v
ery massiv
e stars from fiv
e published sets created with different
evolutionary codes: (i) models from the PAdova and TRieste Stellar
Evolution Code (PARSEC; Bressan et al. 2012
; Chen et al. 2015
);
(ii) the MESA Isochrones and Stellar Tracks (MIST; Choi et al.
2016
) from the Modules for Experiments in Stellar Astrophysics
(MESA;
Paxton
et
al.
2011
);
(iii)
models
(Ekstr
¨
om
et
al.
2012
;
Yusof
et al. 2013
) from the Gene
v
a code (Eggenberger et al. 2008
); (iv)
models from the Binary Population and Spectral Synthesis (BPASS;
Eldridge et al. 2017
) project; and (v) the Bonn Optimized Stellar
Tracks (BoOST; Sz
´
ecsi et al. 2022
) from the ‘Bonn’ code.
We describe the major physical ingredients used in computing
each set of models in Sections 2 and 3
. In Section 4
, we compare
the predictions from each set of models in the Hertzsprung–Russell
(HR) diagram and in terms of the emitted ionizing radiation, as well
as the predictions for the maximum radial expansion of stars, and
their remnant masses. Finally, we draw conclusions in Section 5
.
2  PHYSICAL  INPUTS
2.1 Chemical composition
The chemical composition of the Sun is often used as a yardstick
in computing the metal content of other stars. Ho
we
v
er, the e
xact
v
alue
remains
inconclusi
ve
and
has
undergone
se
veral
re
visions
since
2004 (see Basu 2009
; Asplund, Amarsi & Grevesse 2021
, for an
o
v
ervie
w). Therefore, dif
ferent stellar models often make use of
different abundance scales.
The BP
ASS, P
ARSEC, Gene
v
a, and MIST models base their
chemical compositions on the Sun, while the BoOST models use
a mixture tailored to the sample of massive stars from the FLAMES
surv
e
y (Evans et al. 2005
) with Z
Gal = 0.0088. For stellar winds and
opacity calculations, BoOST models use Z = 0.017 from Grevesse,
Noels
&
Sauval
(
1996
)
as
the
reference
solar
metallicity.
The
BPASS
models use solar abundances from Grevesse & Noels (
1993
) with
Z
⊙= 0.02. The PARSEC models follow Grevesse & Sauval (
1998
)
with revisions from Caffau et al. (
2011
) and Z
⊙= 0.015
24. Gene
v
a
models
use
Asplund,
Grevesse
&
Sauval
(
2005
)
abundances
with
Ne
abundance from Cunha, Hubeny & Lanz (
2006
) and Z
⊙= 0.014
while, finally, the MIST models base their abundance on Asplund
et al. (
2009
) with Z
⊙= 0.014
28.
For the purpose of comparison here, we use Z = 0.014 models for
each set except for BoOST where we use the Galactic composition,
Z = 0.0088 as the closest match. Iron is an important contributor to
metallicity, as numerous iron transition lines dominate both opacity
and mass-loss rates, therefore directly affecting the structure of
massive stars (e.g. Puls, Springmann & Lennon 2000
). The stellar
models
compared
here
have
similar
iron
content,
with
the
normalized
number density [
A
Fe = log(
N
Fe
/
N
H
) + 12.0] ranging from 7.40 (for
BoOST models) to 7.54 (for MIST models).
2.2 Mass-loss rates
Stellar mass is a key determinant of a star’s life and evolutionary
outcome. It can, ho
we
ver, change as stars lose their outer layers
in the form of stellar winds, and through interactions with a binary
companion.
Consequently,
mass-loss
not
only
can
affect
the
structure
and chemical composition of the star, but is also important in
determining its final state (Renzo et al. 2017
).
F
or massiv
e stars, the ef
fects of mass-loss are e
ven more pronounced.
 The mass-loss experienced by hot massive stars (O type
stars and Wolf–Rayet stars) is known to be line-driven (Lamers &
Cassinelli 1999
) while that of cool massive stars (red supergiants;
Levesque 2017
) is suggested to be dust-driven. Both types of massloss
 are an intensively studied subject. Ho
we
v
er, the comple
xity of
the
problem
of
atomic
and
molecular
transitions
in
the
wind
together
with the rarity of stars at these high masses means that the model
assumptions are usually based either on a fe
w observ
ations (a small
sample of stars) or on what we know about the wind properties of
low-mass stars.
All models in this study follow Vink et al. (
2000
, 2001
) for hot
wind-driven mass-loss. The PARSEC, Geneva, BPASS, and MIST
models follow de Jager et al. (
1988
) for cool dust-driven massloss
 and Nugis & Lamers (
2000
) for mass-loss in the naked helium
star phase. The Gene
v
a models further switch to Crowther (
2000
)
for hydrogen-rich stars with log
T
eff
/
K ≤3.7. They also use the
maximum of Vink et al. (
2001
) and Gr
¨
afener & Hamann (
2008
)
for stars with surface hydrogen mass fraction between 0.3 and
0.05, before switching to Nugis & Lamers (
2000
) when the surface
hydrogen mass fraction falls below 0.05. The BoOST models follow
Nieuwenhuijzen
&
de
Jager
(
1990
)
for
cool
winds
and
Hamann
et
al.
(
1995
; reduced by a factor of 10) for stars with surface hydrogen
mass fraction < 0
.
3. For computing mass-loss rates of stars with
surface
hydrogen
mass
fraction
between
0.3
and
0.6,
BoOST
models
linearly interpolate between the mass-loss rates of Vink et al. (
2001
)
and Hamann et al. (
1995
; reduced by a factor of 10).
To account for the dependence of the mass-loss rates on the
chemical composition, BoOST
, MIST
, and BPASS models scale
the mass-loss rates by a factor of Z
0.85 (Vink et al. 2001
).
1 Gene
v
a
1
Note
that
for
some
models
the
factor
Z
0.69 is
quoted,
depending
on
whether
the
dependence
of
the
terminal
velocity
on
Z
is
explicitly
considered
or
not.
Downloaded from https://academic.oup.com/mnras/article/512/4/5717/6564714 by guest on 20 January 2024
Differences in massive star models
5719
MNRAS 512, 5717–5725 (2022)
Table
1. Summary
of
input
parameters
used
in
the
computation
of
the
models
of
massive
stars
from
different
codes.
See
Section
2
for
details.
Stellar
model
Z
⊙
Hot
wind
Cool
wind
Wolf–Rayet
wind
Conv
ectiv
e
boundary
αMLT
Overshoot
type
αovs
αsemi
BPASS
0.020
Vink,
de
Koter
&
Lamers
(
2000
,
2001
)
de
Jager,
Nieuwenhuijzen
&
van
der
Hucht
(
1988
)
Nugis
&
Lamers
(
2000
)
Schwarzschild
(
1958
)
2.0
Pols
et
al.
(
1998
)
0.12
e
–
BoOST
0.008
a
Vink
et
al.
(
2000
,
2001
)
Nieuwenhuijzen
&
de
Jager
(
1990
)
Hamann,
Koesterke
&
Wessolowski
(
1995
)
b
Ledoux
(
1947
)
1.5
Step
0.335
1.0
Gene
v
a
0.014
Vink
et
al.
(
2000
,
2001
)
de
Jager
et
al.
(
1988
)
c
Nugis
&
Lamers
(
2000
)
Schwarzschild
(
1958
)
1.6
d
Step
0.1
–
MIST
0.014
Vink
et
al.
(
2000
,
2001
)
de
Jager
et
al.
(
1988
)
Nugis
&
Lamers
(
2000
)
Ledoux
(
1947
)
1.82
Herwig
(
2000
)
0.016
e
0.1
PARSEC
0.015
Vink
et
al.
(
2000
,
2001
)
de
Jager
et
al.
(
1988
)
Nugis
&
Lamers
(
2000
)
Schwarzschild
(
1958
)
1.74
Bressan,
Chiosi
&
Bertelli
(
1981
)
0.5
e
–
a
For
calculating
mass-loss
rates
and
opacities, Z
⊙=
0.017
is
used.
b
Reduced
by
a
factor
of
10.
c
For
log
T
eff
/
K
≤3.7,
mass-loss
rates
from
Crowther
(
2000
)
are
used.
d
For
stars
with
initial
mass
≥40
M
⊙,
αMLT =
1.0
is
used
but
with
a
different
scale
height
(see
Section
3
).
e
The
rough
equi
v
alent
in
the
step
o
v
ershooting
formalism
is
0.2,
0.25,
and
0.4
for
the
MIST,
PARSEC,
and
BPASS
models,
respectively.
and PARSEC models also use additional mass-loss as described in
Section 3
.
2.3 Convection and overshooting
Internal mixing processes such as convection and overshooting play
an important role in determining both the structure and evolution of
massive stars (see e.g. Sukhbold & Woosley 2014
). Similar to massloss,
 these processes represent another major source of uncertainty
in massive stellar evolution (Schootemeijer et al. 2019
; Kaiser et al.
2020
). In 1D stellar evolution codes convection is modelled using
the
mixing-length
theory
(MLT;
B
¨
ohm-Vitense
1958
)
in
terms
of
the
mixing-length parameter αMLT
. Ho
we
ver, 3D simulations suggest
that convection in massive stars might be more sophisticated and
turbulent than described by MLT (Jiang et al. 2015
).
The BoOST, Gene
v
a, P
ARSEC, and BP
ASS models used here
follow
standard
MLT
(Cox
&
Giuli
1968
)
for
conv
ectiv
e
mixing
with
mixing-length parameter αMLT = (1.5, 1.6, 1.74, 2.0), respectively.
MIST
follows
a
modified
version
of
MLT
given
by
Henyey,
Vardya
&
Bodenheimer (
1965
) with αMLT = 1.82. Conv
ectiv
e boundaries in
PARSEC, Gene
v
a, and BPASS models are determined using the
Schwarzschild criterion (Schwarzschild 1958
). BoOST and MIST
use the Ledoux criterion (Ledoux 1947
) for determining conv
ectiv
e
boundaries with semiconv
ectiv
e mixing parameters of 1.0 and 0.1,
respectiv
ely.
F
or
determining
conv
ectiv
e
core
o
v
ershoot,
Geneva
and
BoOST
use
step
o
v
ershooting
with
o
v
ershoot
parameter
αov = (0.1,
0.335). MIST uses e
xponential o
v
ershooting following Herwig
(
2000
) with αov = 0.016. PARSEC uses o
v
ershoot from Bressan
et
al. (
1981
)
with αov = 0.5.
BPASS
uses
the o
v
ershoot
prescription
from Pols et al. (
1998
) with αov = 0.12. For comparison, the rough
equi
v
alent in the step o
v
ershooting formalism would be 0.2, 0.25,
and 0.4 for the MIST, PARSEC, and BPASS models, respectively
(see
Pols
et
al.
1998
;
Bressan
et
al.
2012
;
Choi
et
al.
2016
,
for
details
of each method).
MIST and PARSEC also include small amounts of o
v
ershoot
associated with conv
ectiv
e re
gions in the env
elope. Ho
we
ver, apart
from modifying surface abundances, envelope overshoot has a
negligible effect on the evolution of the star (Bressan et al. 2012
).
Rotational mixing also plays an important role in the evolution of
massive stars. In fact, the calibration of the free parameters in the
stellar codes is often based on their rotating models. For simplicity,
we only compare non-rotating models for PARSEC, MIST, Gene
v
a,
and
BPASS
in
this
study.
Although,
for
BoOST,
in
the
absence
of
nonrotating

models
for
stars
more
massive
than
60
M
⊙,
we
do
use
slowly
rotating (100
km
s
−1
) models. As shown by Brott et al. (
2011a
), this
small difference in the initial rotation rate is not rele
v
ant from the
point of view of the o
v
erall evolutionary behaviour.
Major
input
parameters
used
in
each
set
of
models
are
summarized
in Table 1
.
3  EDDINGTON  LUMINOSITY  AND  THE
NUMERICAL  TREATMENT  OF  DENSITY
INVERSIONS
The Eddington luminosity is the maximum luminosity that can be
transported by radiation while maintaining hydrostatic equilibrium
(Eddington 1926
). In the low-density envelopes of massive stars
changes in the elemental opacities during the evolution of stars
can cause the local radiative luminosity to exceed the Eddington
luminosity
(Langer
1997
;
Sanyal
et
al.
2015
).
To
maintain
hydrostatic
equilibrium, density, and pressure inv
ersion re
gions form in the
stellar
envelope.
In
the
absence
of
efficient
convection
(which
is
also
typical for the low-density envelopes; Grassitelli et al. 2016
), this
can lead to convergence problems for 1D stellar evolution codes
(Paxton et al. 2013
). Owing to numerical difficulties, the timesteps
 become exceedingly small, preventing further evolution of the
star. While less-massive stars are only affected by this process in
their late evolutionary phases (Harpaz 1984
; Lau et al. 2012
), very
massive
stars
can
exceed
the
Eddington
limit
already
during
the
corehydrogen-burning
 phase (Gr
¨
afener, Owocki & Vink 2012
; Sanyal
et
al.
2015
)
and
inhibit
computation
of
their
evolution.
Therefore,
1D
stellar evolution codes have to employ various solutions to compute
further evolution of very massive stars.
In
PARSEC
models,
density
inversions
and
the
consequent
numerical

difficulties
are
a
v
oided
by
limiting
the
temperature
gradient
such
that the density gradient never becomes negative (see section 2.4 of
Downloaded from https://academic.oup.com/mnras/article/512/4/5717/6564714 by guest on 20 January 2024
5720
P. Agrawal et al.
MNRAS 512, 5717–5725 (2022)
Chen et al. 2015
; Alongi et al. 1993
). Limiting the temperature
gradient prevents inefficient convection and the evolution of the
stars proceeds uninterrupted. Also, the models include a mass-loss
enhancement following Vink (
2011
) whenever the total luminosity
of the star approaches the Eddington luminosity.
MIST models suppress density inversions through the
MLT
++ formalism (Paxton et al. 2013
) of MESA. In this method,
the
actual
temperature
gradient
is
artificially
reduced
to
make
it
closer
to the adiabatic temperature gradient whene
ver radiati
ve luminosity
exceeds the Eddington luminosity abo
v
e a pre-defined threshold.
This approach again increases conv
ectiv
e efficienc
y, helping stars to
o
v
ercome density inv
ersions. Additionally, radiativ
e pressure at the
surface of the star is also enhanced in the MIST models to help with
convergence (Choi et al. 2016
).
In
the
e
xtended
env
elopes
of
massive
stars,
the
density
scale
height
is much larger compared to the pressure scale height (which is
typically used for computing the mixing length). Therefore, setting
the mixing length to be comparable with the density scale height
helps a
v
oid density inversion (Nishida & Schindler 1967
; Maeder
1987
). The Gene
v
a models include this treatment when computing
models with initial masses greater than 40
M
⊙with αMLT = 1.0 (see
section 2.3 of Ekstr
¨
om et al. 2012
). Additionally, the mass-loss rates
for the models are increased by a factor of 3 whenever the local
luminosity in any of the layers of the envelope is higher than five
times the local Eddington luminosity.
BoOST models do not include any artificial treatment to prevent
massive stars from encountering density inversions. Instead, their
models undergo envelope inflation when massive stars reach the
Eddington limit (Sanyal et al. 2015
). On encountering the density
inversions in their envelopes, the computation of very massive stars
becomes
numerically
difficult.
Further
evolution
of
such
stars
is
then
computed
through
post-processing.
It
involves
removing
layers
from
the surface of the star (which would anyway happen due to regular
mass-loss) while correcting for surface properties such as ef
fecti
ve
temperature and luminosity (Sz
´
ecsi et al. 2022
).
BPASS models also allow density inversions to develop in the
envelope
of
massive
stars.
Ho
we
ver,
these
models
are
able
to
continue
the evolution without numerical difficulties, most likely due to the
use
of
a
non-Lagrangian
mesh
(see
Stancliffe
2006
,
for
an
o
v
erview)
and
the
resolution
factors
being
lower
than
in
other
models
(Eggleton
1973
; Eldridge et al. 2017
).
4  COMPARING  THE  MODELS
4.1 Differences between models in the Hertzsprung–Russell
diagram
The evolution of stars can be easily represented through tracks on
the HR diagram, depicting the evolutionary paths followed by a
series of stars. Fig. 1 presents the HR diagram of stars of various
initial
masses
from
the
five
simulation
approaches.
The
observational
analogue to the Eddington limit is the Humphreys–Davidson limit
or HD limit (Humphreys & Davidson 1979
). Since the luminosity
of a star depends on its mass, more massive stars also are more
luminous. This means they can easily exceed the Eddington limit,
dev
elop
density
inv
ersions,
and
require
the
use
of
numerical
solutions
as discussed in Section 3
.
From
Fig.
1
,
we
see
that
the
tracks
of
the
25
M
⊙(or
24
M
⊙in
some
cases) stars agree well during most of the evolution. This is because
stars of this mass do not exceed the Eddington limit and are thus not
affected
by
the
related
numerical
treatments.
The
minor
differences
in
their
tracks
are
due
to
the
difference
in
physical
inputs
(Section
2
)
between

the
simulations.
For
example,
the
differences
in
the
position
of
the
main-sequence
(MS)
hook
feature
in
the
HR
diagram
arise
due
to
the varied extent of conv
ectiv
e o
v
ershoot used in each set of models.
A 40
M
⊙star is clearly affected by the numerical treatment
employed during the post-main-sequence phase of its evolution, as
evidenced by the difference in the tracks in the HR diagram shown
in
Fig.
1
.
More
massive
stars,
i.e,
those
with
initial
masses
80/85
M
⊙
and 120/125 M
⊙, can exceed the Eddington limit in their envelopes
while on the MS and therefore their simulations differ significantly
from each other. At these masses, the mass-loss rates can be as
high
as
10
−3
–10
−4
M
⊙yr
−1
,
completely
dominating
o
v
er
ev
ery
other
physical ingredient in determining the evolutionary path. While all
tracks
have
been
computed
with
similar
prescriptions
for
wind
massloss
 (cf. Section 2
), the actual rates can be strongly modified by the
numerical methods adopted by each code in response to numerical
instabilities (Section 3
), resulting in vast differences in the tracks.
4.2 Ionizing radiation and synthetic populations
The ionization released by a stellar population in e.g. a cluster or
galaxy is influenced by the contribution of the most massive stars
(Topping & Shull 2015
). As shown abo
v
e, howev
er, these are the
stars for which the simulations give the most diverse predictions.
To demonstrate this effect, we calculate the ionizing radiation
emitted by a simple stellar population, supposing a Salpeter (
1955
)
initial mass function with an upper mass of 120
M
⊙and a starforming
 region of 10
7
M
⊙total mass – which is aimed to represent
either a typical starburst galaxy, or a young massive cluster in the
Milky
W
ay.
In
T
able
2
,
we
list
the
Lyman
photon
flux
predicted
by
the
individual stellar models analysed here. To simplify the population
synthesis calculations, the table provides time-averaged values, that
is,
the
photon
number
flux
emitted
o
v
er
the
whole
evolution
is
divided
by
the
lifetime.
This
way
the
emission
coming
from
the
population
is
estimated
by
simply
weighting
the
time-averaged
values
by
the
initial
mass function (i.e. without needing to follow the time evolution
of the modelled cluster or galaxy). The results of these simple
population syntheses are also reported in Table 2
. In the absence
of spectral synthesis models computed for all five sets (cf. Wofford
et al. 2016
), we have opted to simply use blackbody estimation. To
correct for optically thick winds, we follow the method explained in
chapter 4.5.1 of Sz
´
ecsi (
2016
, which relies on Langer 1989
).
We find that, in terms of how much Lyman flux is emitted by
a given synthetic population, the model predictions can differ as
much as ∼18 per
cent between simulations. This supports earlier
findings (e.g. Topping & Shull 2015
) that relying on the ionizing
properties
of
massive
stars
from
evolutionary
models
should
be
done
with caution. Indeed one should keep in mind that the behaviour of
the most massive models, those that dominate the radiation profile
of
any
star-forming
region,
is
weighted
with
large
uncertainties
– the
source of which is the treatment of the Eddington limit, explained in
Section 3
.
4.3 Predictions of maximum stellar radii
The radial expansion of a star plays a significant role in determining
the nature of binary interaction as it can lead to episodes of mass
transfer
in
close
interacting
binaries.
Recent
studies
indicate
that
most
of
the
massive
stars
occur
in
binaries
(Sana
et
al.
2012
;
Moe
&
Di
Stefano
 2017
). Therefore, predictions of stellar radii become even more
important for determining the binary properties of massive stars.
Fig. 2 shows the maximum radial e
xpansion achiev
ed by massive
stars
from
each
simulation.
For
stars
with
initial
mass
up
to
30
M
⊙,
all
Downloaded from https://academic.oup.com/mnras/article/512/4/5717/6564714 by guest on 20 January 2024
Differences in massive star models
5721
MNRAS 512, 5717–5725 (2022)
Figure
1. HR
diagrams
of
the
massive
single
star
models
analysed
in
this
work.
All
models
have
near-solar
composition.
Symbols
mark
every
10
5
yr
of
evolution.
Only
the
core-hydrogenand

core-helium-burning
phases
are
plotted.
The
dashed
red
line
marks
the
observational
Humphreys–Davidson
limit
(Humphreys
&
Davidson
1979
)
where
rele
v
ant.
The
tracks
become
more
varied
with
increasing
initial
mass.
This
is
because
the
codes
apply
various
treatments
for
the
numerical
instabilities
associated
with
the
Eddington-limit
proximity,
cf.
Section
3
.
Table 2. Time-averaged ionizing photon number flux [s
−1
] in the Lyman continuum emitted by the
stellar models during their lives on avera
g
e
, cf. Section 4.2
. The last column provides the amount of
Lyman
radiation
(number
of
photons
[s
−1
])
that
a
10
7
M
⊙population
(e.g.
a
starburst
galaxy
or
a
young
massive
cluster
in
the
Milky
Way)
containing
these
massive
stars
would
emit.
M
ini [M
⊙]
24/25
40
80/85
120/125
pop.
PARSEC
3.7
× 10
48
1.3
× 10
49
5.5
× 10
49
1.0
× 10
50
1.08
× 10
54
MIST
3.3
× 10
48
1.5
× 10
49
5.1
× 10
49
1.1
× 10
50
1.06
× 10
54
Gene
v
a
3.5
× 10
48
1.2
× 10
49
5.1
× 10
49
8.5
× 10
49
9.90
× 10
53
BPASS
3.6
× 10
48
1.3
× 10
49
4.5
× 10
49
7.7
× 10
49
9.34
× 10
53
BoOST
3.7
× 10
48
1.2
× 10
49
4.2
× 10
49
6.9
× 10
49
8.89
× 10
53
simulations predict the formation of a red supergiant. The maximum
difference in the radius predictions here is ࣠
1000
R
⊙. For higher
initial masses, the predictions for maximum stellar radii become
more divergent as proximity to the Eddington limit increases and
numerical treatments adopted by each code modify the mass-loss
rates.
The greatest difference in the maximum radius predictions
(
≳
1000
R
⊙) occurs for stars with initial masses between 40 and
100
M
⊙. Abo
v
e ∼100
M
⊙, stars have even higher mass-loss rates
that can completely strip a star of its envelope before it can become
a red-supergiant. Such stars evolve directly towards the naked
helium star phase and have much smaller radii. Therefore, for stars
with initial masses more than 100
M
⊙, the difference between the
maximum
radius
predictions
by
each
simulation
reduces
to
࣠
100
R
⊙.
The predictions in this mass range seem to further converge into two
main groups: PARSEC and MIST represent one group predicting
smaller radii compared to the second group that consists of BoOST
and BPASS models. The maximum radii in this mass range are
Downloaded from https://academic.oup.com/mnras/article/512/4/5717/6564714 by guest on 20 January 2024
5722
P. Agrawal et al.
MNRAS 512, 5717–5725 (2022)
Figure 2. Maximum stellar radii as a function of the initial mass of the
star. Similar to Fig. 1
, differences in the physical inputs and the numerical
methods
adopted
by
each
code
can
lead
to
a
difference
of
more
than
1000
R
⊙
in predictions in terms of the maximum radial expansion achieved by the
stars.
predicted by the Gene
v
a models. This is due to the difference in the
mass-loss
rates
adopted
during
the
naked
helium
phase
of
the
star,
as
explained in the next section.
4.4 Remnant mass predictions
Stellar evolutionary models provide an easy way of estimating the
properties of stellar remnants such as black holes and neutron stars,
which are needed in many fields including supernova studies (e.g.
Aguilera-Dena
et
al.
2018
;
Raithel,
Sukhbold
& ¨
Ozel
2018
),
gammaray
 bursts progenitors (e.g. Yoon, Langer & Norman 2006
; Szecsi
2017
), and GW event rate predictions (e.g. Stevenson et al. 2019
;
Mapelli et al. 2020
).
Following Belczynski et al. (
2010
), we show in Fig. 3 how the
uncertainties in the models we compare here also pose a challenge
for
the
predictions
of
remnant
properties.
Remnant
masses
have
been
calculated from the carbon-oxygen (CO) core mass and the total
mass of the star at the end of the core helium-burning phase using
the prescription of Belczynski et al. (
2008
; same as the StarTrack
prescription in Fryer et al. 2012
).
The Gene
v
a models do not provide information on core masses in
their publicly available data set. Therefore, the final CO-core mass
for these models has been taken from Georgy et al. (
2012
; for stars
with initial mass
up to 120
M
⊙)
and Yusof et al. (
2013
; for stars
with
initial mass more than 120
M
⊙). Note that in the Gene
v
a models
from Yusof et al. (
2013
), CO-core mass is defined as the mass of the
core where the sum of mass fraction of carbon and oxygen exceeds
75 per
cent, and is different to the definition used by Georgy et al.
(
2012
).
The remnant masses are heavily influenced by the modelling
assumptions
(cf.
Section
2
)
and
the
numerical
methods
(cf.
Section
3
)
especially abo
v
e M
ini = 40
M
⊙where the most massive black holes
are
predicted.
For
stars
with
initial
masses
between
9
and
120
M
⊙,
we
find
that
the
mass
of
the
black
holes
predicted
by
the
different
sets
of
models
can
differ
by
∼20
M
⊙.
The
maximum
black
hole
mass
varies
from about 20
M
⊙for BPASS models to about 35
M
⊙for MIST and
PARSEC
models,
and
32
M
⊙for
the
BoOST
models.
BPASS
models
consistently predict the lo
west v
alues of remnant mass for most of
the massive stars while predictions from the BoOST
, MIST
, and
Figure
3. Final
masses
of
stars
as
a
function
of
their
initial
mass,
M
ZAMS
.
The
top
panel
shows
the
mass
of
stellar
remnants
as
predicted
by
the
different
sets
of
stellar
models.
The
middle
panel
shows
the
carbon-oxygen
core
mass
and
the bottom panel shows the total mass of the star, as used in the calculation
of the remnant masses. For stars more massive than 120
M
⊙, the Gene
v
a
models
from
Yusof
et
al.
(
2013
)
use
a
different
criteria
for
defining
CO-core
compared to the lower mass models from the same set (see Section 4.4 for
details) and therefore, are represented using dotted line. Differences in the
evolutionary
parameters
for
massive
stars
can
cause
variations
of
about
20
M
⊙
in
the
remnant
masses
between
the
stellar
models
from
various
simulations.
Downloaded from https://academic.oup.com/mnras/article/512/4/5717/6564714 by guest on 20 January 2024
Differences in massive star models
5723
MNRAS 512, 5717–5725 (2022)
PARSEC models peak at 60, 90, and 120
M
⊙before flattening out at
the higher initial masses.
F
or
more
massiv
e
stars,
the
variation
in
the
remnant
mass
between
BPASS, BoOST, MIST, and PARSEC models reduces to about
10
M
⊙. An interesting behaviour is shown by the Geneva models,
which predict one of the lowest remnant masses for stars up to
120
M
⊙, reaching a maximum of only 28
M
⊙at 120
M
⊙. These
models, ho
we
ver, predict the highest values of remnant masses
beyond 120
M
⊙. At their farthest, for a model with initial mass
of 200
M
⊙, the predictions between the Gene
v
a models and other
models can be as high as 30
M
⊙. Similar variability is found in the
core
mass
and
the
final
total
mass
of
the
star
(from
which
the
remnant
masses have been calculated).
The significantly higher remnant masses predicted by the Gene
v
a
models for stars with initial mass beyond 120
M
⊙can be explained
as follows. Due to their high luminosity, stars more massive than
100–120
M
⊙rapidly lose mass during the main-sequence phase and
directly
e
volve
to
w
ards
the
nak
ed
helium
phase
(cf.
Fig.
1
).
The
massloss
 prescriptions from both Nugis & Lamers (
2000
) and Hamann
et al. (
1995
) predict that the highest mass-loss rates for stars occur
during
this
naked
helium
phase.
BPASS,
MIST,
and
PARSEC
models
switch
to
mass-loss
rates
from
Nugis
&
Lamers
(
2000
)
when
the
mass
fraction of hydrogen at the surface of the star falls below 0.4, 0.4,
and 0.5, respectively. BoOST models linearly interpolate between
the mass-loss rates of Vink et al. (
2001
) and Hamann et al. (
1995
;
reduced by a factor of 10) for stars with surface hydrogen mass
fraction between 0.3 and 0.6, before completely switching to the
mass-loss rate from Hamann et al. (
1995
; reduced by a factor of 10)
for stars with surface hydrogen mass fraction less than 0.3.
Gene
v
a models, on the other hand, switch to using mass-loss
rates from Nugis & Lamers (
2000
) only when the mass fraction
of hydrogen at the surface of the star falls below 0.05. For stars with
surface hydrogen mass fraction between 0.3 and 0.05, they use the
maximum of Vink et al. (
2001
) and Gr
¨
afener & Hamann (
2008
),
which predict lower mass-loss rates compared to both Nugis &
Lamers (
2000
) and Hamann et al. (
1995
) (see section 2.1 of Yusof
et al. 2013
). Thus, they do not lose as much mass as other models
during the naked helium star phase and end with higher total mass
and thus with the higher remnant mass.
Note
that
the
Belczynski
et
al.
(
2008
)
prescription
is
one
of
several
methods for predicting the remnant properties of the stars. Other
methods for calculating the remnant masses may predict higher or
lo
wer v
alues. F
or e
xample, the remnant mass calculations based on
the binding energy of the star (see e.g. Eldridge et al. 2017
) are
generally lower than those predicted here. However, all the models
we study have near-solar metallicity and therefore rather high massloss

rates;
none
of
them
stays
massive
enough
at
the
end
of
their
lives
to undergo pair instability
5  CONCLUSIONS
We compare 1D evolutionary models of massive and very massive
stars from five independent simulations. Focusing on near-solar
composition, we find that the predictions from different codes can
differ from each other by more than 1000
R
⊙in terms of maximum
radial e
xpansion achiev
ed by the stars, by ≈18 per
cent in terms of
ionizing radiation, and about 20
M
⊙in terms of the stellar remnant
mass. The differences in the evolution of massive stars can arise
due to physical inputs like chemical abundances, mass-loss rates,
and internal mixing properties. Ho
we
v
er, v
ery massiv
e stars, that is
stars with initial masses 40
M
⊙or more, show a larger difference
in evolutionary properties compared to lower mass stars. For these
stars, the differences in the evolution can be largely attributed to
the numerical treatment of the models when the Eddington limit is
exceeded in their low-density envelopes.
The different methods used by 1D codes to compute the evolution
of
massive
stars
beyond
density
inversions
(or
to
a
v
oid
the
inversions)
can modify the radius and temperature of the star, and can therefore
affect the mass-loss rates. A phenomenological justification for the
mass-loss enhancement comes from the fact that there are stars
observed with extremely high, episodical mass-loss, i.e. luminous
blue variables (Bestenlehner et al. 2014
; Sarkisyan et al. 2020
).
Ho
we
ver, other studies, such as the recent measurement of an
approximately 20
M
⊙black hole in the Galactic black hole highmass
 X-ray binary Cyg X-1 (Miller-Jones et al. 2021
), suggest that
the mass-loss rates for massive stars at near-solar metallicity may be
lower than usually assumed in the 1D stellar models (Neijssel et al.
2021
). The exact nature of wind mass-loss for very massive stars
remains
disputed
(Smith
&
Tombleson
2015
).
Moreo
v
er,
variation
in
remnants masses in Fig. 3 shows that other uncertainties in massive
star evolution can lead to differences at least as large as variations in
mass-loss rates, which could also easily explain the formation of a
20
M
⊙black hole in Cyg X-1 in the Galaxy.
None of the solutions that the BoOST, Gene
v
a, MIST, and
PARSEC models employ can currently be established as better
than the others. In each case, the
y hav
e been designed to address
numerical issues in 1D stellar e
volution. Ho
we
ver, the interplay of
these solutions with mass-loss rates and convection further adds to
the
uncertainties
in
massive
stellar
evolution.
Therefore,
a
systematic
study to untangle the effect of the treatment of the Eddington limit
from
other
physical
assumptions
has
been
conducted
in
a
companion
paper (Agrawal et al. 2021
).
In the case of BPASS, the stellar models evolve without requiring
any numerical enhancement. Whether this is a result of using a nonLagrangian
 mesh (the ‘Eggletonian’ mesh, which is more adaptive
to
changes
in
stellar
structure)
or
whether
this
is
an
artefact
of
bigger
time-steps (that helps stars skip problematic short-lived phases of
evolution) is currently not known. A separate study to explore the
effect of the ‘Lagrangian’ versus the ‘Eggletonian’ mesh structure
for massive stars [similar to Stancliffe, Tout & Pols (
2004
) study for
low- and intermediate-mass stars] is highly desirable.
In
conclusion,
it
is
crucial
to
be
aware
of
the
uncertainties
resulting
from
numerical
methods
whenever
the
evolutionary
model
sequences
of massive stars are applied in any scientific project, such as GW
event rate predictions or star formation and feedback studies.
We
only
focus
on
massive
stars
as
isolated
single
stars
in
this
work.
Ho
we
ver, there is mounting evidence that massive stars are formed
as binaries or triples, thus treating them as single stars might not be
correct
(e.g.
Klencki
et
al.
2020
;
Laplace
et
al.
2021
).
Several
studies
have shown that binarity can heavily influence the lives of massive
stars through mass and angular momentum transfer (de Mink et al.
2009
; Marchant et al. 2016
; Eldridge et al. 2017
) and can therefore
help in a
v
oiding density and pressure inversion regions in stellar
envelopes (Shenar et al. 2020
).
We also limit our study to massive stars at near-solar metallicity,
where due to high opacity, the numerical instabilities related to
the proximity to the Eddington limit are maximum. Since opacity
decreases with metallicity, opacity peaks become less prominent at
lo
wer metallicity. Ne
vertheless, stars with lo
w metal content also
reach the Eddington limit, although at higher initial masses (Sanyal
et al. 2015
, 2017
). While progenitors of currently detectable GW
sources may have been born in the early Universe where the metal
content
is
sub-solar
(cf.
Santoliquido
et
al.
2021
),
high
star
formation
rates
at
near-solar
metallicities
offer
a
fertile
ground
for
the
formation
Downloaded from https://academic.oup.com/mnras/article/512/4/5717/6564714 by guest on 20 January 2024
5724
P. Agrawal et al.
MNRAS 512, 5717–5725 (2022)
of more GW sources, although less massive compared to sub-solar
metallicity (Neijssel et al. 2019
). As such, there is good moti
v
ation
for studying the behaviour and reliability of massive star models
across a wide range of metallicities (Agrawal et al. 2021
).
Collecting observational data as well as impro
v
ements in 3D and
hydrodynamical modelling will help us better constrain the models
of massive stars in the future. Until then, ho
we
ver, we urge the
broader community to treat any set of stellar models with caution.
Ideally, one would implement all available simulations as input into
an
y giv
en astrophysical study, and test the outcome also in terms of
stellar evolution-related uncertainties. With tools such as METISSE
(Agrawal et al. 2020
) and SEVN (Spera et al. 2019
), this task is
becoming feasible.
ACKNOWLEDGEMENTS
DS
has
been
supported
by
the
Alexander
von
Humboldt
Foundation.
PA, SS, and JH acknowledge the support from the Australian
Research Council Centre of Excellence for Gravitational Wave Disco

v
ery (OzGrav). We also thank Stefanie Walch-Gassner, Debashis
Sanyal, and Ross Church for useful comments and discussions. We
are
also
grateful
to
the
referee
Cyril
Georgy
for
their
suggestions
that
greatly impro
v
ed the work.
DATA  AVAILABILITY
All the stellar models used in this work are publicly available:
PARSEC: people.sissa.it/
∼sbressan/parsec.html;
MIST: w
aps.cf
a.harvard.edu/MIST/;
Gene
v
a:
obswww.unige.ch/Research/e
vol/tables grids2011/Z014;
BPASS: bpass.auckland.ac.nz/9.html;
BoOST: boost.asu.cas.cz.
Introduction and Phenomenology
17
1
Observing the Cold Interstellar Medium
19
1.1 Observing Techniques
19
1.2 Observational Phenomenology
30
2
Observing Young Stars
35
2.1 Individual Stars
35
2.2 Statistics of Resolved Stellar Populations
38
2.3 Unresolved Stellar Populations and Extragalactic Star Formation
41
II
Physical Processes
49
3
Chemistry and Thermodynamics
51
3.1 Chemical Processes in the Cold ISM
51
3.2 Thermodynamics of Molecular Gas
58
4
Gas Flows and Turbulence
65
4.1 Characteristic Numbers for Fluid Flow
65
4.2 Modeling Turbulence
68
4.3 Supersonic Turbulence
73
4
Problem Set 1
77
5
Magnetic Fields and Magnetized Turbulence
79
5.1 Observing Magnetic Fields
79
5.2 Equations and Characteristic Numbers for Magnetized Turbulence
81
5.3 Non-Ideal Magnetohydrodynamics
85
6
Gravitational Instability and Collapse
91
6.1 The Virial Theorem
91
6.2 Stability Conditions
95
6.3 Pressureless Collapse
103
7
Stellar Feedback
109
7.1 General Formalism
109
7.2 Momentum-Driven Feedback Mechanisms
113
7.3 (Partly) Energy-Driven Feedback Mechanisms
116
III
Star Formation Processes and Problems
125
8
Giant Molecular Clouds
127
8.1 Molecular Cloud Masses
127
8.2 Scaling Relations
134
8.3 Molecular Cloud Timescales
136
Problem Set 2
143
9
The Star Formation Rate at Galactic Scales: Observations
147
9.1 The Star Formation Rate Integrated Over Whole Galaxies
147
9.2 The Spatially-Resolved Star Formation Rate
151
9.3 Star Formation in Dense Gas
158
5
10
The Star Formation Rate at Galactic Scales: Theory
163
10.1 The Top-Down Approach
164
10.2 The Bottom-Up Approach
170
11
Stellar Clustering
179
11.1 Observations of Clustering
179
11.2 Theory of Stellar Clustering
184
12
The Initial Mass Function: Observations
191
12.1 Resolved Stellar Populations
191
12.2 Unresolved Stellar Populations
199
12.3 Binaries
202
Problem Set 3
207
13
The Initial Mass Function: Theory
211
13.1 The Powerlaw Tail
211
13.2 The Peak of the IMF
215
14
Protostellar Disks and Outflows: Observations
225
14.1 Observing Disks
225
14.2 Observations of Outflows
232
15
Protostellar Disks and Outflows: Theory
235
15.1 Disk Formation
235
15.2 Disk Evolution
239
15.3 Outflow Launching
249
16
Protostar Formation
255
16.1 Thermodynamics of a Collapsing Core
255
16.2 The Protostellar Envelope
261
6
17
Protostellar Evolution
267
17.1 Fundamental Theory
267
17.2 Evolutionary Phases for Protostars
275
17.3 Observable Evolution of Protostars
280
Problem Set 4
285
18
Massive Star Formation
289
18.1 Observational Phenomenology
289
18.2 Fragmentation
294
18.3 Barriers to Accretion
297
19
The First Stars
305
19.1 Cosmological Context
305
19.2 Chemistry and Thermodynamics of Primordial Gas
306
19.3 The IMF of the First Stars
310
19.4 The Transition to Modern Star Formation
312
20
Late-Stage Stars and Disks
319
20.1 Stars Near the End of Star Formation
319
20.2 Disk Dispersal: Observation
322
20.3 Disk Dispersal: Theory
324
21
The Transition to Planet Formation
331
21.1 Dynamics of Solid Particles in a Disk
331
21.2 From Pebbles to Planetesimals
336
Problem Set 5
343
A
Statistical Mechanics of Multi-Level Atoms and Molecules
347
7
A.1 Matter-Radiation Interaction
347
A.2 Statistical Equilibrium for Multi-Level Systems
349
A.3 Critical Densities for Multi-Level Systems
351
B
Solutions to Problem Sets
353
Solutions to Problem Set 1
355
Solutions to Problem Set 2
359
Solutions to Problem Set 3
367
Solutions to Problem Set 4
375
Solutions to Problem Set 5
385
Bibliography
393
List of Figures
1.1 H2 level diagram
19
1.2 Dust absorption opacity
21
1.3 Herschel map of IC 5146
22
1.4 Dust extinction map of the Pipe Nebula
23
1.5 COMPLETE spectra of Ophiuchus and Perseus
29
1.6 Distribution of H i and GMCs in M33
31
1.7 Distribution of CO(1 →0) emission in M51
31
1.8
13CO(2 →1) maps of Perseus
33
2.1 Outflow in CO(2 →1)
36
2.2 Sample SEDs of protostellar cores
36
2.3 Bolometric temperatures of protostellar cores
37
2.4 Measured stellar IMFs in a variety of regions
40
2.5 Bolometric luminosity versus stellar population age
43
2.6 Optical spectra of galaxies across the Hubble sequence
44
4.1 Comparison of flows at varying Reynolds numbers
68
4.2 Experimental power spectra for Kolmogorov turbulence
72
4.3 Linewidth versus size in the Polaris Flare cloud
73
4.4 Volume rendering of the density field for supersonic turbulence
75
5.1 Sample Zeeman detection of a magnetic field
80
5.2 Comparison of simulations of Alfvénic and sub-Alfvénic turbulence
84
6.1 Magnetic field strength measurements
103
8.1 GMC mass spectra
134
8.2 GMC surface densities
135
8.3 GMC linewidth-size relation
135
8.4 GMC virial ratios
136
8.5 Surface densities of gas and star formation
138
8.6 Surface density of star formation versus surface density of gas normalized
 by free-fall time
138
8.7 Histogram of distances to nearest GMC
140
8.8 Histogram of stellar ages in IC 348
140
10
8.9 H i and 24 µm maps of NGC 5194 and 2841
142
9.1 Whole-galaxy Kennicutt-Schmidt relation
149
9.2 Whole-galaxy Kennicutt-Schmidt relation, including orbital time
149
9.3 Kennicutt-Schmidt relation, with additional high-redshift data
150
9.4 Kennicutt-Schmidt relation, orbital time version, with additional highredshift
 data
150
9.5 Kennicutt-Schmidt relation, with additional low surface brightness
sample
151
9.6 Kennicutt-Schmidt relation for galaxies resolved at ∼kpc scales
152
9.7 Kennicutt-Schmidt relation normalized by the free-fall time
154
9.8 Kennicutt-Schmidt relation averaged on different size scales in M33
155
9.9 Kennicutt-Schmidt relation for H i gas in inner galaxies
156
9.10 Kennicutt-Schmidt relation for H i gas in outer galaxies
156
9.11 Kennicutt-Schmidt relation for total gas in resolved galaxies
157
9.12 Infrared-HCN luminosity correlation
160
10.1 Kennicutt-Schmidt relation from simulations with only gravity and
hydrodynamics
164
10.2 Star formation rates in galaxy simulations with and without stellar
feedback
168
10.3 Ratio of HCN to CO luminosity as a function of subgrid star formation
 recipe
170
10.4 Density-temperature distribution for different cooling models
172
10.5 Theoretical model for metallicity-dependence of the star formation
rate
174
11.1 Maps of gas and young stars in two clouds
180
11.2 Correlation functions for gas and stars
182
11.3 Velocity distributions in varying molecular lines
183
11.4 Spatial and velocity distributions of gas and stars
183
11.5 Star cluster age distributions
184
11.6 Star cluster mass distributions
184
11.7 Spatial and velocity distributions of gas and stars in a simulation
185
12.1 Color-magnitude diagram of nearby stars
192
12.2 Color-magnitude diagram of nearby stars
194
12.3 Mass-magnitude relationship
194
12.4 Elliptical galaxy spectra in the Na i and Wing-Ford regions
201
12.5 Multiple system fraction versus stellar mass
204
13.1 IMF in a competitive accretion simulation
212
13.2 IMF from an analytic model of turbulent fragmentation
214
13.3 Temperature versus density in a collapsing core
219
13.4 IMF from simulations of non-isothermal fragmentation
221
11
13.5 Density-temperature distribution from a simulation of the formation
of the ONC
222
14.1 Protostellar disks in absorption in the ONC
225
14.2 ALMA image of the disk around HL Tau
226
14.3 Inner disk radii from CO line emission
231
14.4 13CO channel maps of the disk in L1527
232
14.5 Herbig-Haro jets from HST
233
15.1 Simulations of magnetized rotating collapse
239
15.2 Simulations of magnetized rotating collapse with non-ideal MHD
240
15.3 Viscous ring evolution
243
15.4 Maxwell stress in non-ideal MHD simulations of the MRI
247
17.1 Kippenhahn diagram for an accretion protostar
275
17.2 Protostellar mass-radius relation for different accretion rates
280
17.3 Pre-main sequence evolutionary tracks
281
17.4 The protostellar birthline
281
18.1 IR and mm images of an IRDC
292
18.2 A massive core in IR absorption
293
18.3 Simulations of massive star formation with magnetic fields and radiation

294
18.4 Parameter study of disk fragmentation
296
18.5 Simulation of massive star formation with outflows
303
19.1 Heating and cooling processes in primordial gas
308
19.2 Density-temperature evolution in primordial gas
309
19.3 Disk fragmentation around a primordial star
312
20.1 Balmer lines of T Tauri stars
320
20.2 Hα lines from T Tauri stars compared to models
321
20.3 Long-term light curve of FU Orionis
322
20.4 Accreting star fraction versus cluster age
323
20.5 Near infrared excess fraction versus cluster age
323
20.6 Spectral energy distribution of LkHα 330
324
20.7 Dust continuum image of the disk around LkHα 330
324
21.1 Schematic of particle concentration by eddies in a protoplanetary disk
341
B.1 Solution to problem set 1, problem 2b
356
B.2 Solution to problem set 2, problem 1d
361
B.3 Solution to problem set 2, problem 1f
362
B.4 Solution to problem set 3, problem 2c
373
B.5 Solution to problem set 4, problem 1c
377
B.6 Solution to problem set 4, problem 1d
379
12
B.7 Solution to problem set 4, problem 2c
380
B.8 Solution to problem set 5, problem 2b
388
B.9 Solution to problem set 5, problem 2c
388
13
Dedicated to my family, Barbara, Alan,
Ethan, and Rebecca, and with thanks to
my students, who have contributed tremendously
to the development of this book.
Introduction
This book is based on a series of lectures given by the author in his
graduate class on star formation, taught from 2009 - 2016 at the University
 of California, Santa Cruz and Australian National University.
It is intended for graduate students or advanced undergraduates in
astronomy or physics, but does not presume detailed knowledge
of particular areas of astrophysics (e.g., the interstellar medium or
galactic structure). It is intended to provide a general overview of the
field of star formation, at a level that would enable a student to begin
independent research in the area.
This course covers the basics of star formation, ending at the
transition to planet formation. The first two chapters, comprising part
I, begin with a discussion of observational techniques, and the basic
phenomenology they reveal. The goal is to familiarize students with
the basic techniques that will be used throughout, and to provide a
common vocabulary for the rest of the course. The next five chapters
form part II, and provide a similar review of the basic physical
processes that are important for star formation. Part III includes all
the remaining chapters. These discuss star formation over a variety of
scales, starting with the galactic scale and working our way down to
the scales of individual stars and their disks, with slight deviations to
discuss the particular problems of the formation of massive stars and
of the first stars. The book concludes with the clearing of disks and
the transition to planet formation.
The "texts" intended to go with these notes are the review articles
"The Big Problems in Star Formation: the Star Formation Rate, Stellar
Clustering, and the Initial Mass Function", Krumholz, M. R., 2014,
Physics Reports, 539, 49, which provides a snapshot of the theoretical
 literature, and "Star Formation in the Milky Way and Nearby
Galaxies", Kennicutt, R. C., & Evans, N. J., 2012, Annual Reviews of
Astronomy & Astrophysics, 50, 531, which is more focused on observations.
 Another extremely useful reference is the series of review
chapters from the Protostars and Planets VI Conference, which took
place in July 2013. Suggested background readings to accompany
most chapters are listed at the chapter beginning. In addition to these
16
background materials, most chapters also include "suggested literature":
 papers from the recent literature whose content is relevant to
the material covered in that chapter. These readings are included to
help students engage with the active research literature, as well as the
more general reviews.
In addition to the text and reading, this book contains five problem
 sets, which are interspersed with the chapters at appropriate
locations. Solutions to the problems are included as an Appendix.
Part I
Introduction and
Phenomenology
1
Observing the Cold Interstellar Medium
Suggested background reading:
• Kennicutt, R. C., & Evans, N. J. 2012,
ARA&A, 50, 531, sections 1 −2
This first chapter focuses on observations of interstellar gas. Because
the interstellar clouds that form stars are generally cold, most (but
not all) of these techniques require in infrared, sub-millimeter, and
radio observations. Interpretation of the results is often highly nontrivial.
 This will naturally lead us to review some of the important
radiative transfer physics that we need to keep in mind to understand
 the observations. With this background complete, we will then
discuss the phenomenology of interstellar gas derived from these
observations.
1.1
Observing Techniques
1.1.1
The Problem of H2
para-H2
ortho-H2
0
500
1000
1500
2000
E/kB [K]
J =0
J =2
J =4
J =1
J =3
Figure 1.1: Level diagram for the
rotational levels of para- and ortho-H2,
showing the energy of each level. Level
data are taken from http://www.gemini.
edu/sciops/instruments/nir/wavecal/
h2lines.dat.
Before we dive into all the tricks we use to observe the dense interstellar
 medium (ISM), we have to start at the question of why it is
necessary to be so clever. Hydrogen is the most abundant element,
and when it is in the form of free atomic hydrogen, it is relatively
easy to observe. Hydrogen atoms emit radio waves at a wavelength
of 21 cm (1.4 GHz), associated with a hyperfine transition from a
state in which the spin of the electron is parallel to that of the proton
to a state where it is anti-parallel. The energy difference between
these two states corresponds to a temperature ≪1 K, so even in cold
regions it can be excited. This line is seen in the Milky Way and in
many nearby galaxies.
However, at the high densities where stars form, hydrogen tends
to be molecular rather than atomic, and H2 is extremely hard to observe
 directly. To understand why, we can look at an energy level
diagram for rotational levels of H2 (Figure 1.1). A diatomic molecule
like H2 has three types of excitation: electronic (corresponding to excitations
 of one or more of the electrons), vibrational (corresponding
to vibrational motion of the two nuclei), and rotational (correspond20

notes on star formation
ing to rotation of the two nuclei about the center of mass). Generally
electronic excitations are highest in energy scale, vibrational are next,
and rotational are the lowest in energy. Thus the levels shown in
Figure 1.1 are the ones that lie closest to ground.
For H2, the first thing to notice is that the first excited state, the
J = 1 rotational state, is 175 K above the ground state. Since the
dense ISM where molecules form is often also cold, T ∼10 K (as
we will see later), almost no molecules will be in this excited state.
However, it gets even worse: H2 is a homonuclear molecule, and for
reasons of symmetry ∆J = 1 radiative transitions are forbidden in
homonuclear molecules. Indeed, there is no electronic process by
which a hydrogen molecule with odd J to turn into one with even J,
and vice versa, because the allowed parity of J is determined by the
spins of the hydrogen nuclei. We refer to the even J state as para-H2,
and the odd J state as ortho-H2.
The observational significance of this is that there is no J = 1 →0
emission. Instead, the lowest-lying transition is the J = 2 →0
quadrupole. This is very weak, because it’s a quadrupole. More
importantly, however, the J = 2 state is 510 K above the ground
state. This means that, for a population in equilibrium at a temperature
 of 10 K, the fraction of molecules in the J = 2 state is
∼e−510/10 ≈10−22!1 In effect, in a molecular cloud there are simply
1 This oversimplifies things quite a bit,
because in real molecular clouds there
are usually shocked regions where the
temperature is much greater than 10 K,
and H2 rotational emission is routinely
observed from them. However, this
emission tracers rare gas that is much
hotter than the mean temperature in a
cloud, not the bulk of the mass, which
is cold.
no H2 molecules in states capable of emitting. The reason such a high
temperature is required to excite the H2 molecule is its low mass: for
a quantum oscillator or rotor, the level spacing varies with reduced
mass as m−1/2. Thus the levels of H2 are much farther apart than the
levels of other diatomic molecules (e.g., CO, O2, N2). It is the low
mass of the hydrogen atom that creates our problems.
Given this result, we see that, for the most part, observations of the
most abundant species can only be done by proxy. Only in very rare
circumstances is it possible to observe H2 directly – usually when
there is a bright background UV source that allows us to see it in UV
absorption rather than in emission. Since these circumstances do not
generally prevail, we are forced to consider alternatives.
1.1.2
Dust Emission
The most conceptually straightforward proxy technique we use to
study star-forming clouds is thermal dust emission. Interstellar gas
clouds are always mixed with dust, and the dust grains emit thermal
radiation that we can observe. The gas, in contrast, does not emit
thermal radiation because it is nowhere near dense enough to reach
equilibrium with the radiation field. Instead, gas emission comes
primarily in the form of lines, which we will discuss below.
observing the cold interstellar medium
21
Consider a cloud of gas of mass density ρ mixed with dust grains
at a temperature T. The gas-dust mixture has an absorption opacity
κν to radiation at frequency ν. Although the vast majority of the mass
is in gas rather than dust, the opacity will be almost entirely due
to the dust grains except for frequencies that happen to match the
resonant absorption frequencies of atoms and molecules in the gas.
Here we follow the standard astronomy convention that κν is the
opacity per gram of material, with units of cm2 g−1, i.e., we assign
the gas an effective cross-sectional area that is blocked per gram of
gas. For submillimeter observations, typical values of κν are ∼0.01
cm2 g−1. Figure 1.2 shows a typical extinction curve for Milky Way
dust.
101
102
103
104
λ [µm]
10-4
10-3
10-2
10-1
100
101
102
ν [cm2  g−1 ]
Herschel
SCUBA-2
NOEMA
ALMA
102
103
104
ν [GHz]
Figure 1.2: Milky Way dust absorption
opacities per unit gas mass as a function
 of wavelength λ and frequency
ν in the infrared and sub-mm range,
together with wavelength coverage of
selected observational facilities. Dust
opacities are taken from the model of
Draine (2003) for RV = 5.5.
Since essentially no interstellar cloud has a surface density > 100
g cm−2, absorption of radiation from the back of the cloud by gas
in front of it is completely negligible. Thus, we can compute the
emitted intensity very easily. The emissivity for gas of opacity κν is
jν = κνρBν(T), where jν has units of erg s−1 cm−3 sr−1 Hz−1, i.e. it
describes (in cgs units) the number of ergs emitted in 1 second by 1
cm3 of gas into a solid angle of 1 sr in a frequency range of 1 Hz. The
quantity
Bν(T) = 2hν3
c2
1
ehν/kBT −1
(1.1)
is the Planck function.
Since none of this radiation is absorbed, we can compute the intensity
 transmitted along a given ray just by integrating the emission:
Iν =
Z
jνds = ΣκνBν(T) = τνBν(T)
(1.2)
where Σ = R
ρds is the surface density of the cloud and τν = Σκν is
the optical depth of the cloud at frequency ν. Thus if we observe the
intensity of emission from dust grains in a cloud, we determine the
product of the optical depth and the Planck function, which is determined
 solely by the observing frequency and the gas temperature. If
we know the temperature and the properties of the dust grains, we
can therefore determine the column density of the gas in the cloud in
each telescope beam.
Figure 1.3 show an example result using this technique. The advantage
 of this approach is that it is very straightforward. The major
uncertainties are in the dust opacity, which we probably don’t know
better than a factor of few level, and in the gas temperature, which
is also usually uncertain at the factor of ∼2 level. The produces a
corresponding uncertainty in the conversion between dust emission
and gas column density. Both of these can be improved substantially
by observations that cover a wide variety of wavelengths, since these
22
notes on star formation
Figure 1.3: Three-color composite
image of IC 5146 taken by the SPIRE
and PACS instruments aboard Herschel.
Red is SPIRE 500 µm, green is SPIRE
250 µm plus PACS 160 µm, and blue
is PACS 70 µm. Credit: Arzoumanian
et al., A&A, 529, L6, 2011, reproduced
with permission © ESO.
allow one to simultaneously fit the column density, dust opacity
curve, and dust temperature.
Before the Herschel satellite (launched in 2009) such multi-wavelength
observations were rare, because most of the dust emission was in at
far-infrared wavelengths of several hundred µm that are inaccessible
from the ground. Herschel was specifically targeted at this wavelength
range, and has greatly improved our knowledge of cloud properties
from dust emission.
1.1.3
Dust Absorption
A second related technique is, instead of looking at dust emission,
looking at absorption of background starlight by dust, usually in
the near infrared. In this case the calculation is even simpler. One
measures the extinction of the background star and then simply
divides by the gas opacity to get a column density. Probably the best
example of this technique is the Pipe Nebula (Figure 1.4).
The advantages of this compared to dust thermal emission are
threefold. First, since stars are bright compared to interstellar dust
grains, and the observations are done in the near IR rather than the
sub-mm, the available resolution is much, much higher. Second,
since opacity doesn’t depend on temperature, the uncertainty in
converting what we see into a column density is reduced. Third,
observing the cold interstellar medium
23
Figure 1.4: Extinction map of the Pipe
Nebula. The color scale shows the
extinction in K band. Credit: Lombardi
et al., A&A, 454, 781, 2006, reproduced
with permission © ESO.
we know the dust opacity curve in the near infrared considerably
better than we know it in the far-IR or sub-mm, further reducing the
uncertainty. However, there are also drawbacks to this method. Due
to the comparatively higher opacity in the infrared, it is only possible
to use this technique for fairly diffuse regions; in denser regions the
background stars are completely extincted. Moreover, one needs a
good, clean field of background stars to get something like a map,
and only a few clouds have such favorable geometry.
1.1.4
Molecular Lines
Much of what we know about star forming gas comes from observations
 of line emission. These are usually the most complex measurements
 in terms of the modeling and theory required to understand
them. However, they are also by far the richest in terms of the information
 they provide. They are also among the most sensitive, since
the lines can be very bright compared to continuum emission. Indeed,
 the great majority of what we know about the ISM beyond the
local group comes from studying emission in the rotational lines of
the CO molecule, because these (plus the C ii line found in atomic
regions) are by far the easiest types of emission to detect from the
cold ISM.
The simplest line-emitting system is an atom or molecule with
exactly two energy states, but this example contains most of the
24
notes on star formation
concepts we will need. The generalization of these results to a multilevel
 system is given in Appendix A.
Einstein Coefficients and Collision Rates
Consider an atom or molecule
of species X with two non-degenerate states that are separated by
an energy E. Suppose we have a gas of such particles with number
density nX at temperature T. The number density of atoms in the
ground state is n0 and the number density in the excited state is
n1. At first suppose that this system does not radiate. In this case
collisions between the atoms will eventually bring the two energy
levels into thermal equilibrium, and it is straightforward to compute
n0 and n1. They just follow a Maxwellian distribution, so n1/n0 =
e−E/kBT, and thus we have n0 = nX/Z and n1 = nXe−E/kBT/Z, where
Z = 1 + e−E/kBT is the partition function.
Now let us consider radiative transitions between these states.
There are three processes: spontaneous emission, stimulated emission,
 and absorption, which are described by the three Einstein
coefficients. In studying star formation, we can often ignore stimulated
 emission and absorption, because the ambient radiation field is
so weak that these processes occur at negligible rates. The exception
to this is when lines become optically thick, so there are a lot of line
photons bouncing around trapped inside a structure, or when the
frequency of the transition in question is at very low energy, and
interactions with CMB photons become significant. However, for simplicity
 we will begin by just focusing on spontaneous emission and
ignoring absorption and stimulated emission. The full statistical mechanics
 problem including these processes is discussed in Appendix
A.
An atom in the excited state can spontaneously emit a photon
and decay to the ground state. The rate at which this happens is
described by the Einstein coefficient A10, which has units of s−1. Its
meaning is simply that a population of n1 atoms in the excited state
will decay to the ground state by spontaneous emission at a rate
dn1
dt

spon. emis.
= −A10n1.
(1.3)
In cgs units this quantity is measured in atoms per cm3 per s, and
this expression is equivalent to saying that the e-folding time for
decay is 1/A10 seconds. For most of the molecules we will be considering
 in this book, decay times are typically at most a few centuries,
which is short compared to pretty much any time scale associated
with star formation. Thus if spontaneous emission were the only
process at work, all molecules would quickly decay to the ground
state and we wouldn’t see any emission.
observing the cold interstellar medium
25
However, in the dense interstellar environments where stars form,
collisions occur frequently enough to create a population of excited
molecules. Of course collisions involving excited molecules can also
cause de-excitation, with the excess energy going into recoil rather
than into a photon. Since hydrogen molecules are almost always
the most abundant species in the dense regions we’re going to think
about, with helium second, we can generally only consider collisions
between our two-level atom and those partners. For the purposes
of this exercise, we’ll take an even simpler approach and ignore
everything but H2. Putting He back into the picture is easy, as it just
requires adding extra collision terms that are completely analogous
to the ones we will write down.
The rate at which collisions cause transitions between states is a
horrible quantum mechanical problem. We cannot even confidently
calculate the energy levels of single isolated molecules except in the
simplest cases, let alone the interactions between two colliding ones
at arbitrary velocities and relative orientations. Exact calculations
of collision rates are generally impossible. Instead, we either make
due with approximations (at worst), or we try to make laboratory
measurements. Things are bad enough that, for example, we often
assume that the rates for collisions with H2 molecules and He atoms
are related by a constant factor.
Fortunately, as astronomers we generally leave these problems
to chemists, and instead do what we always do: hide our ignorance
behind a parameter. We let the rate at which collisions between
species X and H2 molecules induce transitions from the ground state
to the excited state be
dn1
dt

coll. exc.
= k01n0n,
(1.4)
where n is the number density of H2 molecules and k01 has units of
cm3 s−1. In general k01 will be a function of the gas kinetic temperature
 T, but not of n (unless n is so high that three-body processes
start to become important, which is almost never the case in the ISM).
The corresponding rate coefficient for collisional de-excitation is
k10, and the collisional de-excitation rate is
dn1
dt

coll. de−exc.
= −k10n1n.
(1.5)
A little thought should suffice to convince the reader that k01 and
k10 must have a specific relationship. Consider an extremely dense
region where n is so large that collisional excitation and de-excitation
both occur much, much more often than spontaneous emission,
and we can therefore neglect the spontaneous emission term in
26
notes on star formation
comparison to the collisional ones. If the gas is in equilibrium then
we have
dn1
dt =
dn1
dt

coll. exc.
+
dn1
dt

coll. de−exc.
=
0
(1.6)
n(k01n0 −k10n1)
=
0.
(1.7)
However, we also know that the equilibrium distribution is a Maxwellian,
so n1/n0 = e−E/kBT. Thus we have
nn0(k01 −k10e−E/kBT)
=
0
(1.8)
k01
=
k10e−E/kBT.
(1.9)
This argument applies equally well between a pair of levels even for
a complicated molecule with many levels instead of just 2. Thus, we
only need to know the rate of collisional excitation or de-excitation
between any two levels to know the reverse rate.
Critical Density and Density Inference
We are now in a position to
write down the full equations of statistical equilibrium for the twolevel
 system. In so doing, we will see that we can immediately use
line emission to learn a great deal about the density of gas. In equilibrium
 we have
dn1
dt
=
0
(1.10)
n1A10 + nn1k10 −nn0k01
=
0
(1.11)
n1
n0
(A10 + k10n) −k01n
=
0
(1.12)
n1
n0
=
k01n
A10 + k10n
(1.13)
=
e−E/kBT
1
1 + A10/(k10n)
(1.14)
This physical meaning of this expression is clear. If radiation is
negligible compared to collisions, i.e., A10 ≪k10n, then the ratio
of level populations approaches the Maxwellian ratio e−E/kBT. As
radiation becomes more important, i.e., A10/(k10n) get larger, the
fraction in the upper level drops – the level population is sub-thermal.
This is because radiative decays remove molecules from the upper
state faster than collisions re-populate it.
Since the collision rate depends on density and the radiative decay
rate does not, the balance between these two processes depends on
density. This make it convenient to introduce a critical density ncrit,
defined by
ncrit = A10
k10
,
(1.15)
observing the cold interstellar medium
27
so that
n1
n0
= e−E/kBT
1
1 + ncrit/n.
(1.16)
At densities much larger than ncrit, we expect the level population
to be close to the Maxwellian value, and at densities much smaller
than ncrit we expect the upper state to be under-populated relative to
Maxwellian; ncrit itself is simply the density at which radiative and
collisional de-excitations out of the upper state occur at the same
rate.
This process of thermalization has important consequences for the
line emission we see from molecules. The energy emission rate per
molecule from the line is
L
nX
=
EA10n1
nX
(1.17)
=
EA10
n1
n0 + n1
(1.18)
=
EA10
n1/n0
1 + n1/n0
(1.19)
=
EA10
e−E/kBT
1 + e−E/kBT + ncrit/n
(1.20)
=
EA10
e−E/kBT
Z + ncrit/n
(1.21)
where again Z is the partition function.
It is instructive to think about how this behaves in the limiting
cases n ≪ncrit and n ≫ncrit. In the limit n ≫ncrit, the partition
 function Z dominates the denominator, and we get L/nX =
EA10e−E/kBT/Z. This is just the energy per spontaneous emission, E,
times the spontaneous emission rate, A10, times the fraction of the
population in the upper state when the gas is in statistical equilibrium,
 e−E/kBT/Z. This is density-independent, so this means that
at high density the gas produces a fixed amount of emission per
molecule of the emitting species. The total luminosity is just proportional
 to the number of emitting molecules.
For n ≪ncrit, the second term dominates the denominator, and we
get
L
nX
≈EA10e−E/kBT n
ncrit
.
(1.22)
Thus at low density each molecule contributes an amount of light
that is proportional to the ratio of density to critical density. Note
that this is the ratio of collision partners, i.e., of H2, rather than the
density of emitting molecules. The total luminosity varies as this
ratio times the number of emitting molecules.
The practical effect of this is that different molecules tell us about
different densities of gas in galaxies. Molecules with low critical
28
notes on star formation
densities reach the linear regime at low density, and since most of the
mass tends to be at lower density, they probe this widespread, lowdensity
 component. Molecules with higher critical densities will have
more of their emission contributed by higher density gas, and thus
tell us about rarer, higher-density regions. This is all somewhat qualitative,
 since a transition between L/nX ∝n and L/nX ∼constant
doesn’t represent a particularly sharp change in behavior. Nonetheless,
 the luminosity ratios of lines with different critical densities are
a very important diagnostic of the overall density distribution in the
ISM.
As a caution, we should note that this is computed for optically
thin emission. If the line is optically thick, we can no longer ignore
stimulated emission and absorption processes, and not all emitted
photons will escape from the cloud. In this case the effective critical
density is reduced by a factor of the optical depth. CO, the mostcommonly
 used tracer molecule, is usually optically thick.
Velocity and Temperature Inference
We can also use molecular lines
to infer the velocity and temperature structure of gas if the line in
question is optically thin. For an optically thin line, the width of
the line is determined primarily by the velocity distribution of the
emitting molecules. The physics here is extremely simple. Suppose
we have gas along our line of sight with a velocity distribution ψ(v),
i.e., the fraction of gas with velocities between v and v + dv is ψ(v)dv,
and R ∞
−∞ψ(v) dv = 1.
For an optically thin line, in the limit where natural and pressurebroadening
 of lines is negligible, which is almost always the case
when observing the cold, dense, ISM, we can think of emission
producing a delta function in frequency in the rest frame of the gas.
There is a one-to-one mapping between velocity and frequency. Thus
emission from gas moving at a velocity v relative to us along our line
of sight produces emission at a frequency ν ≈ν0(1 −v/c), where ν0 is
the central frequency of the line in the molecule’s rest frame, and we
assume v/c ≪1. In this case the line profile is described trivially by
φ(ν) = ψ(c(1 −ν/ν0)).
We can measure φ(ν) directly, and this immediately tells us the
velocity distribution ψ(v). In general the velocity distribution of
the gas ψ(v) is produced by a combination of thermal and nonthermal
 motions. Thermal motions arise from the Maxwellian velocity
 distribution of the gas, and produce a Maxwellian profile
φ(ν) ∝e−(ν−νcen)2/2σ2
ν . Here νcen is the central frequency of the line,
which is νcen = ν0(1 −¯
v/c), where ¯
v is the mean velocity of the gas
along our line of sight. The width is σν = ν0c−1p
kBT/µmH, where
T is the gas temperature and µ is the mean mass of the emitting
observing the cold interstellar medium
29
molecule in units of hydrogen masses. This is just the 1D Maxwellian
distribution.
Non-thermal motions involve bulk flows of the gas, and can
produce a variety of velocity distributions depending how the cloud
is moving. Unfortunately even complicated motions often produce
distributions that look something like Maxwellian distributions,
just because of the central limit theorem: if you throw together a
lot of random junk, the result is usually a Gaussian / Maxwellian
distribution. Figure 1.5 shows an example of velocity distributions
measured in two nearby star-forming clouds.
Figure 1.5: Position-integrated velocity
distributions of 12CO (thin lines) and
13CO (thick lines) for the Ophiuchus
and Perseus clouds, measured the
COMPLETE survey. The y axis shows
the beam temperature. Credit: Ridge
et al. (2006), © AAS. Reproduced with
permission.
Determining whether a given line profile reflects predominantly
thermal or non-thermal motion requires that we have a way of estimating
 the temperature independently. This can often be done by
observing multiple lines of the same species. Our expression
L
nX
= EA10
e−E/kBT
Z + ncrit/n
(1.23)
shows that the luminosity of a particular optically thin line is a
function of the temperature T, the density n, and the number density
of emitting molecules nX. If we observe three transitions of the same
molecule, then we have three equations in three unknowns and we
can solve for n, nX, and T independently. Certain molecules, because
of their level structures, make this technique particularly clean. The
most famous example of this is ammonia, NH3.
Complications
Before moving on it is worth mentioning some complications
 that make it harder to interpret molecular line data. The first
is optical depth: for many of the strongest lines and most abundant
species, the line becomes optically thick. As a result observations in
the line show only the surface a given cloud; emission from the back
side of the cloud is absorbed by the front side. One can still obtain
useful information from optically thick lines, but it requires a bit
more thought. We will return to the topic of what we can learn from
optically thick lines in Chapter 8.
The second complication is chemistry and abundances. The formation
 and destruction of molecules in the ISM is a complicated
problem, and in general the abundance of any given species depends
on the density, temperature, and radiation environment of the the
gas. At the edges of clouds, certain molecules may not be present
because they are dissociated by the interstellar UV field. At high
densities and low temperatures, many species freeze out onto the
surfaces of dust grains. This is true for example of CO. One often
sees that peaks in density found in dust emission maps correspond
to local minima of CO emission. This is because in the densest parts
30
notes on star formation
of clouds CO goes out of the gas phase and forms CO ice on the surfaces
 of dust grains. Thus one must always be careful to investigate
whether changes in molecular line emission are due to changes in gas
bulk properties (e.g., density, temperature) or due to changes in the
abundance of the emitting species.
1.2
Observational Phenomenology
1.2.1
Giant Molecular Clouds
As discussed above, we usually cannot observe H2 directly, so we are
forced to do so by proxy. The most common proxy is the rotational
lines of CO. These are useful because CO is the single most abundant
molecule in the ISM after H2, it tends to be found in the same places
as H2 (for reasons that will become clear in Chapter 3, and the CO
molecule has a number of transitions that can be excited at the low
temperatures found in molecular clouds – for example the CO J = 1
state is only 5.5 K above the ground state. Indeed, the CO molecule
is the primary coolant of molecular gas, so its excitation in effect sets
the molecular gas temperature.
In Chapter 8 we will discuss how one infers the mass of an observed
 gas cloud from CO emission, and for the moment we will
take it for granted that one can do so. By mass the Milky Way’s ISM
inside the solar circle is roughly 70% H i and 30% H2. The molecular
fraction rises sharply toward the galactic center, reaching near unity
in the molecular ring at ∼3 kpc, then falling to ∼10% out where we
are. In other nearby galaxies the proportions vary from nearly all H i
to nearly all H2.
In galaxies that are predominantly H i, like ours, the atomic gas
tends to show a filamentary structure, with small clouds of molecular
gas sitting on top of peaks in the H i distribution. In galaxies with
large-scale spiral structure, the molecular gas closely tracks the
optical spiral arms. Figures 1.6 and 1.7 show examples of the former
and the latter, respectively. The physical reasons for the associations
between molecular gas and H i, and between molecular clouds and
spiral arms, are an interesting point that we will discuss in Chapter 3.
As the images show, molecular gas in galaxies that are predominantly
 atomic tends to be organized into discreet clouds, called
giant molecular clouds (GMCs). These can have a range of masses;
in the Milky Way the most massive are a few million M⊙, but there
is a spectrum that seems to continue down to at least 104 M⊙. This
organization into GMCs is clearest where the gas is predominantly
atomic. In regions where molecules make up most of the mass, the
clouds begin to run together and it is no longer possible to identify
observing the cold interstellar medium
31
Figure 1.6: Map of H i in M33
(grayscale), with giant molecular clouds
detected in CO(1 →0) overlayed (circles,
sized by GMC mass). Credit: Imara
et al. (2011), © AAS. Reproduced with
permission.
Figure 1.7: Map of CO(1 →0) emission
in M51, as measured by the PdBI
Arcsecond Whirlpool Survey (PAWS)
project. Credit: Schinnerer et al. (2013),
© AAS. Reproduced with permission.
32
notes on star formation
discrete clouds in a meaningful way.
1.2.2
Internal structure of GMCs
Giant molecular clouds are not spheres. They have complex internal
structures, as illustrated in Figure 1.8. They tend to be highly filamentary
 and clumpy, with most of the mass in low density structures and
only a little bit in very dense parts. However, if one computes a mean
density by dividing the total mass by the rough volume occupied by
the 12CO gas, the result is ∼100 cm−3. Typical size scales for GMCs
are tens of pc – the Perseus cloud shown in Figure 1.8 is a small one
by Galactic standards, but the most massive ones are found predominantly
 in the molecular ring, so our high resolution images are all of
nearby small ones.
This complex structure on the sky is matched by a complex velocity
 structure. GMCs typically have velocity spreads that are much
larger than the thermal sound speed of ∼0.2 km s−1 appropriate to
10 K gas. One can use different tracers to explore the distributions
of gas at different densities in position-position-velocity space – at
every position one obtains a spectrum that can be translated into a
velocity distribution along that line of sight. The data can be sliced
into different velocities.
One can also get a sense of density and velocity structure by
combining different molecular tracers. For example, the data set from
COMPLETE (see Figure 1.5) consists of three-dimensional cubes of
12CO and 13CO emission in position-position-velocity space, and
from this one can draw isosurfaces. Generally the 12CO isosurfaces
contain the 13CO ones, as expected since the 12CO traces less dense
gas and the 13CO traces more dense gas. The density increases as one
moves toward the cloud "center" in both position and velocity, but the
morphology is not simple.
1.2.3
Cores
As we zoom into yet smaller scales, the density rises to 105 −107
cm−3 or more, while the mass decreases to a few M⊙. These regions,
called cores, tend to be strung out along filaments of lower density
gas. Morphologically, cores tend to be closer to round than the lowerdensity
 material around them. These objects are thought to be the
progenitors of single stars or star systems. Cores are distinguished
not just by simple, roundish density structures, but by similarly
simple velocity structures. Unlike in GMCs, where the velocity
dispersion is highly supersonic, in cores it tends to be subsonic. This
is indicated by a thermal broadening that is comparable to what one
would expect from purely thermal motion.
observing the cold interstellar medium
33
Figure 1.8: Map of the Perseus cloud in
13CO(2 →1). The top panel shows the
emission integrated over all velocities,
while the bottom panel shows maps
integrated over different velocity
channels. In each sub-panel in the
bottom, the numbers at the top indicate
the velocity range (in km s−1) of the
emission shown. Credit: Sun et al.,
A&A, 451, 539, 2006, reproduced with
permission ©ESO.
2
Observing Young Stars
Suggested background reading:
• Kennicutt, R. C., & Evans, N. J. 2012,
ARA&A, 50, 531, section 3
• Krumholz, M. R. 2014, Phys. Rep.,
539, 49, section 2
Having discussed how we observe interstellar gas that is forming
stars, we now turn to the phenomenology of the young stars themselves.
 This chapter works form small to large scales, first discussing
individual young stars, then resolved young stellar populations, and
then ending with unresolved stellar populations in the Milky Way
and nearby galaxies.
2.1
Individual Stars
Since we think star formation begins with a core that is purely gas,
the first observable stage of star formation should be a cloud that
is cold and lacks a central point source. Once a protostar forms, it
will begin gradually heating up the cloud, while the gas in the cloud
collapses onto the protostar, reducing the opacity. Eventually enough
material accretes from the envelope to render it transparent in the
near infrared and finally the optical, and we begin to be able to see
the star directly for the first time. The star is left with an accretion
disk, which gradually accretes and is then dispersed. Eventually the
star contracts onto the main sequence.
This theoretical cartoon has been formalized into a system of
classification of young stars based on observational diagnostics. At
one end of this sequence lies purely gaseous sources where there is
no evidence at all for the presence of a star, and at the other end lies
ordinary main sequence stars. In between, objects are classified based
on their emission in the infrared and sub-mm parts of the spectrum.
These classifications probably give more of an impression of discrete
evolutionary stages than is really warranted, but they nonetheless
serve as a useful rough guide to the evolutionary state of a forming
star.
Consider a core of mass ∼1 M⊙, seen in dust or molecular line
emission. When a star first forms at its center, it will be very low
mass and very low luminosity, and will heat up only the dust nearest
36
notes on star formation
to it, and only by a very small amount. Thus the total light output
will still be dominated by the thermal emission of the dust at its
equilibrium temperature. The spectral energy distribution of the
source will therefore look just like that which prevailed before the
star formed.
Figure 2.1: An integrated intensity map
in CO(2 →1), showing material at
velocities between ±30 −50 km s−1 (blue
and red contours, respectively) relative
to the mean. Contours are spaced at
intensities of 1 K km s−1. The outflow
shown is in the Taurus star-forming
region. Credit: Tafalla et al., A&A,423,
L21, 2004, reproduced with permission
© ESO.
However, there might be other indicators that a star has formed.
For example, the density distribution might show a very sharp,
unresolved peak. Another sign that a star has formed might be
the presence of an outflow, which, as we discuss in Chapter 14, all
protostars seem to generate. Outflows coming from the center of a
core can be detected in a few ways. Most directly, one can see bipolar,
high velocity structures in molecular emission (Figure 2.1). One can
also detect indirect evidence of an outflow, from the presence of
highly excited molecular line emission that is produced by shocks at
hundreds of km s−1. One example of such a line is SiO(2 →1) line,
which is generally seen in gas moving at several tens of km s−1 with
temperatures of several hundred K – this is taken to be indication
that emission in this line is produced in warm shocks. Since we
know of no processes other than formation of a compact object with
a ≳100 km s−1 escape velocity that can accelerate gas in molecular
clouds to such speeds, the presence of such an outflow is taken to
indicate that a compact object has formed.
Fig.
1.— SEDs for a starless core (Stutz et al., 2010;
Launhardt et al.,
2013),
a
candidate
first
hydrostatic
core
(Pineda et al.,
2011),
a
very
low-luminosity
object
(Dunham et al., 2008; Green et al., 2013b), a PACS bright red
source (Stutz et al., 2013), a Class 0 protostar (Stutz et al., 2008;
Launhardt et al., 2013; Green et al., 2013b), a Class I protostar
(Green et al., 2013b), a Flat-SED source (Fischer et al., 2010),
and an outbursting Class I protostar (Fischer et al., 2012). The +
and × symbols indicate photometry, triangles denote upper limits,
and solid lines show spectra.
Tbol begins near 20 K for deeply embedded protostars
(Launhardt et al., 2013) and eventually increases to the effective
 temperature of a low-mass star once all of the surrounding
 core and disk material has dissipated. Chen et al.
(1995) proposed the following Class boundaries in Tbol: 70
K (Class 0/I), 650 K (Class I/II), and 2800 K (Class II/III).
10
10-5
10-4
10-3
10-2
10-1
100
Submillimeter / Bolometric Luminosity
Tbol Cla
Fig. 2.— Compa
in the c2d, GB, an
18 Orion protosta
11 of which were
show the Class bou
Lsmm/Lbol from A
from the upper rig
not be monotonic i
With the sensi
tinely detected i
are both Class 0
Additionally, sou
Class I or Class
and sources with
Class II, implyin
α-based Classes
Tbol may inc
one Class bound
to pole-on (Jorg
Fischer et al., 20
may in fact be St
and submillimete
duce the influen
tion on the infer
lengths foregrou
vations probe th
are less opticall
important.
Flux
ily to envelope
gling these effec
of evolutionary
Along these line
Lsmm/Lbol is a
than Tbol (Young
Launhardt et al.,
Figure 2.2: Sample spectral energy
distributions (SEDs) of protostellar
cores, together with the assigned class,
as collected by Dunham et al. (2014).
These are the earliest indications of star formation we have available
 to us. We call objects that show one of these signs, and do not
fall into one of the other categories, class 0 sources. The dividing
line between class 0 and class I is that the star begins to heat the
dust around it to the point that there is non-trivial infrared emission.
Before the advent of Spitzer and Herschel, the dividing line between
class 0 and I was taken to be a non-detection in the IR, but as more
sensitive IR telescopes became available, the detection limit went
down, and it became necessary to specify a dividing line in terms of
a luminosity cut. A source is said to be class 0 if more than 0.5% of
its total bolometric output emerges at wavelengths longer than 350
µm, i.e., if Lsmm/Lbol > 0.5%, where Lsmm is defined as the luminosity
 considering only wavelengths of 350 µm and longer (Figure
2.2).
In practice, measuring Lsmm can be tricky because it can be hard to
get absolute luminosities (as opposed to relative ones) correct in the
sub-mm, so it is also common to define the class 0-I divide in terms
of another quantity: the bolometric temperature Tbol. This is defined
as the temperature of a blackbody that has the same flux-weighted
mean frequency as the observed spectral energy distribution (SED).
That is, if Fν is the flux as a function of frequency from the observed
observing young stars
37
source, then we define Tbol by the implicit equation
R
νBν(Tbol) dν
R
Bν(Tbol) dν =
R
νFν dν
R
Fν dν .
(2.1)
The class 0-I dividing line is also sometimes taken to be Tbol = 70 K.
In cases where Lsmm is accurately measured, Tbol is observed to be a
reasonably good proxy for Lsmm/Lbol (Figure 2.3).
Fig.
1.— SEDs for a starless core (Stutz et al., 2010;
Launhardt et al.,
2013),
a
candidate
first
hydrostatic
core
(Pineda et al.,
2011),
a
very
low-luminosity
object
(Dunham et al., 2008; Green et al., 2013b), a PACS bright red
source (Stutz et al., 2013), a Class 0 protostar (Stutz et al., 2008;
Launhardt et al., 2013; Green et al., 2013b), a Class I protostar
(Green et al., 2013b), a Flat-SED source (Fischer et al., 2010),
and an outbursting Class I protostar (Fischer et al., 2012). The +
and × symbols indicate photometry, triangles denote upper limits,
and solid lines show spectra.
Tbol begins near 20 K for deeply embedded protostars
(Launhardt et al., 2013) and eventually increases to the effective
 temperature of a low-mass star once all of the surrounding
 core and disk material has dissipated. Chen et al.
(1995) proposed the following Class boundaries in Tbol: 70
K (Class 0/I), 650 K (Class I/II), and 2800 K (Class II/III).
1000
100
10
Bolometric Temperature (K)
10-5
10-4
10-3
10-2
10-1
100
Submillimeter / Bolometric Luminosity
Tbol Class 0
Tbol Class I
Tbol Class II
Lsmm/Lbol Class 0
Lsmm/Lbol Class I
c2d+GB
HOPS
PBRS
Fig. 2.— Comparison of Lsmm/Lbol and Tbol for the protostars
in the c2d, GB, and HOPS surveys. The PBRS (§4.2.3) are the
18 Orion protostars that have the reddest 70 to 24 µm colors,
11 of which were discovered with Herschel. The dashed lines
show the Class boundaries in Tbol from Chen et al. (1995) and in
Lsmm/Lbol from Andre et al. (1993). Protostars generally evolve
from the upper right to the lower left, although the evolution may
not be monotonic if accretion is episodic.
With the sensitivity of Spitzer, Class 0 protostars are routinely
 detected in the infrared, and Class I sources by α
are both Class 0 and I sources by Tbol (Enoch et al., 2009).
Additionally, sources with flat α have Tbol consistent with
Class I or Class II, extending roughly from 350 to 950 K,
and sources with Class II and III α have Tbol consistent with
Class II, implying that Tbol is a poor discriminator between
α-based Classes II and III (Evans et al., 2009).
Tbol may increase by hundreds of K, crossing at least
one Class boundary, as the inclination ranges from edge-on
to pole-on (Jorgensen et al., 2009; Launhardt et al., 2013;
Fischer et al., 2013). Thus, many Class 0 sources by Tbol
may in fact be Stage I sources, and vice versa. Far-infrared
and submillimeter diagnostics have a superior ability to reduce
 the influence of foreground reddening and inclination
 on the inferred protostellar properties. At such wavelengths
 foreground extinction is sharply reduced and observations
 probe the colder, outer parts of the envelope that
are less optically thick and thus where geometry is less
important.
Flux ratios at λ ≥70 µm respond primarily
 to envelope density, pointing to a means of disentangling
 these effects and developing more robust estimates
of evolutionary stage (Ali et al., 2010; Stutz et al., 2013).
Along these lines, several authors have recently argued that
Lsmm/Lbol is a better tracer of underlying physical Stage
than Tbol (Young and Evans, 2005; Dunham et al., 2010a;
Launhardt et al., 2013).
4
Figure 2.3: Bolometric temperatures
of protostellar cores as compared to
sub-mm to bolometric luminosity ratios
(Dunham et al., 2014). The samples
shown are from three different surveys
as indicated in the legend.
Once protostars reach class I, their evolution into further classes
is defined in terms of the infrared spectral energy distribution. The
motivating cartoon is a follows. At early times, the envelope of dust
around the protostar is very optically thick at visible and even near
infrared wavelengths. As a result, we cannot directly observe the
stellar photosphere. All the radiation is absorbed by the envelope.
The dust is in thermal equilibrium, so it re-radiates that energy. Since
the radius of the sphere of dust is much larger than that of the star,
and the luminosity radiated by the dust must ultimately be equal
to that of the star, this emission must be at lower temperature and
thus longer wavelengths. Thus as the radiation propagates outward
through the dust it is shifted to longer and longer wavelengths. However,
 at wavelengths longer than the characteristic sizes of the dust
grains, the opacity decreases as roughly κλ ∝λ−2. Thus eventually
the radiation is shifted to wavelengths where the remaining dust
is optically thin, and it escapes. What we observe is therefore not a
stellar photosphere, but a "dust photosphere".
Given this picture, the greater the column density of the dust
around the star, the further it will have to diffuse in wavelength in
order to escape. Thus the wavelength at which the emission peaks, or,
roughly equivalently, the slope of the spectrum at a fixed wavelength,
is a good diagnostic for the amount of circumstellar dust. Objects
whose SEDs peak closer to the visible are presumed to be more
evolved, because they have lost more of their envelopes.
More formally, this classification scheme was based on fluxes as
measured by the Infrared Astronomical Satellite (IRAS). We define
αIR = d log(λFλ)
d log λ
,
(2.2)
as the infrared spectral index, and in practice we measure αIR using
two points from the IRAS SED: 2.2 µm and 10 −25 µm. More positive
values of αIR indicate SEDs that peak at longer wavelengths, further
into the IR, while more negative values indicate SEDs that peak
closer to visible. We define sources with αIR ≥0.0, i.e., rising at
longer wavelengths from 2 to 25 µm, as class I sources. Alternately,
in terms of bolometric temperature, the class I to class II transition is
generally taken to be at 650 K (Figure 2.2).
38
notes on star formation
As more of the envelope accretes, it eventually becomes optically
thin at the peak emitting wavelengths of the stellar photosphere. In
this case we see the stellar blackbody spectrum, but there is also excess
 infrared emission coming from the disk of warm, dusty gas that
still surrounds the star. Thus the SED looks like a stellar blackbody
plus some extra emission at near- or mid-infrared wavelengths. Stars
in this class are also know as classical T Tauri stars, named for the
first object of the class, although the observational definition of a T
Tauri star is somewhat different than the IR classification scheme1,
1 T Tauri stars were first identified in
the optical, long before the availability
of infrared SEDs. They are defined by
high levels of optical variability and
the presence of strong chromospheric
lines, indicating large amounts of
circumstellar material. T Tauri stars are
discussed further in Chapter 20.
so the alignment may not be perfect. In terms of αIR, these stars have
indices in the range −1.6 < αIR < 0.2 A slope of around −1.6 is what
2 Depending on the author, the breakpoint
 may be placed at −1.5 instead
of −1.6. Some authors also introduce
an intermediate classification between
0 and I, called flat spectrum sources,
which they take to be −0.3 < αIR < 0.3.
we expect for a bare stellar photosphere without any excess infrared
emission coming from circumstellar material. Since the class II phase
is the last one during which there is a disk of any significant mass,
this is also presumably the phase where planet formation must occur.
The final stage is class III, the category into which we place
sources whose SEDs have αIR < −1.6. Stars in this class correspond
to weak line T Tauri stars. The SEDs of these stars look like bare
stellar photospheres in the optical through the mid-infrared. If there
is any IR excess at all, it is in the very far IR, indicating that the emitting
 circumstellar material is cool and located far from the star. The
idea here is that the disk around them has begun to dissipate, and is
either now optically thin at IR wavelengths or completely dissipated,
so there is no strong IR excess.
However, these stars are still not mature main sequence stars. First
of all, their temperatures and luminosities do not correspond to those
of main sequence stars. Instead, they are still puffed up to larger
radii, so they tend to have either lower effective temperatures or
higher bolometric luminosities (or both) than main sequence stars of
the same mass. Second, they show extremely high levels of magnetic
activity compared to main sequence stars, producing high levels of
X-ray emission. Third, they show lithium absorption lines in their
atmospheres. This is significant because lithium is easily destroyed by
nuclear reactions at high temperatures, and no main sequence stars
with convective photospheres show Li absorption. Young stars show
it only because there has not yet been time for all the Li to burn.
2.2
Statistics of Resolved Stellar Populations
Young stars tend to be born in the presence of other stars, rather
than by themselves. This is not surprising: the gas cores from which
they form are very small fragments, ∼1 M⊙, inside much larger,
∼106 M⊙clouds. It would be surprising if only one tiny fragment
containing ∼10−6 of the total cloud mass were to collapse. We now
observing young stars
39
pull back to somewhat larger scales to look at the formation of stars
in groups.
2.2.1
Multiplicity
The smallest scale we can look at beyond a single star is multiple
systems. When we do so, we find that a significant fraction of stars
are members of multiple systems – usually binaries, but also some
triples, quadruples, and larger. The multiplicity is a strong function
of stellar mass. The vast majority of B and earlier stars are multiples,
while the majority of G, K, and M stars are singles. This means that
most stars are single, but that most massive stars are multiples. The
distribution of binary periods is extremely broad, ranging from
hours to Myr. The origin of the distribution of periods, and of the
mass-dependence of the multiplicity fraction, is a significant area
of research in star formation theory, one to which we will return in
Chapters 12, 13, and 18.
2.2.2
The Initial Mass Function
If we observe a cluster of stars, the simplest thing to do is simply
count up how many of them there are as a function of mass. The
result is one of the most important objects in astrophysics, the initial
mass function (IMF). This requires a bit of modeling, since of course
what we can actually measure is a luminosity function, not a mass
function. The problem of determining the IMF can be tackled in
two ways: either by looking at stars in the solar neighborhood, or by
looking at individual star clusters.
Looking at stars in the Solar neighborhood has the advantage that
there are a lot of them compared to what you see in a clusters, so one
gets a lot of statistical power. One also does not have to worry about
two things that a major headache for studies of young clusters. First,
young clusters usually have remaining bits of gas and dust around
them, and this creates reddening that can vary with position and has
to be modeled. Second, for clusters younger than ∼10 Myr, the stars
are not on the main sequence yet. Since young stars are brighter than
main sequence stars of the same mass, this produces an age-mass
degeneracy that you have to break by obtaining more information
than just luminosities (usually temperatures or colors), and then
making pre-main sequence evolutionary models.3
3 Protostellar evolution is covered in
Chapter 17.
On the other hand, if we want to talk about the IMF of massive
stars, we are largely stuck looking at young clusters. The same is
also true for brown dwarfs. Since these fade with time, it is hard to
find a large number of them outside of young clusters. An additional
advantage of star clusters is that they are to good approximation
40
notes on star formation
chemically homogenous, so we need not worry about chemical
variations masquerading as mass variations.
A big problem for either method is correction for unresolved
binaries, particularly at the low mass end, where the companions
of brighter stars are very hard to see. When one does all this, the
result is the apparently universal or close-to-universal distribution
illustrated in Figure 2.4.4 The basic features we see are a break peak
4 There have been recent claims of IMF
variation from extragalactic observation,
which we will discuss in Chapter 12.
centered around a few tenths of M⊙, with a fairly steep fall off at
higher masses that is well fit by a powerlaw function with a slope
near −2.3. There is also a fall-off at lower masses, although some
authors argue for a second peak in the brown dwarf regime. This is a
difficult observational problem, both because brown dwarfs are hard
to find, and because their evolutionary tracks are less secure than
those for more massive stars.
2.0
1.5
1.0
0.5 0.0
0.5
1.0
1.5
2.0
logm [M ⊙]
2
0
2
4
6
8
10
12
14
log dn/dlogm + const
Chameleon
IC 348
λ Ori
ONC
ρ Oph
σ Ori
Taurus
Young populations
1.5
1.0
0.5 0.0
0.5
1.0
1.5
2.0
logm [M ⊙]
Hyades
M35
Pleiades
Praesepe
NGC 2298
NGC 6397
NGC 6712
Field
Older populations
Figure 2.4: Stellar initial mass functions
 inferred for a wide variety of
regions in the Milky Way (data compilation
 from Bastian et al. 2010). The left
panel shows young stellar populations
(age under ∼5 Myr), while the right
panel shows older stellar populations in
open clusters (green), globular clusters
(red), and the Galactic field (black).
The names of the regions are as indicated.
 The dotted black lines show the
Chabrier (2005) fit to the IMF (equation
2.3). Note that vertical offsets in the
plot are arbitrary, and the black dotted
lines have been normalized to match
the data at m = 0.5 M⊙. Finally, note
that for many regions the data become
incomplete below ∼0.2 M⊙.
The functional form shown in Figure 2.4 has been parameterized
in a number of ways. Two of the most popular are from Kroupa
observing young stars
41
(2001, 2002) and Chabrier (2003, 2005).5 Both of these fit the field
5 See the reviews by Bastian et al. (2010)
and Offner et al. (2014) for a thorough
listing of alternate parameterizations.
star data, and the data individual clusters, within the error bars. The
functional form for Chabrier is
dn
d log m ∝



exp
h
−(log m−log 0.22)2
2×0.572
i
,
m < 1
exp
h
−(−log 0.22)2
2×0.572
i
m−1.35,
m ≥1
,
(2.3)
while the functional form for Kroupa is
dn
d log m ∝












m
m0
−α0 ,
m0 < m < m1

m1
m0
−α0 
m
m1
−α1 ,
m1 < m < m2

∏n
i=1

mi
mi−1
−αi−1 
m
mn
−αn ,
mn < m < mn+1
,
(2.4)
with
α0 = −0.7 ± 0.7,
m0 = 0.01
α1 = 0.3 ± 0.5,
m1 = 0.08
α2 = 1.3 ± 0.3,
m2 = 0.5
α3 = 1.3 ± 0.7,
m3 = 1, m4 →∞
.
(2.5)
In both of the above expressions, m is understood to be in units of
M⊙.
2.3
Unresolved Stellar Populations and Extragalactic Star Formation

What about cases where we cannot resolve the stellar population, as
is usually the case for extragalactic work? What can we learn about
star formation in that case? The answer turns out to be that the thing
we can most directly measure is the star formation rate, and that
doing so yields some very interesting results.
2.3.1
Measuring the Star Formation Rate: General Theory
The most basic problem in working with unresolved stellar populations
 is how we distinguish young stars from main sequence ones.
Except for the brightest stars in the nearest galaxies, we cannot obtain
spectra, or even colors, for individual stars as we can in the Milky
Way. Instead, the strategy we use to isolate young stars is to exploit
the fact that massive stars have short lifetimes, so if we measure the
total number of massive stars in a galaxy, or some patch of a galaxy,
then we are effectively measuring many such stars formed there over
some relatively short period. We can formalize this theory a bit as
follows.
Consider stars born with an initial mass function dn/dm. The
mean stellar mass for this IMF is m = R
dm m(dn/dm). A time
42
notes on star formation
t after a star is born, the star has a luminosity L(m, t), where the
luminosity can be bolometric, or integrated over some particular
filter or wavelength range. First consider the simplest possible case,
a population of stars all born at the same instant at time 0. A time t
later, the luminosity of the stars is
L(t) = N∗
Z ∞
0
dm L(m, t) dn
dm,
(2.6)
where N∗is the total number of stars, and we have normalized the
IMF so that R (dn/dm) dm = 1. That is, we simply integrate the
luminosity per star at time t over the mass distribution of stars. Now
consider a region, e.g., a galaxy, forming stars at a rate ˙
M∗(t); in
terms of number, the star formation rate is ˙
N∗(t) =
˙
M∗(t)/m. To
find the luminosity of the stellar population that is present today, we
simply take the expression we just derived and integrate over all the
possible stellar ages. Thus we have
L =
Z ∞
0
dt
˙
M∗(t)
m
Z ∞
0
dm L(m, t) dn
dm.
(2.7)
By itself this is of limited use, because the right hand side depends
on the full star formation history ˙
M∗(t). However, let us assume that
˙
M∗is constant in time. The integral still converges as long as L(m, t)
reaches 0 after a finite time. In this case the integrals over m and t are
separable, and we can rearrange them to
L =
˙
M∗
m
Z ∞
0
dm dn
dm
Z ∞
0
dt L(m, t) ≡
˙
M∗
m
Z ∞
0
dm dn
dm⟨Ltlife⟩m
(2.8)
In the final step we defined a new quantity ⟨Ltlife⟩m, which has a
simple physical meaning: it is the total amount of radiant energy that
a star of mass m puts out over its lifetime.
Notice the expression on the right depends only on the constant
star formation rate ˙
M∗, the energy output ⟨Ltlife⟩m, which we can
generally calculate from stellar structure and evolution theory, and
the IMF dn/dm. Thus if we measure L and use the "known" values
of ⟨Ltlife⟩m and dn/dm, we can measure the star formation rate. The
underlying physical assumption is that the stellar population being
observed is in statistical equilibrium between new stars forming and
old stars dying, so the total number of stars present and contributing
to the light at any time is proportional to the rate at which they are
forming. Thus a measurement of the light tells us about the star
formation rate.
Is our assumption that ˙
M∗is constant reasonable? That depends
on the system we are observing. For an entire galaxy that is forming
stars quiescently and has not been externally perturbed, it is probably
 reasonable to assume that ˙
M∗cannot vary on timescales much
observing young stars
43
shorter than the dynamical time of the galaxy, which is ∼200 Myr for
a galaxy like the Milky Way. If we choose to observe the luminosity
at a wavelength where the light is coming mostly from stars with
lifetimes shorter than this, so that L(m, t) reaches 0 (at least to good
approximation) at times much less than 200 Myr, then assuming
constant ˙
M∗is quite reasonable.
However, it is always important to keep this constraint in mind
– we can only measure the star formation rate as long as we believe
it to be constant on timescales long compared to the lifetimes of the
stars responsible for generating the luminosity we are measuring.
One can actually see how the ratio of luminosity to star formation
rate behaves in systems that do not satisfy the constraint by generating
 synthetic stellar populations. In the simple case of a system
that begins with no stars and then forms stars at a constant rate, the
bolometric luminosity after the onset of star formation just increases
linearly with time until the first stars start evolving off the main
sequence, and only becomes constant after ∼4 Myr (Figure 2.5).
Figure 2.5: Bolometric luminosity
versus time for stellar populations as
a function of population age. The top
panel shows the luminosity normalized
by the star formation rate, while
the bottom shows the luminosity
normalized by the total stellar mass.
Credit: Krumholz & Tan (2007), © AAS.
Reproduced with permission.
The need to satisfy this constraint generally drives us to look for
luminosities that are dominated by very massive stars, because these
have very short lifetimes. Thus we will begin by discussing what
luminosities we can measure that are particularly good at picking
out massive stars. This is far from an exhaustive list – astronomers
have invented many, many methods to infer star formation rates for
galaxies at a range of redshifts. The accuracy of these techniques
is highly variable, and in some cases amounts to little more than
a purely empirical calibration. We focus here on the most reliable
and widely used techniques that we can apply to relatively nearby
galaxies.
2.3.2
Recombination Lines
Probably the most common technique, and the only one that can be
used from the ground for most galaxies, is hydrogen recombination
lines. To illustrate why this is useful, it is helpful to look at some
galaxy spectra (Figure 2.6). As we move from quiescent E4 and SB
galaxies to actively star-forming Sc and Sm/Im galaxies, there is a
striking different in the prominence of emission lines.
In the example optical spectra, the most prominent lines are the
Hα line at 6563 Å and the Hβ at 4861 Å. These are lines produced by
the 3 →2 and 4 →2, respectively, electronic transitions in hydrogen
atoms. In the infrared (not shown in the figure) are the Paschen α
and β lines at 1.87 and 1.28 µm, and the Bracket α and γ lines at 4.05
and 2.17 µm. These come from the 4 →3, 5 →3, 5 →4, and 7 →4
transitions.
44
notes on star formation
Figure 2.6: Example spectra of galaxies
of varying Hubble type. In each panel,
the galaxy name and Hubble type are
listed. Credit: Kennicutt (1992), © AAS.
Reproduced with permission.
observing young stars
45
Why are these related to star formation? The reason is that these
lines come from H ii regions: regions of ionized gas produced
primarily by the ionizing radiation of young stars. Since only massive
stars (larger than 10 −20 M⊙) produce significant ionizing fluxes,
these lines indicate the presence of young stars. Within these ionized
regions, one gets hydrogen line emission because atoms sometimes
recombine to excited states rather than to the ground state. These
excited atoms then radiatively decay down to the ground state,
producing line emission in the process.
Obtaining a numerical conversion between the observed luminosity
 in one of these lines and the star formation rate is a four-step
process. First, one performs a quantum statistical mechanics calculation
 to compute the yield of photons in the various lines per
recombination. This can be done very precisely from first principles.
Second, one equates the total recombination rate to the total ionization
 rate, and uses this to determine the total rate of emission for the
line in question per ionizing photon injected into the nebula. Third,
one uses stellar models to compute ⟨Liontlife⟩m, the total ionizing
photon production by a star of mass m over its lifetime. Fourth, one
evaluates the integral over the IMF given by equation (2.8) to obtain
the numerical conversion between star formation rate and luminosity.
As of this writing, the most up-to-date resource for the results of such
calculations is Kennicutt & Evans (2012).
Note that there are significant uncertainties in these numbers,
the dominant one of which is the IMF. The reason the IMF matters
so much is that the light is completely dominated by the massive
stars, while the mass is all in the low mass stars that are not observed
directly. To give an example, for a Chabrier IMF at zero age, stars
more massive than 15 M⊙contribute 99% of the total ionizing flux
for a stellar population, but constitute less than 0.3% of the mass.
Thus we are extrapolating by at least a factor of 300 in mass, and
small changes in the IMF can produce large changes in the resulting
ionizing luminosity to mass conversion.
Another complication is that some of the line emission is likely
to be absorbed by dust grains within the source galaxy, and some
of the ionizing photons are absorbed by dust grains rather than
hydrogen atoms. Thus, one must make an extinction correction to the
luminosities.
2.3.3
Radio Free-Free
A closely related method for measuring massive stars is to use freefree
 emission at radio wavelengths. An H ii region emits optical lines
from transitions between energy levels of hydrogen and other atoms,
46
notes on star formation
but it also emits free-free radiation in the radio. This is radiation
produced by bremsstrahlung: free electrons scattering off ions, and
emitting because accelerating charges emit. It is the opposite side of
the coin from recombination line emission: the former occurs when
free electrons and protons encounter one another and do not become
bound, while the latter occurs when they do.
We will not treat bremsstrahlung or its application to H ii regions
here, but the relevant point for us is that the free-free luminosity of
H ii regions at radio wavelengths is proportional to neni, i.e., the
product of the electron and ion densities. Since the recombination
rate is also proportional to nenH+, and due to chemical balance the
recombination rate must equal the ionization rate, the free-free luminosity
 is directly proportional to the rate at which ionizing photons
are injected into the H ii region. Thus one can convert between freefree
 emission rate and ionization rate based on the physics of H ii
regions, and from then convert that into a star formation rate exactly
as for optical recombination lines.
The free-free method has one major advantage, which is that radio
emission is not obscured by dust, so one of the dust absorption corrections
 goes away. The correction for absorption of ionizing photons
by dust grains within the H ii region remains, but this is generally
only a few tens of percent. Thus radio free-free measurements are
more reliable that recombination line ones. Indeed, they are the only
technique we can use for most H ii regions in the Milky Way, since
these tend to be located in the Galactic plane and thus suffer from
heavy extinction at optical wavelengths. The downside is that the
free-free emission is quite weak, and separating free-free from other
sources of radio emission requires the ability to resolve individual
H ii regions. Thus at present this technique is useful primarily for the
Milky Way and a few other nearby galaxies, since those are the only
places where we can detect and resolve individual H ii regions.
2.3.4
Infrared
The recombination line methods work well for galaxies that are
like the Milky Way, but considerably less well for galaxies that are
dustier and have higher star formation rates. This is because the
dust extinction problem becomes severe, so that the vast majority
of the Balmer line emission is absorbed. The Paschen and Bracket
emission is much less sensitive to this, since those lines are in the IR,
but even they can be extincted in very dusty galaxies, and they are
also much harder to use than Hα and Hβ because they are 1 −2 orders
of magnitude less bright intrinsically.
Instead, for dusty sources the tracer of choice is far infrared. The
observing young stars
47
idea here is that, in a sufficiently dusty galaxy, essentially all stellar
light will eventually be absorbed by dust grains. These grains will
then re-emit the light in the infrared. As a result, the SED peaks
in the IR. In this case one can simply use the total IR output of the
galaxy as a sort of calorimeter, measuring the total bolometric power
of the stars in that galaxy. In galaxies or regions of galaxies with
high star formation rates, which tend to be where Hα and other
recombination line techniques fail, this bolometric power tends to be
completely dominated by young stars. Since these stars die quickly,
the total number present at any given time is simply proportional to
the star formation rate.
The derivation of the conversion in this case is very straightforward
 – the L(m, t) that is required is just the total bolometeric output
of the stars. Results are given in Kennicutt & Evans (2012), and Problem
 Set 1 includes an example calculation. Of course IR emission has
its problems too. First of all, it misses all the optical and UV radiation
 from young stars that is not absorbed within the galaxy, which
makes it a poor choice for dust-poor galaxies where a majority of the
radiation from young stars escapes.
A second problem is that if the SFR is low, then old rather than
young stars may dominate the bolometric output. In this case the IR
indicator can give an artificially high SFR. A more common problem
for the dusty galaxies where IR tends to be used most is contamination
 from an active galactic nucleus (AGN). If an AGN contributes
significantly to the bolometric output of a galaxy, that can masquerade
 as star formation. This can be hard to detect in a very dusty
galaxy where most of the AGN light, along with most of the starlight,
is absorbed and reprocessed by dust.
2.3.5
Ultraviolet
Yet another way of measuring star formation rates is by the broadband
 ultraviolet (UV) flux at wavelengths that are longer than 912 Å
(corresponding to 13.6 eV, the energy required to ionized hydrogen)
but shorter than where old stars put out most of their light. This
range is roughly 1250 −2500 Å. This light does not ionize hydrogen,
so unlike shorter wavelengths it can get out of a galaxy.
For galaxies in the right redshift range this light gets redshifted
into the visible, so we can see it from the ground. However, for
local galaxies these wavelengths are only accessible from space (or
least a balloon or rocket). For this reason this band was not used
much until the launch of the Galaxy Evolution Explorer (GALEX)
satellite, which had detectors operating at 1300-1800 and 1800-2800
Å(referred to as FUV and NUV, respectively). Emission in the FUV
48
notes on star formation
band is dominated by stars with masses ∼5 M⊙and up, which
have lifetimes of ∼50 Myr, so the total FUV light measures the
star formation rate integrated over this time scale. Sadly, GALEX is
no longer in operation, and there is no comparable mission on the
immediate horizon, so this technique is largely of archival value for
now.
FUV suffers from the same problems with dust extinction as
Hα, and they are perhaps even more severe, since opacity increases
as frequency does. On the other hand, FUV is less sensitive to the
IMF than Hα, because ionizing photons come from hotter and thus
more massive stars than FUV ones. For systems with low overall
star formation rates, ionization-based star formation rate indicators
can become quite noisy due to the rarity of the massive stars they
trace. FUV has fewer problems in this regard. However, there is a
corresponding disadvantage, in that the ∼50 Myr lifetime of FUVemitting
 stars is getting uncomfortably close to the typical orbital
periods of galaxies, and so one can legitimately worry about whether
the SFR has really be constant over the required timescale. This problem
 becomes even worse if one looks at small-subregions of galaxies,
rather than galaxies as a whole. One also has to worry about stars
moving from their birth locations over such long timescales.
2.3.6
Combined Estimators
As one might guess from the discussion thus far, none of the indicators
 by itself is particularly good. Recombination lines and UV get
into trouble in dusty galaxies because they miss light from young
stars that is obscured by dust, while IR gets into trouble because it
misses light from young stars that is not dust-obscured. This suggests
that the best way to proceed is to combine one or more estimators,
and this is indeed the current state of the art. A number of combined
indicators are suggested in Kennicutt & Evans (2012).
Part II
Physical Processes
3
Chemistry and Thermodynamics
Suggested background reading:
• Krumholz, M. R. 2014, Phys. Rep.,
539, 49, sections 3.1 −3.2
Suggested literature:
• Glover, S. C. O., Federrath, C., Mac
Low, M.-M., & Klessen, R. S. 2010,
MNRAS, 404, 2
Having completed our whirlwind tour of the observational phenomenology,
 we now turn to the physical processes that govern the
behavior of the star-forming ISM and its transformation into stars.
The goal of this section is to develop physical intuition for how this
gas behaves, and to develop some analytic tools for use through the
remainder of the book. This chapter covers the microphysics of the
cold ISM.
3.1
Chemical Processes in the Cold ISM
We will begin our discussion of the microphysics of the cold ISM
with the goal of understanding something important that should
be clear from the observational discussion: the parts of the ISM
associated with star formation are overwhelmingly molecular gas.
This is in contrast to the bulk of the ISM, at least in the Milky Way
and similar galaxies, which is composed of atomic or ionized gas
with few or no molecules. Our goal is to understand why the ISM
in some places becomes predominantly molecular, and how this
transition is related star formation. We will focus this discussion on
the most important atoms in the ISM: hydrogen, carbon, and oxygen.
3.1.1
Hydrogen Chemistry
Molecular hydrogen is a lower energy state than atomic hydrogen, so
an isolated box of hydrogen left for an infinite amount of time will
eventually become predominantly molecular. In interstellar space,
though, the atomic versus molecular fraction in a gas is determined
by a balance between formation and destruction processes.
Atomic hydrogen can turn into molecular hydrogen in the gas
phase, but this process is extremely slow. This is ultimately due to
the symmetry of the hydrogen molecule. To form an H2 molecule,
two H atoms must collide and then undergo a radiative transition
52
notes on star formation
that removes enough energy to leave the resulting pair of atoms in a
bound state. However, two H atoms that are both in the ground state
constitute a symmetric system, as does an H2 molecule in its ground
state. Because both the initial and final states are symmetric, the system
 has no dipole moment, and cannot emit dipole radiation. Thus
transitions between the bound and unbound states are forbidden.
Radiative transitions can in fact occur, but the rate is extremely small,
and generally negligible under astrophysical circumstances.1 One can
1 One can be more precise about
this based on an argument given by
Gould & Salpeter (1963). Consider the
nuclei fixed, and examine the possible
electronic state. The total electronic
wave function must be anti-symmetric
under particle exchange, so either
the spatial part of the wave function
must be symmetric and the spin part
anti-symmetric, or vice versa. In turns
out that the ground, bound state is
spatially symmetric and spin antisymmetric,
 so the two electrons have
opposite spin and the total electronic
spin is 0, making the state a singlet; we
denote this state ψ↑↓. The non-bound
repulsive state is the opposite: spatially
anti-symmetric, spin symmetric, so
the total electronic spin is 1 and the
state is a triplet; we denote this ψ↑↑.
The rate of electric dipole transitions
between these two states, and thus
the rate at which H2 can form from
atomic hydrogen in the gas phase, is
proportional to the square of the matrix
element ⟨ψ↑↑|D|ψ↑↓⟩, where D is the
electric dipole operator. However, D
does not act on the spin parts of the
wave functions, and since the spin
parts of ψ↑↓and ψ↑↑are orthogonal,
the matrix element should vanish. It
does not do so exactly only because
spin-spin and spin-orbit interactions
slightly perturb the system so that
the ground eigenstate is not exactly
the pure singlet ψ↑↓, but instead is a
linear combination of mostly ψ↑↓with a
small component of the triplet ψ↑↑. The
relative size of the triplet component
is of order the ratio of the spin-orbit
and spin-spin interaction energies to
the electronic energies, which is ∼α2,
where α ≈1/137 is the fine structure
constant. Similarly, the repulsive
state contains a singlet component
of order α2 as well. Thus the bound
and repulsive states are not purely
orthogonal, but the matrix element is
of order α2. Since the transition rate
is proportional to the square of this
matrix element, it is of order α4 ∼10−9
compared to allowed transitions.
circumvent this limitation by considering either starting or final states
there are not symmetric (for example because one of the H atoms
is in an excited state, or the final H2 molecule is in an excited state),
but this does not lead to a significant rate of gas phase H2 formation
either, because the lowest-lying energy states of the H2 molecule are
energetic enough that only a negligible fraction of collisions have
enough energy to produce them. A third option for gas phase formation
 is to have three-way collisions, and we will return to this in
Chapter 19. For now we simply remark that, since three-body collisions
 occur at a rate that depends on the cube of density, at typical
interstellar densities they are generally negligible as well.
Due to this limitation, the dominant formation process is instead
formation on the surfaces of dust grains. In this case the excess energy
 released by forming the molecule is transferred into vibrations
in the dust grain lattice, and there is no need for forbidden photon
emission. The rate of H2 formation by surface catalysis is given by
1
2S(T, Tgr)η(Tgr)ngrnHσgrvH.
(3.1)
Here S is the probability that a hydrogen molecule that hits a dust
grain will stick, which is a function of both the gas temperature and
the grain temperature. η is the probability that a hydrogen atom
that sticks will migrate across the grain surface and find another
H atom before it is evaporated off the grain surface ngr and nH are
the number densities of grains and hydrogen atoms, σgr is the mean
cross section for a dust grain, and vH is the thermal velocity of the
hydrogen atoms.
The last three factors can be estimated reasonably well from
observations of dust extinction and gas velocity dispersions, while
the former two have to be determined by laboratory measurements
and/or theoretical chemistry calculations. Rather than dive into this
extensive literature, we will simply skip directly to the result: for
conditions appropriate to cool atomic or molecular regions in the
Milky Way, the formation rate is roughly
RnnH,
(3.2)
where nH and n are the number densities of H atoms and H nuclei
chemistry and thermodynamics
53
(in atomic or molecular form), respectively, and R ≈3 × 10−17
cm3 s−1 is the rate coefficient. It may be a factor of a few lower in
warmer regions where the sticking probability is reduced. This is for
Milky Way dust content. If we go to a galaxy with less dust, the rate
coefficient will be reduced proportionally.
The reverse process, destruction, is mostly due to photo-destruction.
As with H2 formation, things are somewhat complicated by the symmetry
 of the H2 system. The binding energy of H2 in the ground
state is only 4.5 eV, but this doesn’t mean that 4.5 eV photons can
destroy it. A reaction of the form
H2 + hν →H + H
(3.3)
is forbidden by symmetry for exactly the same reason as its inverse,
and occurs at a negligibly small rate. Allowed transitions are possible
if the H2 molecule is in an excited state that thus asymmetric, or if
one of the H atoms is left in an excited state. However, the former
is almost never the case at the low temperatures found in molecular
clouds, and the latter requires a photon energy of 14.5 eV. Photons
with an energy that high are not generally available, because they can
ionize neutral hydrogen and thus have very short mean free paths
through the interstellar medium.
Instead, the main H2 destruction process proceeds in two stages.
Hydrogen molecules have a series of excited electronic states with
energies of 11.2 −13.6 eV (corresponding to 912 −1100 Å) above
the ground state, which produce absorption features known as the
Lyman and Werner bands. Since these energies exceed the binding
energy of the H2 molecule (4.5 eV), absorptions into them undergo
radiative decay to a ground electronic state that can be unbound.
This happens roughly 10-15% of the time, depending on exactly
which excited state is decaying. Photons in the LW energy range are
produced by hot stars, and the Galaxy is saturated with them, which
is why most of the Galaxy’s volume is filled with atomic or ionized
rather than molecular gas. (There are some galaxies that are mostly
molecular, for reasons we will see below.)
Consider a region where the number density of photons of frequency
 ν is given by E∗
ν. The destruction rate of H2 will then be
Z
nH2σH2,νcE∗
ν fdiss,ν dν,
(3.4)
where nH2 is the molecular hydrogen number density, σH2,ν is the
absorption cross-section at frequency ν, and fdiss,ν is the dissociation
probability when a photon of frequency ν is absorbed. The expression
 inside the integral is just the number of hydrogen molecule
targets times the cross section per target times the number of photons
54
notes on star formation
times the relative velocities of the photons and molecules (= c) times
the probability of dissociation per collision. The integral in frequency
goes over the entire LW band, from 912 −1100 Å.
To understand the circumstances under which H2 can become the
dominant form of hydrogen, we can take a simple example. Suppose
we have some cloud of gas, which we will treat as a uniform slab,
which has a beam of UV radiation shining on its surface. The number
density of hydrogen nuclei in the cloud is n, and the UV radiation
field shining on the surface has a photon number density E∗
0. The
photon flux is F∗= cE∗
0.
As a result of this radiation field, the outer parts of the cloud are
atomic hydrogen. However, when a hydrogen molecule absorbs a
photon and then re-emits that energy, the energy generally comes
out in the form of multiple photons of lower energy, which are no
longer able to excite resonant LW transitions. Thus photons are
being absorbed as hydrogen forms, and the number of photons
penetrating the cloud decreases as one moves further and further into
it. Eventually the number of photons drops to near zero, and the gas
becomes mostly molecular. This process is known as self-shielding.
We can get a rough estimate of when self-shielding is important
by writing down two equations to describe this process. First, let
us equate the rates of H2 formation and destruction, i.e., assume
the cloud is in chemical equilibrium. (This is generally true because
the reaction rates go as n2, so as long as turbulence produces high
density regions, there will be places where the reaction occurs quite
fast.) This gives
nHnR =
Z
nH2σH2,νcE∗
ν fdiss,ν dν ≈fdiss
Z
nH2σH2,νcE∗
ν dν.
(3.5)
In the second step we have made the approximation that fdiss is
roughly frequency-independent, which is true, since it only varies by
factors of less than order unity.
Second, let us write down the equation for photon conservation.
 This just says that the change in photon number density as we
move into the cloud is given by the rate at which collisions with H2
molecules remove photons:
dF∗
ν
dx = cdE∗
ν
dx = −nH2σH2,νcE∗
ν
(3.6)
In principle there should be a creation term at lower frequencies,
representing photons absorbed and re-emitted, but we are only interested
 in the higher LW frequencies, where there is only photon
removal. The term on the right hand side is just the photon absorption
 rate we calculated above.
Now we can integrate the equation (3.6) over frequency over the
chemistry and thermodynamics
55
LW band. Doing so and dividing by a factor of c gives
dE∗
dx = −
Z
nH2σH2,νE∗
ν dν,
(3.7)
where E∗is the frequency-integrated photon number density. If we
combine this equation with the chemical balance equation (3.5), we
obtain
dE∗
dx = −nHnR
c fdiss
(3.8)
This just says that the rate at which photons are taken out of the
beam is equal to the recombination rate, increased by a factor of
1/ fdiss because only ∼1 in 10 absorptions actually have to be balanced
 by a recombination.
If we make the further approximation that the transition from
atomic to molecular hydrogen is sharp, so that nH ≈n throughout
the atomic layer, and we assume that R does not vary with position,
then the equation is trivial to integrate. At any depth x inside the
slab,
E∗(x) = E∗
0 −n2R
c fdiss
x.
(3.9)
The transition to molecular hydrogen occurs where E∗reaches zero,
which is at xH2 = c fdissE∗
0/(n2R). The total column of atomic hydrogen
 is
NH = nxH2 = c fdissE∗
0
nR
(3.10)
It is helpful at this point to put in some numbers. In the Milky
Way, the observed interstellar UV field is E∗
0 = 7.5 × 10−4 LW photons
cm−3, and we can take n = 100 cm−3 as a typical number density
in a region where molecules might form. Plugging these in with
fdiss = 0.1 and R = 3 × 10−17 cm−3 s−1 gives NH = 7.5 × 1020 cm−2,
or in terms of mass, a column of Σ = 8.4 M⊙pc−2. More precise
calculations give numbers closer to 2 × 1020 cm−2 for the depth of
the shielding layer on one side of a GMC. (Of course a comparable
column is required on the other side, too.) Every molecular cloud
must be surrounded by an envelope of atomic gas with roughly this
column density.
This has important implications. First, this means that molecular
clouds with column densities of 100 M⊙pc−2 in molecules must have
∼10% of their total mass in the form of an atomic shield around
them. Second, it explains why most of the Milky Way’s ISM in the
Solar vicinity is not molecular. In the regions outside of molecular
clouds, the mean column density is a bit under 1021 cm−2, so the
required shielding column is comparable to the mean column density
of the entire atomic disk. Only when the gas clumps together can
molecular regions form. This also explains why other galaxies which
56
notes on star formation
have higher column densities also have higher molecular fractions. To
take an extreme example, the starburst galaxy Arp 220 has a surface
density of a few ×104 M⊙pc−2 in its nucleus, and the molecular
fraction there is at least 90%, probably more.
3.1.2
Carbon / Oxygen Chemistry
H2 is the dominant species in molecular regions, but it is very hard
to observe directly for the reasons discussed in Chapter 1 – the
temperatures are too low for it to be excited. Moreover, as we will
discuss shortly, H2 is also not the dominant coolant for the same
reason. Instead, that role falls to the CO molecule.
Why is CO so important? The main reason is abundances: the
most abundant elements in the universe after H and He are O, C,
and N, and CO is the simplest (and, under ISM conditions, most
energetically favorable) molecule that can be made from them. Moreover,
 CO can be excited at very low temperatures because its mass
is much greater than that of H2, and its dipole moment is weak but
non-zero. (A weak dipole moment lowers the energy of radiation
emitted, which in turn lowers the temperature needed for excitation.)
Just as in the bulk of the ISM, hydrogen is mostly H, in the bulk of
the ISM the oxygen is mostly O and the carbon is mostly C+. It is C+
rather than C because the ionization potential of carbon is less than
that of hydrogen, and as a result it tends to be ionized by starlight.
So how do we get from C+ and O to CO?
The formation of CO is substantially different than that of H2 in
that it is dominated by gas-phase rather than grain-surface reactions.
This is because there are no symmetric systems involved, and thus
no symmetry barriers to radiation. However, since the temperatures
in regions where CO is forming tend to be low, the key processes
involve ion-neutral reactions. These are important because the rate at
which they occur is to good approximation independent of temperature,
 while neutral-neutral reactions occur at a rate that declines with
temperature as roughly T1/2.2
2 These dependencies are relatively
easy to understand. For neutral-neutral
reactions, there are no long-distance
forces between particles, and thus the
rate of collisions is proportional to the
mean velocities of the particles involved,
which scales as T1/2. In contrast, for
ion-neutral reactions the ion induces
an electric dipole moment in the
neutral and then attracts it via Coulomb
forces. The slower the particles’ relative
velocities, the more important is this
electric attraction, and this effect cancels
out the lower overall rates of encounter
caused by lower particle velocities.
There are two main pathways to CO. One passes through the OH
molecule, and involves a reaction chain that looks like
H2 + CR
→
H+
2 + e−+ CR
(3.11)
H+
2 + H2
→
H+
3 + H
(3.12)
H+
3 + O
→
OH+ + H2
(3.13)
OH+ + H2
→
OH+
2 + H
(3.14)
OH+
2 + e−
→
OH + H
(3.15)
C+ + OH
→
CO+ + H
(3.16)
CO+ + H2
→
HCO+ + H
(3.17)
chemistry and thermodynamics
57
HCO+ + e−
→
CO + H.
(3.18)
Here CR indicates cosmic ray. There are also a number of possible
variants (e.g., the OH+
2 could form OH+
3 before proceeding to OH).
The second main route is through the CH molecule, where reaction
chains tend to follow the general pattern
C+ + H2
→
CH+
2 + hν
(3.19)
CH+
2 + e−
→
CH + H
(3.20)
CH + O
→
CO + H.
(3.21)
The rate at which the first reaction chain manufactures CO is limited
by the supply of cosmic rays that initiate the production of H+
2 , while
the rate at which the second reaction chain proceeds is limited by
the rate of the final neutral-neutral reaction. Which chain dominates
depends on the cosmic ray ionization rate, density, temperature, and
similar details. Note that both of these reaction chains require the
presence of H2.
CO is destroyed via radiative excitation followed by dissociation
in essentially the same manner as H2. The shielding process for CO
is slightly different however. As with H2, photons that dissociate CO
can be absorbed both by dust grains and by CO molecules. However,
 due to the much lower abundance of CO compared to H2, the
balance between these two processes is quite different than it is for
hydrogen, with dust shielding generally the more important of the
two. Moreover, there is non-trivial overlap between the resonance
lines of CO and those of H2, and thus there can be cross-shielding of
CO by H2.
At this point the problem is sufficiently complex that one generally
resorts to numerical modeling. The net result is that clouds tend to
have a layered structure. In poorly-shielded regions where the FUV
has not yet been attenuated, H i and C+ dominate. Further in, where
the FUV has been partly attenuated, H2 and C+ dominate. Finally a
transition to H2 and CO as the dominant chemical states occurs at
the center. For typical Milky Way conditions, the final transition to
a CO-dominated composition occurs once the V-band extinction AV
exceeds 1 −2 mag. This corresponds to a column density of a few
×1021 cm−2, or ∼20 M⊙pc−2, for Milky Way dust. In comparison,
recall that typical GMC column densities are ∼1022 cm−2, or ∼100
M⊙pc−2. This means that there is a layer of gas where the hydrogen
is mostly H2 and the carbon is still C+, but it constitutes no more
than a few tens of percent of the mass. However, in galaxies with
lower dust to gas ratios, the layer where H2 dominates but the carbon
is not yet mostly CO can be much larger.
58
notes on star formation
3.2
Thermodynamics of Molecular Gas
Having discussed the chemistry of molecular gas, we now turn to
the problem of its thermodynamics. What controls the temperature
of molecular gas? We have already seen that observations imply
temperatures that are extremely low, ∼10 K or even a bit less. How
are such cold temperatures achieved? To answer this question, we
must investigate what processes heat and cool the molecular ISM.
3.2.1
Heating Processes
The dominant heating process in the atomic ISM is the grain photoelectric
 effect: photons from stars with energies of ∼8 −13.6 eV hit
dust grains and eject fast electrons via the photoelectric effect. The
fast electrons then thermalize and deposit their energy at heat in the
gas. The rate per H nucleus at which this process deposits energy can
be written approximately as3
3 For a justification of this statement,
and a much more complete description
of the photoelectric heating process, see
a general interstellar medium textbook
such as Tielens (2005) or Draine (2011).
ΓPE ≈4.0 × 10−26χFUVZ′
de−τd erg s−1
(3.22)
where χFUV is the intensity of the far ultraviolet radiation field scaled
to its value in the Solar neighborhood, Z′
d is the dust abundance
scaled to the Solar neighborhood value, and τd is the dust optical
depth to FUV photons. The result is, not surprisingly, proportional
to the radiation field strength (and thus the number of photons
available for heating), the dust abundance (and thus the number of
targets for those photons), and the e−τd factor by which the radiation
field is attenuated.
At FUV wavelengths, typical dust opacities are κd ≈500 cm2 g−1,
so at a typical molecular cloud surface density Σ ≈50 −100 M⊙pc−2,
τd ≈5 −10, and thus e−τd ≈10−3. Thus in the interiors of molecular
clouds, photoelectric heating is strongly suppressed simply because
the FUV photons cannot get in. Typical photoelectric heating rates
are therefore of order a few ×10−29 erg s−1 per H atom deep in cloud
interiors, though they can obviously be much larger at cloud surfaces
or in regions with stronger radiation fields.
We must therefore consider another heating process: cosmic rays.
The great advantage of cosmic rays over FUV photons is that, because
they are relativistic particles, they have much lower interaction cross
sections, and thus are able to penetrate into regions where light
cannot. The process of cosmic ray heating works as follows. The first
step is the interaction of a cosmic ray with an electron, which knocks
the electron off a molecule:
CR + H2 →H+
2 + e−+ CR
(3.23)
chemistry and thermodynamics
59
The free electron’s energy depends only weakly on the CR’s energy,
and is typically ∼30 eV.
The electron cannot easily transfer its energy to other particles in
the gas directly, because its tiny mass guarantees that most collisions
are elastic and transfer no energy to the impacted particle. However,
the electron also has enough energy to ionize or dissociate other
hydrogen molecules, which provides an inelastic reaction that can
convert some of its 30 eV to heat. Secondary ionizations do indeed
occur, but in this case almost all the energy goes into ionizing the
molecule (15.4 eV), and the resulting electron has the same problem
as the first one: it cannot effectively transfer energy to the much more
massive protons.
Instead, there are a number of other channels that allow electrons
to dump their energy into motion of protons, and the problem is
deeply messy. The most up to date work on this is Glassgold et al.
(2012), and we can very briefly summarize it here. A free electron
can turn its energy into heat through three channels. The first is
dissociation heating, in which the electron strikes an H2 molecule
and dissociates it:
e−+ H2 →2H + e−.
(3.24)
In this reaction any excess energy in the electron beyond what is
needed to dissociate the molecule (4.5 eV) goes into kinetic energy
of the two recoiling hydrogen atoms, and the atoms, since they are
massive, can then efficiently share that energy with the rest of the gas.
A second pathway is that an electron can hit a hydrogen molecule
and excite it without dissociating it. The hydrogen molecule then
collides with another hydrogen molecule and collisionally de-excites,
and the excess energy again goes into recoil, where it is efficiently
shared. The reaction is
e−+ H2
→
H∗
2 + e−
(3.25)
H∗
2 + H2
→
2H2.
(3.26)
Finally, there is chemical heating, in which the H+
2 ion that is created
by the cosmic ray undergoes chemical reactions with other molecules
that release heat. There are a large number of possible exothermic
reaction chains, for example
H+
2 + H2
→
H+
3 + H
(3.27)
H+
3 + CO
→
HCO+ + H2
(3.28)
HCO+ + e−
→
CO + H.
(3.29)
Each of these reactions produces heavy ions recoiling at high speed
that can efficiently share their energy via collisions. Computing the
60
notes on star formation
total energy release requires summing over all these possible reaction
chains, which is why the problem is ugly. The final results is that
the energy yield per primary cosmic ray ionization is in the range
∼13 eV under typical molecular cloud conditions, but that it can be
several eV higher or lower depending on the local density, electron
abundance, and similar variables.
Combining this with the primary ionization rate for cosmic rays
in the Milky Way, which is observationally-estimated to be about
∼10−16 s−1 per H nucleus in molecular clouds, this gives a total
heating rate per H nucleus
ΓCR ∼2 × 10−27 erg s−1.
(3.30)
The heating rate per unit volume is ΓCRn, where n is the number density
 of H nuclei (= 2× the density of H molecules). This is sufficient
that, in the interiors of molecular clouds, it generally dominates over
the photoelectric heating rate.
3.2.2
Cooling Processes
In molecular clouds there are two main cooling processes: molecular
lines and dust radiation. Dust can cool the gas efficiently because
dust grains are solids, so they are thermal emitters. However, dust
is only able to cool the gas if collisions between dust grains and
hydrogen molecules occur often enough to keep them thermally
well-coupled. Otherwise the grains cool off, but the gas stays hot.
The density at which grains and gas become well-coupled is around
104 −105 cm−3, which is higher than the typical density in a GMC, so
we will not consider dust cooling further at this point. We will return
to it later in Chapter 16 when we discuss collapsing objects, where
the densities do get high enough for dust cooling to be important.
The remaining cooling process is line emission, and by far the
most important molecule for this purpose is CO, for the reasons
stated earlier. The physics is fairly simple. CO molecules are excited
by inelastic collisions with hydrogen molecules, and such collisions
convert kinetic energy to potential energy within the molecule. If the
molecule de-excites radiatively, and the resulting photon escapes the
cloud, the cloud loses energy and cools.
Let us make a rough attempt to compute the cooling rate via this
process. A diatomic molecule like CO can be excited rotationally,
vibrationally, or electronically. At the low temperatures found in
molecular clouds, usually only the rotational levels are important.
These are characterized by an angular momentum quantum number
J, and each level J has a single allowed radiative transition to level J −
1. Larger ∆J transitions are strongly suppressed because they require
chemistry and thermodynamics
61
emission of multiple photons to conserve angular momentum.
Unfortunately the CO cooling rate is quite difficult to calculate,
because the lower CO lines are all optically thick. A photon emitted
from a CO molecule in the J = 1 state is likely to be absorbed by
another one in the J = 0 state before it escapes the cloud, and if
this happens that emission just moves energy around within the
cloud and provides no net cooling. The cooling rate is therefore a
complicated function of position within the cloud – near the surface
the photons are much more likely to escape, so the cooling rate is
much higher than deep in the interior. The velocity dispersion of
the cloud also plays a role, since large velocity dispersions Doppler
shift the emission over a wider range of frequencies, reducing the
probability that any given photon will be resonantly re-absorbed
before escaping.
In practice this means that CO cooling rates usually have to be
computed numerically, and will depend on the cloud geometry if we
want accuracy to better than a factor of ∼2. However, we can get
a rough idea of the cooling rate from some general considerations.
The high J levels of CO are optically thin, since there are few CO
molecules in the J −1 state capable of absorbing them, so photons they
emit can escape from anywhere within the cloud. However, the temperatures
 required to excite these levels are generally high compared
to those found in molecular clouds, so there are few molecules in
them, and thus the line emission is weak. Moreover, the high J levels
also have high critical densities, so they tend to be sub-thermally
populated, further weakening the emission.
On other hand, low J levels of CO are the most highly populated,
and thus have the highest optical depths. Molecules in these levels
produce cooling only if they are within one optical depth the cloud
surface. Since this restricts cooling to a small fraction of the cloud
volume (typical CO optical depths are many tens for the 1 →0 line),
this strongly suppresses cooling.
The net effect of combining the suppression of low J transitions
by optical depth effects and of high J transitions by excitation effects
is that cooling tends to be dominated a single line produced by the
lowest J level for which the line is not optically thick. This line is
marginally optically thin, but is kept close to LTE by the interaction
of lower levels with the radiation field. Which line this is depends on
the column density and velocity dispersion of the cloud, but typical
peak J values in Milky Way-like galaxies range from J = 2 →1 to
J = 5 →4.
For an optically thin transition of a quantum rotor where the
population is in LTE, the rate of energy emission per H nucleus from
transitions between angular momentum quantum numbers J and J −1
62
notes on star formation
is given by
ΛJ,J−1
=
xem (2J + 1)e−EJ/kBT
Z(T)
AJ,J−1(EJ −EJ−1)
(3.31)
EJ
=
hBJ(J + 1)
(3.32)
AJ,J−1
=
512π4B3µ2
3hc3
J4
2J + 1.
(3.33)
Here xem is the abundance of the emitting species per H nucleus, T is
the gas temperature, Z(T) is the partition function, AJ,J−1 is the Einstein
 A coefficient from transitions from state J to state J −1, EJ is the
energy of state J, B is the rotation constant for the emitting molecule,
and µ is the electric dipole moment of the emitting molecule. The
first equation is simply the statement that the energy loss rate is
given by the abundance of emitters multiplied by the fraction of emitters
 in the J state in question times the spontaneous emission rate for
this state times the energy emitted per transition. Note that there is
no explicit density dependence as a result of our assumption that the
level with which we are concerned is in LTE. The latter two equations
are general results for quantum rotors.
The CO molecule has B = 57 GHz and µ = 0.112 Debye, and at
Solar metallicity its abundance in regions where CO dominates the
carbon budget is xCO ≈1.1 × 10−4. Plugging in these two values, and
evaluating for J in the range 2 −5, typical cooling rates are of order
10−27 −10−26 erg s−3 when the temperature is ∼10 K. This matches
the heating rate we computed above, and this is why the equilibrium
temperatures of molecular clouds are ∼10 K.
3.2.3
Implications
The calculation we have just performed has two critical implications
that strongly affect the dynamics of molecular clouds. First, the
temperature will be relatively insensitive to variations in the local
heating rate. The cosmic ray and photoelectric heating rates are
to good approximation temperature-independent, but the cooling
rate is extremely temperature sensitive because, for the dominant
cooling lines of CO have level energies are large compared to kBT.
Equation (3.31) would in fact seem to suggest that the cooling rate
is exponentially sensitive to temperature. In practice the sensitivity
is not quite that great, because which J dominates changes with
temperature. Nonetheless, numerical calculations still show that ΛCO
varies with T to a power of p ∼2 −3. This means that a factor f
increase in the local heating rate will only change the temperature by
a factor ∼f 1/p. Thus we expect molecular clouds to be pretty close
to isothermal, except near extremely strong local heating sources.
chemistry and thermodynamics
63
A second important point is the timescales involved. The gas
thermal energy per H nucleus is4
4 This equation is only approximate
because this neglects quantum mechanical
 effects that are of order unity at
these low temperatures. However, since
the result we are after here is an order
of magnitude one, we will not worry
about this corrections.
e ≈1
2
3
2kBT

= 10−15

T
10 K

erg
(3.34)
The factor of 1/2 comes from 2 H nuclei per H2 molecule. The characteristic
 cooling time is tcool = e/ΛCO. Suppose we have gas that
is mildly out of equilibrium, say T = 20 K instead of T = 10
K. The heating and cooling are far out of balance, so we can ignore
 heating completely compared to cooling. At a cooling rate
of ΛCO ∼few × 10−26 erg s−1 for 20 K gas (assuming the scaling
ΛCO ∝T2−3 as mentioned above), tcool ∼1 kyr. In contrast, the
crossing time for a molecular cloud is tcr = L/σ ∼10 Myr for L = 30
pc and σ = 3 km s−1. The conclusion of this analysis is that radiative
effects happen on time scales much shorter than mechanical ones. Gas
that is driven out of thermal equilibrium by any hydrodynamic effect
will return to its equilibrium temperature long before any mechanical
motions can take place. For this reason, gas in molecular clouds is
often approximated as isothermal.
4
Gas Flows and Turbulence
Suggested background reading:
• Krumholz, M. R. 2014, Phys. Rep.,
539, 49, section 3.3
Suggested literature:
• Federrath, C. 2013, MNRAS, 436,
1245
This chapter covers the physics of turbulence in the cold interstellar
medium. This will be something of a whirlwind tour, since turbulence
 is an entire research discipline unto itself. Our goal is to understand
 the basic statistical techniques used to describe and model
interstellar turbulence, so that we will be prepared to apply them in
the context of star formation.
4.1
Characteristic Numbers for Fluid Flow
4.1.1
The Conservation Equations
To understand the origins of turbulence, both in the ISM and more
generally, we start by examining the equations of fluid dynamics and
the characteristic numbers that they define. Although the ISM is magnetized,
 we will first start with the simpler case of an unmagnetized
fluid. Fluids are governed by a series of conservation laws. The most
basic one is conservation of mass:
∂
∂tρ = −∇· (ρv).
(4.1)
This equation asserts that the change in mass density at a fixed point
is equal to minus the divergence of density times velocity at that
point. Physically, this is very intuitive: density at a point changes at a
rate that is simply equal to the rate at which mass flows into or out of
an infinitesimal volume around that point.
We can write a similar equation for conservation of momentum:
∂
∂t(ρv) = −∇· (ρvv) −∇P + ρν∇2v.
(4.2)
Note that the term vv here is a tensor product. This is perhaps more
clear if we write things out in index notation:
∂
∂t(ρvi) = −∂
∂xj
(ρvivj) −∂
∂xi
P + ρν ∂
∂xj

∂
∂xj
vi
!
(4.3)
66
notes on star formation
The intuitive meaning of this equation can be understood by examining
 the terms one by one. The term ρv is the density of momentum at
a point. The term ∇· (ρvv) is, in analogy to the equivalent term in the
conservation of mass equation, the rate at which momentum is advected
 into or out of that point by the flow. The term ∇P is the rate
at which pressure forces acting on the fluid change its momentum. Finally,
 the last term, ρν∇2v, is the rate at which viscosity redistributes
momentum; the quantity ν is called the kinematic viscosity.
The last term, the viscosity one, requires a bit more discussion. All
the other terms in the momentum equation are completely analogous
to Newton’s second law for single particles. The viscous term, on
the other hand, is unique to fluids, and does not have an analog for
single particles. It describes the change in fluid momentum due to
the diffusion of momentum from adjacent fluid elements. We can
understand this intuitively: a fluid is composed of particles moving
with random velocities in addition to their overall coherent velocity.
If we pick a particular fluid element to follow, we will notice that
these random velocities cause some of the particles that make it up
to diffuse across its boundary to the neighboring element, and some
particles from the neighboring element to diffuse into the one we
are following. The particles that wander across the boundaries of
our fluid element carry momentum with them, and this changes
the momentum of the element we are following. The result is that
momentum diffuses across the fluid, and this momentum diffusion is
called viscosity.
Viscosity is interesting and important because it’s the only term
in the equation that converts coherent, bulk motion into random,
disordered motion. That is to say, the viscosity term is the only one
that is dissipative, or that causes the fluid entropy to change.
4.1.2
The Reynolds Number and the Mach Number
To understand the relative importance of terms in the momentum
equation, it is helpful to make order of magnitude estimates of
their sizes. Let us consider a system of characteristic size L and
characteristic velocity V; for a molecular cloud, we might have L ∼10
pc and V ∼5 km s−1. The natural time scale for flows in the system
is L/V, so we expect time derivative terms to be of order the thing
being differentiated divided by L/V. Similarly, the natural length
scale for spatial derivatives is L, so we expect spatial derivative
terms to be order the quantity being differentiated divided by L. If
we apply these scalings to the momentum equation, we expect the
gas flows and turbulence
67
various terms to scale as follows:
ρV2
L
∼ρV2
L
+ ρc2
s
L + ρν V
L2 ,
(4.4)
where cs is the gas sound speed, and we have written the pressure as
P = ρc2
s. Canceling the common factors, we get
1 ∼1 + c2
s
V2 + ν
VL.
(4.5)
From this exercise, we can derive two dimensionless numbers that
are going to control the behavior of the equation. We define the Mach
number and the Reynolds number as
M
∼
V
cs
(4.6)
Re
∼
LV
ν .
(4.7)
The meanings of these dimensionless numbers are fairly clear from
the equations. If M ≪1, then c2
s/V2 ≫1, and this means that the
pressure term is important in determining how the fluid evolves. In
contrast, if M ≫1, then the pressure term is unimportant for the
behavior of the fluid. In a molecular cloud,
cs =
s
kBT
µmH
= 0.18
 T
10 K
1/2
km s−1,
(4.8)
where µ = 2.33 is the mean mass per particle in a gas composed of
molecular hydrogen and helium in the usual cosmic abundance ratio
of 1 He per 10 H atoms. Thus M = V/cs ∼20, and we learn that
pressure forces are unimportant.
The Reynolds number is a measure of how important viscous
forces are. Viscous forces are significant for Re ∼1 or less, and are
unimportant of Re ≫1. We can think of the Reynolds number as
describing a characteristic length scale L ∼ν/V in the flow. This
is the length scale on which diffusion causes the flow to dissipate
energy. Larger scale motions are effectively dissipationless, while
smaller scales ones are damped out by viscosity.
To estimate the Reynolds number in the molecular ISM, we
must know its viscosity. For an ideal gas, the kinematic viscosity
is ν = 2uλ, where u is the RMS molecular speed (which is of order
 cs) and λ is the particle mean free-path. The mean free path is
of order the inverse of cross-section times density, λ ∼1/(σn) ∼
[(1 nm)2(100 cm−3)]−1 ∼1012 cm. Plugging this in then gives
ν ∼1016 cm2 s−1 and Re ∼109. Viscous forces are clearly unimportant
 in molecular clouds.
68
notes on star formation
The extremely large value of the Reynolds number immediately
yields a critical conclusion: molecular clouds must be highly turbulent,
 because flows with Re of more than ∼103 −104 invariably are.
Figure 4.1 illustrates this graphically from laboratory experiments.
Re#=#0.05#
Re#=#10#
Re#=#200#
Re#=#3000#
Flows#at#different#Reynolds#number,#from#the#NSF#fluid#
dynamics#film#series#
Figure 4.1: Flows at varying Reynolds
number Re. In each panel, a fluid that
has been dyed red is injected from the
top into the clear fluid on the bottom.
The fluids are a glycerin-water mixture,
for which the viscosity can be changed
by altering the glycerin to water ratio.
By changing the viscosity and the
injection speed, it is possible to alter the
Reynolds number of the injected flow.
The frames show how the flow develops
as the Reynolds number is varied.
This image is a still from the National
Committee for Fluid Mechanics Film
Series (Taylor, 1964), which, once you
get past the distinctly 1960s production
values, are a wonderful resource for
everything related to fluids.
4.2
Modeling Turbulence
We have remarkably little understanding of how turbulence actually
works. However, we have developed some simple models and tools
to describe it, and we will next explore those.
4.2.1
Velocity Statistics
One quantity of interest in a turbulent medium is the structure of the
velocity field. How does the velocity change from point to point? In
a turbulent medium velocity fluctuates in time and space, and so the
best way to proceed is to study those fluctuations statistically. Many
statistical tools exist to characterize turbulent motions, and many are
used in astrophysics, but we will stick to a few of the simpler ones.
We will also make two simplifying assumptions. First we assume
that the turbulence is homogenous, in the sense that the turbulent
motions vary randomly but not systematically, with position in
the fluid. Second, we assume that it is isotropic, so that turbulent
motions do not have a preferred directions. Neither of these are likely
to be strictly true in a molecular cloud, particularly the second, since
large-scale magnetic fields provide a preferred direction, but we will
gas flows and turbulence
69
start with these assumptions and relax them later.
Let v(x) be the velocity at position x within some volume of interest
 V. To characterize how this varies with position, we define the
autocorrelation function
A(r) ≡1
V
Z
v(x) · v(x + r) dx ≡⟨v(x) · v(x + r)⟩,
(4.9)
where the angle brackets indicate an average over all positions x.
Here, A(0) = ⟨|v|2⟩is just the mean square velocity in the fluid. If
the velocity field is isotropic, then clearly A(r) cannot depend on the
direction, and thus must depend only on r = |r|. Thus A(r) tells us
how similar or different the velocities are at points separated by some
distance r.
It is often more convenient to think about this in Fourier space
than in real space, so rather than the autocorrelation function we
often instead think about its Fourier transform. We define the Fourier
transform of the velocity field in the usual way, i.e.,
˜
v(k) =
1
(2π)3/2
Z
v(x)e−ik·x dx.
(4.10)
We then define the power spectrum
Ψ(k) ≡|˜
v(k)|2.
(4.11)
Again, for isotropic turbulence, the power spectrum depends only
on the magnitude of the wave number, k = |k|, not its direction, so it
is more common to talk about the power per unit radius in k-space,
P(k) = 4πk2Ψ(k).
(4.12)
This is just the total power integrated over some shell from k to k + dk
in k-space. Note that Parseval’s theorem tells us that
Z
P(k) dk =
Z
|˜
v(k)|2 dk =
Z
v(x)2 dx,
(4.13)
i.e., the integral of the power spectral density over all wavenumbers
is equal to the integral of the square of the velocity over all space, so
for a flow with constant density (an incompressible flow) the integral
of the power spectrum just tells us how much kinetic energy per unit
mass there is in the flow. The Wiener-Khinchin theorem also tells us
that P(k) is just the Fourier transform of the autocorrelation function,
Ψ(k) =
1
(2π)3/2
Z
A(r)e−ik·r dr.
(4.14)
The power spectrum at a wavenumber k then just tells us what
fraction of the total power is in motions at that wavenumber, i.e., on
70
notes on star formation
that characteristic length scale. The power spectrum is another way
of looking at the spatial scaling of turbulence. It tells us how much
power there is in turbulent motions as a function of wavenumber k =
2π/λ. A power spectrum that peaks at low k means that most of the
turbulent power is in large-scale motions, since small k corresponds
to large λ. Conversely, a power spectrum that peaks at high k means
that most of the power is in small-scale motions.
The power spectrum also tells us about the how the velocity
dispersion will vary when it is measured over a region of some
characteristic size. Suppose we consider a volume of size ℓ, and
measure the velocity dispersion σv(ℓ) within it. Further suppose that
the power spectrum is described by a power law P(k) ∝k−n. The
total kinetic energy per unit mass within the region is, up to factors
of order unity,
KE ∼σv(ℓ)2,
(4.15)
but we can also write the kinetic energy per unit mass in terms of the
power spectrum, integrating over those modes that are small enough
to fit within the volume under consideration:
KE ∼
Z ∞
2π/ℓP(k) dk ∝ℓn−1.
(4.16)
It therefore follows immediately that
σv = cs
 ℓ
ℓs
(n−1)/2
,
(4.17)
where we have normalized the relationship by defining the sonic
scale ℓs as the size of a region within which the velocity dispersion is
equal to the thermal sound speed of the gas.
4.2.2
The Kolmogorov Model and Turbulent Cascades
The closest thing we have to a model of turbulence is in the case of
subsonic, hydrodynamic turbulence; the basic theory for that goes
back to Kolmogorov (1941).1 Real interstellar clouds are neither sub1
 An English translation of Kolmogorov
(1941) (which is in Russian) can be
found in Kolmogorov (1991).
sonic nor hydrodynamic (since they are strongly magnetized, as we
discuss in Chapter 5), but this theory is still useful for understanding
how turbulence works. Kolmogorov’s theory of turbulence begins
with the realization that turbulence is a phenomenon that occurs
when Re is large, so that there is a large range of scales where dissipation
 is unimportant. It is possible to show by Fourier transforming
Equation (4.2) that for incompressible motion transfer of energy can
only occur between adjacent wavenumbers. Energy at a length scale
k cannot be transferred directly to some scale k′ ≪k. Instead, it must
cascade through intermediate scales between k and k′.
gas flows and turbulence
71
This gives a simple picture of how energy dissipates in fluids.
Energy is injected into a system on some large scale that is dissipationless,
 and it cascades down to smaller scales until it reaches a
small enough scale that Re ∼1, at which point dissipation becomes
significant. In this picture, if the turbulence is in statistical equilibrium,
 such that is neither getting stronger or weaker, the energy at
some scale k should depend only on k and on the rate of injection or
dissipation (which are equal) ψ.
This allows us to make the following clever dimensional argument:
k has units of 1/L, i.e., one over length. The power spectrum P(k) has
units of energy per unit mass per unit radius in k-space. The energy
per unit mass is like a velocity squared, so it has units L2/T2, and
this is divided by k, so P(k) has units of L3/T2. The injection and
dissipation rates ψ have units of energy per unit mass per unit time,
which is a velocity squared divided by a time, or L2/T3.
Since P(k) is a function only of k and ψ, we can write P(k) =
Ckαψβ for some dimensionless constant C. Then by dimensional
analysis we have
L3
T2
∼
L−α
 L2
T3
β
(4.18)
L3
∼
L−α+2β
(4.19)
T−2
∼
T−3β
(4.20)
β
=
2
3
(4.21)
α
=
2β −3 = −5
3
(4.22)
This immediately tell us three critical things. First, the power in
the flow varies with energy injection rate to the 2/3 power. Second,
this power is distributed such that the power at a given wavenumber
k varies as k−5/3. This means that most of the power is in the largest
scale motions, since power diminishes as k increases. Third, if we
now take this spectral slope and use it to derive the scale-dependent
velocity dispersion from equation (4.17), we find that σv ∝ℓ1/3, i.e.,
velocity dispersion increase with size scale as size to the 1/3 power.
This is an example of what is known in observational astronomy
as a linewidth-size relation – linewidth because the observational
diagnostic we use to characterize velocity dispersion is the width of a
line. This relationship tells us that larger regions should have larger
linewidths, with the linewidth scaling as the 1/3 power of size in the
subsonic regime.
The subsonic regime can be tested experimentally on Earth, and
Kolmogorov’s model provides an excellent fit to observations. Figure
4.2 shows one example.
72
notes on star formation
FIGURE
14. One-dimensional energy spectra of the velocity-component fluctuations in the
R, = 182 wake flow. 0.
u1
spectrum, F,(k,); 0 ,
u2
spectrum, F,(k,); A,
u3
spectrum, F3(kl).
t = f
I
I
I
I
I
 I
I L I I I
I
I
l
l
1

I
I
l
l
 I
I
l
l

I 0
5

Io6 1;
FIGURE
15. One-dimensional spectra of streamwise- and lateral-component
velocity fluctuations
for an nxisymmetric jet; Re = 3.7 x 106, x/d = 70,
r/d = 0. 0,
Fl(kJ;
0 ,
F2(kl).
Figure 4.2: An experimentallymeasured
 power spectrum for turbulence
 generated by an air jet. The x
axis is the wavenumber, and the open
and filled points show the velocity
power spectrum for the velocity components
 parallel and transverse to the
stream, respectively. Credit: Champagne,
 J. Fluid. Mech., 86, 67-108, 1978,
reproduced with permission.
gas flows and turbulence
73
4.3
Supersonic Turbulence
4.3.1
Velocity Statistics
We have seen that real interstellar clouds not only have Re ≫1, they
also have M ≫1, and so the flows within them are supersonic. This
means that pressure is unimportant on size scales L ≫ℓs. Since
viscosity is also unimportant on large scales (since Re ≫1), this
means that gas tends to move ballistically on large scales. On small
scales this will produce very sharp gradients in velocity, since fastmoving
 volumes of fluid will simply overtake slower ones. Since the
viscosity term gets more important on smaller scales, the viscosity
term will eventually stop the fluid from moving ballistically. In
practice this means the formation of shocks – regions where the
flow velocity changes very rapidly, on a size scale determined by the
viscosity.2
2 In real interstellar clouds the relevant
viscosity is the magnetic one, as we
shall see in Chapter 5.
We expect that the velocity field that results in this case will look
like a series of step functions. The power spectrum of a step function
is a power law P(k) ∝k−2. One can establish this easily from direct
calculation. Let us zoom in on the region around a shock, so that the
change in velocity on either side of the shock is small. The Fourier
transform of v in 1D is
˜
v(k) =
1
√
2π
Z
v(x)e−ikx dx
(4.23)
The integral of the periodic function e−ikx vanishes for all periods
in the regions where v is constant. It is non-zero only in the period
that includes the shock. The amplitude of R
v(x)e−ikx dx during that
period is simply proportional to the length of the period, i.e., to 1/k.
Thus, ˜
v(k) ∝1/k. It then follows that P(k) ∝k−2 for a single shock.
An isotropic system of overlapping shocks should therefore also look
approximately like a power law of similar slope. This gives a velocity
dispersion versus size scale σv ∝ℓ1/2, and this is exactly what is
observed. Figure 4.3 shows an example.
310
V. Ossenkopf and M.-M. Mac Low: Turbulent velocity structure in molec
Fig. 1. Size-linewidth relation for the Polaris Flare CO observations
with IRAM (smallest scales), KOSMA, and the CfA 1.2 m telescope
(largest scale, see Bensch et al. (2001a) for details). The diamonds
show the relation when the linewidth for a given scale is integrated
from the total linewidths at each point. The triangles represent the
widths when only the dispersions of the centroids of the lines are measured.
 The error bars do not represent true local errors but the two
extreme cases of the line windowing as discussed in Sect. 2.2.
exactly with the KOSMA result. Thus the shift is probably also
influenced by the different noise behaviour.
For the size-linewidth relation based on the velocity centroids,
 we find one power law stretching over three orders of
magnitude connecting the three different maps. The average velocity
 variances range from below the thermal linewidth up to
about 1 km s−1. The common slope is given by γ = 0.50±0.04.
However, the data are also consistent with a reduction of the
slope down to 0.24 at the largest scales, if the full extent of the
error bars is taken into account.
In the size-linewidth relationship integrated from the full
local linewidths, there is a transition of the slope from almost
zero at scales below 10′ to 0.2 at the full size of the flare. The
plot shows that the total linewidths are dominated by the lineof-sight
 integration up to the largest scales.
Although the slopes measured with this method are very
shallow, they do appear to show the change of slope interpreted
by Goodman et al. (1998) as a transition to coherent behaviour
below about 0.5 pc. As the findings of Goodman et al. are
also based on the total linewidths this suggests that the change
might rather reflect the transition from a regime where single
separated clumps are identified, to measurements of a superposition
 of substructures at smaller scales.
3.2. Velocity probability distribution function
Another quantity characterising the velocity structure both in
observational data and in turbulence simulations is the probability
 distribution function (PDF) of velocities. Although it
contains no information on the spatial correlation in velocit

lik th
i
li
idth
l ti
th ∆
i
it
The shape of the wings o
diagnostic of intermittency
termittency produces a tra
tial wings. Two-dimension
Chappell & Scalo (1999),
Gaussian velocity PDFs fo
exponential wings for mod
Due to the limited am
molecular lines, there is n
PDF from observations. O
PDFs is computation of th
ties (Kleiner & Dickmann
et al. 1999). This method
on spatial correlation as d
higher moments of the ce
observational restrictions d
Another method was
(1990), who estimated velo
observations of single line
moments of profiles, Falg
Gaussian behaviour for m
comparison with three-dim
lations. Most of their PDF
sition of two Gaussians w
three times the width of
their method is only reliab
very high signal to noise.
with the centroid velocity
3.2.1. Centroid velocity
In computing the centroid
ther assign the same weigh
the different contributions
point. We find that the PD
wing behaviour with both
sity weighting in the follow
by observational noise. W
here, instead of the more s
applied by Miesch et al. (
from the uncertainty abou
the influence of the numer
Figure 2 shows the cen
sets. We find that the IRAM
by an asymmetry of the v
kind of large-scale flow w
the wings of the distributi
consistent with a Gaussian
in the lin-log plots shown
a definite conclusion not p
Beyond this phenome
PDFs can be quantified by
frequently used moments
⟨vc⟩=
! ∞
−∞
dvcP(vc)vc
Figure 4.3: Linewidth versus size in
the Polaris Flare Cloud obtained from
CO observations. Diamonds show
the total measured velocity width
within apertures of the size indicated
on the x axis, while triangles show
the dispersion obtained by taking the
centroid velocity in each pixel and
measuring the dispersion of centroids.
The three sets of points joined by lines
represent measurements from three
separate telescopes. Credit: Ossenkopf
& Mac Low, A&A, 390, 307, 2002,
reproduced by permission © ESO.
Note that, although the power spectrum is only slightly different
than that of subsonic turbulence (−2 versus about −5/3), there is
really an important fundamental difference between the two regimes.
Most basically, in Kolmogorov turbulence decay of energy happens
via a cascade from large to small scales, until a dissipative scale is
reached. In the supersonic case, on the other hand, the decay of
energy is via the formation of shocks, and as we have just seen a
single shock generates a power spectrum ∝k−2, i.e., it non-locally
couples many scales. Thus, in supersonic turbulence there is no
locality in k-space. All scales are coupled at shocks.
74
notes on star formation
4.3.2
Density Statistics
In subsonic flows the pressure force is dominant. Thus if the gas
is isothermal, then the density stays nearly constant – any density
inhomogeneities are ironed out immediately by the strong pressure
forces. In supersonic turbulence, on the other hand, the flow is highly
compressible. It is therefore of great interest to ask about the statistics
of the density field.
Numerical experiments and empirical arguments (but not fully
rigorous proofs) indicate that the density field for a supersonicallyturbulent,
 isothermal medium is well-described by a lognormal
distribution,
p(s) =
1
p
2πσ2
s
exp

−(s −s0)2
2σ2
s

,
(4.24)
where s = ln(ρ/ρ) is the log of the density normalized to the mean
density ρ. This distribution describes the probability that the density
at a randomly chosen point will be such that ln(ρ/ρ) is in the range
from s to s + ds. The median of the distribution s0 and the dispersion
σs must be related to one another, because we require that
ρ =
Z
p(s)ρ ds.
(4.25)
With a bit of algebra, one can show that this equation is satisfied if
and only if
s0 = −σ2
s /2.
(4.26)
Instead of computing the probability that a randomly chosen
point in space will have a particular density, we can also compute
the probability that a randomly chosen mass element will have a
particular density. This more or less amounts to a simple change of
variables. Consider some volume of interest V, and examine all the
material with density such that ln(ρ/ρ) is in the range from s to s + ds.
This material occupies a volume dV = p(s)V, and thus must have a
mass
dM
=
ρp(s) dV
(4.27)
=
ρes ·
1
p
2πσ2
s
exp

−(s −s0)2
2σ2
s

dV
(4.28)
=
ρ
1
p
2πσ2
s
exp

−(s + s0)2
2σ2
s

dV
(4.29)
It immediately follows that the mass PDF is simply
pM(s) =
1
p
2πσ2
s
exp

−(s + s0)2
2σ2
s

,
(4.30)
i.e., exactly the same as the volume PDF but with the peak moved
from −s0 to +s0. Physically, the meaning of these shifts is that the
gas flows and turbulence
75
typical volume element in a supersonic turbulent field is at a density
lower than the mean, because much of the mass is collected into
shocks. The typical mass element lives in one of these shocked
regions, and thus is at higher-than-average density. Figure 4.4 shows
an example of the density distribution produced in a numerical
simulation of supersonic turbulence.
FIG. 8c
FIG. 8d
Figure 4.4: Volume rendering of the
density field in a simulation of supersonic
 turbulence. The surfaces
shown are isosurfaces of density. Credit:
Padoan & Nordlund (1999), © AAS.
Reproduced with permission.
The lognormal functional form is not too surprising, given the central
 limit theorem. Supersonic turbulence consists of an alternating
series of shocks, which cause the density to be multiplied by some
factor, and supersonic rarefactions, which cause it to drop by some
factor. The result of multiplying a lot of positive density increases
by a lot of negative density drops at random tends to produce a normal
 distribution in the multiplicative factor, and thus a lognormal
distribution in the density.
This argument does not, however, tell us about the dispersion of
densities, which must be determined empirically from numerical
simulations. The general result of these simulations (e.g., Federrath,
2013) is that
σ2
s ≈ln

1 + b2M2
β0
β0 + 1

,
(4.31)
where the factor b is a number in the range 1/3 −1 that depends
on how compressive versus solenoidal the velocity field is, and β0
is the ratio of thermal to magnetic pressure at the mean density and
magnetic field strength, something we will discuss further in Chapter
5.
In addition to the density PDF, there are higher order statistics
describing correlations of the density field from point to point. We
will defer a discussion of these until we get to models of the IMF in
Chapter 13, where they play a major role.
Problem Set 1
1. Molecular Tracers.
Here we will derive a definition of the critical density, and use
it to compute some critical densities for important molecular
transitions. For the purposes of this problem, you will need to
know some basic parameters (such as energy levels and Einstein
coefficients) of common interstellar molecules. You can obtain
these from the Leiden Atomic and Molecular Database (LAMDA,
http://www.strw.leidenuniv.nl/~moldata). It is also worth taking
 a quick look through the associated paper (Schöier et al.,
2005)3 so you get a feel for where these numbers come from.
3 Schöier et. al, 2005, A&A, 432, 369
(a) Consider an excited state i of some molecule, and let Aij
and kij be the Einstein A coefficient and the collision rate, respectively,
 for transitions from state i to state j. Write down
expressions for the rates of spontaneous radiative and collisional
 de-excitations out of state i in a gas where the number
density of collision partners is n.
(b) We define the critical density ncrit of a state as the density for
which the spontaneous radiative and collisional de-excitation
rates are equal.4 Using your answer to the previous part, derive
4 There is some ambiguity in this
definition. Some people define the
critical density as the density for which
the rate of radiative de-excitation equals
the rate of all collisional transitions out
of a state, not just the rate of collisional
de-excitations out of it. In practice this
usually makes little difference.
an expression for ncrit in terms of the Einstein coefficient and
collision rates for the state.
(c) When a state has a single downward transition that is far more
common than any other one, as is the case for example for the
rotational excitation levels of CO, it is common to refer to the
critical density of the upper state of the transition as the critical
density of the line. Compute critical densities for the following
lines: CO J = 1 →0, CO J = 3 →2, CO J = 5 →4, and
HCN J = 1 →0, using H2 as a collision partner. Perform your
calculation for the most common isotopes: 12C, 16O, and 14N.
Assume the gas temperature is 10 K, the H2 molecules are all
para-H2, and neglect hyperfine splitting.
(d) Consider a molecular cloud in which the volume-averaged
density is n = 100 cm−3. Assuming the cloud has a lognor78

notes on star formation
mal density distribution as given by equation (4.24), with a
dispersion σ2
s = 5.0, compute the fraction of the cloud mass
that is denser than the critical density for each of these transitions.
 Which transitions are good tracers of the bulk of the
mass in a cloud? Which are good tracers of the denser, and thus
presumably more actively star-forming, parts of the cloud?
2. Infrared Luminosity as a Star Formation Rate Tracer.
We use a variety of indirect indicators to measure the star formation
 rate in galaxies, and one of the most common is to measure
 the galaxy’s infrared luminosity. The underlying assumptions
 behind this method are that (1) most of the total radiant
output in the galaxy comes from young, recently formed stars,
and (2) that in a sufficiently dusty galaxy most of the starlight
will be absorbed by dust grains within the galaxy and then reradiated
 in the infrared. We will explore how well this conversion
works using the popular stellar population synthesis package
Starburst99 (Leitherer et al., 1999; Vázquez & Leitherer, 2005),
http://www.stsci.edu/science/starburst99/.
(a) Once you have read enough of the papers to figure out what
Starburst99 does, use it with the default parameters to compute
the total luminosity of a stellar population in which star formation
 occurs continuously at a fixed rate ˙
M∗. What is the ratio of
Ltot/ ˙
M∗after 10 Myr? After 100 Myr? After 1 Gyr? Compare
these ratios to the conversion factor between LTIR and ˙
M∗given
in Table 1 of Kennicutt & Evans (2012)5.
5 Kennicutt & Evans, 2012, ARA&A, 50,
531
(b) Plot Ltot/ ˙
M∗as a function of time for this population. Based
on this plot, how old does a stellar population have to be before
LTIR becomes a good tracer of the total star formation rate?
(c) Try making the IMF slightly top-heavy, by removing all stars
below 0.5 M⊙. How much does the luminosity change for a
fixed star formation rate? What do you infer from this about
how sensitive this technique is to assumptions about the form of
the IMF?
5
Magnetic Fields and Magnetized Turbulence
Suggested background reading:
• Crutcher, R. M. 2012, ARA&A, 50, 29
Suggested literature:
• Li, P. S., McKee, C. F., Klein, R. I., &
Fisher, R. T. 2008, ApJ, 684, 380
In our treatment of fluid flow and turbulence in Chapter 4, we concentrated
 on the hydrodynamic case. However, real star-forming
clouds are highly magnetized. We therefore devote this chapter to the
question of how magnetic fields change the nature of molecular cloud
fluid flow.
5.1
Observing Magnetic Fields
5.1.1
Zeeman Measurements
We begin by reviewing the observational evidence for the existence
and strength of magnetic fields in interstellar clouds. There are
several methods that can be used to measure magnetic fields, but
the most direct is the Zeeman effect. The Zeeman effect is a slight
shift in the energy levels of an atom or molecule in the presence of
a magnetic field. Ordinarily the energies of a level depend only the
direction of the electron spin relative to its orbital angular momentum
 vector, not on the direction of the net angular momentum vector.
However, in the presence of an external magnetic field, states with
different orientations of the net angular momentum vector of the
atom have slightly different energies due to the interaction of the
electron magnetic moment with the external field. This causes levels
that are normally degenerate to split apart slightly in energy. As a
result, transitions into or out of these levels, which would normally
produce a single spectral line, instead produce a series of separate
lines at slightly different frequencies.
For the molecules with which we are concerned, the level is normally
 split into three sublevels – one at slightly higher frequency
than the unperturbed line, one at slightly lower frequency, and one at
the same frequency. The strength of this splitting varies depending
on the electronic configuration of the atom or molecule in question.
For OH, for example, the splitting is Z = 0.98 Hz/µG, where the pa80

notes on star formation
rameter Z is called the Zeeman sensitivity, and the shift is ∆ν = BZ,
where B is the magnetic field strength. Zeeman measurements target
molecules where Z is as large as possible, and these are generally
molecules or atoms that have an unpaired electron in their outer shell.
Examples include atomic hydrogen, OH, CN, CH, CCS, SO, and O2.
Figure 5.1: Sample Zeeman detection
of an interstellar magnetic field using
the CN line in the region DR21(OH).
The top panel shows the observed
total intensity (Stokes I, red lines),
which is well-fit by two different
velocity components (blue lines).
The CN molecule has 7 hyperfine
components, of which 4 have a large
Zeeman splitting and 3 have a small
splitting. The middle panel shows
the measured Stokes V (circularly
polarized emission) for the sum of
the 4 strong splitting components,
while the bottom panel shows the
corresponding measurement for the 3
weak components. The smooth lines
show the best fit, with the line of sight
magnetic field as the fitting parameter.
Credit: Crutcher et al. (1999), ©AAS.
Reproduced with permission.
Zeeman splitting is not trivial to to measure due to Doppler broadening.
 To see why, consider the example of OH. The Doppler width
of a line is σν = ν0(σv/c), where for the OH transition that is normally
 used for Zeeman measurements ν0 = 1.667 GHz. If the OH
molecule has a velocity dispersion of order 0.1 km s−1, as expected
even for the lowest observed velocity dispersions found on small
scales in molecular clouds, then (σv/c) ∼10−6, so σν ∼1 kHz. This
means that, unless the field is considerably larger than 1000 µG (1
mG), which it usually is not, the Zeeman splitting is smaller than
the Doppler line width. Thus the split lines are highly blended, and
cannot be seen directly in the spectrum.
However, there is a trick to avoid this problem: radiation from the
different Zeeman sublevels has different polarization. If the magnetic
field is along the direction of propagation of the radiation, emission
from the higher frequency Zeeman sublevel is right circularly polarized,
 while radiation from the lower frequency level is left circularly
polarized. The unperturbed level is unpolarized. Thus although one
cannot see the line split if one looks at total intensity (as measured
by the Stokes I parameter), one can see that the different polarization
components peak at slightly different frequencies, so that the circularly
 polarized spectrum (as measured by the Stokes V parameter)
looks different than the total intensity spectrum. One can deduce the
magnetic field strength along the line of sight from the difference
between the total and polarized signals. Figure 5.1 shows a sample
detection.
Applying this technique to line emission from molecular clouds
indicates that they are threaded by magnetic fields whose strengths
range from tens to thousands of µG, with higher density gas generally
 showing stronger fields. We can attempt to determine if this
is dynamically important by a simple energy argument. For a lowdensity
 envelope of a GMC with n ∼100 cm−3 (ρ ∼10−22 g cm−3),
we might have v of a few km s−1, giving a kinetic energy density
eK = 1
2ρv2 ∼10−11 erg cm−3.
(5.1)
For the magnetic field of 20 µG, typical of molecular clouds on large
scales, the energy density is
eB = B2
8π ∼10−11 erg cm−3.
(5.2)
magnetic fields and magnetized turbulence
81
Thus the magnetic energy density is comparable to the kinetic energy
density, and is dynamically significant in the flow.
5.1.2
The Chandrasekhar-Fermi Method
While the Zeeman effect provides by far the most direct method
of measuring magnetic field strengths, it is not the only method
for making this measurement. Another commonly-used technique,
which we will not discuss in any detail, is the Chandrasekhar-Fermi
method (Chandrasekhar & Fermi, 1953). This method relies on the
fact that interstellar dust grains are non-spherical, which has two
important implications. First, a non-spherical grain acts like an
antenna, in that it interacts differently with electromagnetic waves
that are oriented parallel and perpendicular to its long axis. As a
result, grains both absorb and emit light preferentially along their
long axis. This would not matter if the orientations of grains in
the interstellar medium were random. However, there is a second
effect. Most grains are charged, and as a result they tend to become
preferentially aligned with the local magnetic field. The combination
of these two effects means that the dust in a particular region of
the ISM characterized by a particular large scale magnetic field will
produce a net linear polarization in both the light it emits and any
light passing through it. The direction of the polarization then reveals
the orientation of the magnetic field on the plane of the sky.
By itself this effect tells us nothing about the strength of the field –
in principle there should be some relationship between field strength
and degree of dust polarization, but there are enough other compounding
 factors and uncertainties that we cannot with any confidence
 translate the observed degree of polarization into a field
strength. However, if we have measurements of the field orientation
as a function of position, then we can estimate the field strength from
the morphology of the field. As we shall see below, the degree to
which field lines are straight or bent is strongly correlated with the
ratio of magnetic energy density to turbulent energy density, and so
the degree of alignment becomes a diagnostic of this ratio. In fact,
one can even attempt to make quantitative field strength estimates
from this method, albeit with very large uncertainties.
5.2
Equations and Characteristic Numbers for Magnetized Turbulence

Now that we know that magnetic fields are present, we now turn to
some basic theory for magnetized flow. To understand how magnetic
fields affect the flows in molecular clouds, it is helpful to write
82
notes on star formation
down the fundamental evolution equation for the magnetic field in a
plasma, known as the induction equation1
1 One may find a derivation of this
result in many sources. The notation we
use here is taken from Shu (1992).
∂B
∂t + ∇× (B × v) = −∇× (η∇× B)
(5.3)
Here B is the magnetic field, v is the fluid velocity (understood to be
the velocity of the ions, which carry all the mass, a distinction that
will become important below), and η is the electrical resistivity. If the
resistivity is constant in space, we can use the fact that ∇· B = 0 to
simplify this slightly to get
∂B
∂t + ∇× (B × v) = η∇2B.
(5.4)
The last term here looks very much like the ν∇2v term we had in the
equation for conservation of momentum (equation 4.2) to describe
viscosity. That term described diffusion of momentum, while the one
in this equation describes diffusion of the magnetic field.2
2 We are simplifying quite a bit here.
The real dissipation mechanism in
molecular clouds is not simple resistivity,
 it is something more complex called
ion-neutral drift, which is discussed
in Section 5.3. However, the qualitative
 analysis given in this section is
unchanged by this complexity, and the
algebra is significantly easier if we use a
simple scalar resistivity.
We can understand the implications of this equation using dimensional
 analysis much as we did for the momentum equation in
Section 4.1.2. As we did there, we let L be the characteristic size of
the system and V be the characteristic velocity, so L/V is the characteristic
 timescale. Spatial derivatives have the scaling 1/L, and
time derivatives have the scaling V/L. We let B be the characteristic
magnetic field strength. Applying these scalings to equation (5.4), the
various terms scale as
BV
L + BV
L
∼
η B
L2
(5.5)
1
∼
η
VL
(5.6)
In analogy to the ordinary hydrodynamic Reynolds number, we
define the magnetic Reynolds number by
Rm = LV
η .
(5.7)
Magnetic diffusion is significant only if Rm ∼1 or smaller.
What is Rm for a typical molecular cloud? As in the hydrodynamic
 case, we can take L to be a few tens of pc and V to be a few
km s−1. The magnetic field B is a few tens of µG. The electrical resistivity
 is a microphysical property of the plasma, which, for a weakly
ionized plasma, depends on the ionization fraction in the gas and the
ion-neutral collision rate. We will show in Section 5.3 that a typical
value of the resistivity3 in molecular clouds is η ∼1022 −1023 cm2 s−1.
3 Again keeping in mind that this is
not a true resistivity, it is an order
of magnitude effective resistivity
associated with ion-neutral drift.
If we consider a length scale L ∼10 pc and a velocity scale V ∼3
km s−1, then LV ∼1025 cm2 s−1, then this implies that the Rm for
molecular clouds is hundreds to thousands.
magnetic fields and magnetized turbulence
83
Again in analogy to hydrodynamics, this means that on large
scales magnetic diffusion is unimportant for molecular clouds –
although it is important on smaller scales. The significance of a large
value of Rm becomes clear if we write down the induction equation
with η = 0 exactly:
∂B
∂t + ∇× (B × v) = 0.
(5.8)
To understand what this equation implies, it is useful consider the
magnetic flux Φ threading some fluid element. We define this as
Φ =
Z
A B · ˆ
n dA,
(5.9)
where we integrate over some area A that defines the fluid element.
The time derivative of this is then
dΦ
dt
=
Z
A
∂B
∂t · ˆ
n dA +
I
∂A B · v × dl
(5.10)
=
Z
A
∂B
∂t · ˆ
n dA +
I
∂A B × v · dl
(5.11)
where ∂A is the boundary of A. Here the second term on the right
comes from the fact that, if the fluid is moving at velocity v, the area
swept out by a vector dl per unit time is v × dl, so the flux crossing
this area is B · v × dl. Then in the second step we used the fact that
∇· B = 0 to exchange the dot and cross products.
If we now apply Stokes theorem again to the second term, we get
dΦ
dt
=
Z
A
∂B
∂t · ˆ
n dA +
Z
A ∇× (B × v) · ˆ
n dA
(5.12)
=
Z
A
∂B
∂t + ∇× (B × v)

· ˆ
n dA
(5.13)
=
0.
(5.14)
The meaning of this is that, when Rm is large, the magnetic flux
through each fluid element is conserved. This is called flux-freezing,
since we can envision it geometrically as saying that magnetic field
lines are frozen into the fluid, and move along with it. Thus on large
scales the magnetic field moves with the fluid. However, on smaller
scales the magnetic Reynolds number is ∼1, and the field lines
are not tied to the gas. We will calculate this scale in Section 5.3.
Before doing so, however, it is helpful to calculate another important
dimensionless number describing the MHD flows in molecular
clouds.
The conservation of momentum equation including magnetic
forces is
∂
∂t(ρv) = −∇· (ρvv) −∇P + ρν∇2v + 1
4π (∇× B) × B,
(5.15)
84
notes on star formation
and if we make order of magnitude estimates of the various terms in
this, we have
ρV2
L
∼
−ρV2
L
+ ρc2
s
L + ρνV
L2 + B2
L
(5.16)
1
∼
1 + c2
s
V2 + ν
VL + B2
ρV2
(5.17)
The second and third terms on the right hand side we have already
defined in terms of M = V/cs and Re = LV/ν. We now define our
fourth and final characteristic number,
MA ≡V
vA
,
(5.18)
where
vA =
B
p
4πρ
(5.19)
is the Alfvén speed – the speed of the wave that, in magnetohydrodynamics,
 plays a role somewhat analogous to the sound wave in
hydrodynamics. In flows with MA ≫1, which we refer to as superAlfvénic,
 the magnetic force term is unimportant, while in those with
MA ≪1, referred to as sub-Alfvénic, it is dominant.
For characteristic molecular cloud numbers n ∼100 cm−3, B
of a few tens of µG, and V of a few km s−1, we see that vA is of
order a few km s−1, about the same as the velocity. Thus the flows
in molecular clouds are highly supersonic (M ≫1), but only transAlfvénic
 (MA ∼1), and magnetic forces have a significant influence.
These forces make it much easier for gas to flow along field lines
than across them, and result in a pattern of turbulence that is highly
anisotropic (Figure 5.2).
No. 1, 1998
DISSIPATION IN COMPRESSIBLE MHD TURBULENCE
L101
TABLE 1
Dissipation Characteristics of Saturated MHD Turbulence
Model
b
3 2
E/rL cs
3 2
E /rL c
K
s
dEB/EK
tdiss/tf
a
a
K
t
/t
diss
f
tdec/tf
a
a
K
t
/t
dec
f
A ......
0.01
20.3
13.0
0.56
0.83
0.54
0.82
0.65
B ......
0.1
18.9
11.8
0.61
0.74
0.46
0.69
0.39
C ......
1.0
17.0
12.9
0.32
0.70
0.53
0.58
0.37
D ......
`
15.4
15.4
0
0.69
0.69
0.40
0.40
a The variables tdiss,
, tf, tdec, and
are defined in the text.
K
K
t
t
diss
dec
Fig. 2.—Images of the logarithm of the density (colors) on three faces of the computational volume, representative magnetic field lines (dark blue lines), and
isosurface of the passive contaminant (red) after saturation. Left:
; right:
.
b 5 0.01
b 5 1
the four models displayed. From the values in the table, the
change in E with b is not large, amounting to only a ª30%
increase in the E saturation amplitude as b varies from ` to
0.01. The dissipation times for saturated turbulence all lie in
the range ª0.5–0.8tf, with slightly longer dissipation times for
stronger B0 models.
The structure of driven compressible MHD turbulence
changes as the field strength is varied. Figure 2 shows the
logarithm of the density along three faces of the computational
volume, representative magnetic field lines, and an isosurface
of the passive contaminant after saturation for both b 5 0.01
and
models computed at a resolution of 2563. In both
b 5 1
cases, the density is compressed into small-scale knots and
filaments; in the
model, these are elongated in the
b 5 0.01
direction parallel to the field. The mass-weighted (volumeweighted)
 mean of
in the strong magnetic field model
log (r/r )
0
is 0.28 (20.29), whereas for the weak field model it is 0.20
(20.22), which indicates that the density contrasts are larger
for strong fields at fixed turbulent Mach number. The maximum
density in the strong field model is 83; for the weak field model,
it is 44. The passive contaminant is confined to a narrow range
of flux tubes for
, indicating that cross-field diffusion
b 5 0.01
is small; for
, it diffuses isotropically.
b 5 1
There is a tendency toward equipartition of kinetic and magnetic
 energy in all of the models. From Table 1, the turbulent
magnetic energy dEB is between 30% and 60% of EK. In the
weak field case, significant amplification of the magnetic field
is produced by the turbulence, so that after saturation, the energy
 in the fluctuations in the field is 10 times larger than that
in the mean field. In the weakly magnetized model, the field
lines are thoroughly tangled (Fig. 2, right). In the strong field
model, the field lines are relatively well ordered (Fig. 2, left),
as expected (e.g., Weiss 1966).
Next consider models of decaying turbulence. The initial
conditions are taken from the saturated driven models presented
above. Figure 1b shows the evolution of E for decay from
saturated initial conditions for various magnetic field strengths.
At late times the decay of E follows a power law in time, with
an index between 0.8 and 0.9 (consistent with the finding of
Mac Low et al. 1998). This implies that the dissipation time
varies with time. We define decay times tdec (
) as the time
K
tdec
taken for 50% of the initial energy (kinetic energy) to be lost;
values for the decay time in these decay runs are given in Table
1. For all models, the decay times are in the range 0.4–0.8tf,
comparable to the range of steady state dissipation times.
The decay rate measured here could in principle differ substantially
 from decay simulations that begin with unsaturated
initial conditions. To investigate this possibility, we have computed
 the decay of supersonic turbulence from initial conditions
in which the magnetic and velocity field perturbations are taken
from the saturated, driven model A, but the density is reset to
a uniform value. The result is plotted as a dashed line in Figure
1b. The corresponding decay times are
and
t
/t 5 0.80
dec
f
, nearly identical to those for model A’s decay.
K
t
/t 5 0.68
dec
f
Finally, to make contact with other studies of decaying MHD
turbulence, we have performed simulations that begin with a
uniform density and magnetic field and velocity perturbations
that follow a k22 spectrum normalized to have the same initial
energy as our driven turbulence simulations at saturation. The
result is shown as a dotted curve in Figure 1b; the decay times
for this model are
and
, again compaK

t
/t 5 1.0
t
/t 5 0.6
dec
f
dec
f
rable to the other dissipation times that we have found. Thus,
we conclude that turbulent decay times are not strongly affected
by specifics of initial conditions. The energy decay times found
for
-dimensional models (Ostriker et al. 1998) are a factor
1
2 2
Figure 5.2: Simulations of sub-Alfvénic
(left) and Alfvénic (right) turbulence.
Colors on the cube surface are slices of
the logarithm of density, blue lines are
magnetic field lines, and red surfaces
are isodensity surfaces for a passive
contaminant added to the flow. Credit:
Stone et al. (1998), © AAS. Reproduced
with permission.
magnetic fields and magnetized turbulence
85
5.3
Non-Ideal Magnetohydrodynamics
We have just shown that the magnetic Reynolds number is a critical
parameter for magnetized turbulence, and that this depends on the
resistivity η. In the final part of this Chapter we will discuss in a bit
more detail the physical origins of resistivity and related effects.
5.3.1
Ion-Neutral Drift
Molecular clouds are not very good plasmas. Most of the gas in a
molecular cloud is neutral, not ionized. The ion fraction may be
10−6 or lower. Since only ions and electrons can feel the Lorentz
force directly, this means that fields only exert forces on most of the
particles in a molecular cloud indirectly. The indirect mechanism is
that the magnetic field exerts forces on the ions and electrons (and
mostly ions matter for this purpose), and these then collide with the
neutrals, transmitting the magnetic force.
If the collisional coupling is sufficiently strong, then the gas acts
like a perfect plasma. However, when the ion fraction is very low, the
coupling is imperfect, and ions and neutrals do not move at exactly
the same speed. The field follows the ions, since they are much less
resistive, and flux freezing for them is a very good approximation,
but the neutrals are able to drift across field lines. This slippage
between ions and neutrals is called ion-neutral drift, or ambipolar
diffusion.
To estimate how this process works, we need to think about the
forces acting on both ions and neutrals. The ions feel a Lorentz force
fL = 1
4π (∇× B) × B.
(5.20)
The other force in play is the drag force due to ion-neutral collisions,
which is
fd = γρnρi(vi −vn),
(5.21)
where the subscript i and n refer to ions and neutrals, respectively,
and γ is the drag coefficient, which can be computed from the microphysics
 of the plasma. In a very weakly ionized fluid, the neutrals
and ions very quickly reach terminal velocity with respect to one another,
 so the drag force and the Lorentz force must balance. Equating
our expressions and solving for vd = vi −vn, the drift velocity, we get
vd =
1
4πγρnρi
(∇× B) × B
(5.22)
To figure out how this affects the fluid, we write down the equation
 of magnetic field evolution under the assumption that the field is
86
notes on star formation
perfectly frozen into the ions:
∂B
∂t + ∇× (B × vi) = 0.
(5.23)
To figure out how the field behaves with respect to the neutrals,
which constitute most of the mass, we simply use our expression for
the drift speed vd to eliminate vi. With a little algebra, the result is
∂B
∂t + ∇× (B × vn) = ∇×

B
4πγρnρi
× [B × (∇× B)]

.
(5.24)
Referring back to the induction equation (5.3), we can see that the
resistivity produced by ion-neutral drift is not a scalar, and that it is
non-linear, in the sense that it depends on B itself.
However, our scaling analysis still applies. The magnitude of the
resistivity produced by ion-neutral drift is
ηAD =
B2
4πρiρnγ.
(5.25)
Thus, the magnetic Reynolds number is
Rm = LV
ηAD
= 4πLVρiρnγ
B2
≈4πLVρ2xγ
B2
,
(5.26)
where x = ni/nn is the ion fraction, which we’ve assumed is ≪1 in
the last step. Ion-neutral drift will allow the magnetic field lines to
drift through the fluid on length scales L such that Rm ≲1. Thus, we
can define a characteristic length scale for ambipolar diffusion by
LAD =
B2
4πρ2xγV
(5.27)
In order to evaluate this numerically, we must calculate two things
from microphysics: the ion-neutral drag coefficient γ and the ionization
 fraction x. For γ, the dominant effect at low speeds is that ions
induce a dipole moment in nearby neutrals, which allows them to undergo
 a Coulomb interaction. This greatly enhances the cross-section
relative to the geometric value. We will not go into details of that
calculation, and will simply adopt the results: γ ≈9.2 × 1013 cm3 s−1
g−1 (Smith & Mac Low 1997; note that Shu 1992 gives a value that is
lower by a factor of ∼3, based on an earlier calculation).
The remaining thing we need to know to compute the drag force
is the ion density. In a molecular cloud the gas is almost all neutral,
and the high opacity excludes most stellar ionizing radiation. The
main source of ions is cosmic rays, which can penetrate the cloud, although
 nearby strong x-ray sources can also contribute if present. We
have already discussed cosmic rays in the context of cloud heating
magnetic fields and magnetized turbulence
87
and chemistry, and here too they play a central role. Calculating the
ionization fraction requires balancing this against the recombination
rate, which is a nasty problem. That is because recombination is
dominated by different processes at different densities, and recombinations
 are usually catalyzed by dust grains rather than occurring
in the gas phase. We will not go into the details of these calculations
here, and will instead simply quote a rough fit to their results given
by Tielens (2005),
ni ≈2 × 10−3 cm−3 
nH
104 cm−3
1/2 
ζ
10−16 s−1
1/2
,
(5.28)
where nH is the number density and ζ is the cosmic ray primary4
4 I.e., counting only ionizations caused
by direct cosmic ray hits, as opposed
to ionizations caused when primary
electrons go on to ionize additional
atoms or molecules.
ionization rate. Thus at a density nH ∼100 cm−3, we expect x ≈
10−6.
Plugging this into our formulae, along with our characteristic
numbers L of a few tens of pc, V ∼a few km s−1, and B ∼10 µG, we
find
Rm
≈
50
(5.29)
LAD
∼
0.5 pc.
(5.30)
If we put in numbers for L and V more appropriate for cores than
entire GMCs, we get LAD ∼0.05 pc. Thus we expect the gas to act
like a fully ionized gas on scales larger than this, but to switch over
to behaving hydrodynamically on small scales.
5.3.2
Turbulent Reconnection
A final non-ideal MHD effect that may be important in molecular
clouds, though this is still quite uncertain, is turbulent reconnection.
The general idea of reconnection is that, in regions of non-zero
resistivity where oppositely directed field lines are brought into close
contact, the field lines can break and the field geometry can relax to a
lower energy configuration. This may allow the field to slip out of the
matter, and it always involves a reduction in magnetic pressure and
energy density. The released energy is transformed into heat.
The simplest model of reconnection, the Sweet-Parker model,
considers two regions of oppositely-directed field that meet at a
plane. On that plane, a large current must flow in order to maintain
the oppositely-directed fields on either side of it. Within this sheet
reconnection can occur. As with ion-neutral drift, we can define a
characteristic Reynolds-like number for this process, in this case
called the Lundqvist number:
RL = LV
η ,
(5.31)
88
notes on star formation
where here η is the true microphysical resistivity, as opposed to the
term describing ion-neutral diffusion.
The rate at which reconnection can occur in the Sweet-Parker
model is dictated by geometry. Matter is brought into the thin reconnection
 region, it reconnects, and then it must exit so that new
reconnecting matter can be brought in. Matter can only exit the layer
at the Alfvén speed, and since the cross-section of the reconnection
layer is small, this sets severe limits on the rate at which reconnection
can occur. It turns out that one can show that the maximum speed at
which matter can be brought into the reconnection region is of order
R1/2
L
vA.
To figure out this speed, we need to know the resistivity, which is
related to the electrical conductivity σ by
η =
c2
4πσ.
(5.32)
We will not provide a full calculation of plasma conductivity here5,
5 Again, Shu (1992) is a good source
for those who wish to see a rigorous
derivation.
but we can sketch the basic outlines of the argument. The conductivity
 of a plasma is the proportionality constant between the applied
electric field and the resulting current,
J = σE.
(5.33)
In a plasma the current is carried by motions of the electrons, which
move much faster than the ions due to their lower mass, and the
current is simply the electron charge times the electron number
density times the mean electron speed: J = eneve. To compute the
mean electron speed, one balances the electric force against the
drag force exerted by collisions with neutrals (which dominate in a
weakly ionized plasma), in precisely the same way we derived the
mean ion-neutral drift speed by balancing the drag force against the
Lorentz force. Not surprisingly ve ends up being proportional to E,
and inversely proportional to the number density of the dominant
non-electron species (H2 in molecular clouds) and the cross section of
this species for electron collisions. The final result of this procedure is
σ =
nee2
menH2⟨σv⟩e−H2
≈1017x s−1,
(5.34)
where ⟨σv⟩e−H2 ≈10−9 cm3 s−1 is the mean cross-section times
velocity for electron-ion collisions. Plugging this into the resistivity
gives
η ≈103 cm2 s−1
x
(5.35)
Plugging in our typical value x ∼10−6 gives η ∼109 cm2 s−1, and
using L ∼10 pc and V of a few km s−1, typical molecular cloud
magnetic fields and magnetized turbulence
89
numbers, this implies
RL ∼1016.
(5.36)
Of course this makes the reconnection speed truly tiny, of order
10−8 of vA. So why is reconnection at all interesting? Why is it worth
considering? The answer turns on the word turbulent. It turns out
that the Sweet-Parker model underpredicts the observed reconnection
rate in laboratory experiments or observed in Solar flares and the
Earth’s magnetosphere. Indeed, if Sweet-Parker were right, there
would be no such things as Solar flares.
We currently lack a good understanding of reconnection, but a
rough idea is that, in a turbulent medium, reconnection sheets are
can be much wider due to turbulent broadening, and that this in
turn removes the geometric constraint that makes the reconnection
velocity much smaller than the Alfvén speed. Exactly how and when
this is important in molecular clouds is a subject of very active debate
in the literature.
6
Gravitational Instability and Collapse
Suggested background reading:
• Krumholz, M. R. 2014, Phys. Rep.,
539, 49, section 3.4
The previous two chapters provided a whirlwind tour of fluid dynamics
 and turbulence. However, in that discussion we completely
omitted gravity, which is obviously critical to the process of star formation.
 We will now remedy that omission by bringing gravity back
into the discussion.
6.1
The Virial Theorem
To open this topic, we will start by proving a powerful and general
theorem about the behavior of fluids, known as the virial theorem.1
1 Like the equations of motion, there
is both an Eulerian form and a Lagrangian
 form of the virial theorem,
depending on which version of the
equations of motion we start with. We
will derive the Eulerian form here,
following the original proof by McKee
& Zweibel (1992), but the derivation
of the Lagrangian form proceeds in a
similar manner, and can be found in
many standard textbooks, for example
Shu (1992).
To derive the virial theorem, we begin with the MHD equations of
motion, without either viscosity or resistivity (since neither of these
are important for GMCs on large scales) but with gravity. We leave in
the pressure forces, even though they are small, because they are also
trivial to include. Thus we have
∂ρ
∂t
=
−∇· (ρv)
(6.1)
∂
∂t(ρv)
=
−∇· (ρvv) −∇P + 1
4π (∇× B) × B −ρ∇φ.
(6.2)
Here φ is the gravitational potential, so −ρ∇φ is the gravitational
force per unit volume. These equations are the Eulerian equations
written in conservative form.
Before we begin, life will be a bit easier if we re-write the entire
second equation in a manifestly tensorial form – this simplifies the
analysis tremendously. To do so, we define two tensors: the fluid
pressure tensor Π and the Maxwell stress tensor TM, as follows:
Π
≡
ρvv + PI
(6.3)
TM
≡
1
4π

BB −B2
2 I

(6.4)
Here I is the identity tensor. In tensor notation, these are
(Π)ij
≡
ρvivj + Pδij
(6.5)
92
notes on star formation
(TM)ij
≡
1
4π

BiBj −1
2 BkBkδij

.
(6.6)
With these definitions, the momentum equation just becomes
∂
∂t(ρv) = −∇· (Π −TM) −ρ∇φ.
(6.7)
The substitution for Π is obvious. The equivalence of ∇· TM to
1/(4π)(∇× B) × B is easy to establish with a little vector manipulation,
 which is most easily done in tensor notation:
(∇× B) × B
=
ϵijkϵjmn
 ∂
∂xm
Bn

Bk
(6.8)
=
−ϵjikϵjmn
 ∂
∂xm
Bn

Bk
(6.9)
=
(δinδkm −δimδkn)
 ∂
∂xm
Bn

Bk
(6.10)
=
Bk
∂
∂xk
Bi −Bk
∂
∂xi
Bk
(6.11)
=

Bk
∂
∂xk
Bi + Bi
∂
∂xk
Bk

−Bk
∂
∂xi
Bk
(6.12)
=
∂
∂xk
(BiBk) −1
2
∂
∂xi

B2
k

(6.13)
=
∇·

BB −B2
2 I

.
(6.14)
To derive the virial theorem, we begin by imagining a cloud of
gas enclosed by some fixed volume V. The surface of this volume is
S. We want to know how the overall distribution of mass changes
within this volume, so we begin by writing down a quantity the
represents the mass distribution. This is the moment of inertia,
I =
Z
V ρr2 dV.
(6.15)
We want to know how this changes in time, so we take its time
derivative:
˙
I
=
Z
V
∂ρ
∂t r2 dV
(6.16)
=
−
Z
V ∇· (ρv)r2 dV
(6.17)
=
−
Z
V ∇· (ρvr2) dV + 2
Z
V ρv · r dV
(6.18)
=
−
Z
S(ρvr2) · dS + 2
Z
V ρv · r dV.
(6.19)
In the first step we used the fact that the volume V does not vary in
time to move the time derivative inside the integral. Then in the second
 step we used the equation of mass conservation to substitute. In
gravitational instability and collapse
93
the third step we brought the r2 term inside the divergence. Finally
in the fourth step we used the divergence theorem to replace the
volume integral with a surface integral.
Now we take the time derivative again, and multiply by 1/2 for
future convenience:
1
2
¨
I
=
−1
2
Z
S r2 ∂
∂t(ρv) · dS +
Z
V
∂
∂t(ρv) · r dV
(6.20)
=
−1
2
d
dt
Z
S r2(ρv) · dS
−
Z
V r · [∇· (Π −TM) + ρ∇φ] dV.
(6.21)
The term involving the tensors is easy to simplify using a handy
identity, which applies to an arbitrary tensor. This is a bit easier to
follow in tensor notation:
Z
V r · ∇· T dV
=
Z
V xi
∂
∂xj
Tij dV
(6.22)
=
Z
V
∂
∂xj
(xiTij) dV −
Z
V Tij
∂
∂xj
xi dV
(6.23)
=
Z
S xiTij dSj −
Z
V δijTij dV
(6.24)
=
Z
S r · T · dS −
Z
V Tr T dV,
(6.25)
where Tr T = Tii is the trace of the tensor T.
Applying this to our result our tensors, we note that
Tr Π
=
3P + ρv2
(6.26)
Tr TM
=
−B2
8π
(6.27)
Inserting this result into our expression for ¨
I gives the virial theorem,
which we will write in a more suggestive form to make its physical
interpretation clearer:
1
2
¨
I = 2(T −TS) + B + W −1
2
d
dt
Z
S(ρvr2) · dS,
(6.28)
where
T
=
Z
V
1
2ρv2 + 3
2 P

dV
(6.29)
TS
=
Z
S r · Π · dS
(6.30)
B
=
1
8π
Z
V B2 dV +
Z
S r · TM · dS
(6.31)
W
=
−
Z
V ρr · ∇φ dV.
(6.32)
Written this way, we can give a clear interpretation to what these
terms mean. T is just the total kinetic plus thermal energy of the
94
notes on star formation
cloud. TS is the confining pressure on the cloud surface, including
both the thermal pressure and the ram pressure of any gas flowing
across the surface. B is the the difference between the magnetic
pressure in the cloud interior, which tries to hold it up, and the
magnetic pressure plus magnetic tension at the cloud surface, which
try to crush it. W is the gravitational energy of the cloud. If there is
no external gravitational field, and φ comes solely from self-gravity,
then W is just the gravitational binding energy. The final integral
represents the rate of change of the momentum flux across the cloud
surface.
¨
I is the integrated form of the acceleration. For a cloud of fixed
shape, it tells us the rate of change of the cloud’s expansion or contraction.
 If it is negative, the terms that are trying to collapse the
cloud (the surface pressure, magnetic pressure and tension at the
surface, and gravity) are larger, and the cloud accelerates inward. If
it is positive, the terms that favor expansion (thermal pressure, ram
pressure, and magnetic pressure) are larger, and the cloud accelerates
outward. If it is zero, the cloud neither accelerates nor decelerates.
We get a particularly simple form of the virial theorem if there is
no gas crossing the cloud surface (so v = 0 at S) and if the magnetic
field at the surface to be a uniform value B0. In this case the virial
theorem reduces to
1
2
¨
I = 2(T −TS) + B + W
(6.33)
with
TS
=
Z
S rP dS
(6.34)
B
=
1
8π
Z
V(B2 −B2
0) dV.
(6.35)
For this simplified physical setup, TS just represents the mean radius
times pressure at the virial surface, and B just represents the total
magnetic energy of the cloud minus the magnetic energy of the
background field over the same volume. Notice that, if a cloud is in
equilibrium (¨
I = 0) and magnetic and surface forces are negligible,
then we have 2T = −W. Based on this result, we define the virial
ratio
αvir = 2T
|W|.
(6.36)
For an object for which magnetic and surface forces are negligible,
and with no flow across the virial surface, a value of αvir > 1 implies
¨
I > 0, and a value αvir < 1 implies ¨
I < 0. Thus αvir = 1 roughly
divides clouds that have enough internal pressure or turbulence to
avoid collapse from those that do not.
gravitational instability and collapse
95
6.2
Stability Conditions
Armed with the virial theorem, we are now in a position to understand,
 at least qualitatively, under what conditions a cloud of gas will
be stable against gravitational contraction, and under what conditions
 it will not be. If we examine the terms on the right hand side
of the virial theorem, we can group them into those that are generally
 or always positive, and thus oppose collapse, and those that
are generally or always negative, and thus encourage it. The main
terms opposing collapse are T , which contains parts describing both
thermal pressure and turbulent motion, and B, which describes magnetic
 pressure and tension. The main terms favoring collapse are W,
representing self-gravity, and TS, representing surface pressure. The
final term, the surface one, could be positive or negative depending
on whether mass is flowing into our out of the virial volume. We will
begin by examining the balance among these terms, and the forces
they represent.
6.2.1
Thermal Support and the Jeans Instability
Gas pressure is perhaps the most basic force in opposing collapse.
Unlike turbulent motions, which can compress in some places even
as they provide overall support, gas pressure always tries to smooth
out the gas. Similarly, self-gravity is the most reliable promoter of
collapse. A full, formal analysis of the interaction between pressure
and self-gravity was provided by James Jeans in 1902 (Jeans, 1902),
and we will go through it below. However, we can already see what
the basic result will have to look like just from the virial theorem.
We expect the dividing line between stability and instability to lie at
αvir ≈1. For an isolated, isothermal cloud of mass M and radius R
with only thermal pressure, we have
T
=
3
2 Mc2
s
(6.37)
W
=
−a GM2
R
,
(6.38)
where a is a factor of order unity that depends on the internal density
structure. Thus the condition αvir ≳1 corresponds to
Mc2
s ≳GM2
R
=
⇒
R ≳GM
c2
s
,
(6.39)
or, rewriting in terms of the mean density ρ ∼M/R3,
R ≲
cs
p
Gρ.
(6.40)
96
notes on star formation
The formal analysis proceeds as follows. Consider a uniform,
infinite, isothermal medium at rest. The density is ρ0, the pressure
is P0 = ρ0c2
s, and the velocity is v0 = 0. We will write down the
equations of hydrodynamics and self-gravity for this gas:
∂
∂tρ + ∇· (ρv)
=
0
(6.41)
∂
∂t(ρv) + ∇· (ρvv)
=
−∇P −ρ∇φ
(6.42)
∇2φ
=
4πGρ.
(6.43)
Here the first equation represents conservation of mass, the second
represents conservation of momentum, and the third is the Poisson
equation for the gravitational potential φ. We take the background
density ρ0, velocity v0 = 0, pressure P0, and potential φ0 to be an
exact solution of these equations, so that all time derivatives are zero
as long as the gas is not disturbed.
Note that this involves the "Jeans swindle": this assumption is
actually not really consistent, because the Poisson equation cannot be
solved for an infinite uniform medium unless ρ0 = 0. In other words,
there is no function φ0 such that ∇2φ0 is equal to a non-zero constant
value on all space. That said, we will ignore this complication, since
the approximation of a uniform infinite medium is a reasonable
one for a very large but finite uniform medium. It is possible to
construct the argument without the Jeans swindle, but doing so adds
mathematical encumbrance without physical insight, so we will not
do so.
That digression aside, now let us consider what happens if we
perturb this system. We will write the density as ρ = ρ0 + ϵρ1, where
ϵ ≪1. Similarly, we write v = ϵv1 and φ = φ0 + ϵφ1. Since we can
always use Fourier analysis to write an arbitrary perturbation as a
sum of Fourier components, without loss of generality we will take
the perturbation to be a single, simple Fourier mode. The reason to
do this is that, as we will see, differential equations are trivial to solve
when the functions in question are simple plane waves.
Thus we write ρ1 = ρa exp[i(kx −ωt)]. Note that we implicitly
understand that we use only the real part of this exponential. It is
just easier to write things in terms of an ei(kx−ωt) than it is to keep
track of a bunch of sines and cosines. In writing this equation, we
have chosen to orient our coordinate system so that the wave vector
k of the perturbation is in the x direction. Again, there is no loss of
generality in doing so.
Given this density perturbation, what is the corresponding perturbation
 to the potential? From the Poisson equation, we have
∇2(φ0 + ϵφ1) = 4πG(ρ0 + ϵρ1).
(6.44)
gravitational instability and collapse
97
Since by assumption ρ0 and φ0 are exact solutions to the Poisson
equation, we can cancel the φ0 and ρ0 terms out of the equation,
leaving
∇2φ1 = 4πGρ1 = 4πGρaei(kx−ωt).
(6.45)
This equation is trivial to solve, since it is just of the form y′′ = aebx.
The solution is
φ1 = −4πGρa
k2
ei(kx−ωt).
(6.46)
By analogy to what we did for ρ1, we write this solution as φ1 =
φaei(kx−ωt), with
φa = −4πGρa
k2
.
(6.47)
Now that we have found the perturbed potential, let us determine
what motion this will induce in the fluid. To do so, we first take the
equations of mass and momentum conservation and we linearize
them. This means that we substitute in ρ = ρ0 + ϵρ1, v = ϵv1,
P = P0 + ϵP1 = c2
s(ρ0 + ϵρ1), and φ = φ0 + ϵφ1. Note that v0 = 0.
We then expand the equations in powers of ϵ, and we drop all the
terms that are of order ϵ2 or higher on the grounds that they become
negligible in the limit of small ϵ.
Linearizing the equation of mass conservation we get
∂
∂t(ρ0 + ϵρ1) + ∇· [(ρ0 + ϵρ1)(ϵv1)]
=
0
(6.48)
∂
∂tρ0 + ϵ ∂
∂tρ1 + ϵ∇· (ρ0v1)
=
0
(6.49)
∂
∂tρ1 + ∇· (ρ0v1)
=
0.
(6.50)
In the second step, we dropped a term of order ϵ2. In the third step
we used the fact that ρ0 is constant, i.e., that the background density
has zero time derivative, to drop that term. Applying the same
procedure to the momentum equation, we get
∂
∂t[(ρ0 + ϵρ1)(ϵv1)] + ∇· [(ρ0 + ϵρ1)(ϵv1)(ϵv1)]
=
−c2
s∇(ρ0 + ϵρ1)
−(ρ0 + ϵρ1)∇(φ0 + ϵφ1)
(6.51)
ϵ ∂
∂t(ρ0v1)
=
−c2
s∇ρ0 −ρ0∇φ0
−ϵ

c2
s∇ρ1 + ρ1∇φ0 + ρ0∇φ1

(6.52)
∂
∂t(ρ0v1)
=
−c2
s∇ρ1 −ρ0∇φ1.
(6.53)
In the second step we dropped terms of order ϵ2, and in the third
step we used the fact that the background state is uniform to drop
terms involving gradients of ρ0 and φ0.
98
notes on star formation
Now that we have our linearized equations, we’re ready to find
out what v1 must be. By analogy to what we did for ρ1 and φ1, we
take v1 to be a single Fourier mode, of the form
v1 = vaei(kx−ωt)
(6.54)
Substituting for ρ1, φ1, and v1 into the linearized mass conservation
equation (6.50), we get
∂
∂t

ρaei(kx−ωt)
+ ∇· (ρ0vaei(kx−ωt))
=
0
(6.55)
−iωρaei(kx−ωt) + ikρ0va,xei(kx−ωt)
=
0
(6.56)
−ωρa + kρ0va,x
=
0
(6.57)
ωρa
kρ0
=
va,x
(6.58)
where va,x is the x component of va.
We have now found the velocity perturbation in terms of ρa, ω,
and k. Similarly substituting into the linearized momentum equation
(6.53) gives
∂
∂t

ρ0vaei(kx−ωt)
=
−c2
s∇(ρaei(kx−ωt))
−ρ0∇(φaei(kx−ωt))
(6.59)
−iωρ0vaei(kx−ωt)
=
−ikc2
sρaˆ
xei(kx−ωt)
−ikρ0φaei(kx−ωt)ˆ
x
(6.60)
ωρ0va,x
=
k

c2
sρa + ρ0φa

.
(6.61)
Now let us take this equation and substitute in the values for φa and
va,x that we previously determined:
ωρ0
ωρa
kρ0

=
kc2
sρa −kρ0
4πGρa
k2

(6.62)
ω2
=
c2
sk2 −4πGρ0
(6.63)
This expression is known as a dispersion relation, because it describes
 the dispersion of the plane wave solution we have found, i.e.,
how that wave’s spatial frequency k relates to its temporal frequency
ω.
To see what this implies, let us consider what happens when we
put in a perturbation with a short wavelength or a large spatial frequency.
 In this case k is large, and c2
sk2 −4πGρ0 > 0, so ω is a positive
or negative real number. The density is ρ = ρ0 + ρaei(kx−ωt), which
represents a uniform background density with a small oscillation
in space and time on top of it. Since |ei(kx−ωt)| < 1 at all times and
places, the oscillation does not grow.
gravitational instability and collapse
99
On the other hand, suppose that we impose a perturbation with
a large spatial range, or a small spatial frequency. In this case c2
sk2 −
4πGρ0 < 0, so ω is a positive or negative imaginary number. For an
imaginary ω, |e−iωt| either decays to zero or grows infinitely large
in time, depending on whether we take the positive or negative
imaginary root. Thus at least one solution for the perturbation will
not remain small. It will grown in amplitude without limit.
This represents an instability: if we impose an arbitrarily small amplitude
 perturbation on the density at a sufficiently large wavelength,
that perturbation will eventually grow to be large. Of course once ρ1
becomes large enough, our linearization procedure of dropping terms
proportional to ϵ2 becomes invalid, since these terms are no longer
small. In this case we must follow the full non-linear behavior of the
equations, usually with simulations.
We have, however, shown that there is a critical size scale beyond
which perturbations that are stabilized only by pressure must grow
to non-linear amplitude. The critical length scale is set by the value of
k for which ω = 0,
kJ =
s
4πGρ0
c2
s
.
(6.64)
The corresponding wavelength is
λJ = 2π
kJ
=
s
πc2
s
Gρ0
.
(6.65)
This is known as the Jeans length. One can also define a mass scale
associated with this: the Jeans mass, MJ = ρλ3
J/8.2
2 The definition of the Jeans mass is
somewhat ambiguous, and multiple definitions
 can be found in the literature.
The one we have chosen corresponds
to considering the mass within a cube
of half a Jeans length in size. Possible
alternatives include choosing a cube
one Jeans length in size or choosing a
sphere one Jeans length in radius or
diameter, to name just two possibilities.
These definitions all scale with density
and Jeans length in the same way, and
differ only in their coefficients.
If we plug in some typical numbers for a GMC, cs = 0.2 km
s−1 and ρ0 = 100mp cm−3, we get λJ = 3.4 pc. Since every GMC
we have seen is larger than this size, and there are clearly always
perturbations present, this means that molecular clouds cannot be
stabilized by gas pressure against collapse. Of course one could have
guessed this result just by evaluating terms in the virial theorem: the
gas pressure term is very small compared to the gravitational one.
Ultimately, the virial theorem and the Jeans instability analysis are
just two different ways of extracting the same information from the
equations of motion.
One nice thing about the Jeans analysis, however, is that it makes
it obvious how fast we should expect gravitational instabilities to
grow. Suppose we have a very unstable system, where c2
sk2 ≪4πGρ0.
This is the case for GMC, for example. There are perturbations on the
size of the entire cloud, which might be 50 pc in size. This is a spatial
frequency k = 2π/(50 pc) = 0.12 pc−1. Plugging this in with cs = 0.2
km s−1 and ρ0 = 100mp cm−3 gives c2
sk2/(4πGρ) = 0.005. In this case
100
notes on star formation
we have
ω ≈±i
p
4πGρ0.
(6.66)
Taking the negative i root, which corresponds to the growing
mode, we find that
ρ1 ∝exp([4πGρ0]1/2t).
(6.67)
Thus the e-folding time for the disturbance to grow is ∼1/
p
Gρ0. We
define the free-fall time as
tff =
s
3π
32Gρ0
,
(6.68)
where the numerical coefficient of √
3π/32 comes from doing the
closely related problem of the collapse of a pressureless sphere,
which we will cover in Section 6.3. The free-fall time is the characteristic
 time scale required for a medium with negligible pressure
support to collapse.
The Jeans analysis is of course only appropriate for a uniform
medium, and it requires the Jeans swindle. Problem Set 2 contains
a calculation of the maximum mass of a spherical cloud that can
support itself against collapse by thermal pressure, called the BonnorEbert
 mass (Ebert, 1955; Bonnor, 1956). Not surprisingly, the BonnorEbert
 mass is simply MJ times factors of order unity.
6.2.2
Magnetic Support and the Magnetic Critical Mass
We now examine another term that generally opposes collapse: the
magnetic one. Let us consider a uniform spherical cloud of radius R
threaded by a magnetic field B. We imagine that B is uniform inside
the cloud, but that outside the cloud the field lines quickly spread
out, so that the magnetic field drops down to some background
strength B0, which is also uniform but has a magnitude much smaller
than B.
Here it is easiest to work directly with the virial theorem. The
magnetic term in the virial theorem is
B = 1
8π
Z
V B2 dV +
Z
S r · TM · dS
(6.69)
where
TM = 1
4π

BB −B2
2 I

.
(6.70)
If the field inside the cloud is much larger than the field outside it,
then the first term, representing the integral of the magnetic pressure
within the cloud, is
1
8π
Z
V B2 dV ≈B2R3
6
.
(6.71)
gravitational instability and collapse
101
Here we have dropped any contribution from the field outside the
cloud. The second term, representing the surface magnetic pressure
and tension, is
Z
S x · TM · dS =
Z
S
B2
0
8π x · dS ≈B2
0R3
0
6
(6.72)
Since the field lines that pass through the cloud must also pass
through the virial surface, it is convenient to rewrite everything in
terms of the magnetic flux. The flux passing through the cloud is
ΦB = πBR2, and since these field lines must also pass through the
virial surface, we must have ΦB = πB0R2
0 as well. Thus, we can
rewrite the magnetic term in the virial theorem as
B ≈B2R3
6
−B2
0R3
0
6
=
1
6π2

Φ2
B
R −Φ2
B
R0
!
≈
Φ2
B
6π2R.
(6.73)
In the last step we used the fact that R ≪R0 to drop the 1/R0
term. Now let us compare this to the gravitational term, which is
W = −3
5
GM2
R
(6.74)
for a uniform cloud of mass M. Comparing these two terms, we find
that
B + W =
Φ2
B
6π2R −3
5
GM2
R
≡3
5
G
R

M2
Φ −M2
(6.75)
where
MΦ ≡
r
5
2

ΦB
3πG1/2

(6.76)
We call MΦ the magnetic critical mass. Since ΦB does not change as
a cloud expands or contracts (due to flux-freezing), this magnetic
critical mass does not change either.
The implication of this is that clouds that have M > MΦ always
have B + W < 0. The magnetic force is unable to halt collapse no matter
 what. Clouds that satisfy this condition are called magnetically
supercritical, because they are above the magnetic critical mass MΦ.
Conversely, if M < MΦ, then B + W > 0, and gravity is weaker than
magnetism. Clouds satisfying this condition are called subcritical.
For a subcritical cloud, since B + W ∝1/R, this term will get
larger and larger as the cloud shrinks. In other words, not only
is the magnetic force resisting collapse is stronger than gravity, it
becomes larger and larger without limit as the cloud is compressed to
a smaller radius. Unless the external pressure is also able to increase
without limit, which is unphysical, then there is no way to make a
magnetically subcritical cloud collapse. It will always stabilize at
some finite radius. The only way to get around this is to change the
102
notes on star formation
magnetic critical mass, which requires changing the magnetic flux
through the cloud. This is possible only via ion-neutral drift or some
other non-ideal MHD effect that violates flux-freezing.
Of course our calculation is for a somewhat artificial configuration
 of a spherical cloud with a uniform magnetic field. In reality a
magnetically-supported cloud will not be spherical, since the field
only supports it in some directions, and the field will not be uniform,
since gravity will always bend it some amount. Figuring out the magnetic
 critical mass in that case requires solving for the cloud structure
numerically. A calculation of this effect by Tomisaka (1998) gives
MΦ = 0.12 ΦB
G1/2
(6.77)
for clouds for which pressure support is negligible. The numerical
coefficient we obtained for the uniform cloud case (equation 6.76)
is 0.17, so this is obviously a small correction. It is also possible to
derive a combined critical mass that incorporates both the flux and
the sound speed, and which limits to the Bonnor-Ebert mass for
negligible field and the magnetic critical mass for negligible pressure.
It is not so easy to determine observationally whether the magnetic
 fields are strong enough to hold up molecular clouds. The
observations are somewhat complicated by the fact that, using the
most common technique of Zeeman splitting, one can only measure
the line of sight component of the field. This therefore gives only a
lower limit on the magnetic critical mass. Nonetheless, for a large
enough sample, one can estimate true magnetic field strengths statistically
 under the assumption of random orientations. When this
analysis is performed, the current observational consensus is that
magnetic fields in molecular clouds are not, by themselves, strong
enough to prevent gravitation collapse. Figure 6.1 shows a summary
 of the current observations. Clearly atomic gas is magnetically
subcritical, but molecular gas is supercritical.
6.2.3
Turbulent Support
There is one more positive term in the virial theorem, which is the
turbulent component of T . This one is not at all well understood,
largely because we don’t understand turbulence itself. This term
almost certainly provides some support against collapse, but the
amount is not well understood, and we will defer any further discussion
 of this effect until we get to our discussions of the star formation
rate in Chapter 10.
gravitational instability and collapse
103
1018
1019
1020
1021
1022
1023
1024
1025
NH [cm−2]
10-1
100
101
102
103
104
|BLOS| [µG]
Subcritical
Supercritical
Figure 6.1: Measurements of the line
of sight magnetic field strength from
the Zeeman effect, versus total gas
column density in H atoms cm−2 (data
from the compilation of Crutcher 2012).
The three clumps of points represent,
from left to right, measurements from
the Zeeman splitting of H i, OH, and
CN. The dashed black line indicates
the separation between field strengths
that are large enough to render the gas
subcritical, and those weak enough for
it to be supercritical.
6.3
Pressureless Collapse
As a final topic for this chapter, let us consider what we should
expect to happen if gas does begin to collapse, in the simplest case
of an initially-spherical cloud with an initial density distribution
ρ(r). We would like to know how the gas moves under the influence
of gravity and thermal pressure, under the assumption of spherical
symmetry. For convenience we define the enclosed mass
Mr =
Z r
0 4πr′2ρ(r′) dr′
(6.78)
or equivalently
∂Mr
∂r
= 4πr2ρ.
(6.79)
The equation of mass conservation for the gas in spherical coordinates
 is
∂
∂tρ + ∇· (ρv)
=
0
(6.80)
∂
∂tρ + 1
r2
∂
∂r(r2ρv)
=
0,
(6.81)
where v is the radial velocity of the gas. It is useful to write the
equations in terms of Mr rather than ρ, so we take the time derivative
of Mr to get
∂
∂t Mr
=
4π
Z r
0 r′2 ∂
∂tρ dr′
(6.82)
=
−4π
Z r
0
∂
∂r′ (r′2ρv) dr′
(6.83)
104
notes on star formation
=
−4πr2ρv
(6.84)
=
−v ∂
∂r Mr.
(6.85)
In the second step we used the mass conservation equation to substitute
 for ∂ρ/∂t, and in the final step we used the definition of Mr to
substitute for ρ.
To figure out how the gas moves, we write down the Lagrangian
version of the momentum equation:
ρ Dv
Dt = −∂
∂r P −ρfg,
(6.86)
where fg is the gravitational force per unit mass. As a reminder, the
total derivative D/Dt indicates we are not evaluating the derivative
at a fixed position, but that instead we are following a fixed shell of
mass as it moves; that is, ∂v/∂t means “change in fluid velocity at
a fixed position”, while Dv/Dt means “change in the velocity of a
particular shell of mass as it moves".
For the momentum equation, we take advantage of the fact that
the gas is isothermal to write P = ρc2
s. The gravitational force is
fg = GMr/r2. Thus we have
Dv
Dt = −c2
s
ρ
∂
∂r ρ −GMr
r2
.
(6.87)
To go further, let us make one more simplifying assumption: that
the sound speed cs is zero. This is not as bad an approximation as
one might think. Consider the virial theorem: the thermal pressure
term is just proportional to the mass, since the gas sound speed stays
about constant. On the other hand, the gravitational term varies as
1/R. Thus, even if pressure starts out competitive with gravity, as the
core collapses the dominance of gravity will increase, and before too
long the collapse will resemble a pressureless one.
In this case the momentum equation is trivial:
Dv
Dt = −GMr
r2
.
(6.88)
This just says that a shell’s inward acceleration is equal to the gravitational
 force per unit mass exerted by all the mass interior to it, which
is constant. To solve the system, we will use the trick of changing
from t to r as our independent variable. That is, rather than asking
about the velocity as a function of time, we will ask about it as a
function of position. To make this change of variable, we invoke the
chain rule:
Dv
Dt = D2r
Dt2 = D
Dt
 Dr
Dt

= Dr
Dt
D
Dr
 Dr
Dt

= v Dv
Dr
(6.89)
gravitational instability and collapse
105
Thus we have
v Dv
Dr = −GMr
r2
,
(6.90)
which is trivial to integrate via separation of variables:
Z v
0 v′ dv′ = −GMr
Z r
r0
dr′
r′2 ,
(6.91)
where we are considering a fluid element that starts at radius r0
with a velocity v = 0. Evaluating the integrals and solving gives the
velocity as a function of position:
v = −
p
2GMr
1
r −1
r0
1/2
.
(6.92)
To obtain the solution as a function of time, we can integrate again.
The equation we have just written down is a first-order ODE for the
radius as a function of time:
˙
r = −
p
2GMr
1
r −1
r0
1/2
,
(6.93)
This ODE can be evaluated by the trigonometric substitution r =
r0 cos2 ξ. The solution, first obtained by Hunter (1962), is
−2r0(cos ξ sin ξ) ˙
ξ
=
−
s
2GMr
r0

1
cos2 ξ −1
1/2
(6.94)
2(cos ξ sin ξ) ˙
ξ
=
s
2GMr
r3
0
tan ξ
(6.95)
2 cos2 ξ dξ
=
s
2GMr
r3
0
dt
(6.96)
ξ + 1
2 sin 2ξ
=
t
s
2GMr
r3
0
.
(6.97)
We are interested in the time at which a given fluid element reaches
the origin, r = 0. This corresponds to ξ = π/2, so this time is
t = π
2
s
r3
0
2GMr
.
(6.98)
Suppose that the gas we started with was of uniform density ρ, so
that Mr = (4/3)πr3
0ρ. In this case we have
t = tff =
s
3π
32Gρ,
(6.99)
where we have defined the free-fall time tff: it is the time required for
a uniform sphere of pressureless gas to collapse to infinite density.
106
notes on star formation
This is of course just the characteristic growth time for the Jeans
instability in the regime of negligible pressure, up to a factor of order
unity.
For a uniform fluid this means that the collapse is synchronized
– all the mass reaches the origin at the exact same time. A more
realistic case is for the initial state to have some level of central
concentration, so that the initial density rises inward. Let us take
the initial density profile to be ρ = ρc(r/rc)−α, where α > 0 so the
density rises inward. The corresponding enclosed mass is
Mr =
4
3 −απρcr3
c
 r
rc
3−α
(6.100)
Plugging this in, the collapse time is
t =
s
(3 −α)π
32Gρc
r0
rc
α/2
.
(6.101)
Since α > 0, this means that the collapse time increases with initial
radius r0. This illustrates one of the most basic features of a collapse,
which will continue to hold even in the case where the pressure is
non-zero. Collapse of centrally concentrated objects occurs inside-out,
meaning that the inner parts collapse before the outer parts.
Within the collapsing region near the star, the density profile
also approaches a characteristic shape. If the radius of a given fluid
element r is much smaller than its initial radius r0, then its velocity is
roughly
v ≈vff ≡−
r
2GMr
r
,
(6.102)
where we have defined the free-fall velocity vff as the characteristic
speed achieved by an object collapsing freely onto a mass Mr. The
mass conservation equation is
∂Mr
∂t
= −v∂Mr
∂r
= −4πr2vρ
(6.103)
If we are near the star so that v ≈vff, then this implies that
ρ = (∂Mr/∂t)r−3/2
4π√2GMr
.
(6.104)
To the extent that we look at a short interval of time, over which
the accretion rate does not change much (so that ∂Mr/∂t is roughly
constant), this implies that the density near the star varies as ρ ∝
r−3/2.
What sort of accretion rate do we expect from a collapse like this?
For a core of mass Mc = [4/(3 −α)]πρcr3
c, the last mass element
gravitational instability and collapse
107
arrives at the center at a time
tc =
s
(3 −α)π
32Gρc
=
r
3 −α
3
tff(ρc),
(6.105)
so the time-averaged accretion rate is
⟨˙
M⟩=
r
3
3 −α
Mc
tff(ρc).
(6.106)
In order to get a sense of the numerical value of this, let us suppose
 that our collapsing object is a marginally unstable Bonnor-Ebert
sphere (see Problem Set 2). Such an object does not have negligible
pressure, but the pressure will only change the collapse rate at order
 unity. Problem Set 2 includes a calculation of the structure of a
maximum-mass Bonnor-Ebert sphere, so we will just quote the value.
The maximum mass is
MBE = 1.18
c4
s
p
G3Ps
,
(6.107)
where Ps is the pressure at the surface of the sphere and cs is the
thermal sound speed in the core.
Let us suppose that the surface of the core, at radius rc, is in
thermal pressure balance with its surroundings. Thus Ps = ρcc2
s, so
we may rewrite the Bonnor-Ebert mass as
MBE = 1.18
c3
s
p
G3ρc
.
(6.108)
A Bonnor-Ebert sphere does not have a powerlaw structure, but if
we substitute into our equation for the accretion rate and say that
the factor of
p
3/(3 −α) is a number of order unity, we find that the
accretion rate is
⟨˙
M⟩≈c3
s/
p
G3ρc
1/
p
Gρc
= c3
s
G .
(6.109)
This is an extremely useful expression, because we know the
sound speed cs from microphysics. Thus, we have calculated the
rough accretion rate we expect to be associated with the collapse
of any object that is marginally stable based on thermal pressure
support. Plugging in cs = 0.19 km s−1, we get ˙
M ≈2 × 10−6 M⊙yr−1
as the characteristic accretion rate for these objects. Since the typical
stellar mass is a few tenths of M⊙, based on the peak of the IMF, this
means that the characteristic star formation time is of order 105 −106
yr. Of course this conclusion about the accretion rate only applies
to collapsing objects that are supported mostly by thermal pressure.
Other sources of support produce higher accretion rates, as we will
see when we get to massive stars.
7
Stellar Feedback
Suggested background reading:
• Krumholz, M. R., et al. 2014,
in “Protostars and Planets VI",
ed. H. Beuther et al., pp. 243-266
Suggested literature:
• Murray, N., Quataert, E., & Thompson,
 T. A. 2010, ApJ, 709, 191
• Dale, J. E., Ngoumou, J., Ercolano,
B., & Bonnell, I. A. 2014, MNRAS,
442, 694
The final piece of physics we will cover before moving on to the star
formation process itself is the interaction of stellar radiation, winds,
and other forms of feedback with the interstellar medium. Our goal
in this chapter is to develop a general formalism for describing the
various forms of feedback that stars an exert on their environments,
and to make an inventory of the most important processes.
7.1
General Formalism
7.1.1
IMF-Averaged Yields
In most cases when considering feedback, we will be averaging over
many, many stars. Consequently, it makes sense to focus not on
individual stars, but on the collective properties of stellar populations.
For this reason, a very useful first step is to consider budgets of mass,
momentum, and energy.
We have already encountered a formalism of this sort in our
discussion of galactic star formation rate indicators in Chapter 2, and
the idea is similar here. To begin, let us fix the IMF
ξ(m) ≡
dn
d ln m,
(7.1)
with the normalization chosen so that R
ξ(m) dm = 1. Note that
ξ(m) is defined per unit logarithm mass rather than per unit mass,
so that it describes the number of stars in a mass range from ln m to
ln m + d ln m. However, this function also has a second interpretation,
since dn/d ln m = m(dn/dm): this quantity is the total stellar mass
found in stars with masses between m and m + dm. Consequently, the
mean stellar mass is
m =
R ∞
−∞mξ(m) d ln m
R ∞
−∞ξ(m) d ln m =
1
R ∞
−∞ξ(m) d ln m,
(7.2)
110
notes on star formation
where the second step follows from our choice of normalization.
The numerator here represents the total mass of the stars, and the
denominator is the number of stars. Note that ξ(m) is presumably
zero outside some finite interval in mass – we are writing the limits
of integration as −∞to ∞only for convenience.
We will further assume that, from stellar evolution, we know the
rate q at which stars produce some quantity Q as a function of their
starting mass and age, where ˙
Q = q. For example if the quantity
Q we are concerned with is total radiant energy E, then q is the
bolometric luminosity L(m, t) of a star of mass m and age t. Now
consider a population of stars that forms in a single burst at time 0.
The instantaneous production rate for these stars is
q(t) = M
Z ∞
−∞d ln m ξ(m)q(m, t).
(7.3)
We use this equation to define the IMF-averaged production rate,
D q
M
E
=
Z ∞
−∞d ln m ξ(m)q(m, t).
(7.4)
Note that this rate is a function of the age of the stellar population t.
We can also define a lifetime-averaged yield. Integrating over all time,
the total amount of the quantity produced is
Q = M
Z ∞
−∞d ln m ξ(m)
Z ∞
0
dt q(M, t).
(7.5)
We therefore define the IMF-averaged yield
 Q
M

=
Z ∞
−∞d ln m ξ(m)
Z ∞
0
dt q(M, t).
(7.6)
The meaning of these quantities is that ⟨q/M⟩is the instantaneous
rate at which the stars are producing Q per unit stellar mass, and
⟨Q/M⟩is the total amount produced per unit mass of stars formed
over the stars’ entire lifetimes.
In practice we cannot really integrate to infinity for most quantities,
 since the lifetimes of some stars may be very, very long compared
 to what we are interested in. For example the luminous output
of a stellar population will have a large contribution for ∼5 Myr
coming from massive stars, which is mostly what is of interest. However,
 if we integrate for 1000 Gyr, we will find that the luminous
output is dominated by the vast numbers of ∼0.2 M⊙stars near the
peak of the IMF that are fully convective and thus are able to burn all
of their hydrogen to He. In reality, though, this is longer than the age
of the Universe. In practice, therefore, we must define our lifetime
averages as cutting off after some finite time.
It can also be useful to define a different IMF average. The quantities
 we have discussed thus far are yields per unit mass that goes into
stellar feedback
111
stars. Sometimes we are instead interested in the yield per unit mass
that stays locked in stellar remnants for a long time, rather than the
mass that goes into stars for ∼3 −4 Myr and then comes back out in
supernovae. Let us define the mass of the remnant that a star of mass
m leaves as w(m). If the star survives for a long time, w(m) = m. In
this case, the mass that is ejected back into the ISM is
Mreturn = M
Z ∞
−∞d ln m ξ(m)[m −w(m)] ≡RM,
(7.7)
where we define R as the return fraction. The mass fraction that stays
locked in remnants is 1 −R.
Of course “long time" here is a vague term. By convention (defined
 by Tinsley 1980), we choose to take w(m) = m for m = 1 M⊙.
We take w(m) = 0.7 M⊙for m = 1 −8 M⊙and w(m) = 1.4 M⊙for
m > 8 M⊙, i.e., we assume that stars from 1 −8 M⊙leave behind
0.7 M⊙white dwarfs, and stars larger than that mass form 1.4 M⊙
neutron stars. If one puts this in for a Chabrier (2005) IMF, the result
is R = 0.46, meaning that these averages are larger by a factor of
1/0.54.
Given this formalism, it is straightforward to use a set of stellar
evolutionary tracks plus an IMF to compute ⟨q/M⟩or ⟨Q/M⟩for
any quantity of interest. Indeed, this is effectively what starburst99
(Leitherer et al., 1999) and programs like it do. The quantities of
greatest concern for massive star feedback are the bolometric output,
ionizing photon output, wind momentum and energy output, and
supernova output.
7.1.2
Energy- versus Momentum-Driven Feedback
Before discussing individual feedback mechanisms in detail, it is
also helpful to lay out two general categories that can be used to
understand them. Let us consider a population of stars surrounded
by initially-uniform interstellar gas. Those stars eject both photons
and baryons (in the form of stellar winds and supernova ejecta) into
the surrounding gas, and these photons and baryons carry both
momentum and energy. We want to characterize how the ISM will
respond.
One important consideration is that, as we have already shown,
it is very hard to raise the temperature of molecular gas (or even
dense atomic gas) because it is able to radiate so efficiently. A factor
of ∼10 increase in the radiative heating rate might yield only a tens
of percent increase in temperature. This is true as long as the gas is
cold and dense, but at sufficiently high temperatures or if the gas
is continuously illuminated then the cooling rate begins to drop off,
and it is possible for gas to remain hot.
112
notes on star formation
A critical distinction is therefore between mechanisms that are able
to keep the gas hot for a time that is long enough to be significant
(generally of order the crossing time of the cloud or longer), and
those where the cooling time is much shorter. For the latter case, the
energy delivered by the photons and baryons will not matter, only
the momentum delivered will. The momentum cannot be radiated
away. We refer to feedback mechanism where the energy is lost
rapidly as momentum-driven feedback, and to the opposite case
where the energy is retained for at least some time as energy-driven,
or explosive, feedback.
To understand why the distinction between the two is important,
let us consider two extreme limiting cases. We place a cluster of stars
at the origin and surround it by a uniform region of gas with density
ρ. At time t = 0, the stars "turn on" and begin emitting energy and
momentum, which is then absorbed by the surrounding gas. Let
the momentum and energy injection rates be ˙
pw and ˙
Ew; it does
not matter if the energy and momentum are carried by photons or
baryons, so long as the mass swept up is significantly greater than
the mass carried by the wind.
The wind runs into the surrounding gas and causes it to begin
moving radially outward, which in turn piles up material that is further
 away, leading to an expanding shell of gas. Now let us compute
the properties of that shell in the two extreme limits of all the energy
being radiated away, and all the energy being kept. If all the energy
is radiated away, then at any time the radial momentum of the shell
must match the radial momentum injected up to that time, i.e.,
psh = Mshvsh = ˙
pwt.
(7.8)
The kinetic energy of the shell is
E =
p2
sh
2Msh
= 1
2vsh ˙
pwt.
(7.9)
For comparison, if none of the energy is radiated away, the energy is
simply
E = ˙
Ewt.
(7.10)
Thus the energy in the energy-conserving case is larger by a factor of
1
vsh
· 2 ˙
Ew
˙
pw
.
(7.11)
If the energy injected by the stars is carried by a wind of baryons,
then 2 ˙
Ew/ ˙
pw is simply the speed of that wind, while if it is carried
by photons, then 2 ˙
Ew/ ˙
pw = 2c. Thus the energy in the energyconserving
 case is larger by a factor of 2c/vsh for a photon wind,
stellar feedback
113
and vw/vsh for a baryon wind. These are not small factors: observed
expanding shells typically have velocities of at most a few tens of
km s−1, while wind speeds from massive stars, for example, can be
thousands of km s−1. Thus it matters a great deal where a particular
feedback mechanism lies between the energy- and momentumconserving
 limits.
7.2
Momentum-Driven Feedback Mechanisms
We are now ready to consider individual mechanisms by which stars
can deliver energy and momentum to the gas around them. Our
goal is to understand what forms of feedback are significant and to
estimate their relative budgets of momentum and energy.
7.2.1
Radiation Pressure and Radiatively-Driven Winds
The simplest form of feedback to consider is radiation pressure. Since
the majority of the radiant energy deposited in the ISM will be reradiated
 immediately, radiation pressure is (probably) a momentumdriven
 feedback. To evaluate the momentum it deposits, one need
merely evaluate the integrals over the IMF we have written down
using the bolometric luminosities of stars. Murray & Rahman (2010)
find
 L
M

= 1140 L⊙M−1
⊙= 2200 erg s−1 g−1,
(7.12)
and the corresponding momentum injection rate is
 ˙
prad
M

= 1
c
 L
M

= 7.3 × 10−8 cm s−2 = 23 km s−1 Myr−1
(7.13)
The physical meaning of this expression is that for every gram of
matter that goes into stars, those stars produce enough light over 1
Myr to accelerate another gram of matter to a speed of 23 km s−1.
For very massive stars, radiation pressure also accelerates winds off
the star’s surfaces; for such stars, the wind carries a bit under half
the momentum of the radiation field. Including this factor raises the
estimate by a few tens of percent. However, these winds may also be
energy conserving, a topic we will approach momentarily.
Integrated over the lifetimes of the stars out to 100 Myr, the total
energy production is
 Erad
M

= 1.1 × 1051 erg M−1
⊙
(7.14)
The majority of this energy is produced in the first ∼5 Myr of a
stellar population’s life, when the massive stars live and die.
114
notes on star formation
It is common to quote the energy budget in units of c2, which
gives a dimensionless efficiency with which stars convert mass into
radiation. Doing so gives
ϵ = 1
c2
 Erad
M

= 6.2 × 10−4.
(7.15)
The radiation momentum budget is simply this over c,
D prad,tot
M
E
= 190 km s−1.
(7.16)
This is an interesting number, since it is not all that different than
the circular velocity of a spiral galaxy like the Milky Way. It is a
suggestion that the radiant momentum output by stars may be
interesting in pushing matter around in galaxies – probably not by
itself, but perhaps in conjunction with other effects.
7.2.2
Protostellar Winds
A second momentum-driven mechanism, that we will discuss in
more detail in Chapters 14 and 15, is protostellar jets. All accretion
disks appear to produce some sort of wind that carries away some of
the mass and angular momentum, and protostars are no exception.
The winds from young stars carry a mass flux of order a few tens of
percent of the mass coming into the stars, and eject it with a velocity
of order the Keplerian speed at the stellar surface. Note that these
winds are distinct from the radiatively-driven ones that come from
main sequence O stars. They are very different in both their driving
mechanism and physical characteristics.
Why do we expect protostellar winds to be a momentum-driven
feedback mechanism instead of an energy-driven one? The key lies in
their characteristic speeds. Consider a star of mass M∗and radius R∗.
Its wind will move at a speed of order
vw ∼
s
GM∗
R∗
= 250 km s−1
 M∗
M⊙
1/2  R∗
3R⊙
−1/2
,
(7.17)
where the scalings are for typical protostellar masses and radii. The
kinetic energy per unit mass carried by the wind is v2
w/2, and when
the wind hits the surrounding ISM it will shock and this kinetic
energy will be converted to thermal energy. We can therefore find
the post-shock temperature from energy conservation. The thermal
energy per unit mass is (3/2)kBT/µmH, where µ is the mean particle
mass in H masses. Thus the post-shock temperature will be
T = µmHv2
w
3kB
∼5 × 106 K
(7.18)
stellar feedback
115
for the fiducial speed above, where we have used µ = 0.61 for fully
ionized gas. This is low enough that gas at this temperature will be
able to cool fairly rapidly, leaving us in the momentum-conserving
limit.
So how much momentum can we extract? To answer that, we will
use our formalism for IMF averaging. Let us consider stars forming
over some timescale tform. This can be a function of mass if we wish.
Similarly, let us assume for simplicity that the accretion rate during
the formation stage is constant; again, this assumption actually
makes no difference to the result, it just makes the calculation easier.
Thus a star of mass m accretes at a rate ˙
m = m/tform over a time
tform, and during this time it produces a wind with a mass flux f ˙
m
that is launched with a speed vK. Thus IMF-averaged yield of wind
momentum is
D pw
M
E
=
Z ∞
−∞d ln m ξ(m)
Z tform
0
dt f mvK
tform
.
(7.19)
In reality vK, f, and the accretion rate probably vary over the formation
 time of a star, but to get a rough answer we can assume that they
are constant, in which case the integral is trivial and evaluates to
D pw
M
E
= f vK
Z ∞
−∞d ln m ξ(m)m = f vK
(7.20)
where the second step follows from the normalization of the IMF.
Thus we learn that winds supply momentum to the ISM at a rate of
order f vK. Depending on the exact choices of f and vK, this amounts
to a momentum supply of a few tens of km s−1 per unit mass of stars
formed.
Thus in terms of momentum budget, protostellar winds carry
over the full lifetimes of the stars that produce them about as much
momentum as is carried by the radiation each Myr. Thus if one
integrates over the full lifetime of even a very massive, short-lived
star, it puts out much more momentum in the form of radiation than
it does in the form of outflows. So why worry about outflows at all,
in this case?
There are two reasons. First, because the radiative luminosities
of stars increase steeply with stellar mass, the luminosity of a stellar
population is dominated by its few most massive members. In small
star-forming regions with few or no massive stars, the radiation
pressure will be much less than our estimate, which is based on
assuming full sampling of the IMF, suggests. On the other hand,
protostellar winds produce about the same amount of momentum
per unit mass accreted no matter what stars are doing the accreting
– this is just because vK is not a very strong function of stellar mass.
(This is a bit of an oversimplification, but it is true enough for this
116
notes on star formation
purpose.) This means that winds will be significant even in regions
that lack massive stars, because they can be produced by low-mass
stars too.
Second, while outflows carry less momentum integrated over
stars’ lifetimes, when they are on they are much more powerful.
Typical formation times, we shall see, are of order a few times 105
yr, so the instantaneous production rate of outflow momentum
is typically ∼100 km s−1 Myr−1, a factor of several higher than
radiation pressure. Thus winds can dominate over radiation pressure
significantly during the short phase when they are on.
7.3
(Partly) Energy-Driven Feedback Mechanisms
7.3.1
Ionizing Radiation
Massive stars produce significant amounts of ionizing radiation.
From Murray & Rahman (2010), the yield of ionizing photons from a
zero-age population is
 S
M

= 6.3 × 1046 photons s−1 M−1
⊙.
(7.21)
The corresponding lifetime-averaged production of ionizing photons
is
Stot
M

= 4.2 × 1060 photons M−1
⊙.
(7.22)
H ii Region Expansion
We will not go into tremendous detail on
how these photons interact with the ISM, but to summarize: photons
capable of ionizing hydrogen will be absorbed with a very short
mean free path, producing a bubble of fully ionized gas within which
all the photons are absorbed. The size of this bubble can be found by
equating the hydrogen recombination rate with the ionizing photon
production rate, giving
S = 4
3πr3
i nenpαB,
(7.23)
where ri is the radius of the ionized region, ne and np are the number
densities of electrons and protons, and αB is the recombination rate
coefficient for case B, and which has a value of roughly 3 × 10−13
cm3 s−1. Cases A and B, what they mean, and how this quantity
is computed, are all topics discussed at length in standard ISM
INTRODUCTION
A common signature associated with the earliest stages of highmass
 star formation is the presence of hot molecular cores, which
are compact (≤0.05 pc) objects with high temperatures (≳100 K)
and densities (n ≳106 cm−3), characterized by a very rich chemistry
of complex organic molecules (COMs, molecules with >6 atoms,
e.g. Blake et al. 1987, Kurtz 2005, Herbst & van Dishoeck 2009,
Ob¨
erg et al. 2014). Such a rich chemistry is supposed to be triggered
first during a cold and dense phase, which favours the formation of
simple hydrogenated species on the surface of dust grains. In a sub⋆E-mail:
 a.palau@crya.unam.mx
sequent ‘warm-up’ phase, radicals are efficiently recombined on
the grain surfaces (e.g. Garrod & Herbst 2006; Aikawa et al. 2008;
Garrod, Widicus Weaver & Herbst 2008), and finally the heating
from the nascent massive star evaporates the complex molecules
from the dust grain mantles and triggers additional gas-phase reactions
 (e.g. Millar, MacDonald & Gibb 1997). However, these
models fail to predict by more than one order of magnitude the abundances
 of well-measured COMs, such as HCOOCH3 and CH3OCH3
(e.g. Taquet, Ceccarelli & Kahane 2012, Lykke et al. 2017), to the
point that very recent works are starting to propose that the role
of gas-phase chemistry might be more important than previously
thought (e.g. Balucani, Ceccarelli & Taquet 2015, Enrique-Romero
et al. 2016).
C
⃝2017 The Authors
Published by Oxford University Press on behalf of the Royal Astronomical Society
Downloaded from https://academic.oup.com/mnras/article/467/3/2723/2877226 by University of Manchester user on 17 February 2023
2724
A. Palau et al.
In addition, COMs have unambiguously been detected in cavities
 of outflows powered by low-mass (≲2 M⊙) protostars
(e.g. IRAS 16293−2422: Chandler et al. 2005; L1157-B1: Arce
et al. 2008; Codella et al. 2015) and intermediate-mass (2–8 M⊙)
protostars (e.g. Orion-KL: Liu et al. 2002; Favre et al. 2011b;
Zapata, Schmid-Burgk & Menten 2011; NGC 2071: van Kempen
et al. 2014). Actually, chemical modelling indicates that photodissociation
 in conjunction with reactive desorption in the outflow cavity
walls could be a relevant process to enhance gas-phase abundances
of COMs (Drozdovskaya et al. 2015), although this has been tested
only in the low-mass case.
Recently, several works have studied the morphology of the COM
emission at sufficiently high spatial resolution to disentangle the
possible origin from the disc and/or outflow. In particular, Palau et al.
(2011) present emission from COMs towards three intermediatemass
 hot cores (one in IRAS 22198+6336, two in AFGL 5142)
down to disc spatial scales (∼500 au), and find that in two cases
the COM emission is resolved in the disc direction, suggesting
that COMs are tracing protostellar discs in these cases. On the
other hand, Fuente et al. (2014) did not resolve the emission from
several COMs down to a spatial resolution of 1700 au towards
NGC 7129-FIRS2, leaving open the possibility that some COMs
are tracing shocks in the outflow. However, these hot cores are
associated with intermediate-mass protostars, and thus their UV
radiation and/or outflow momentum might be too faint to efficiently
heat and evaporate the molecules in the outflow cavity walls.
We
present
here
subarcsecond
interferometric
observations
 of COMs towards the prototypical high-mass protostar
IRAS 20126+4104, with a luminosity of ∼8900 L⊙, a mass of
∼12 M⊙(Chen et al. 2016) and located at a distance of 1.64 kpc
(e.g. Cesaroni et al. 1999; Moscadelli et al. 2011). This allowed
us to resolve the emission from COMs, of up to 10 atoms, down
to ∼600 AU for this high-mass protostar, adding crucial information
 about the possible origin of COM emission. This is important,
because the object is known to drive a highly collimated bipolar
outflow (opening angle ∼9◦), oriented in the south-east–north-west
direction (with position angle PA = 115◦), and being almost on
the plane of the sky (Moscadelli et al. 2011). In addition, the jet
structure associated with this outflow has been recently studied
at subarcsecond angular resolution, revealing that the jet is asymmetric,
 with the southeastern lobe being probably older than the
northwestern one, and being already associated with a cavity bright
in H2 at 2.12 µm, located at about 800–1000 au from the protostar
(Cesaroni et al. 2013). On the other hand, the northwestern lobe
should be still at the very beginning of the creation of the cavity.
Therefore, the subarcsecond observations presented here constitute
an excellent data set to study the emission of COMs at an angular
resolution that allows to disentangle the emission coming from the
jet and the emission coming from the disc. In Section 2, we describe
the observations. In Section 3, we present the observed spectra towards
 IRAS 20126+4104 with the line identification and integrated
emission images of the strongest detected COMs. In Section 4, we
study the morphology of the COM emission relative to the dust continuum,
 and present a shock model coupled to a gas–grain chemical
network used to explain our findings. In Section 5, we discuss the
results and in Section 6, we present our main conclusions.
2 OBSERVATIONS
The data set presented in this work is part of the data set reported
in Cesaroni et al. (2014), which is focused on the 1.4 mm continuum
 and CH3CN (12–11) emission. We provide here only a brief
description of the observations, and refer the reader to Cesaroni et al.
(2014) for further details. The IRAM Plateau de Bure Interferometer
(PdBI1) was used in A and B configurations to observe the continuum
 and line emission at 220.500 GHz of IRAS 20126+4104.
Observations were carried out on 2008 January 29, February 13
and 16 and March 15, with the phase centre being α(J2000) =
20:14:26.036, δ(J2000) = 41:13:32.52. Phase and bandpass calibration
 were performed using 2013+370 and 3C273, yielding a
phase rms noise of 30◦. This corresponds to an uncertainty in absolute
 position of 0.03–0.05 arcsec. The absolute flux density scale
was determined from MWC349.
Two correlator units of 160 MHz of bandwidth with 256 spectral
channels were used to observe the CH3CN (12–11) lines in each
polarization (Cesaroni et al. 2014). Four additional units (per polarization)
 of 320 MHz bandwidth with 128 channels were used to
observe the continuum across ∼1.2 GHz. This, together with the
aforementioned units of 160 MHz, allowed us to cover a total frequency
 range of 1.65 GHz. Most of the COMs were detected in the
320 MHz units, which provide a spectral resolution of 2.5 MHz or
3.4 km s−1.
Calibration and imaging were performed using the GILDAS software
 package,2 using natural weighting over the entire frequency
range. The synthesized beam is 0.46 arcsec × 0.32 arcsec at
PA = 56◦and the rms of the final cleaned maps is ∼3 mJy beam−1
per channel. The conversion factor from Jy beam−1 to K is
170.5 K Jy−1 beam.
3 RESULTS
Fig. 1 presents the beam averaged spectrum in the frequency range
219 750–221 400 MHz for the two positions indicated in Fig. 2(a)
with green dots. One position is centred on the peak of the continuum
 emission (the putative position of the disc, Cesaroni et al. 2014)
and the other position is centred along the outflow direction, about
∼1 arcsec to the south-east. In order to identify the lines detected
 above 5σ (see Fig. 1), we used the XCLASS software (M¨
oller,
Endres & Schilke 2017) to generate synthetic spectra that are fitted
 to the observed spectra. XCLASS assumes Local Thermodynamic
Equilibrium,3 and takes into account opacity effects and line blending
 from multiple species and components. XCLASS uses the spectroscopic
 data saved in the VAMDC4 portal, combining the CDMS
(Cologne Database for Molecular Spectroscopy; M¨
uller et al. 2005)
and JPL (Jet Propulsion Laboratory; Pickett et al. 1998) spectral line
catalogues. The main adjustable parameters in the creation of synthetic
 spectra are the source size, the rotational temperature, the column
 density of the molecule, the line width and the velocity of the
source. We used the model optimizer MAGIX (M¨
oller et al. 2013)
within XCLASS to fit the observed spectra with the synthetic spectra
 generated including the molecules responsible for each detected
line (listed in Table 1). To obtain reasonable fits for CH3CN, we
had to use two components: a foreground cold component and an
inner hotter component.
1 IRAM is supported by INSU/CNRS (France), MPG (Germany) and IGN
(Spain).
2 GILDAS:
Grenoble
Image
and
Line
Data
Analysis
System,
see
http://www.iram.fr/IRAMFR/GILDAS.
3 XCLASS: eXtended CASA Line Analysis Software Suite, considers that one
excitation temperature describes the different line transitions for each model
component.
4 Virtual Atomic and Molecular Data Centre, http://vamdc.eu/.
MNRAS 467, 2723–2752 (2017)
Downloaded from https://academic.oup.com/mnras/article/467/3/2723/2877226 by University of Manchester user on 17 February 2023
COMs in IRAS 20126+4104 at ∼600 au
2725
Figure 1. Top: PdBI beam averaged spectrum towards the peak of the continuum of IRAS 20126+4104 (the putative position of the disc, marked in Fig. 2a
with green dots). Bottom: idem towards the ‘outflow’ position (see main text, marked in Fig. 2a with green dots). The red line corresponds to the synthetic
spectrum resulting from summing the individual synthetic spectra fitted using XCLASS. Vertical green lines mark the transitions whose zeroth-order moment has
been imaged and is shown in Figs 2 and 3. The grey horizontal line marks the 5σ detection threshold. Labels indicate the molecule that dominates the emission
in each spectral line.
For the adjustable parameters, we assumed a filling factor equal
to unity, and a linewidth of 8.0 km s−1 (for all the components,
except for 13CO, for which we used 15.0 km s−1, and for the foreground
 component of CH3CN for which we used 2.5 km s−1).
The line width of 8.0 km s−1 was obtained from the average of
line widths measured for the strongest detected lines. The adopted
VLSR for each molecule are listed in Table 1, and are obtained
from a Gaussian fit to the strongest line of each molecule, in the
case the molecule is not blended and is unambiguously identified,
or from a simultaneous fit to all the lines of HCOOCH3 for the
other cases, as HCOOCH3 is one of the molecules with highest
number of detected transitions in our observed frequency range.
MNRAS 467, 2723–2752 (2017)
Downloaded from https://academic.oup.com/mnras/article/467/3/2723/2877226 by University of Manchester user on 17 February 2023
2726
A. Palau et al.
(a)
(b)
(c)
(d)
Figure 2. (a) PdBI 1.4 mm continuum image (Cesaroni et al. 2014); (b)
zeroth-order moment for 13CO + CH3OH; (c) zeroth-order moment for SO,
integrated from −8 to +8 km s−1 with respect to the systemic velocity (low
velocity); (d) zeroth-order moment for SO, integrated from 11 to 32 km s−1
with respect to the systemic velocity (high velocity, red contours) and from
−26 to −12 km s−1 with respect to the systemic velocity (high velocity,
blue contours). The transitions corresponding to panels ‘b’, ‘c’ and ‘d’ are
marked with green vertical lines in Fig. 1, and their frequency and quantum
numbers are given in Table 1. In all panels, the two crosses correspond to the
K-band infrared sources reported by Sridharan, Williams & Fuller (2005)
tracing the outflow cavities, the colour image corresponds to the emission
of H2 at 2.12 µm from Cesaroni et al. (2013), also tracing the (southeastern)
outflow cavity (Cesaroni et al. 2013), and the star symbol marks the position
of the 1.4 mm peak (panel ‘a’). The two green dots in panel ‘a’ indicate
the positions (peak, outflow) where the spectra shown in Fig. 1 have been
extracted.
The column density ratios CH3OH/13CH3OH and CH3CN/CH13
3 CN
were allowed to vary from 30 to 60 (e.g. Wilson & Rood 1994;
Visser, van Dishoeck & Black 2009; Jørgensen et al. 2016; Li
et al. 2017), and the best fits correspond to values of these
ratio abundances around 30. The rotational temperature was
left as a free parameter (ranging from 50 to 300 K, Cesaroni
et al. 1997, Isokoski, Bottinelli & van Dishoeck 2013) for CH3CN,
CH3COCH3, HCOOCH3 and NH2CN (only for the disc) as these
are the molecules with highest number of transitions detected in the
observed frequency range.
The averaged value of the fitted rotational temperatures, for the
outflow and peak positions, is used as an input for the remaining
molecules,5 leaving the column density as the only free parameter in
those cases. Table 1 lists the temperatures and column densities used
to generate the synthetic spectra. The errors of the fitted parameters
calculated by XCLASS are in the range 15–30 K for the temperature,
and 0.1–1 for the logarithm of the column density (in cm−2).
Fig. 1 shows the total fitted synthetic spectra (summing
up
the
contributions
of
all
the
identified
lines),
and
in
5 For 13CO, likely tracing more extended material, we assumed a temperature
of 100 K.
Appendix A we provide individual synthetic spectra for each molecular
 species.6
Figs 2 and 3 present the zeroth-order moment of the strongest
detected molecular lines. The simplest molecules are 13CO and SO.
The SO emission shows two velocity components. One is a lowvelocity
 component that traces the same velocity range as the other
molecular lines (integrated from −8 to +8 km s−1 with respect to
the systemic velocity, VLSR ∼−3.5 km s−1, Moscadelli et al. 2011;
Isokoski et al. 2013). The other one is a high-velocity component
(integrated up to ∼±30 km s−1 with respect to the systemic velocity).
 While the low-velocity SO emission presents an extended
X-shaped morphology (see Fig. 2c), the high-velocity emission

traces
the
well-known
collimated
outflow
driven
by
IRAS 20126+4104, with the redshifted lobe towards the south-east
and the blueshifted lobe towards the north-west of the continuum
source. The PA of the SO outflow is ∼130◦, similar to the PA obtained
 by Moscadelli et al. (2011) from water masers, of ∼115◦
(Fig. 2d). Both high-velocity redshifted and blueshifted emission
overlap at the position of the millimetre source.
Slightly more complex molecules (with up to four atoms) are
H213CO and HNCO. The HNCO emission also presents a X-shaped
structure, similar to SO, although more compact (Fig. 3b). On the
other hand, H213CO is better resolved in the south-west–north-east
direction, i.e. perpendicular to the outflow (Fig. 3a, PA ∼75◦).
Concerning even more complex molecules, we detected two
molecules with 5 atoms (HCOOH, CH2CO), four molecules with
6 atoms (CH3OH, CH3CN and both
13C isotopologues) and
four molecules containing between 8 and 10 atoms (HCOOCH3,
CH3CH2CN, CH3OCH3 and CH3COCH3). We would like to emphasize
 that all these molecules are detected both at the disc and
at the outflow positions (Fig. 1). At the position of the disc we
additionally detected NH2CN and (CH2OH)2. The molecule with
the highest number of strong transitions in the covered frequency
range is HCOOCH3 (see Fig. A11 of Appendix A). The integrated
emission of these molecules consists of a centrally peaked structure
at the position of the millimetre continuum source (Fig. 3) with an
elongation towards the south(east), especially clear in HCOOCH3,
CH3OCH3 and HCOOH. An elongation towards the south is also
notable in CH3CN (Cesaroni et al. 2014), and is attributed to an
inhomogeneous medium surrounding IRAS 20126+4104, which
should be less dense to the south because the outflow seems to have
already created a cavity (Cesaroni et al. 2013, 2014).
Table 2 lists the results of a 2D-Gaussian fit to the integrated
emission (using the task ‘JMFIT’ from the AIPS package) of the
strongest lines. The measured sizes range from 600 to 1200 au,
with PA ≳90◦for all the cases, except for H213CO. In particular,
the PA of HCOOH, HCOOCH3, CH3OCH3 and CH3COCH3 are
100–110◦. This orientation is close to the PA measured for the
jet from water masers (∼115◦, Moscadelli et al. 2011). Although
the uncertainties in the 2D-Gaussian fits are in some cases large
6 The total synthetic spectrum of Fig. 1 for the disc position presents a
clear deficit of emission at some frequencies with respect to the observed
spectrum, especially at around 220 150 and 220 199 MHz. We searched
for possible transitions responsible for this excess of observed emission and
found that for 220 150 MHz this excess could be due to CH2CH13CN (vinyl
cyanide). However, since we did not find evidences of the corresponding
main isotope in our spectrum, this identification remains tentative. As for
the emission at 220 199 MHz, this could be due to CH3COOH (acetic
acid). In this case, the molecule is not included in the CDMS data base and
prevents us from generating the synthetic spectrum with XCLASS, remaining
its identification tentative as well.
MNRAS 467, 2723–2752 (2017)
Downloaded from https://academic.oup.com/mnras/article/467/3/2723/2877226 by University of Manchester user on 17 February 2023
COMs in IRAS 20126+4104 at ∼600 au
2727
Table 1. Properties of the emission of COMs from IRAS 20126+4104 observed with a spatial resolution of ∼600 au, for two positions representative of the disc and the outflow. Molecules are sorted by increasing
number of atoms (increasing complexity).
Freq.a
ncritb
Euc
vdiscd
Tdisce
Toutfe
Ndisce
Noutfe
Molecule
Transition
(MHz)
(cm−3)
(K)
(km s−1)
(K)
(K)
(cm−2)
(cm−2)
τ disce
τ outfe
Xdisce
Xoutfe
Xoutf
Xdisc
13CO
2 – 1
220398.7
6.0 × 103
16
−6.4
100
100
7.9 × 1016
2.6 × 1017
0.04
0.23
2.9 × 10−8
5.0 × 10−7
17
SO 3
65 – 54
219949.4
7.1 × 105
35
−3.4
230
180
3.4 × 1016
1.3 × 1016
0.42
0.26
1.2 × 10−8
2.5 × 10−8
2.0
H213CO
31,2 – 21,1
219908.5
4.6 × 105
33
−2.4
230
180
5.6 × 1015
1.9 × 1015
0.07
0.04
2.0 × 10−9
3.6 × 10−9
1.7
HNCO
100, 10 – 90, 9
219798.3
8.6 × 105
58–102
−3.4
230
180
5.2 × 1016
1.0 × 1016
0.37
0.13
1.9 × 10−8
2.0 × 10−8
1.0
CH2CO
111, 11 – 101, 10
220178.2
−
76
−2.4
230
180
1.5 × 1016
5.5 × 1015
0.07
0.04
5.6 × 10−9
1.0 × 10−8
1.9
t-HCOOH
100, 10 – 90, 9
220038.1
−
59
−1.4
230
180
4.3 × 1016
4.0 × 1015
0.12
0.02
1.6 × 10−8
7.5 × 10−9
0.5
NH2CN
111, 10 – 101, 9
221361.2
−
63–295
−1.4
210(30)
−
3.3 × 1015
−
0.10
−
1.2 × 10−9
−
−
CH3OHf
10−5, 5 – 11−4, 8
220401.4
3.3 × 104
252–802
−0.4
230
180
2.5 × 1018
7.2 × 1017
0.21
0.09
9.3 × 10−7
1.4 × 10−6
1.5
CH3CNg
123 – 113
220709.0
1.9 × 106
69–419
−2.3
212(30)
235(15)
2.1 × 1016
3.8 × 1015
0.94
0.14
7.7 × 10−9
7.2 × 10−9
0.9
CH3CN v8=1h
12−6 – 11−6
221196.7
−
588–931
−1.4
230(30)
186(15)
6.3 × 1016
1.3 × 1016
0.21
0.03
2.3 × 10−8
2.4 × 10−8
1.0
HCOOCH3
1814, 5 – 1714,4
221047.8
−
103–357
−1.4
250(30)
170(15)
2.5 × 1017
5.5 × 1016
0.04
0.02
9.3 × 10−8
1.0 × 10−7
1.1
CH3CH2CN
252, 24 – 242, 23
220660.9
−
143
−3.4
230
180
5.2 × 1015
1.2 × 1015
0.06
0.02
1.9 × 10−9
2.3 × 10−9
1.2
CH3OCH3
244, 20 – 233, 21
220893.1
−
274–381
−1.4
230
180
1.0 × 1017
8.1 × 1016
0.04
0.04
3.9 × 10−8
1.5 × 10−7
4.0
CH3COCH3
220, 22 – 210, 21
220361.9
−
63–310
−1.4
230(30)
190(20)
2.6 × 1017
1.7 × 1016
0.11
0.02
9.7 × 10−8
3.2 × 10−8
0.3
aGg′(CH2OH)2
214, 18 – 204, 17i
221007.8
−
122–156
−1.4
230
−
7.9 × 1016
−
0.06
−
2.9 × 10−8
−
−
aFrequency of the transition imaged in Figs 2 and 3, or frequency with highest opacity within the observed frequency range otherwise. In all cases, the frequency is the nominal frequency for the corresponding
transition as given in the JPL or CDMS data bases (Picket et al. 1998, M¨
uller et al. 2005), whose quantum numbers are given in column (2).
bCritical density at 200 K for the transition specified in columns (2) and (3), calculated using the data available in the Leiden Atomic and Molecular Database (Sch¨
oier et al. 2005), and following equation 4 of
Shirley (2015). For HNCO and CH3CN, we give the critical density after logarithmic interpolation in temperature. For the case of H213CO, we give the critical density for the 31, 2 – 21, 1 transition of the main
isotope reported by Shirley (2015), which corresponds to a temperature of ∼100 K.
cUpper level energy corresponding to the transition specified in columns (2) and (3). For those molecules for which we detected more than one transition (see Appendix A), we give the range of upper level
energies covered by the different detected transitions (at the outflow position, or at the disc position if the molecule was only detected in the disc).
dVelocity adopted for each molecule (see Section 3) at the disc position. The velocity adopted at the outflow position is −3.4 km s−1 for all molecules except for 13CO and CH3CN, for which we adopted −6.4
and −4.4 km s−1, respectively.
eT and N correspond to the rotational temperature and column density resulting from the XCLASS fit for the disc and outflow positions. These values are also the ones used to build the synthetic spectra shown in
Fig. 1 and Appendix A. Wherever T is given with a number in parenthesis (the uncertainty), it has been fitted by XCLASS. If no number in parenthesis is given, T has been fixed to the average value for the disc or
outflow positions. τ corresponds to the opacity of the transition given in columns (2) and (3). The abundances, X, are given relative to the column density of H2 (see Section 3).
fBlended with 13CO (see Figs A1 and A8 of Appendix A).
gCH3CN has been fitted using two components: a cold foreground component and a hot inner component. In this table, we list only the parameters corresponding to the hot component.
hTransition with a small contribution from CH3OCH3 (see Figs A10 and A13 of Appendix A).
iThis transition corresponds to v = 1 – v = 0.
MNRAS 467, 2723–2752 (2017)
Downloaded from https://academic.oup.com/mnras/article/467/3/2723/2877226 by University of Manchester user on 17 February 2023
2728
A. Palau et al.
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
(i)
Figure 3. PdBI zeroth-order moment maps for a number of transitions (marked with green vertical lines in Fig. 1 and given in Table 1) from COMs detected
towards IRAS 20126+4104. In all panels, the two crosses correspond to the K-band infrared sources reported by Sridharan et al. (2005) tracing the outflow
cavities and the colour image corresponds to the emission of H2 at 2.12 µm from Cesaroni et al. (2013), also tracing the (south-eastern) outflow cavity (Cesaroni
et al. 2013, marked with a red ellipse in panel ‘a’ for further reference). The star symbol marks the position of the 1.4 mm peak from Cesaroni et al. (2014,
also shown in Fig. 2a).
(0.1–0.2 arcsec), the residual maps still indicate a clear excess of
emission to the south(east).
In Table 1, we list the fitted/adopted rotational temperature Trot
and the fitted column density N obtained by XCLASS for both the disc
and outflow positions. Trot ranges from 210 to 250 K for the disc
position and from 170 to 190 K for the outflow position (excluding
the fit to CH3CN), consistent with Cesaroni et al. (1997) and Chen
et al. (2016). To estimate the average Trot we did not take into
account the fit to CH3CN because we used two components in this
case. The resulting average Trot is 230 K for the disc and 180 K for
the outflow. The column densities at the disc position are around
1016–1017 cm−2, while those at the outflow position are about one
order of magnitude lower.
In order to test the LTE assumption, especially at the outflow
position where the density is not as high as in the disc, we used
the radiative transfer code RADEX (van der Tak et al. 2007) with the
temperature and column density inferred for the outflow position
(180 K and Table 1) and a linewidth of 8 km s−1, for the transitions
of the molecules detected by us (Table 1) and available in this code
(HNCO, H2CO, CH3CN).7 For these transitions, we determined the
densities required to reach brightness temperatures comparable to
those observed, and found that densities in the range 104–105 cm−3
yield brightness temperatures in the range 17–92 K, consistent
with our observations.8 Since the densities required to detect those
7 For CH3OH we refrained from using RADEX because our specific combination
 of parameters yielded instabilities in the code. In addition, the critical
density of CH3OH is only ∼104 cm−3 (see Table 1), and hence it should be
well thermalized for the range of densities inferred from the other molecules
(104–105 cm−3).
8 For the case of a density of 104 cm−3, we need in general column densities
in RADEX that are a factor of a few larger than those derived using XCLASS.
MNRAS 467, 2723–2752 (2017)
Downloaded from https://academic.oup.com/mnras/article/467/3/2723/2877226 by University of Manchester user on 17 February 2023
COMs in IRAS 20126+4104 at ∼600 au
2729
Table 2. Morphological properties of the emission of COMs from
IRAS 20126+4104 at a spatial resolution of ∼600 au.
Ang. sizeb
PAb
Sizeb
Moleculea
(arcsec × arcsec)
(◦)
(au × au)
H213CO
0.74 × 0.49
75 ± 10
1210 × 800
HNCO
0.53 × 0.46
114 ± 11
870 × 750
CH2CO
0.54 × 0.41
102 ± 20
890 × 670
HCOOH
0.48 × 0.37
105 ± 35
790 × 610
CH3OHc
0.83 × 0.79
85 ± 8
1360 × 1300
CH3CN v8 = 1
0.55 × 0.42
88 ± 5
720 × 610
HCOOCH3
0.73 × 0.43
98 ± 37
1200 × 710
CH3CH2CN
0.56 × 0.50
91 ± 42
920 × 820
CH3OCH3
0.69 × 0.49
96 ± 9
1130 × 800
CH3COCH3
0.52 × 0.43
96 ± 44
850 × 710
aThe frequency and quantum numbers of the imaged transition are given in
Table 1.
bDeconvolved sizes and PA obtained from a 2D-Gaussian fit to the zerothorder
 moment image of each transition. Uncertainties are typically ≲0.1 arcsec,
 except for HCOOCH3 and CH3CH2CN, which are ∼0.2–0.3 arcsec.
cBlended with 13CO (see Figs A1 and A8 of Appendix A).
transitions are easily reached at such close distances of a high-mass
protostar (see e.g. Palau et al. 2014), the LTE assumption seems to
be appropriate for both the disc and the outflow positions. This was
also hinted by the fact that the inferred rotational temperatures at
both positions are high, of the order of ∼200 K.
Finally, we estimated the column density of H2 by using
the 1.4 mm continuum emission shown in Fig. 2(a) (Cesaroni
et al. 2014), for the disc and outflow positions. To do this, we
integrated the 1.4 mm continuum emission inside the same polygon
where the spectra were extracted, and found 51 mJy for the disc and
5.7 mJy for the outflow. To estimate the corresponding mass of gas
and dust, we assumed optically thin emission, a dust temperature
equal to the average rotational temperature inferred by XCLASS for
the disc and outflow positions (see previous paragraph) and a dust
opacity at 1.4 mm of 0.7981 cm2 g−1 (inferred from the opacity tables
 of Ossenkopf & Henning 1994, for the case of thin ice mantles
at a density of 106 cm−3). Dividing the derived mass by the area of
the polygon with which we measured the 1.4 mm flux density, we
obtained an H2 column density of 2.7 × 1024 cm−2 for the disc and
5.3 × 1023 cm−2 for the outflow position. With these H2 column
densities, we calculated the abundances for each COM for the disc
and the outflow, finding values typically in the range 10−9–10−8 (see
Table 1), fully consistent with the CH3CN and CH3OH abundances
derived by Chen et al. (2016) at similar angular resolution for this
source. It is interesting to note that in most cases the abundance
of the COM is very similar or even higher at the outflow position
than at the disc position, with the clearest case being CH3OCH3,
for which the abundance in the outflow is a factor of 4 higher than
the abundance in the disc. The only COM presenting an abundance
clearly higher (about three times) in the disc than in the outflow
is CH3COCH3, suggesting an anticorrelation between CH3COCH3
and CH3OCH3.
4 ANALYSIS
In this section, we aim at studying more deeply the origin of the
COM emission and the abundance enhancement by comparing the
Thus, in the case that the true density at the outflow position was ∼104
cm−3, the LTE assumption would yield lower limit column densities by a
factor of a few, in full agreement with the work of Faure et al. (2014).
continuum versus the line emission maps, and by running a chemical
model to test different hypotheses for the chemical origin of COMs.
4.1 Line-to-continuum ratio maps
In the previous section, we found that the abundance of COMs
at the outflow position is of the same order as the abundance of
COMs at the position of the disc. Such a high abundance at the
outflow position may be due to either a real enhancement of COMs
at this position or to uncertainties in the excitation temperature,
as an underestimation of the excitation temperature at the outflow
position would yield a higher column density. By performing lineto-continuum
 ratio maps, in this section we evaluate which COMs
have been enhanced truly by the passage of the outflow.
The 1.4 mm continuum emission shown in Fig. 2(a) presents
an elongation towards the south-east, which is coincident with a
H2 infrared knot tracing the outflow cavity (Sridharan et al. 2005;
Cesaroni et al. 2013). Similarly, many of the partially resolved
COMs in IRAS 20126+4104 also present an elongation towards
the south-east, suggesting that such an elongation might be associated
 with the outflow cavity as well. Since, at first order, the
integrated intensity maps trace the COMs column density, and the
continuum map traces the total gas column density, with their ratio
being a first approach to the abundance, we computed the ratio of
the integrated intensity maps of different COMs to the continuum
emission (normalized to the value of that ratio at the peak of the
continuum emission, which is the putative position of the disc),
shown in Fig. 4.
Fig. 4 reveals for several COMs an enhancement in the
normalized line-to-continuum ratio towards the (south)east of
IRAS 20126+4104, i.e. along the outflow direction. This enhancement
 is particularly strong in the case of H2
13CO, HCOOCH3 and
most importantly CH3OCH3 (see Fig. 4a, f, h), with the ratio of the
COM in the cavity wall being more than three times higher than
the ratio in the disc. In particular, for the two molecules for which
this ratio is highest (H2
13CO and CH3OCH3), the normalized lineto-continuum
 ratio peaks about ∼0.5 arcsec to the east of the peak
of the continuum, and lies exactly upstream (to the west) of the H2
knot reported by Cesaroni et al. (2013), interpreted as tracing the
outflow cavity wall (marked with a red ellipse in Figs 3a and 4).
We consider now which physical process the line-to-continuum
ratio may be tracing. In the case of optically thin emission, and
assuming the Rayleigh–Jeans approximation, that the background
temperature is much lower than the excitation temperature, and that
the dust opacity is similar at the disc and outflow positions, the
line-to-continuum ratio, normalized to the ratio at the disc, can be
expressed as

TB,line
TB,cont

outf

TB,line
TB,cont

disc
= Xoutf
Xdisc
QTex,disc Tdust,disc eEu/(k Tex,disc)
QTex,outf Tdust,outfeEu/(k Tex,outf) ,
(1)
where TB is the brightness temperature of the line or the continuum
emission, X is the abundance of the molecule, Q is the partition
function at a given excitation temperature Tex, Eu is the energy of
the upper level of the imaged transition, k is the Boltzmann constant
and Tdust is the dust temperature. In our case, all the molecules for
which the line-to-continuum ratio is calculated present optically
thin emission (τ ≲0.4) even at the putative position of the disc
(see Table 1). Therefore, the normalized line-to-continuum ratio
depends essentially on the different abundances of the molecule at
the disc and outflow positions, and on the different Tex and Tdust at
the disc and outflow positions.
MNRAS 467, 2723–2752 (2017)
Downloaded from https://academic.oup.com/mnras/article/467/3/2723/2877226 by University of Manchester user on 17 February 2023
2730
A. Palau et al.
(a)
(b)
(c)
(d)
(e)
(f)
(g)
(h)
(i)
Figure 4. Normalized line-to-continuum ratio maps (generated by computing the ratio of the PdBI zeroth-order moment maps from Fig. 3 with respect to the
1 mm continuum emission, relative to the value of the ratio at the 1 mm peak so that all figures show a comparable scale). The star symbol marks the position
of the 1.4 mm peak from Cesaroni et al. (2014, also shown in Fig. 2a) and the red ellipse indicates the H2 knot tracing the outflow cavity (Cesaroni et al. 2013,
marked also in Fig. 3a). See Table 3 for further details about the physical conditions (abundance/temperature) that each line-to-continuum ratio map is probably
tracing.
We define a factor F that includes the dependence of the normalized
 line-to-continuum ratio on Tex, Tdust and Eu:
F ≡QTex,disc Tdust,disc eEu/(k Tex,disc)
QTex,outf Tdust,outf eEu/(k Tex,outf) .
(2)
Taking into account that the dependence of the partition function
with Tex for symmetric and asymmetric top molecules is proportional
 to T3/2, and assuming that Tex ∼Tdust, F can be finally written
as
F =

Tdisc
Toutf
5/2
e
Eu
k (1/Tdisc−1/Toutf).
(3)
We note that the assumption Tex ∼Tdust should be valid as a first
approach because what is relevant to estimate F is the ratio of those
temperatures at the disc and outflows positions, and it is likely that
both temperatures decrease in a similar way from one position to
the other. We further discuss this assumption in Section 5.1.
Thus, if F ∼1, the normalized line-to-continuum ratio will trace
the abundance variation between the disc and outflow positions. But
if F is of the order of the normalized line-to-continuum ratio, this
ratio will be a temperature tracer rather than an abundance tracer.
Since we have modelled the emission of the detected molecules at
the disc and outflow positions using XCLASS, we can have a first
estimate of F for the transitions for which we have imaged the
line-to-continuum ratio. The values of F for these transitions are
reported in Table 3, along with the observed peak of the normalized
line-to-continuum ratio.
Table 3 shows that the observed normalized line-to-continuum
ratio is very similar to the F factor for HNCO, CH2CO, HCOOH and
CH3COCH3, indicating that the variations in the line-to-continuum
map might be due to different temperatures in these cases. On the
contrary, for the case of H2
13CO, CH3OCH3 and, to a less extent,
HCOOCH3,9 the observed ratio is still larger by more than a factor
9 Strictly speaking, also CH3CN v8 = 1 presents a large difference between
the observed normalized line-to-continuum ratio and the F factor, but we
avoid its discussion here because the modelling of CH3CN required two
components, making its interpretation more difficult.
MNRAS 467, 2723–2752 (2017)
Downloaded from https://academic.oup.com/mnras/article/467/3/2723/2877226 by University of Manchester user on 17 February 2023
COMs in IRAS 20126+4104 at ∼600 au
2731
Table 3. Parameters used to assess the relevance of the abundance versus
temperature in the line-to-continuum ratio for certain transitions of COMs
detected in IRAS 20126+4104.
Eub
Moleculea
(K)
Fc
Ratiod
Tracing?e
H213CO
32.9
1.77
3.4
A+T
HNCO
58.0
1.72
1.6
T
CH2CO
76.5
1.68
1.6
T
HCOOH
58.6
1.72
1.6
T
CH3CN v8 = 1
931.0
0.65
2.0
A?
HCOOCH3
230.9
1.78
3.2
A+T
CH3CH2CN
143.0
1.55
2.4
A+T
CH3OCH3
274.4
1.32
3.2
A
CH3COCH3
123.9
1.44
1.6
T
aThe frequency and quantum numbers of the imaged transition are given in
Table 1.
bEnergy of the upper level of the imaged transition.
cF as defined in equation (3), using the temperatures for the disc and outflow
positions reported in Table 1.
dMaximum normalized line-to-continuum ratio as measured in the maps
shown in Fig. 4.
eTentative indication of what the line-to-continuum ratio might be tracing
for each transition, after comparing the observed line-to-continuum ratio
given in column (4) with the contribution of the different disc and outflow
 temperatures assessed by the ‘F’ factor given in column (3). ‘A’ for
‘abundance’ and ‘T’ for ‘temperature’.
of ∼2 compared to the F factor, and thus the observed variations in
the normalized line-to-continuum maps could be indicative of a real
abundance enhancement at the position of the H2 knot tracing the
outflow cavity. This is also consistent with the ratio of the abundance
at the outflow versus the abundance at the disc obtained from the
XCLASS fit for H2
13CO and CH3OCH3 (Table 1).
Thus, our data suggest that for those COMs for which the line-tocontinuum
 ratio is sensitive to abundance variations, the abundance
of these molecules peaks at the position of the H2 knot. This, together
 with the result presented in the previous section that the
abundances of most COMs at the disc and outflow positions are
comparable, and the fact that the gas temperature at the outflow
position is lower than in the disc, suggests a mechanism, additional
to thermal desorption, of enhancing the COM abundances in the
gas phase, probably related to the passage of a shock. In the next
section, we aim at studying the different processes that might be at
work in the outflow cavity to efficiently enhance the abundance of
COMs, namely shocks and UV radiation from the central massive
protostar.
4.2 Chemical modelling
We first studied the possibility that COMs are processed and released
 into the gas phase via photo-processes triggered by the stellar
radiation field. To do this, we ran models over a grid of Av (from
1 to 100 mag) to simulate different depths along the outflow cavity.
 In these models, presented in Walsh, Millar & Nomura (2010),
Walsh et al. (2012, 2014), density, impinging flux, gas and dust
temperature, and visual extinction are kept constant. We find that
for Av < 10 mag most species cannot survive the strong radiation
field in the gas phase (G ∼105 Gism, in Draine units, Draine 1978),
with the exception of H2 and CO that can self-shield, and the grains
are also stripped of the ice mantle. Further into the cavity wall,
the solution tends towards the ‘high extinction’ results, where thermal
 desorption dominates. In regions where the photodesorption
rate is faster than the thermal desorption rate, the photodissociation
rates are also high so that molecules released from the grains are
destroyed in the gas phase. Furthermore, recent photodesorption
experiments also show that larger molecules do not photodesorb
intact (Bertin et al. 2016; Cruz-Diaz et al. 2016). Therefore, the
UV radiation from the massive protostar does not seem to favour
the enhancement of COM abundances in the gas phase, and in the
following we consider the role of shocks along the outflow cavity.
To test our hypothesis that shocks may play a role in the liberation
of COMs from the grain mantle in the outflow cavity walls, we
calculate the chemical evolution of the gas and grain mantle as a
function of time (or distance) from the shock front. We assume
a C-type shock with shock velocity of 40 km s−1, a pre-shock
density of 104 cm−3 and a pre-shock gas and dust temperature of
80 K. The shock physical structure was constructed following the
parametric approximation of Jim´
enez-Serra et al. (2008) for C-type
shocks. The value of the pre-shock dust temperature is taken from
the modelled temperature profile of IRAS 20126+4104 at 1000
AU (Palau et al. 2014), and the value of the density corresponds to
an average of the typical values estimated in outflow cavity walls
(e.g. Neufeld et al. 2009, Bruderer et al. 2009, Visser et al. 2012,
Gomez-Ruiz et al. 2015, Kuiper, Yorke & Turner 2015, Gusdorf
et al. 2016).
Concerning the shock velocity, a water maser spot is detected to
the south-east of IRAS 20126+4104 with about 15 km s−1 (planeof-sky
 velocities, Cesaroni et al. 2014), while radial velocities are
detected up to ∼25 km s−1 (Cesaroni et al. 1999, Cesaroni et al.
2005, this work), which makes a total of ∼30 km s−1. Adopting
 a shock velocity slightly higher (40 km s−1) seems reasonable
 because there is only one water maser to the south-east of
IRAS 20126+4104, and the large number of water masers found to
the north-west suggest a higher velocity.
We assume that the gas and dust temperatures are decoupled, with
the dust remaining cold (80 K). We begin the chemical evolution
calculation at the time step corresponding to the peak temperature of
the ions that also corresponds to the peak sputtering rate. We assume
at this point that all grain mantle material is sputtered into the gas
phase. For the COMs observed in IRAS 20126+4104 we assume
the initial abundance is equal to that observed (Table 1), while
for all other species we adopt initial abundances from a single-point
molecular cloud model (10 K, 104 cm−3). For H2CO, we also use the
model output, as opposed to converting the abundance from H213CO
to H212CO, because H2CO has gas-phase pathways to formation,
unlike many of the larger COMs (e.g. CH3OH) that likely originate
mainly (or solely) from the ice mantle. The abundances measured in
IRAS 20126+4104 are about one–two orders of magnitude larger
than the abundances measured in pre-stellar cores (Vastel et al. 2014,
Jim´
enez-Serra et al. 2016), which is reasonable given the hot core
nature and the size scales (much closer to the massive protostar)
that we are studying here, and are a factor of 3–10 larger than the
abundances measured by Taquet et al. (2015) towards the hot corino
NGC 1333-IRAS2A at similar spatial scales.
The chemical network used here is based on the latest release
of the UMIST Database for Astrochemistry (RATE12, McElroy
et al. 2013) supplemented with gas–grain interactions (freeze out
and desorption) and grain surface chemistry. The grain-surface network
 and associated gas-phase chemistry is extracted from the
Ohio State University (OSU) network (Garrod et al. 2008). The
reaction rate coefficients are calculated as described in Walsh et al.
(2012, 2014). The gas-phase chemistry was also supplemented with
additional neutral–neutral reactions extracted from the NIST Chemical
 Kinetics Database (http://kinetics.nist.gov/kinetics/index.jsp).
MNRAS 467, 2723–2752 (2017)
Downloaded from https://academic.oup.com/mnras/article/467/3/2723/2877226 by University of Manchester user on 17 February 2023
2732
A. Palau et al.
Figure 5. Top: Physical structure of a shock with velocity, Vs = 40 km s−1
and a pre-shock density of 104 cm−3. Ti and Tn represent the temperature
of the ions and neutrals, respectively. Middle and bottom: Fractional abundances
 (with respect to H2) of gas-phase COMs as a function of distance
from the shock front. In all panels, the vertical dashed line corresponds
to the peak ion temperature (see text for details). The thick grey vertical
line indicates the time-scale when most of the molecules keep their initial
abundance, of ∼2000 yr.
These reactions included collisional dissociation and association
and reactions with atomic H and O and small radicals such as CH3
and OH (see Appendix B).
The shock structure and chemical evolution results are shown in
Fig. 5. The COMs survive in the gas phase until a time of ∼2000 yr
when they are destroyed by reactions with atomic hydrogen, small
radicals such as OH, and collisional dissociation (corresponding
to a temperature of ∼2000 K for the neutral gas). Thus, the main
effect of the shock is the increase in temperature, which favours
the aforementioned reactions as they have a significant barrier. The
time-scale for destruction for two-body reactions, if the temperature
is high enough, is set by the density. The peak in the sputtering
rate in our model corresponds to only 200–300 K in the neutral
species (gas is mainly neutral), so the gas-phase species do not
get destroyed until the neutral temperature approaches its peak of
about 2000 K. Thus, the time-scale of ∼2000 yr is a combination of
both density and the rise time of the neutral gas temperature postshock.
 The key point of our model is that it shows that COMs can
survive long enough after the passage of a shock. As the temperature
falls in the post-shock regime, several COMs begin to increase in
abundance again, mainly through reactions in the gas phase, except
for CH3OH for which some grain-surface chemistry contributes.
CH3OCH3 does not recover at all because it is solely reliant on
grain-surface reformation. There are two molecules, HCOOCH3
and HNCO, which remain fairly flat with time. This is because their
collisional dissociation rates are significantly slower at the peak of
the gas temperature (by at least an order of magnitude) than those
for the other molecules.
The simple model presented in Section 4.2 shows that COMs
such as the ones detected in IRAS 20126+4104 (e.g. H2
13CO,
HCOOCH3, CH3OCH3) can survive in the gas phase for a sufficient
period following the passage of a C-type shock of about 40 km s−1.
For slower shocks, the peak temperature of the ions and neutrals
gets lower, impeding the destruction of COMs via neutral–neutral
reactions; however, sputtering of the grain mantle is less efficient.
For higher density material, the time-scale of the shock and the
chemistry is shorter, e.g. for a density of 105 cm−3, the COMs
survive in the gas for ∼200 yr.
5 DISCUSSION
In previous sections, we presented subarcsecond angular resolution
images of several COMs associated with IRAS 20126+4104. In almost
 all cases, the morphology of the COMs presents an elongation
towards the south-east, i.e. along the outflow direction. For most of
the COMs (with the exception of CH3COCH3), our XCLASS fits to
the spectra at the disc and outflow positions reveal that the abundance
 at the outflow position is comparable or even larger than the
abundance at the disc. We performed normalized line-to-continuum
ratio maps in order to locate the abundance peak in the surroundings
of IRAS 20126+4104 and found that for H2
13CO and CH3OCH3
the abundance peaks at the position of an H2 knot rather than at the
disc position (Fig. 4).
The fact that CH3OCH3 is among the COMs showing the
strongest abundance enhancement along the outflow direction is
consistent with observations towards other high-mass star-forming
regions. In particular, CH3OCH3 is found in OrionKL further to
the south compared to other COMs (Favre et al. 2011a,b; Peng
et al. 2013), suggesting its association with shocks. Similarly, ¨
Oberg
et al. (2011) report the detection of CH3OCH3 towards the shock
SMM4-W near a low-mass protostar.
This suggests that the mechanism that enhances the emission
from COMs may not be exclusively related to the presence of a
massive protostar, but could also be triggered by the passage of
a shock. The chemical modelling coupled to a parametric shock
model presented in Section 4.2 shows that COMs like CH2CO,
HNCO, HCOOCH3, CH3OCH3 and H213CO can survive in the gas
phase for ∼2000 yr after the passage of a C-type ∼40 km s−1 shock.
If a non-negligible amount of COMs in IRAS 20126+4104 result
from shocks along the outflow, COMs should present relatively
broad linewidths. However, we could fit the spectra at the disc
and outflow positions using line widths of about ∼8 km s−1, for
almost all the molecules (including the outflow tracer SO). This is
suggesting that, at least at these two positions, most of the COMs
are not coming from the high-velocity gas itself but from the warm
cavity walls, or from a post-shock region where the gas has been
already decelerated.
MNRAS 467, 2723–2752 (2017)
Downloaded from https://academic.oup.com/mnras/article/467/3/2723/2877226 by University of Manchester user on 17 February 2023
COMs in IRAS 20126+4104 at ∼600 au
2733
The current models for the formation of COMs consider a dense
and cold phase where simple hydrogenated species are formed on
the surface of dust grains, followed by a warm-up phase where efficient
 recombination of radicals takes place on the grain surfaces
(e.g. Garrod & Herbst 2006; Aikawa et al. 2008; Garrod et al. 2008).
However, these models underpredict the abundance of HCOOCH3
and CH3OCH3 with respect to their parent molecule CH3OH (e.g.
fig. 1 of Taquet et al. 2012). Our observations suggest that additional
ingredients related to shocks should be taken into account by these
models. For example, COMs could be produced through ion–neutral
gas-phase chemistry in the post-shock region for moderate temperatures
 (of ∼100 K, as these are temperatures for which COMs begin
to increase in abundance again following the passage of the shock).
Taquet, Wirstr¨
om & Charnley (2016) re-investigated the formation
of several COMs, such as HCOOCH3 and CH3OCH3, for hot core
conditions and found that ion–neutral chemistry (in which protontransfer
 reactions involving ammonia play a key role) can produce
COMs up to abundances of 10−6. It remains to be investigated this
gas-phase chemistry for shock conditions with lower densities and
shorter time-scales. Another ingredient that might help models recover
 the observed abundances is sputtering of the grain mantles
by the passage of a shock. This is actually supported by the fact
that the weakly bound molecules (e.g. H2CO, HNCO, CH2CO) are
co-spatial with the strongly bound COMs (larger COMs such as
HCOOCH3, CH3OCH3, etc.), pointing to a global mechanism, additional
 to thermal desorption, which is releasing them to the gas
phase.
5.1 Caveats
A possible caveat in our derivation of abundances is that if the density
 were not high enough to thermalize dust and gas in the outflow,
then the dust temperature could be lower than the gas temperature.
In this case, the total H2 column density would have been underestimated
 and the abundances of the molecules would have been
overestimated. Since the density in the outflow cavity should be
lower than in the disc, this should mostly affect the abundances
derived at the outflow position. Palau et al. (2014) estimate the dust
temperature to be ∼80 K at the radius corresponding to the outflow
 position,10 of ∼1000 au. If we recalculate the abundances at
the outflow position assuming such a dust temperature in the estimate
 of the H2 column density, the abundances decrease only by a
factor of 2. Thus, our conclusion that the abundances of COMs at
the outflow position are of the same order, or might be even higher
in some cases, as the abundances at the disc position is robust.
It is also important to keep in mind that in the model presented in
Section 4.2, the assumed pre-shock densities (∼104 cm−3) might be
low given the embedded and massive nature of IRAS 20126+4104.
As explained above, if we used a pre-shock density of ∼105
cm−3, COMs would survive in the gas phase about ∼200 yr. Such
short time-scales for the COM enhancement are consistent with
the time-scales of shocked near-infrared H2 emission, clearly spatially
 associated with the COM enhancement, of <1000 yr (Gusdorf
et al. 2011), which supports the idea that we are seeing a ‘short’
time-dependent phenomenon. Furthermore, this time-scale is of the
10 The estimate of 80 K as the dust temperature at the outflow position
is a first-order approach and probably a lower limit, as this temperature
is inferred from a spherical model that does not consider the presence of
cavities produced by outflows (Palau et al. 2014).
order of the approximated lifetime of water masers tracing the outflow
 at this position (Cesaroni et al. 2013, 2014), as seen also in
other sources (e.g. Burkhardt et al. 2016; Burns et al. 2016), and
is comparable to the time-scale required by models used to explain
 the SiO or CH3CHO emission in shocks (Gusdorf et al. 2011,
Codella et al. 2015). In addition, these short time-scales could also
explain why no COM enhancement is detected in the northern outflow
 cavity. Therefore, the short time-scales required by our model
seem feasible, supporting the idea that the COMs detected along
the outflow in IRAS 20126+4104 have been evaporated from the
dust grains by the shocks associated with the outflow.
We end with the caveat that, despite the large extension to the
high-temperature network described in Appendix B to run the model
presented in Section 4.2, such a network likely remains incomplete
for many gas-phase COMs given the lack of data in the literature.
If our theory is correct, i.e. that gas-phase COMs in intermediateto
 high-mass protostars originate from shock-induced sputtering
instead of the traditional ‘hot core’, then we would urge the gasphase
 laboratory community to revisit high-temperature gas-phase
chemistry with a view to quantifying the chemistry of COMs in postshocked
 gas. Future high angular (∼0.1 arcsec) resolution observations
 (with e.g. ALMA and NOEMA) towards a broad sample of
sources will help further elucidate the origin of COMs in protostars.
6 CONCLUSIONS
We present subarcsecond angular resolution observations carried
out with the PdBI at 220.5 GHz towards IRAS 20126+4104. These
observations reveal for the first time resolved emission from COMs
towards IRAS 20126+4104 with a spatial resolution of ∼600 au.
Our main conclusions are summarized as follows:
(i) We detect and resolve the emission from SO, HNCO, H2
13CO,
CH3CN, CH3OH, HCOOH, HCOOCH3, CH3OCH3, CH3CH2CN
and CH3COCH3. In addition, we detect NH2CN and (CH2OH)2.
(ii) While SO and HNCO present a X-shaped morphology consistent
 with tracing the outflow cavity walls, most of the COMs
have their peak emission at the putative position of the protostar
(the disc), but also show an extension towards the south(east), coinciding
 with an H2 knot from the outflow at about 800–1000 au
from the protostar. This is especially clear for the case of H2
13CO,
HCOOH, HCOOCH3 and CH3OCH3.
(iii) By fitting the observed spectra at two representative positions
 for the disc and the outflow, we found that the abundances
of most COMs are comparable at the two positions. In the case
of H2
13CO and CH3OCH3 the abundance at the outflow position
is larger by a factor of 2–4 than the abundance in the disc. This
suggests a mechanism of enhancing the COM abundances related
to the passage of a shock.
(iv) We explored the possibility that the COMs detected along
the outflow direction are enhanced by the UV-radiation from
IRAS 20126+4104 escaping through the outflow cavity wall. However,
 for Av < 10 mag most species cannot survive the strong radiation
 field in the gas phase.
(v) We coupled a parametric shock model to a large gas–grain
chemical network including COMs, and find that the observed
COMs should survive in the gas phase for ∼2000 yr, comparable
 to the shock lifetime estimated from the water masers at the
outflow position.
Therefore, our data indicate that COMs in IRAS 20126+4104
may arise not only from the disc, but also from dense and hot
regions associated with the outflow.
MNRAS 467, 2723–2752 (2017)
Downloaded from https://academic.oup.com/mnras/article/467/3/2723/2877226 by University of Manchester user on 17 February 2023
2734
A. Palau et al.
ACKNOWLEDGEMENTS
The authors are grateful to the anonymous referee for his/her insightful
 comments that helped improve the clarity and quality of
the paper. AP is grateful to Vianney Taquet, Simon Bruderer and
Ewine van Dishoeck for thoughtful discussions. AP acknowledges
financial support from UNAM-DGAPA-PAPIIT IA102815 grant,
M´
exico. CW acknowledges support from the Netherlands Organization
 for Scientific Research (NWO, program number 639.041.335).
ASM is partially supported by the Collaborative Research Centre
SFB 956, sub-project A6, funded by the Deutsche Forschungsgemeinschaft
 (DFG). IJ-S acknowledges the financial support received
from the STFC through an Ernest Rutherford Fellowship (proposal
number ST/L004801/1). AF thanks the Spanish MINECO for funding
 support from grants FIS2012-32096, AYA2012-32032 and ERC
under ERC-2013-SyG, G. A. 610256 NANOCOSMOS. LAZ is
grateful to CONACyT, M´
exico and DGAPA, UNAM for their financial
 support. The authors acknowledge the efforts of the GILDAS
team to keep this software up to date.
INTRODUCTION
This is the second in a series of papers based on the new catalogue
of symbiotic stars (SySts). In Paper I (Akras et al. 2019), the compilation
 of known (323) and candidate (87) SySts as well as an atlas
of 348 spectral energy distributions (SED) from 1 to 22 μm, using
the Two Micron All Sky Survey (2MASS, Skrutskie et al. 2006)
and the Wide-field Infrared Survey Explorer (WISE, Wright et al.
2010) data are presented. The classification of all known SySts in
the S-D-D
′scheme, based on their SED profiles, is revised. Seventyfour
 per cent are classified as S-type (stellar), 13 per cent as D-type
⋆E-mail: akras@astro.ufrj.br
† CNPq Fellow (PDI-DA 300336/2016-0).
‡ CNPq Fellow (248503/2013-8).
(dusty), 8 per cent as S+IR-type (stellar + infrared excess), and
3.5 per cent as D
′-type.
SySts are ideal astrophysical laboratories for investigating and
studying the formation of aspherical circumstellar envelopes, mass
transfer accretion disks processes, formation of soft and hard-X rays
emission, dust-forming regions, colliding winds among others (e.g.
Jordan et al. 1996; Sokoloski 2003; Totov 2003; Leedj¨
arv 2004;
Mikolajewska 2012; Luna et al. 2013; Skopal & Carikov´
ıa 2015;
Mukai et al. 2016). Besides all these phenomena and processes,
they are also considered as candidates for the progenitors of type Ia
supernova (SN Ia, Munari & Renzini 1992; Han & Podsiadlowski
2004; Di Stefano 2010; Wang et al. 2010; Dilday et al. 2012).
Yet, the numbers of known SySts in the Milky Way (257, Paper I)
and nearby galaxies (66, Paper I) are still far from being consistent
with the expected number derived from population models (e.g.
C
⃝2018 The Author(s)
Published by Oxford University Press on behalf of the Royal Astronomical Society
Downloaded from https://academic.oup.com/mnras/article/483/4/5077/5238730 by guest on 12 January 2024
5078
S. Akras et al.
3 × 105, Munari & Renzini 1992; 4 × 105, Magrini, Corradi &
Munari 2003; 1.2–15 × 103, L¨
u, Yungelson & Han 2006).
Many attempts have been made to discover new members by
developing diagnostic colour–colour diagrams (DCCD) in the optical
 ([O III] 4363/H γ versus [O III] 5007/H β, Gutierrez-Moreno,
Moreno & Cort´
es 1995; various combinations of emission line ratios,
 Ilkiewicz & Mikolajewska 2017; r–H α versus r–i, Corradi
et al. 2008, Corradi et al. 2010; Rodr´
ıguez-Flores et al. 2014),
near-IR (J–H versus H–Ks, Allen & Glass 1974; Phillips 2007;
Corradi et al. 2008; Clyne et al. 2015, I–J versus J–Ks, Schmeja &
Kimeswenger 2001) and mid-IR regime (K-[12] versus [12] –[25],
Luud & Tuvikene 1987; Leedj¨
arv 1992).
The motivation of this work is to find new colour criteria in the
regime of near and mid-IR that will identify SySts using machine
learning algorithms. Recall that SySts display SED peaks in the
wavelength range between ∼1 and ∼25 μm (Ivison et al. 1995,
Paper I). Therefore, the 2MASS/WISE surveys are very helpful
to distinguish SySts from other strong H α emitters (e.g. genuine
planetary nebulae (PNe), Wolf–Rayet stars (WR), Be stars, AeBe
stars, cataclysmic variables (CV), Mira stars, weak and classical T
Tauri stars (WTT,ClTT), young stellar objects (YSO)).
The paper is organized as follows: new 2MASS/AllWISE DCCDs
 are generated and presented in Section 2. The results from a
machine learning approach, classification tree, linear discriminant
analysis (LDA), and K-nearest neighbours (KNN), are presented in
Sections 3 and 4. In Section 5, we apply our classification criteria to
a compilation of candidate SySts. This compilation includes candidates
 from the list of candidates (Paper I), the IPHAS (Drew et al.
2005; Corradi et al. 2008; ) and the VPHAS + (DR2; Drew et al.
2014) surveys. A number of new very likely SySts candidates are
presented. We finish with our conclusions in Section 6.
2 DIAGNOSTIC COLOUR–COLOUR
DIAGRAMS (DCCD)
The 2MASS J–H versus H–Ks DCCD has extensively been used
to study the near-IR properties of SySts, to classify them into Sand
 D-types or to identify new candidates (Allen & Glass 1974;
Rodr´
ıguez-Flores 2006; Phillips 2007; Corradi et al. 2008, Corradi
et al. 2010; Baella, Pereira & Miranda 2013; Clyne et al. 2015;
Baella et al. 2016).
Corradi et al. (2008) propose two specific regions in which the
majority of the S- and D-types are placed. Few years later, these
regions were redefined by Rodr´
ıguez-Flores et al. (2014) being
more restricted. In the J–H versus H–Ks DCCD from Corradi et al.
(2008), one can see that there is a small overlap between the S- and
D-types probably because of some mis-classifications. The same
overlap is not observed in the DCCD from Rodr´
ıguez-Flores et al.
(2014) due to the preliminary selection of SySts from the IPHAS
r–H α versus r–i DCCD and the likely better classification by the
authors (see Fig. 1 in Rodr´
ıguez-Flores et al. 2014).
In Fig. 1, we present the 2MASS J–H versus H–Ks DCCD for
all the known Galactic SySts. For the vast majority of them, the
classification is based on the SED profiles (Paper I), whereas for
those without an SED profile and thus a new classification, the old
one has been considered. Besides SySts, various classes of objects
that show H α emission such as PNe, WR stars, Be, and AeBe stars,
CVs, Mira stars, CTT, and WTT stars as well as post-AGB stars
and single K-M giants are also included.
The sample size of all these classes of object as well as the
